{"./":{"url":"./","title":"MongoDB官方文档中文版","keywords":"","body":"MongoDB 中文手册 | MongoDB 中文文档 | 官方手册中文版翻译 项目介绍 MongoDB 是专为可扩展性，高性能和高可用性而设计的数据库。它可以从单服务器部署扩展到大型、复杂的多数据中心架构。利用内存计算的优势，MongoDB 能够提供高性能的数据读写操作。 MongoDB 的本地复制和自动故障转移功能使您的应用程序具有企业级的可靠性和操作灵活性。 本项目为 MongoDB 中文手册(中文文档),与MongoDB 英文文档保持同步。 项目地址维护地址在线阅读 项目协议 本项目为署名-非商业性使用-相同方式共享 CC BY-NC-SA 4.0请务必遵循如下条件： 署名：必须提到原作者，提供指向此许可协议的链接，表明是否有做修改非商业性使用：不能对本作品进行任何形式的商业性使用相同方式共享：若对本作品进行了修改，必须以相同的许可协议共享 报告问题 在我们的 Github MongoDB-Manual-zh/issues上提 issue. 贡献翻译 请您勇敢地去翻译和改进翻译。虽然我们追求卓越，但我们并不要求您做到十全十美，因此请不要担心因为翻译上犯错——在大部分情况下，我们的服务器已经记录所有的翻译，因此您不必担心会因为您的失误遭到无法挽回的破坏。（改编自维基百科） 翻译贡献者可以参考翻译贡献指南以获取更多帮助。 文档翻译贡献者名单 申请加入 MongoDB 汉化小组 作为贡献者 你享有署名权 MongoDB 中文文档翻译贡献者名单 感谢以下翻译贡献者： Avatar GItHub Email @ys17513628804 shuai.yang@jinmuinfo.com @snomiao snomiao@gmail.com @hbnKing --- @littlemongoing 中文社区领头的 mongoer @aojie654 aojie654@live.cn 文档生成 本文档使用 Docsify 文档生成工具生成。 项目进度 按章节查看完成度 其他 欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远。予人成功才是最大的成功 。 免责声明 锦木信息& MongoDB 中文社区 纯粹出于学习目的与个人兴趣翻译本手册，不追求任何经济利益。 本译文只供学习研究参考之用，不得用于商业用途。我方将保留对此版本译文的署名权及其它相关权利。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"00-The-MongoDB-Manual.html":{"url":"00-The-MongoDB-Manual.html","title":"MongoDB用户手册","keywords":"","body":"MongoDB 用户手册 MONGODB 4.2发布于2019年8月13日 有关MongoDB 4.2中的新功能，请参阅MongoDB 4.2 发行说明。 欢迎使用MongoDB 4.2手册！MongoDB是一个文档数据库，旨在简化开发和扩展。该手册介绍了MongoDB中的关键概念，介绍了查询语言，并提供了操作和管理方面的考虑因素和过程以及全面的参考部分。该手册也以HTML tar.gz和EPUB的形式提供。 MongoDB提供数据库的社区版和企业版： MongoDB社区版是MongoDB的开源和免费版本。 MongoDB企业版作为MongoDB高级企业版订阅的一部分提供，并包括对MongoDB部署的全面支持。MongoDB企业版还添加了以企业为中心的功能，例如LDAP和Kerberos支持，磁盘上的加密以及审计。 MongoDB还提供 Atlas（云中托管的MongoDB企业版服务选项），无需安装开销，并提供免费的入门套餐。 该手册记录了MongoDB社区版和企业版的特性和功能。 入门 MongoDB 在以下版本中提供了“ 入门指南”。 mongo Shell版Node.JS版 Python版C ++版 Java版C＃版 Ruby版 完成《入门指南》后，您可能会发现以下有用的主题。 介绍 开发者 管理员 参考 MongoDB简介安装指南数据库和集合文档资料 CRUD操作聚合SQL到MongoDB索引 生产须知副本集分片集群MongoDB安全 shell方法查询运算符参考词汇表 支持 MongoDB社区 如有疑问，讨论或常规技术支持，请访问 MongoDB社区论坛。MongoDB社区论坛是与其他MongoDB用户联系，提出问题并获得答案的集中场所。 译者注：MongoDB中文社区提供MongoDB中文用户原创博客/文档翻译/技术问答/技术大会/线上活动等板块平台交流服务，访问MongoDB中文社区网站请点击：https://mongoing.com/ 进入技术交流社群请联系小芒果，微信ID：mongoingcom MongoDB Atlas或Cloud 如有技术支持问题，请登录您的MongoDB Cloud帐户并打开工单。 MongoDB Enterprise或Ops Manager 如有技术支持问题，请通过MongoDB支持门户提交工单 。 问题 有关如何为MongoDB服务或相关项目之一提交JIRA工单的说明，请参阅 https://github.com/mongodb/mongo/wiki/Submit-Bug-Reports。 社区 参与MongoDB社区是与其他才华横溢，志趣相投的工程师建立关系，提高对正在从事的有趣工作的认识并提高技能的一种好方法。要了解MongoDB社区，请参阅 参与MongoDB。 译者注：MongoDB中文社区提供MongoDB中文用户原创博客/文档翻译/技术问答/技术大会/线上活动等板块平台交流服务，访问MongoDB中文社区网站请点击：https://mongoing.com/ 进入技术交流社群请联系小芒果，微信ID：mongoingcom 学习 除了文档外，还有许多学习使用MongoDB的方法。您可以： 在MongoDB大学注册免费的在线课程 浏览MongoDB演示文稿的存档 加入本地的MongoDB用户组（MUG） 参加即将举行的MongoDB 活动或 网络研讨会 阅读MongoDB博客 下载架构指南 许可 该手册已根据知识共享署名-非商业性-相同方式共享3.0美国许可证进行了许可 有关MongoDB许可的信息，请参阅MongoDB许可。 其他资源 MongoDB，Inc. MongoDB背后的公司。 MongoDB Atlas 数据库即服务。 MongoDB Cloud Manager 适用于MongoDB的基于云的托管运营管理解决方案。 MongoDB Ops Manager MongoDB的企业运营管理解决方案：包括自动化，备份和监控。 MongoDB生态系统 可用于MongoDB的驱动程序，框架，工具和服务的文档。 原文链接：https://docs.mongodb.com/v4.2/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction.html":{"url":"01-introduction.html","title":"MongoDB简介","keywords":"","body":" MongoDB简介 在本页 文档数据库 主要特性 欢迎使用MongoDB 4.2手册！MongoDB是一个文档数据库，旨在简化开发和扩展。该手册介绍了MongoDB中的关键概念，介绍了查询语言，并提供了操作和管理上的注意事项和过程以及全面的参考章节。 MongoDB提供数据库的社区版和企业版： MongoDB社区版是MongoDB的可用源和免费版本。 MongoDB企业版作为MongoDB高级企业版订阅的一部分提供，并且包括对MongoDB部署的全面支持。MongoDB企业版还添加了以企业为中心的功能，例如LDAP和Kerberos支持，磁盘加密和审核。 文档数据库 MongoDB中的记录是一个文档，它是由字段和值对组成的数据结构。MongoDB文档类似于JSON对象。字段的值可以包括其他文档，数组和文档数组。 使用文档的优点是： 文档（即对象）对应于许多编程语言中的内置数据类型。 嵌入式文档和数组减少了对昂贵连接的需求。 动态模式支持流畅的多态性。 集合/视图/按需实例化视图 MongoDB将文档存储在集合中。集合类似于关系数据库中的表。 除集合外，MongoDB还支持： 只读视图（从MongoDB 3.4开始） 按需实例化视图（从MongoDB 4.2开始）。 主要特性 高性能 MongoDB提供高性能的数据持久化。特别是， 对嵌入式数据模型的支持减少了数据库系统上的I / O操作。 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。 丰富的查询语言 MongoDB支持丰富的查询语言以支持读写操作（CRUD）以及： 数据聚合 文本搜索和地理空间查询。 也可以看看 SQL到MongoDB的映射图 SQL到聚合的映射图 高可用 MongoDB的复制工具（称为副本集）提供： 自动故障转移 数据冗余。 副本集是一组维护相同数据集合的 mongod实例，提供了冗余和提高了数据可用性。 水平拓展 MongoDB提供水平可伸缩性作为其核心 功能的一部分： 分片将数据分布在一个集群的机器上。 从3.4开始，MongoDB支持基于分片键创建数据区域。在平衡群集中，MongoDB仅将区域覆盖的读写定向到区域内的那些分片。有关 更多信息，请参见区域章节。 支持多种存储引擎 MongoDB支持多个存储引擎： WiredTiger存储引擎（包括对静态加密的支持 ） 内存存储引擎。 另外，MongoDB提供可插拔的存储引擎API，允许第三方为MongoDB开发存储引擎。 ← MongoDB手册内容 原文链接：https://docs.mongodb.com/v4.2/introduction/ 译者：小芒果 参见 原文 - Introduction Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/01-getting-started.html":{"url":"01-introduction/01-getting-started.html","title":"入门","keywords":"","body":" 入门 下方页面提供了在MongoDB Shell中进行查询的各种示例。有关使用MongoDB驱动程序的示例，请参阅“ 其他示例”部分中的链接。 示例 在 shell内单击以进行连接。连接后，您可以在上面的 shell中运行示例。 切换数据库 在shell中，db是指您当前的数据库。键入db以显示当前数据库。 复制 db 该操作应返回test，这是默认数据库。 要切换数据库，请键入 use 。例如，要切换到 examples 数据库： 复制 use examples 切换之前您无需创建数据库。当您第一次在数据库中存储数据时（例如在数据库中创建第一个集合），MongoDB会创建数据库。 要验证您的数据库现在是examples，在上面的shell中键入db。 复制 db 要在数据库中创建集合，请参见下一个选项卡。 译者注：填充一个集合（插入）/选择所有文档/指定平等匹配/指定要返回的字段（投影）相关操作请到原文查看和复制代码。 链接：https://docs.mongodb.com/v4.2/tutorial/getting-started/ 下一步 建立自己的部署 要设置自己的部署： MongoDB Atlas免费套餐集群 MongoDB Atlas是一种快速，便捷，免费的MongoDB入门途径。要了解更多信息，请参阅 Atlas入门教程。 本地MongoDB安装 有关在本地安装MongoDB的更多信息，请参阅 安装MongoDB。 其他示例 有关其他示例，包括MongoDB驱动程序特定的示例（Python，Java，Node.js等），请参阅： 查询文档示例 查询文档 查询嵌入/嵌套文档 查询数组 查询嵌入式文档数组 从查询返回的项目字段 查询空字段或缺少字段 更新文档示例 更新文档 删除文档示例 删除文档 其他主题 介绍 开发者 管理员 参考 MongoDB简介 安装指南 数据库和集合 文档资料 CRUD操作 聚合 SQL到MongoDB 索引 生产须知 副本集 分片集群 MongoDB安全 Shell方法 查询运算符 参考 词汇表 原文链接：https://docs.mongodb.com/v4.2/tutorial/getting-started/ 译者：小芒果 参见 原文 - Getting Started Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/02-getting-started.html":{"url":"01-introduction/02-getting-started.html","title":"Create an Atlas Free Tier Cluster","keywords":"","body":" Create an Atlas Free Tier Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Create an Atlas Free Tier Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/03-databases-and-collections.html":{"url":"01-introduction/03-databases-and-collections.html","title":"数据库和集合","keywords":"","body":" 数据库和集合 在本页面 数据库 集合 MongoDB将BSON文档（即数据记录）存储在集合中；数据库中的集合。 数据库 在MongoDB中，文档集合存在数据库中。 要选择使用的数据库，请在mongoshell程序中发出 use 语句，如下方示例： 复制 use myDB 创建数据库 如果数据库不存在，则在您第一次为该数据库存储数据时，MongoDB会创建该数据库。这样，您可以切换到不存在的数据库并在mongoshell中执行以下操作 ： 复制 use myNewDB db.myNewCollection1.insertOne( { x: 1 } ) 该insertOne()操作将同时创建数据库myNewDB和集合myNewCollection1（如果它们尚不存在）。确保数据库名称和集合名称均遵循MongoDB 命名限制。 集合 MongoDB将文档存储在集合中。集合类似于关系数据库中的表。 创建集合 如果不存在集合，则在您第一次为该集合存储数据时，MongoDB会创建该集合。 复制 db.myNewCollection2.insertOne( { x: 1 } ) db.myNewCollection3.createIndex( { y: 1 } ) 如果insertOne()和 createIndex()操作都还不存在，则会创建它们各自的集合。确保集合名称遵循MongoDB 命名限制。 显示创建 MongoDB提供了db.createCollection()使用各种选项显式创建集合的方法，例如设置最大大小或文档验证规则。如果未指定这些选项，则无需显式创建集合，因为在首次存储集合数据时，MongoDB会创建新集合。 要修改这些收集选项，请参见collMod。 文档验证 3.2版中的新功能。 默认情况下，集合不要求其文档具有相同的模式。也就是说，单个集合中的文档不需要具有相同的字段集，并且字段的数据类型可以在集合中的不同文档之间有所不同。 但是，从MongoDB 3.2开始，您可以在更新和插入操作期间对集合强制执行文档验证规则。有关详细信息，请参见模式验证。 修改文档结构 要更改集合中文档的结构，例如添加新字段，删除现有字段或将字段值更改为新类型，请将文档更新为新结构。 唯一标识符 3.6版的新功能。 注意 在featureCompatibilityVersion必须设置为\"3.6\"或更大。有关更多信息，请参见View FeatureCompatibilityVersion。 集合被分配了一个不变的UUID。副本集的所有成员和分片群集中的分片的集合UUID均相同。 要检索集合的UUID，请运行 listCollections命令或db.getCollectionInfos()方法。 原文链接：https://docs.mongodb.com/v4.2/core/databases-and-collections/ 译者：小芒果 参见 原文 - Databases and Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/03-databases-and-collections/01-views.html":{"url":"01-introduction/03-databases-and-collections/01-views.html","title":"视图","keywords":"","body":" 视图 3.4 版本新功能 本页索引 创建视图 表现 删除视图 修改视图 支持操作 从 3.4 开始, MongoDB 添加了基于已存在的集合或者 View (视图) 创建只读的 View 支持. 创建视图 创建或者定义一个视图, MongoDB 3.4 的介绍是: the viewOn and pipelineoptions to the existingcreatecommand (anddb.createCollectionhelper): db.runCommand( { create: , viewOn: , pipeline: } ) or if specifying a defaultcollationfor the view: db.runCommand( { create: , viewOn: , pipeline: , collation: } ) a newmongoshell helperdb.createView(): db.createView(, , , ) 表现 视图具备以下几种表现: 只读 视图是只读的; 通过视图进行写操作会报错. 以下为支持视图的读操作: db.collection.find() db.collection.findOne() db.collection.aggregate() db.collection.count() db.collection.distinct() 索引使用 & 排序操作 视图使用其上游集合的索引. 由于索引是基于集合的, 所以你不能基于视图创建, 删除或重建索引, 也不能获取视图的索引列表. 你不能指定 $natural 排序. 例如, 下列操作是 错误的: db.view.find().sort({$natural: 1}) Project 限制 视图上的 find() 方法不支持如下projection 操作: $ $elemMatch $slice $meta 不能改变名称 你不能重命名视图. 视图创建 视图是在读操邹期间根据需要实时计算的, 同时 MongoDB 基于视图的读操作是底层聚合管道 (aggregation pipeline) 的一部分. 因此, 视图不支持一下操作: db.collection.mapReduce(), $text 操作, 因为 $text 只在聚合的第一阶段有效, geoNear 命令和 $geoNear 管道阶段. 如果用于创建视图的聚合管道屏蔽了 _id 字段, 那么视图中的文档也会没有 _id 字段. 分片视图 如果视图依赖的集合是分片的, 那么视图也视为分片的. 因此, 你不能指定分片视图中 $lookup 的 from字段与 $graphLookup 操作. Views 与 Collation You can specify a default collation for a view at creation time. If no collation is specified, the view’s default collation is the “simple” binary comparison collator. That is, the view does not inherit the collection’s default collation. String comparisons on the view use the view’s default collation. An operation that attempts to change or override a view’s default collation will fail with an error. If creating a view from another view, you cannot specify a collation that differs from the source view’s collation. If performing an aggregation that involves multiple views, such as with $lookup or $graphLookup , the views must have the same collation. 公共视图定义 列出集合的操作, 如 db.getCollectionInfos() 和 db.getCollectionNames(), 的结果中会包括它们的视图. IMPORTANT 视图定义是公开的; 即在视图上的 db.getCollectionInfos() 和 explain 操作将会包括定义视图的管道. 因此, 请避免直接引用视图定义中敏感的字段和值. 删除视图 要删除视图, 请使用视图上的 db.collection.drop() 方法. 修改视图 你可以通过删除或者重建的方式修改视图, 也可以使用 collMod 命令. 支持操作 以下操作支持视图, 除了本文中提到的限制除外: 命令 方法 create db.createCollection() db.createView() collMod db.getCollection() db.getCollectionInfos() db.getCollectionNames() find distinct count db.collection.aggregate() db.collection.find() db.collection.findOne() db.collection.count() db.collection.distinct() 原文链接：https://docs.mongodb.com/v4.2/core/views/ 译者 ：王恒 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/03-databases-and-collections/02-materialized-views.html":{"url":"01-introduction/03-databases-and-collections/02-materialized-views.html","title":"On-Demand Materialized Views","keywords":"","body":" On-Demand Materialized Views ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - On-Demand Materialized Views Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/03-databases-and-collections/03-capped-collections.html":{"url":"01-introduction/03-databases-and-collections/03-capped-collections.html","title":"封顶集合","keywords":"","body":" 封顶集合 本文索引 概述 表现 限制与推荐 使用 概述 封顶集合 capped collection 是固定大小的集合, 支持高吞吐的插入操作和根据插入顺序的查询操作. 封顶集合的工作方式与循环缓冲区 (circular buffers) 类似: 当一个集合填满了被分配的空间, 则通过覆盖最早的文档来为新的文档腾出空间. 参阅 createCollection() 或 create 获取更多创建封顶集合的信息. 表现 顺序插入 封顶集合保证了插入的顺序. 因此, 历史查询不需要索引排序. 没有这种索引开销, 封顶集合可以支持更高的插入吞吐量. 自动删除最早的文档 为了给新的文档腾出空间, 封顶集合会自动删除集合中最早的文档, 不需要定时脚本或者显示的删除操作. 例如, 在 oplog.rs 集合中存储了 replica set 的操作的日志, 该集合就使用的是封顶集合. 除此之外, 还可以考虑以下潜在的用例: 存储由高容量 (high-volume) 系统生成的日志信息. 在封顶集合中不用索引插入文档的速度接近直接输出日志到文件系统. 而且, 内置的 先进先出 的属性维护了事件的顺序, 这在管理存储时用得到 (译注: 有些日志存储系统的顺序可能会乱, 如 Elasticsearch). 在封顶集合中记性数据缓存 (少量的). 由于缓存是高频读很少写, 因此你需要确保集合 始终 保留在工作区间 (即 RAM 中) 或者 接受一些使用索引带来的写入的成本 (or accept some write penalty for the required index or indexes ). _id 索引 封顶集合有 _id 字段并且有一个基于 _id 字段的默认索引. 限制与推荐 更新 如果您计划更新封顶集合中的文档, 请创建一个索引, 来避免更新操进行集合扫描. 文档大小 在 3.2 版本中修改. 更新或替换文档大小的操作会失败. (注: 之前的 MMAPv1 可以修改) 文档删除 你不能删除封顶集合中的文档. 要删除集合中的所有文档, 请使用 drop() 方法删除集合, 并重新创建封顶的集合. 分片 你不能对封顶集合进行分片操作. 查询效率 使用自然顺序 (natural ordering) 来有效地检索集合最近插入的元素. 这 (有点) 类似 tail 一个日志文件 (查看他的尾部). 聚合 $out 聚合管道操作符 $out不能将结果写入封顶集合. 使用 创建封顶集合 When creating a capped collection you must specify the maximum size of the collection in bytes, which MongoDB will pre-allocate for the collection. The size of the capped collection includes a small amount of space for internal overhead. 您必须使用 db.createCollection() 方法显式地创建封顶集合, 该过程可以通过 mongo shell 来帮忙执行 create 命令. 在创建封顶集合时, 您必须预先指定集合的最大容量 (以字节为单位). 其中包括少量的内部空间. db.createCollection( \"log\", { capped: true, size: 100000 } ) 如果 size 字段小于或等于 4096, 则该集合将具有 4096 字节的容量. 此外, MongoDB 会提升用户所提供给的 size 大小直到其满足 256 的倍数为止. Additionally, you may also specify a maximum number of documents for the collection using themaxfield as in the following document: db.createCollection(\"log\", { capped : true, size : 5242880, max : 5000 } ) IMPORTANT Thesizeargument is_always_required, even when you specifymaxnumber of documents. MongoDB will remove older documents if a collection reaches the maximum size limit before it reaches the maximum document count. SEE db.createCollection()andcreate. 封顶集合查询 If you perform afind()on a capped collection with no ordering specified, MongoDB guarantees that the ordering of results is the same as the insertion order. To retrieve documents in reverse insertion order, issuefind()along with thesort()method with the$naturalparameter set to-1, as shown in the following example: db.cappedCollection.find().sort( { $natural: -1 } ) 检查集合是否封顶 Use theisCapped()method to determine if a collection is capped, as follows: db.collection.isCapped() 集合转换为固定大小集合 You can convert a non-capped collection to a capped collection with theconvertToCappedcommand: db.runCommand({\"convertToCapped\": \"mycoll\", size: 100000}); Thesizeparameter specifies the size of the capped collection in bytes. WARNING This command obtains a global write lock and will block other operations until it has completed. Automatically Remove Data After a Specified Period of Time As an alternative to 封顶集合, consider MongoDB’sTTL(“time to live”) indexes. As described inExpire Data from Collections by Setting TTL, these indexes allow you to expire and remove data from normal collections based on the value of a date-typed field and a TTL value for the index. IMPORTANT TTL indexesare not compatible with 封顶集合. Tailable Cursor You can use atailable cursorwith 封顶集合. Similar to the Unixtail-fcommand, the tailable cursor “tails” the end of a capped collection. As new documents are inserted into the capped collection, you can use the tailable cursor to continue retrieving documents. SeeTailable Cursorsfor information on creating a tailable cursor. 原文链接：https://docs.mongodb.com/v4.2/core/capped-collections/ 参见 原文 - Capped Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/04-document.html":{"url":"01-introduction/04-document.html","title":"文档","keywords":"","body":" 文档 在本页面 文档结构 点符号 文档限制 文档结构的其他用途 更多阅读 MongoDB将数据记录存储为BSON文档。BSON是JSON文档的二进制表示形式，尽管它包含比JSON更多的数据类型。有关BSON规范，请参见bsonspec.org。另请参阅BSON类型。 文档结构 MongoDB文档由字段和值对组成，并具有以下结构： 复制 { field1: value1, field2: value2, field3: value3, ... fieldN: valueN } 字段的值可以是任何BSON 数据类型，包括其他文档，数组和文档数组。例如，以下文档包含各种类型的值： 复制 var mydoc = { _id: ObjectId(\"5099803df3f4948bd2f98391\"), name: { first: \"Alan\", last: \"Turing\" }, birth: new Date('Jun 23, 1912'), death: new Date('Jun 07, 1954'), contribs: [ \"Turing machine\", \"Turing test\", \"Turingery\" ], views : NumberLong(1250000) } 上面的字段具有以下数据类型： _id拥有一个ObjectId。 name包含一个包含字段first和last的嵌入式文档。 birth和death保留Date类型的值。 contribs拥有字符串数组。 views拥有NumberLong类型的值。 字段名称 字段名称是字符串。 文档对字段名称有以下限制： 字段名称_id保留用作主键；它的值在集合中必须是唯一的，不可变的，并且可以是数组以外的任何类型。 字段名称不能包含null字符。 顶级字段名称不能以美元符号（$）字符开头。 否则，从MongoDB 3.6开始，服务器允许存储包含点（即.）和美元符号（即 $）的字段名称。 重要 MongoDB查询语言不能总是有效地表达对字段名称包含这些字符的文档的查询（请参阅SERVER-30575）。 在查询语句中添加支持之前，不推荐在字段名称中使用$和 .，官方MongoDB的驱动程序不支持。 BSON文档可能有多个具有相同名称的字段。但是，大多数MongoDB接口都使用不支持重复字段名称的结构（例如，哈希表）来表示MongoDB。如果需要处理具有多个同名字段的文档，请参见驱动程序文档。 内部MongoDB流程创建的某些文档可能具有重复的字段，但是任何 MongoDB流程都不会向现有的用户文档添加重复的字段。 字段值限制 MongoDB 2.6至MongoDB版本，并将featureCompatibilityVersion（fCV）设置为\"4.0\"或更早版本 对于索引集合，索引字段的值有一个最大索引键长度限制。有关详细信息，请参见Maximum Index Key Length。 点符号 MongoDB使用点符号访问数组的元素并访问嵌入式文档的字段。 数组 要通过从零开始的索引位置指定或访问数组的元素，请将数组名称与点（.）和从零开始的索引位置连接起来，并用引号引起来： 复制 \".\" 例如，给定文档中的以下字段： 复制 { ... contribs: [ \"Turing machine\", \"Turing test\", \"Turingery\" ], ... } 要指定contribs数组中的第三个元素，请使用点符号\"contribs.2\"。 有关查询数组的示例，请参见： 查询数组 查询嵌入式文档数组 也可以看看 $[\\]用于更新操作的所有位置运算符， $[/] 过滤后的位置运算符，用于更新操作， $ 用于更新操作的位置运算符， $ 数组索引位置未知时的投影运算符 在数组中查询带数组的点符号示例。 嵌入式文档 要使用点符号指定或访问嵌入式文档的字段，请将嵌入式文档名称与点（.）和字段名称连接在一起，并用引号引起来： 复制 \".\" 例如，给定文档中的以下字段： 复制 { ... name: { first: \"Alan\", last: \"Turing\" }, contact: { phone: { type: \"cell\", number: \"111-222-3333\" } }, ... } 要指定在字段中命名last的name字段，请使用点符号\"name.last\"。 要在字段number中的phone文档中 指定contact，请使用点号\"contact.phone.number\"。 有关查询嵌入式文档的示例，请参见： 查询嵌入/嵌套文档 查询嵌入式文档数组 文件限制¶ 文档具有以下属性： 文档大小限制 BSON文档的最大大小为16 MB。 最大文档大小有助于确保单个文档不会使用过多的RAM或在传输过程中占用过多的带宽。要存储大于最大大小的文档，MongoDB提供了GridFS API。有关GridFS的更多信息，请参见mongofiles和驱动程序的文档。 文档字段顺序 除以下情况外，MongoDB会在执行写操作后保留文档字段的顺序： 该_id字段始终是文档中的第一个字段。 包含renaming字段名称的更新可能会导致文档中字段的重新排序。 _id字段 在MongoDB中，存储在集合中的每个文档都需要一个唯一的 _id字段作为主键。如果插入的文档省略了该_id字段，则MongoDB驱动程序会自动为该_id字段生成一个ObjectId。 这也适用于通过使用upsert：true更新操作插入的文档。 该_id字段具有以下行为和约束： 默认情况下，MongoDB 在创建集合期间会在_id字段上创建唯一索引。 该_id字段始终是文档中的第一个字段。如果服务器首先接收到没有该_id字段的文档，则服务器会将字段移到开头。 该_id字段可以包含除数组之外的任何BSON数据类型的值。 警告 为确保复制正常进行，请勿在_id 字段中存储BSON正则表达式类型的值。 以下是用于存储值的常用选项_id： 使用一个ObjectId。 使用自然的唯一标识符（如果有）。这样可以节省空间并避免附加索引。 生成一个自动递增的数字。 在您的应用程序代码中生成一个UUID。为了在集合和_id 索引中更有效地存储UUID值，请将UUID存储为BSON BinData类型的值。 在以下情况下，BinData更有效地将类型为索引的键存储在索引中： 二进制子类型的值在0-7或128-135的范围内，并且 字节数组的长度为：0、1、2、3、4、5、6、7、8、10、12、14、16、20、24或32。 使用驱动程序的BSON UUID工具生成UUID。请注意，驱动程序实现可能会以不同的方式实现UUID序列化和反序列化逻辑，这可能与其他驱动程序不完全兼容。有关UUID互操作性的信息，请参阅驱动程序文档。 注意 大多数MongoDB驱动程序客户端将包括该_id字段，并ObjectId在将插入操作发送到MongoDB之前生成一个；但是，如果客户发送的文档中没有_id 字段，则mongod会添加该_id字段并生成ObjectId。 文档结构的其他用途 除了定义数据记录外，MongoDB还在整个文档结构中使用，包括但不限于：查询过滤器，更新规范文档和索引规范文档。 查询过滤器文档 查询过滤器文档指定确定用于选择哪些记录以进行读取，更新和删除操作的条件。 您可以使用 : 表达式指定相等条件和查询运算符 表达式。 复制 { : , : { : }, ... } 有关示例，请参见： 查询文档 查询嵌入/嵌套文档 查询数组 查询嵌入式文档数组 更新规范文档 更新规范文档使用更新运算符来指定要在db.collection.update()操作期间在特定字段上执行的数据修改。 复制 { : { : , ... }, : { : , ... }, ... } 有关示例，请参阅更新规范。 索引规范文档 索引规范文档定义了要索引的字段和索引类型： 复制 { : , : , ... } 进一步阅读 有关MongoDB文档模型的更多信息，请下载 MongoDB应用程序现代化指南。 下载内容包括以下资源： 演示使用MongoDB进行数据建模的方法 白皮书涵盖了从RDBMS数据模型迁移到MongoDB的最佳实践和注意事项 参考MongoDB模式及其等效RDBMS 应用程序现代化记分卡 原文链接：https://docs.mongodb.com/v4.2/core/document/ 译者：小芒果 参见 原文 - Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/05-bson-types.html":{"url":"01-introduction/05-bson-types.html","title":"BSON类型","keywords":"","body":" BSON类型 在本页面 对象Id ObjectId 字符串 String 时间戳 Timestamps 日期 Date BSON是一种二进制序列化格式，用于在MongoDB中存储文档和进行远程过程调用。BSON规范位于 bsonspec.org。 每种BSON类型都具有整数和字符串标识符，如下表所示： 类型 Type 对应数字 Number 别名 Alias 备注 Notes 双精度浮点型Double 1 “double” 字符串String 2 “string” 对象Object 3 “object” 数组Array 4 “array” 二进制数据Binary data 5 “binData” 未定义Undefined 6 “undefined” 不推荐使用。 对象编号ObjectId 7 “objectId” 布尔型Boolean 8 “bool” 日期Date 9 “date” 空值Null 10 “null” 正则表达式Regular Expression 11 “regex” DBPointer 12 “dbPointer” 不推荐使用。 JavaScript 13 “javascript” Symbol 14 “symbol” 不推荐使用。 JavaScript (带范围) 15 “javascriptWithScope” 32位整数 32-bit integer 16 “int” 时间戳 Timestamp 17 “timestamp” 64位整数 64-bit integer 18 “long” 小数128 Decimal128 19 “decimal” 3.4版的新功能。 最小键 Min key -1 “minKey” 最大键 Max key 127 “maxKey” 您可以将这些值与$type运算符一起使用，以按其BSON类型查询文档。所述$type聚合操作者返回的类型操作者表达使用列出的BSON类型字符串之一。 要确定字段的类型，请参阅mongo Shell中的Check Types。 如果将BSON转换为JSON，请参阅扩展JSON参考。 以下各节描述了特定BSON类型的特殊注意事项。 ObjectId ObjectId很小，可能唯一，可以快速生成并排序。ObjectId值的长度为12个字节，包括： 一个4字节的时间戳记值，代表自Unix时代以来以秒为单位的ObjectId的创建 5字节随机值 3字节递增计数器，初始化为随机值 虽然BSON格式本身是低位优先的，但时间戳和 计数器值却是高位优先的，最高有效字节在字节序列中排在最前面。 在MongoDB中，存储在集合中的每个文档都需要一个唯一的 _id字段作为主键。如果插入的文档省略了该_id字段，则MongoDB驱动程序会自动为该字段生成一个ObjectId_id。 这也适用于通过upsert：true通过更新操作插入的文档。 MongoDB客户端应添加一个_id具有唯一ObjectId 的字段。在该_id字段中使用ObjectIds 还可以带来以下好处： 在mongoshell中，您可以使用ObjectId.getTimestamp()方法访问ObjectId的创建时间。 在存储ObjectId值的_id字段上按大致相当于创建时间进行排序。 重要 尽管ObjectId值应随时间增加，但不一定是单调的。这是因为他们： 仅包含一秒的时间分辨率，因此 在同一秒内创建的ObjectId值没有保证的顺序，并且 由客户端生成，客户端可能具有不同的系统时钟。 也可以看看 ObjectId() 字符串 BSON字符串为UTF-8。通常，在对BSON进行序列化和反序列化时，每种编程语言的驱动程序都会从该语言的字符串格式转换为UTF-8。这样就可以轻松地将大多数国际字符存储在BSON字符串中。 [1]此外，MongoDB $regex查询在正则表达式字符串中支持UTF-8。 [1] 给定使用UTF-8字符集的sort()字符串，在字符串上使用将是合理正确的。但是，由于内部 sort()使用C ++ strcmpAPI，因此排序顺序可能会错误地处理某些字符。 时间戳 BSON有一个特殊的时间戳类型给MongoDB内部 使用，而非常规相关的日期 类型。此内部时间戳记类型是64位值，其中： 最重要的32位是一个time_t值（自Unix时代以来的秒数） 最低有效32位是ordinal给定秒内的操作增量。 虽然BSON格式是低位优先的，因此首先存储了最低有效位，但是无论字节序如何，在所有平台上mongod实例始终将time_t值与ordinal值比较。 在单个mongod实例中，时间戳记值始终是唯一的。 在复制中，操作日志具有一个ts字段。该字段中的值反映了使用BSON时间戳值的操作时间。 注意 BSON时间戳类型供MongoDB内部 使用。在大多数情况下，在应用程序开发中，您将需要使用BSON日期类型。有关更多信息，请参见日期。 当插入包含带有空时间戳值的顶级字段的文档时，MongoDB会将空时间戳值替换为当前时间戳值，但以下情况除外。如果_id 字段本身包含空的时间戳记值，则将始终按原样插入而不替换它。 示例 插入带有空时间戳值的文档： 复制 db.test.insertOne( { ts: new Timestamp() } ); 运行db.test.find() 然后将返回类似于以下内容的文档： { \"_id\" : ObjectId(\"542c2b97bac0595474108b48\"), \"ts\" : Timestamp(1412180887, 1) } 服务器已使用插入时的时间戳值替换了ts的空时间戳值。 日期 Date BSON Date是一个64位整数，代表自Unix纪元（1970年1月1日）以来的毫秒数。这导致可以追溯到过去和未来约2.9亿年的日期范围。 该官方BSON规范 指的是BSON Date类型为UTC日期时间。 BSON日期类型是有符号整数。[2]负值表示1970年之前的日期。 示例 在 mongo shell中使用构造函数 new Date() 构造一个Date ： 复制 var mydate1 = new Date() 示例 在 mongo shell中使用构造函数ISODate()构造一个Date ： 复制 var mydate2 = ISODate() 示例 以字符串形式返回Date值： 复制 mydate1.toString() 示例 返回日期值的月份部分；月是零索引，因此一月是0月： 复制 mydate1.getMonth() [2] 在2.0版之前，Date值被错误地解释为无符号整数，这会影响排序，范围查询和Date字段索引。由于升级时不会重新创建索引，因此，如果您早期版本使用Date值创建了索引，请对与应用相关的、1970年前的日期进行重新索引。 原文链接：https://docs.mongodb.com/v4.2/reference/bson-types/ 译者：小芒果 参见 原文 - BSON Types Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/05-bson-types/01-bson-type-comparison-order.html":{"url":"01-introduction/05-bson-types/01-bson-type-comparison-order.html","title":"Comparison/Sort Order","keywords":"","body":" Comparison/Sort Order On this page Numeric Types Strings Arrays Dates and Timestamps Non-existent Fields BinData When comparing values of differentBSON types, MongoDB uses the following comparison order, from lowest to highest: MinKey (internal type) Null Numbers (ints, longs, doubles, decimals) Symbol, String Object Array BinData ObjectId Boolean Date Timestamp Regular Expression MaxKey (internal type) Numeric Types MongoDB treats some types as equivalent for comparison purposes. For instance, numeric types undergo conversion before comparison. Strings Binary Comparison By default, MongoDB uses the simple binary comparison to compare strings. Collation New in version 3.4. Collationallows users to specify language-specific rules for string comparison, such as rules for lettercase and accent marks. Collation specification has the following syntax: { locale : , caseLevel : , caseFirst : , strength : , numericOrdering : , alternate : , maxVariable : , backwards : } When specifying collation, thelocalefield is mandatory; all other collation fields are optional. For descriptions of the fields, seeCollation Document. If no collation is specified for the collection or for the operations, MongoDB uses the simple binary comparison used in prior versions for string comparisons. Arrays With arrays, a less-than comparison or an ascending sort compares the smallest element of arrays, and a greater-than comparison or a descending sort compares the largest element of the arrays. As such, when comparing a field whose value is a single-element array (e.g.[1]) with non-array fields (e.g.2), the comparison is between1and2. A comparison of an empty array (e.g.[]) treats the empty array as less thannullor a missing field. Dates and Timestamps Changed in version 3.0.0:Date objects sort before Timestamp objects. Previously Date and Timestamp objects sorted together. Non-existent Fields The comparison treats a non-existent field as it would an empty BSON Object. As such, a sort on theafield in documents{}and{a:null}would treat the documents as equivalent in sort order. BinData MongoDB sortsBinDatain the following order: First, the length or size of the data. Then, by the BSON one-byte subtype. Finally, by the data, performing a byte-by-byte comparison. Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/05-bson-types/02-mongodb-extended-json.html":{"url":"01-introduction/05-bson-types/02-mongodb-extended-json.html","title":"MongoDB Extended JSON","keywords":"","body":" MongoDB Extended JSON On this page Parsers and Supported Format BSON Data Types and Associated Representations JSONcan only represent a subset of the types supported byBSON. To preserve type information, MongoDB adds the following extensions to the JSON format: Strict mode . Strict mode representations of BSON types conform to the JSON RFC . Any JSON parser can parse these strict mode representations as key/value pairs; however, only the MongoDB internal JSON parser recognizes the type information conveyed by the format. mongo Shell mode . The MongoDB internal JSON parser and the mongo shell can parse this mode. The representation used for the various data types depends on the context in which the JSON is parsed. Parsers and Supported Format Input in Strict Mode The following can parse representations in strict mode_with_recognition of the type information. REST Interfaces mongoimport --query option of various MongoDB tools MongoDB Compass Other JSON parsers, includingmongoshell anddb.eval(), can parse strict mode representations as key/value pairs, but_without_recognition of the type information. Input inmongoShell Mode The following can parse representations inmongoshell mode_with_recognition of the type information. REST Interfaces mongoimport --query option of various MongoDB tools mongo shell Output in Strict mode mongoexportandREST and HTTP Interfacesoutput data inStrict mode. Output inmongoShell Mode bsondumpoutputs inmongoShell mode. BSON Data Types and Associated Representations The following presents the BSON data types and the associated representations inStrict mode_andmongo_Shell mode. Binary data_binary Strict Mode mongo Shell Mode { \"$binary\": \"\", \"$type\": \"\" } BinData ( , ) is the base64 representation of a binary string. is a representation of a single byte indicating the data type. In Strict mode it is a hexadecimal string, and in Shell mode it is an integer. See the extended bson documentation. http://bsonspec.org/spec.html Date data_date Strict Mode mongo Shell Mode { \"$date\": \"\" } new Date ( ) InStrict mode,is an ISO-8601 date format with a mandatory time zone field following the templateYYYY-MM-DDTHH:mm:ss.mmm. The MongoDB JSON parser currently does not support loading ISO-8601 strings representing dates prior to theUnix epoch. When formatting pre-epoch dates and dates past what your system’stime_ttype can hold, the following format is used: { \"$date\" : { \"$numberLong\" : \" \" } } InShell mode,is the JSON representation of a 64-bit signed integer giving the number of milliseconds since epoch UTC. Timestamp data_timestamp Strict Mode mongo Shell Mode { \"$timestamp\": { \"t\": , \"i\": } } Timestamp( , ) t > is the JSON representation of a 32-bit unsigned integer for seconds since epoch. i > is a 32-bit unsigned integer for the increment. Regular Expression data_regex Strict Mode mongo Shell Mode { \"$regex\": \"\", \"$options\": \"\" } // sRegex > is a string of valid JSON characters. jRegex > is a string that may contain valid JSON characters and unescaped double quote ( \" ) characters, but may not contain unescaped forward slash ( / ) characters. sOptions > is a string containing the regex options represented by the letters of the alphabet. jOptions > is a string that may contain only the characters ‘g’, ‘i’, ‘m’ and ‘s’ (added in v1.9). Because the JavaScript and mongo Shell representations support a limited range of options, any nonconforming options will be dropped when converting to this representation. OID data_oid Strict Mode mongo Shell Mode { \"$oid\": \"\" } ObjectId( \"\" ) is a 24-character hexadecimal string. DB Reference data_ref Strict Mode mongo Shell Mode { \"$ref\": \"\", \"$id\": \"\" } DBRef(\"\", \"\") name > is a string of valid JSON characters. id > is any valid extended JSON type. Undefined Type data_undefined Strict Mode mongo Shell Mode { \"$undefined\": true } undefined The representation for the JavaScript/BSON undefined type. You_cannot_useundefinedin query documents. Consider the following document inserted into thepeoplecollection: db.people.insert( { name : \"Sally\", age : undefined } ) The following queries return an error: db.people.find( { age : undefined } ) db.people.find( { age : { $gte : undefined } } ) However, you can query for undefined values using$type, as in: db.people.find( { age : { $type : 6 } } ) This query returns all documents for which theagefield has valueundefined. MinKey data_minkey Strict Mode mongo Shell Mode { \"$minKey\": 1 } MinKey The representation of the MinKey BSON data type that compares lower than all other types. SeeComparison/Sort Orderfor more information on comparison order for BSON types. MaxKey data_maxkey Strict Mode mongo Shell Mode { \"$maxKey\": 1 } MaxKey The representation of the MaxKey BSON data type that compares higher than all other types. SeeComparison/Sort Orderfor more information on comparison order for BSON types. NumberLong New in version 2.6. data_numberlong Strict Mode mongo Shell Mode { \"$numberLong\": \"\" } NumberLong( \"\" ) NumberLongis a 64 bit signed integer. You must include quotation marks or it will be interpreted as a floating point number, resulting in a loss of accuracy. For example, the following commands insert9223372036854775807as aNumberLongwith and without quotation marks around the integer value: db.json.insert( { longQuoted : NumberLong(\"9223372036854775807\") } ) db.json.insert( { longUnQuoted : NumberLong(9223372036854775807) } ) When you retrieve the documents, the value oflongUnQuotedhas changed, whilelongQuotedretains its accuracy: db.json.find() { \"_id\" : ObjectId(\"54ee1f2d33335326d70987df\"), \"longQuoted\" : NumberLong(\"9223372036854775807\") } { \"_id\" : ObjectId(\"54ee1f7433335326d70987e0\"), \"longUnQuoted\" : NumberLong(\"-9223372036854775808\") } NumberDecimal New in version 3.4. data_numberdecimal Strict Mode mongo Shell Mode { \"$numberDecimal\": \"\" } NumberDecimal( \"\" ) NumberDecimalis ahigh-precision decimal. You must include quotation marks, or the input number will be treated as a double, resulting in data loss. For example, the following commands insert123.40as aNumberDecimalwith and without quotation marks around the value: db.json.insert( { decimalQuoted : NumberDecimal(\"123.40\") } ) db.json.insert( { decimalUnQuoted : NumberDecimal(123.40) } ) When you retrieve the documents, the value ofdecimalUnQuotedhas changed, whiledecimalQuotedretains its specified precision: db.json.find() { \"_id\" : ObjectId(\"596f88b7b613bb04f80a1ea9\"), \"decimalQuoted\" : NumberDecimal(\"123.40\") } { \"_id\" : ObjectId(\"596f88c9b613bb04f80a1eaa\"), \"decimalUnQuoted\" : NumberDecimal(\"123.400000000000\") } 参见 原文 - MongoDB Extended JSON (v2) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/05-bson-types/03-mongodb-extended-json-v1.html":{"url":"01-introduction/05-bson-types/03-mongodb-extended-json-v1.html","title":"MongoDB Extended JSON","keywords":"","body":" MongoDB Extended JSON On this page Parsers and Supported Format BSON Data Types and Associated Representations JSONcan only represent a subset of the types supported byBSON. To preserve type information, MongoDB adds the following extensions to the JSON format: Strict mode . Strict mode representations of BSON types conform to the JSON RFC . Any JSON parser can parse these strict mode representations as key/value pairs; however, only the MongoDB internal JSON parser recognizes the type information conveyed by the format. mongo Shell mode . The MongoDB internal JSON parser and the mongo shell can parse this mode. The representation used for the various data types depends on the context in which the JSON is parsed. Parsers and Supported Format Input in Strict Mode The following can parse representations in strict mode_with_recognition of the type information. REST Interfaces mongoimport --query option of various MongoDB tools MongoDB Compass Other JSON parsers, includingmongoshell anddb.eval(), can parse strict mode representations as key/value pairs, but_without_recognition of the type information. Input inmongoShell Mode The following can parse representations inmongoshell mode_with_recognition of the type information. REST Interfaces mongoimport --query option of various MongoDB tools mongo shell Output in Strict mode mongoexportandREST and HTTP Interfacesoutput data inStrict mode. Output inmongoShell Mode bsondumpoutputs inmongoShell mode. BSON Data Types and Associated Representations The following presents the BSON data types and the associated representations inStrict mode_andmongo_Shell mode. Binary data_binary Strict Mode mongo Shell Mode { \"$binary\": \"\", \"$type\": \"\" } BinData ( , ) is the base64 representation of a binary string. is a representation of a single byte indicating the data type. In Strict mode it is a hexadecimal string, and in Shell mode it is an integer. See the extended bson documentation. http://bsonspec.org/spec.html Date data_date Strict Mode mongo Shell Mode { \"$date\": \"\" } new Date ( ) InStrict mode,is an ISO-8601 date format with a mandatory time zone field following the templateYYYY-MM-DDTHH:mm:ss.mmm. The MongoDB JSON parser currently does not support loading ISO-8601 strings representing dates prior to theUnix epoch. When formatting pre-epoch dates and dates past what your system’stime_ttype can hold, the following format is used: { \"$date\" : { \"$numberLong\" : \" \" } } InShell mode,is the JSON representation of a 64-bit signed integer giving the number of milliseconds since epoch UTC. Timestamp data_timestamp Strict Mode mongo Shell Mode { \"$timestamp\": { \"t\": , \"i\": } } Timestamp( , ) t > is the JSON representation of a 32-bit unsigned integer for seconds since epoch. i > is a 32-bit unsigned integer for the increment. Regular Expression data_regex Strict Mode mongo Shell Mode { \"$regex\": \"\", \"$options\": \"\" } // sRegex > is a string of valid JSON characters. jRegex > is a string that may contain valid JSON characters and unescaped double quote ( \" ) characters, but may not contain unescaped forward slash ( / ) characters. sOptions > is a string containing the regex options represented by the letters of the alphabet. jOptions > is a string that may contain only the characters ‘g’, ‘i’, ‘m’ and ‘s’ (added in v1.9). Because the JavaScript and mongo Shell representations support a limited range of options, any nonconforming options will be dropped when converting to this representation. OID data_oid Strict Mode mongo Shell Mode { \"$oid\": \"\" } ObjectId( \"\" ) is a 24-character hexadecimal string. DB Reference data_ref Strict Mode mongo Shell Mode { \"$ref\": \"\", \"$id\": \"\" } DBRef(\"\", \"\") name > is a string of valid JSON characters. id > is any valid extended JSON type. Undefined Type data_undefined Strict Mode mongo Shell Mode { \"$undefined\": true } undefined The representation for the JavaScript/BSON undefined type. You_cannot_useundefinedin query documents. Consider the following document inserted into thepeoplecollection: db.people.insert( { name : \"Sally\", age : undefined } ) The following queries return an error: db.people.find( { age : undefined } ) db.people.find( { age : { $gte : undefined } } ) However, you can query for undefined values using$type, as in: db.people.find( { age : { $type : 6 } } ) This query returns all documents for which theagefield has valueundefined. MinKey data_minkey Strict Mode mongo Shell Mode { \"$minKey\": 1 } MinKey The representation of the MinKey BSON data type that compares lower than all other types. SeeComparison/Sort Orderfor more information on comparison order for BSON types. MaxKey data_maxkey Strict Mode mongo Shell Mode { \"$maxKey\": 1 } MaxKey The representation of the MaxKey BSON data type that compares higher than all other types. SeeComparison/Sort Orderfor more information on comparison order for BSON types. NumberLong New in version 2.6. data_numberlong Strict Mode mongo Shell Mode { \"$numberLong\": \"\" } NumberLong( \"\" ) NumberLongis a 64 bit signed integer. You must include quotation marks or it will be interpreted as a floating point number, resulting in a loss of accuracy. For example, the following commands insert9223372036854775807as aNumberLongwith and without quotation marks around the integer value: db.json.insert( { longQuoted : NumberLong(\"9223372036854775807\") } ) db.json.insert( { longUnQuoted : NumberLong(9223372036854775807) } ) When you retrieve the documents, the value oflongUnQuotedhas changed, whilelongQuotedretains its accuracy: db.json.find() { \"_id\" : ObjectId(\"54ee1f2d33335326d70987df\"), \"longQuoted\" : NumberLong(\"9223372036854775807\") } { \"_id\" : ObjectId(\"54ee1f7433335326d70987e0\"), \"longUnQuoted\" : NumberLong(\"-9223372036854775808\") } NumberDecimal New in version 3.4. data_numberdecimal Strict Mode mongo Shell Mode { \"$numberDecimal\": \"\" } NumberDecimal( \"\" ) NumberDecimalis ahigh-precision decimal. You must include quotation marks, or the input number will be treated as a double, resulting in data loss. For example, the following commands insert123.40as aNumberDecimalwith and without quotation marks around the value: db.json.insert( { decimalQuoted : NumberDecimal(\"123.40\") } ) db.json.insert( { decimalUnQuoted : NumberDecimal(123.40) } ) When you retrieve the documents, the value ofdecimalUnQuotedhas changed, whiledecimalQuotedretains its specified precision: db.json.find() { \"_id\" : ObjectId(\"596f88b7b613bb04f80a1ea9\"), \"decimalQuoted\" : NumberDecimal(\"123.40\") } { \"_id\" : ObjectId(\"596f88c9b613bb04f80a1eaa\"), \"decimalUnQuoted\" : NumberDecimal(\"123.400000000000\") } 参见 原文 - MongoDB Extended JSON (v1) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/99-MongoDB-Advantages-of-databases.html":{"url":"01-introduction/99-MongoDB-Advantages-of-databases.html","title":"MongoDB数据库的优点","keywords":"","body":" MongoDB数据库的优点 到目前为止，MongoDB是一个新的和普遍使用的数据库。 它是一个基于文档的非关系数据库提供程序。 虽然它比传统的数据库快100倍，但早期说它将广泛地取代传统的RDBMS。 但是，不可否认的是：在性能和可扩展性方面 MongoDB 有着明显的优势。 关系数据库具有典型的架构设计，可以显示表的数量以及这些表之间的关系，而在MongoDB中则没有关系的概念。 MongoDB优点 MongoDB 的架构较少。它是一个文档数据库，它的一个集合持有不同的文档。 从一个到另一个的文档的数量，内容和大小可能有差异。 MongoDB 中单个对象的结构很清淅。 MongoDB 中没有复杂的连接。 MongoDB 提供深度查询的功能，因为它支持对文档的强大的动态查询。 MongoDB 很容易扩展。 它使用内部存储器来存储工作集，这是其快速访问的原因。 MongoDB的独特功能 使用方便 重量轻/轻量级 比RDBMS快得多 应该使用MongoDB在哪些场景 大而复杂的数据 移动和社会基础设施数据 内容管理和交付 用户数据管理 数据中心 MongoDB和RDBMS的性能分析 在关系数据库(RDBMS)中，表用作存储元素，而在 MongoDB 中使用的是集合。 在RDBMS中有多个模式，在每个模式中，可创建用于存储数据的表，而 MongoDB 是面向文档的数据库，数据是以类似JSON格式的BSON格式编写的存储的。 MongoDB几乎比传统数据库系统快100倍。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/99-MongoDB-characteristic.html":{"url":"01-introduction/99-MongoDB-characteristic.html","title":"MongoDB特点","keywords":"","body":" MongoDB特点 下面列出的是MongoDB的一些重要功能特性： 1.支持特别查询 在MongoDB中，可以通过字段，范围查询进行搜索，并且还支持正则表达式搜索。 2.索引 可以索引文档中的任何字段。 3.复制 MongoDB支持主从复制。主机可以执行读写操作，从机从主机复制数据，只能用于读取或备份(不写入) 4.复制数据 MongoDB可以在多台服务器上运行。 复制数据以保持系统正常运行，并在硬件故障的情况下保持其运行状态。 5.负载均衡 由于数据放在碎片中，因此具有自动负载平衡配置。 6.支持映射缩减和聚合工具 7.使用JavaScript而不是Procedure 8.它是一个用C++编写的无模式数据库 9.提供高性能 10.轻松存储任何大小的文件，而不会使您的堆栈复杂化 11.在故障的情况下易于管理 12.它还支持： 具有动态模式的JSON数据模型 自动分片用于水平可扩展性 内置复制高可用性 现在，许多公司使用 MongoDB 来创建新类型的应用程序，以提高性能和可用性。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"01-introduction/99-MongoDB-history.html":{"url":"01-introduction/99-MongoDB-history.html","title":"MongoDB历史","keywords":"","body":" MongoDB历史 MongoDB最初于2007年开发，当时公司正在建立一个类似于窗口天蓝(window azure)的服务平台。 “Window azure是由Microsoft创建的云计算平台和基础设施，通过全球网络构建，部署和管理应用程序和服务。” MongoDB由位于纽约的一个名为10gen的组织开发，现在被称为MongoDB Inc.，它最初被开发为PAAS(平台即服务)。 2009年晚些时候，它被作为一个由MongoDB公司维护和支持的开源数据库服务器在市场上引入。 MongoDB的第一个真正产品是从2010年3月发布的MongoDB 1.4版本开始的。2014年1月10日发布的最新版本：MongoDB2.4.9。 首先应该知道什么是面向文档的数据库？ 面向文档的数据库示例 MongoDB是面向文档的数据库。这是MongoDB的一个主要功能。它提供面向文档的存储。这很简单，可以很容易地编程。 MongoDB将数据存储为文档，因此被称为面向文档的数据库。 FirstName = \"Max\", Address = \"Haikou City\", Spouse = [{Name: \"Maxsu\"}]. FirstName =\"Kobe\", Address = \"LAC\" 有两个不同的文件(用“.”分隔开)。以这种方式存储数据称为面向文档的数据库。 Mongodb属于一类名为面向文档数据库(Document Oriented Databases)。它属于一个叫作“NoSQL数据库”的数据库类别称。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation.html":{"url":"02-installation.html","title":"安装 MongoDB","keywords":"","body":" 安装 MongoDB 在本页面 MongoDB社区版安装教程 MongoDB企业版安装教程 将社区版升级到企业版教程 支持平台 MongoDB有两个服务器版本：社区版和 企业版。 MONGODB ATLAS MongoDB Atlas 是MongoDB公司提供的MongoDB云服务，无需安装开销，并提供免费的入门套餐。 手册的这部分包含有关安装MongoDB的信息。 有关将当前部署升级到MongoDB 4.2的说明，请参阅升级过程。 有关升级到当前版本的最新修补程序版本的说明，请参阅升级到MongoDB的最新版本。 MongoDB社区版安装教程 MongoDB社区版安装教程包括： 平台 对应教程 Linux 在Red Hat或CentOS上安装MongoDB社区版在Ubuntu上安装MongoDB Community Edition在Debian上安装MongoDB社区版在SUSE上安装MongoDB社区版在Amazon Linux上安装MongoDB社区版 macOS 在macOS上安装MongoDB社区版 Windows 在Windows上安装MongoDB社区版 MongoDB企业版安装教程 MongoDB企业版安装教程包括： 平台 对应教程 Linux 在Red Hat或CentOS上安装MongoDB企业版在Ubuntu上安装MongoDB企业版在Debian上安装MongoDB企业版在SUSE上安装MongoDB企业版在Amazon Linux上安装MongoDB企业版 macOS 在macOS上安装MongoDB企业版 Windows 在Windows上安装MongoDB企业版 Docker 使用Docker安装MongoDB企业版 将社区版升级到企业版教程 重要 不要使用这些说明升级到另一个发行版本。要升级发行版本，请参阅相应的发行升级说明，例如Upgrade to MongoDB 4.2。 升级到MongoDB企业版（单节点） 升级到MongoDB企业版（副本集） 升级到MongoDB企业版（分片集群） 支持的平台 在版本3.4中进行了更改： MongoDB不再支持32位x86平台。 x86_64 平台支持停产通知 Ubuntu 14.04 支持已在MongoDB 4.2+中删除。 Debian 8 支持已在MongoDB 4.2+中删除。 macOS 10.11 支持已在MongoDB 4.2+中删除。 即将停产的通知： Windows 8.1 / 2012R2 MongoDB将在将来的版本中终止支持。 Windows 8/2012 MongoDB将在后续版本中终止支持。 Windows 7 / 2008R2 MongoDB将在后续版本中终止支持。 平台 4.2社区版与企业版 4.0社区版与企业版 3.6社区版与企业版 3.4社区版与企业版 Amazon Linux 2 ✓ ✓ Amazon Linux 2013.03及更高版本 ✓ ✓ ✓ ✓ Debian 10 4.2.1+ Debian 9 ✓ ✓ 3.6.5+ Debian 8 ✓ ✓ ✓ RHEL / CentOS / Oracle Linux [1] 8.0及更高版本 4.2.1+ 4.0.14+ 3.6.17+ RHEL / CentOS / Oracle Linux [1] 7.0及更高版本 ✓ ✓ ✓ ✓ RHEL / CentOS / Oracle Linux [1] 6.2及更高版本 ✓ ✓ ✓ ✓ SLES 15 4.2.1+ SLES 12 ✓ ✓ ✓ ✓ Solaris 11 64位 仅社区版 Ubuntu 18.04 ✓ 4.0.1+ Ubuntu 16.04 ✓ ✓ ✓ ✓ Ubuntu 14.04 ✓ ✓ ✓ Windows Server 2019 ✓ Windows 10 /Server 2016 ✓ ✓ ✓ ✓ Windows 8.1 / Server 2012 R2 ✓ ✓ ✓ ✓ Windows 8 /Server 012 ✓ ✓ ✓ ✓ Windows 7 / Server 2008 R2 ✓ ✓ ✓ ✓ Windows Vista ✓ macOS 10.13及更高版本 ✓ ✓ macOS 10.12 ✓ ✓ ✓ ✓ macOS 10.11 ✓ ✓ ✓ macOS 10.10 ✓ ✓ [1] （1，2，3）的MongoDB仅支持运行Red Hat Compatible Kernel (RHCK)的Oracle的Linux。MongoDB不支持Unbreakable Enterprise Kernel (UEK)。 ARM64 平台支持停产通知 Ubuntu 16.04 ARM64 支持已在MongoDB Community 4.2+中删除。 平台 4.2社区版与企业版 4.0社区版与企业版 3.6社区版与企业版 3.4社区版与企业版 Ubuntu 18.04 仅社区版 Ubuntu 16.04 仅企业版 ✓ ✓ ✓ PPC64LE（MongoDB企业版） 平台支持停产通知 Ubuntu 16.04 PPC64LE 支持已在MongoDB 4.2+中删除。 平台 4.2企业 4.0企业 3.6企业 3.4企业 RHEL / CentOS 7 ✓ ✓ ✓ ✓ Ubuntu 18.04 ✓ Ubuntu 16.04 ✓ 从3.6.13开始删除 从3.4.21开始删除 s390x 平台 4.2社区版与企业版 4.0企业版 3.6企业版 3.4企业版 RHEL / CentOS 7 ✓ 4.0.6+ 从3.6.17开始删除 从3.4.14开始删除 RHEL / CentOS 6 ✓ ✓ 从3.6.14开始删除 从3.4.22开始删除 SLES12 ✓ 4.0.6+ 从3.6.17开始删除 从3.4.15开始删除 Ubuntu 18.04 4.2.1+ 4.0.6+ ← MongoDB扩展JSON（v1）安装MongoDB社区版 → 原文链接：https://docs.mongodb.com/v4.2/installation/ 译者：桂陈 Update：小芒果 参见 原文 - Installation Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community.html":{"url":"02-installation/01-install-community.html","title":"安装MongoDB社区版","keywords":"","body":" 安装MongoDB社区版 下方文档提供了安装MongoDB社区版的说明。 在Linux上安装 在Linux上安装MongoDB Community Edition和必需的依赖项。 在macOS上安装 从MongoDB归档文件在macOS系统上安装MongoDB Community Edition。 在Windows上安装 在Windows系统上安装MongoDB Community Edition，并可以选择将MongoDB作为Windows服务启动。 ← 安装MongoDB在Linux上安装MongoDB社区版 → 原文链接：https://docs.mongodb.com/v4.2/administration/install-community/ 译者：小芒果 参见 原文 - Install MongoDB Community Edition Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux.html":{"url":"02-installation/01-install-community/01-install-on-linux.html","title":"Install on Linux","keywords":"","body":" 在Linux上安装MongoDB社区版 这些文档提供了为受支持的Linux系统安装MongoDB社区版的说明。 推荐 为了获得最佳的安装体验，MongoDB提供了适用于流行Linux发行版的软件包。这些软件包是运行MongoDB的首选方式。以下指南详细介绍了这些系统的安装过程： 在Red Hat上安装 使用.rpm软件包在Red Hat企业版和相关Linux系统上安装MongoDB社区版。 在Ubuntu上安装 使用.deb软件包在Ubuntu Linux系统上安装MongoDB社区版。 在Debian上安装 使用.deb 软件包在Debian系统上安装MongoDB社区版。 在SUSE上安装 使用.rpm软件包在SUSE Linux系统上安装MongoDB Community Edition 。 在亚马逊上安装 使用.rpm软件包在Amazon Linux AMI系统上安装MongoDB社区版。 WINDOWS LINUX子系统（WSL）-不支持 MongoDB不支持Linux的Windows子系统（WSL）。 原文链接：https://docs.mongodb.com/v4.2/administration/install-on-linux/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/01-install-mongodb-on-red-hat.html":{"url":"02-installation/01-install-community/01-install-on-linux/01-install-mongodb-on-red-hat.html","title":"Install on Red Hat","keywords":"","body":" Install on Red Hat ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Red Hat Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/01-install-mongodb-on-red-hat/01-install-mongodb-on-red-hat-tarball.html":{"url":"02-installation/01-install-community/01-install-on-linux/01-install-mongodb-on-red-hat/01-install-mongodb-on-red-hat-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu.html":{"url":"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu.html","title":"Install on Ubuntu","keywords":"","body":" Install on Ubuntu ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Ubuntu Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu/01-install-mongodb-on-ubuntu-tarball.html":{"url":"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu/01-install-mongodb-on-ubuntu-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu/02-installation-ubuntu-community-troubleshooting.html":{"url":"02-installation/01-install-community/01-install-on-linux/02-install-mongodb-on-ubuntu/02-installation-ubuntu-community-troubleshooting.html","title":"Troubleshoot Ubuntu Installation","keywords":"","body":" Troubleshoot Ubuntu Installation ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Troubleshoot Ubuntu Installation Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/03-install-mongodb-on-debian.html":{"url":"02-installation/01-install-community/01-install-on-linux/03-install-mongodb-on-debian.html","title":"Install on Debian","keywords":"","body":" Install on Debian ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Debian Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/03-install-mongodb-on-debian/01-install-mongodb-on-debian-tarball.html":{"url":"02-installation/01-install-community/01-install-on-linux/03-install-mongodb-on-debian/01-install-mongodb-on-debian-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/04-install-mongodb-on-suse.html":{"url":"02-installation/01-install-community/01-install-on-linux/04-install-mongodb-on-suse.html","title":"Install on SUSE","keywords":"","body":" Install on SUSE ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on SUSE Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/04-install-mongodb-on-suse/01-install-mongodb-on-suse-tarball.html":{"url":"02-installation/01-install-community/01-install-on-linux/04-install-mongodb-on-suse/01-install-mongodb-on-suse-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/05-install-mongodb-on-amazon.html":{"url":"02-installation/01-install-community/01-install-on-linux/05-install-mongodb-on-amazon.html","title":"Install on Amazon","keywords":"","body":" Install on Amazon ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Amazon Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/01-install-on-linux/05-install-mongodb-on-amazon/01-install-mongodb-on-amazon-tarball.html":{"url":"02-installation/01-install-community/01-install-on-linux/05-install-mongodb-on-amazon/01-install-mongodb-on-amazon-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/02-install-mongodb-on-os-x.html":{"url":"02-installation/01-install-community/02-install-mongodb-on-os-x.html","title":"Install on macOS","keywords":"","body":" 在macOS上安装MongoDB社区版 在本页面 概述 注意事项 安装MongoDB社区版 附加信息 MONGODB ATLAS MongoDB Atlas 是MongoDB公司提供的MongoDB云服务，无需安装开销，并提供免费的入门套餐。 概述 使用本教程可使用第三方brew包管理器在macOS上安装MongoDB 4.2社区版。 MongoDB版本 本教程将安装MongoDB 4.2社区版。要安装其他版本的MongoDB，请使用此页面左上角的版本下拉菜单选择该版本的文档。 注意事项 平台支持 MongoDB 4.2 社区版支持macOS 10.12或更高版本。 有关更多信息，请参见支持的平台。 生产注意事项 在生产环境中部署MongoDB之前，请考虑 生产说明文档，该文档提供了生产MongoDB部署的性能注意事项和配置建议。 安装MongoDB社区版¶ 前提条件 如果您在OSX主机上安装了Homebrew brew软件包， 并且以前已经使用了官方的 MongoDB Homebrew Tap，请跳过前提条件并转到“ 过程”步骤。 安装XCode Apple的XCode包含所需的brew命令行工具，可在App Store上免费获得。确保您正在运行最新版本。 安装Homebrew OSX 默认不包括Homebrewbrew软件包。按照 官方说明进行安装brew。 点击MongoDB Homebrew 在终端上发出以下命令，以点击官方的 MongoDB Homebrew Tap： 复制 brew tap mongodb/brew 过程 请按照以下步骤使用第三方brew程序包管理器安装MongoDB社区版。 在终端上，发出以下命令： 复制 brew install mongodb-community@4.2 提示 如果您以前安装了该公式的较旧版本，则可能会遇到ChecksumMismatchError。若要解决，请参阅 ChecksumMismatchError故障排除。 除二进制文件外，安装还会创建： 配置文件 （/usr/local/etc/mongod.conf） （）log directory path/usr/local/var/log/mongodb （）data directory path/usr/local/var/mongodb 运行MongoDB社区版 请按照以下步骤运行MongoDB社区版。这些说明假定您使用的是默认设置。 您可以使用brew来将MongoDB作为macOS服务运行，也可以作为后台进程手动运行MongoDB。建议将MongoDB作为macOS服务运行，因为这样做会自动设置正确的系统ulimit值（有关更多信息，请参阅 ulimit设置）。 要将MongoDB（即mongod进程）作为macOS服务运行，请发出以下命令： 复制 brew services start mongodb-community@4.2 要停止mongod作为macOS服务运行，请根据需要使用以下命令： 复制 brew services stop mongodb-community@4.2 要将MongoDB（即mongod进程）作为后台进程手动运行，请发出以下命令： 复制 mongod --config /usr/local/etc/mongod.conf --fork 要停止mongod作为后台进程运行，请从mongo shell 连接到mongod，然后根据需要发出shutdown命令。 两种方法都使用在安装过程中创建的/usr/local/etc/mongod.conf文件。您也可以将自己的MongoDB 配置选项添加到此文件。 MACOS阻止MONGOD打开 mongod安装后，macOS可能无法运行。如果在启动时收到安全错误，mongod 显示无法识别或验证开发人员，请执行以下操作以授予mongod运行权限： 打开系统偏好设置 选择“ 安全性和隐私”窗格。 在常规选项卡下，单击关于mongod消息右侧的按钮，根据您的macOS版本标记为“始终打开” 或“ 始终允许”。 要验证MongoDB是否正在运行，请在正在运行的进程中搜索mongod： 复制 ps aux | grep -v grep | grep mongod 您还可以查看日志文件以查看mongod进程的当前状态 ：/usr/local/var/log/mongodb/mongo.log。 连接和使用MongoDB 要开始使用MongoDB，请将mongoshell 连接到正在运行的实例。在新终端上，发出以下命令： 复制 mongo MACOS阻止MONGOD打开 mongod安装后，macOS可能无法运行。如果在启动时收到安全错误，mongod 显示无法识别或验证开发人员，请执行以下操作以授予mongod运行权限： 打开系统偏好设置 选择“ 安全性和隐私”窗格。 在常规选项卡下，单击关于mongod消息右侧的按钮，根据您的macOS版本标记为“始终打开” 或“ 始终允许”。 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 其他信息 默认为localhost绑定 默认情况下，MongoDB在启动时将bindIp设置为 127.0.0.1，绑定到localhost网络接口。这意味着mongod只能接受来自同一计算机上运行的客户端的连接。除非将此值设置为有效的网络接口，否则远程客户端将无法连接到mongod，并且mongod不能初始化副本集。 可以配置以下值： 在MongoDB配置文件中使用bindIp，或 通过命令行参数 --bind_ip 警告 绑定到非本地主机（例如，可公共访问）的IP地址之前，请确保已保护群集免受未经授权的访问。有关安全建议的完整列表，请参阅“ 安全清单”。至少应考虑 启用身份验证并 强化网络基础架构。 有关配置的更多信息bindIp，请参见 IP绑定。 对ChecksumMismatchError进行故障排除¶ 如果您以前安装了该公式的较旧版本，则可能会遇到类似于以下内容的ChecksumMismatchError： 复制 Error: An exception occurred within a child process: ChecksumMismatchError: SHA256 mismatch Expected: c7214ee7bda3cf9566e8776a8978706d9827c1b09017e17b66a5a4e0c0731e1f Actual: 6aa2e0c348e8abeec7931dced1f85d4bb161ef209c6af317fe530ea11bbac8f0 Archive: /Users/kay/Library/Caches/Homebrew/downloads/a6696157a9852f392ec6323b4bb697b86312f0c345d390111bd51bb1cbd7e219--mongodb-macos-x86_64-4.2.0.tgz To retry an incomplete download, remove the file above. 修复： 删除下载的.tgz档案。 点击公式。 复制 brew untap mongodb/brew && brew tap mongodb/brew 重试安装。 复制 brew install mongodb-community@4.2 ← Install MongoDB Community on Amazon Linux using .tgz TarballInstall MongoDB Community on macOS using .tgz Tarball → 原文链接：https://docs.mongodb.com/v4.2/tutorial/install-mongodb-on-os-x/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/02-install-mongodb-on-os-x/01-install-mongodb-on-os-x-tarball.html":{"url":"02-installation/01-install-community/02-install-mongodb-on-os-x/01-install-mongodb-on-os-x-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/03-install-mongodb-on-windows.html":{"url":"02-installation/01-install-community/03-install-mongodb-on-windows.html","title":"Install on Windows","keywords":"","body":" 在Windows上安装MongoDB社区版 在本页面 概述 注意事项 安装MongoDB社区版 将MongoDB社区版作为Windows服务运行 从命令解释器运行MongoDB社区版 其他注意事项 MONGODB ATLAS MongoDB Atlas 是MongoDB公司提供的MongoDB云服务，无需安装开销，并提供免费的入门套餐。 概述 使用本教程可以使用默认安装向导在Windows上安装MongoDB 4.2社区版。 MongoDB版本 本教程将安装MongoDB 4.2社区版。要安装其他版本的MongoDB社区，请使用此页面左上角的版本下拉菜单选择该版本的文档。 安装方法 本教程使用默认安装向导在Windows上安装MongoDB。或者，您可以选择使用msiexec.exe命令行（cmd.exe）以无人参与的方式在Windows上安装MongoDB 。这对于希望使用自动化部署MongoDB的系统管理员很有用。 ➤有关说明，请参阅使用msiexec.exe在Windows上安装MongoDB社区版。 注意事项 平台支持 MongoDB 4.2 社区版在x86_64架构上支持Windows 的以下 64位版本 ： Windows Server 2019 Windows 10 / Windows Server 2016 Windows 8.1 / Windows Server 2012 R2 Windows 8 / Windows Server 2012 Windows 7 / Windows Server 2008 R2 MongoDB仅支持这些平台的64位版本。 有关更多信息，请参见支持的平台。 生产注意事项 在生产环境中部署MongoDB之前，请考虑 生产说明文档，该文档提供了生产MongoDB部署的性能注意事项和配置建议。 安装MongoDB社区版 前提条件 Windows 10之前的Windows版本上的用户必须在安装MongoDB之前安装以下更新： ➤ Windows系统Universal C运行时更新 Windows 10，Server 2016和Server 2019上的用户不需要此更新。 程序 请按照以下步骤使用MongoDB安装程序向导安装MongoDB社区版。安装过程将同时安装MongoDB二进制文件和默认配置文件 \\bin\\mongod.cfg。 下载安装程序。 从以下链接下载MongoDB社区安装程序.msi： ➤ MongoDB的下载中心 在“ 版本”下拉列表中，选择要下载的MongoDB版本。 在平台下拉菜单中，选择Windows。 在Package下拉列表中，选择msi。 点击下载。 运行MongoDB安装程序。 例如，从Windows资源管理器/文件资源管理器中： 转到下载MongoDB安装程序的目录（.msi文件）。默认情况下，这是您的Downloads目录。 双击.msi文件。 遵循MongoDB社区版安装向导。 该向导将引导您完成MongoDB和MongoDB Compass的安装。 选择安装类型 您可以选择“ 完整”（建议大多数用户使用）或“ 自定义”安装类型。“ 完整设置”选项会将MongoDB和MongoDB工具安装到默认位置。使用“ 自定义 安装”选项可以指定要安装的可执行文件以及安装位置。 服务配置 从MongoDB 4.0开始，您可以在安装过程中将MongoDB设置为Windows服务，也可以仅安装二进制文件。 MongoDB服务 MongoDB 以下内容将MongoDB安装并配置为Windows服务。 从MongoDB 4.0开始，您可以在安装过程中将MongoDB配置和启动为Windows服务，并在成功安装后启动MongoDB服务。 选择“ 将MongoDB作为服务安装”。 选择以下任一项： 以网络服务用户身份运行服务（默认） 这是Windows内置的Windows用户帐户 或者 以本地或域用户身份运行服务 对于现有的本地用户帐户，请为“ 帐户域”指定一个句点（即.），并为该用户指定“ 帐户名”和“ 帐户密码 ”。 对于现有的域用户，请为该用户指定“ 帐户域”，“ 帐户名称”和“ 帐户密码 ”。 服务名称。指定服务名称。默认名称为MongoDB。如果您已经拥有使用指定名称的服务，则必须选择另一个名称。 数据目录。指定数据目录，它对应于 --dbpath。如果目录不存在，安装程序将创建该目录并设置对服务用户的目录访问权限。 日志目录。指定日志目录，它对应于 --logpath。如果目录不存在，安装程序将创建该目录并设置对服务用户的目录访问权限。 对于Windows 8或更高版本，您可以让向导安装 MongoDB Compass。要安装Compass，请选择Install MongoDB Compass（默认）。 注意 安装脚本需要PowerShell 3.0或更高版本。如果您使用Windows 7，请取消单击 Install MongoDB Compass。您可以从下载中心手动下载Compass。 准备就绪后，点击安装。 如果您将MongoDB安装为Windows服务 成功安装后将启动MongoDB服务[1]。 要开始使用MongoDB，请将mongo.exe shell 连接到正在运行的MongoDB实例。要么： 在Windows资源管理器/文件资源管理器中，转到目录C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\，然后双击 mongo.exe` 或者，使用管理特权打开命令解释器并运行： 复制 “ C：\\ Program Files \\ MongoDB \\ Server \\ 4.2 \\ bin \\ mongo.exe” 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 [1] 使用配置文件\\bin\\mongod.cfg配置MongoDB实例 。 如果您没有将MongoDB安装为Windows服务¶ 如果您仅安装了可执行文件而没有将MongoDB作为Windows服务安装，则必须手动启动MongoDB实例。 有关启动MongoDB实例的说明，请参阅从命令解释器运行MongoDB社区版。 将社区版MongoDB作为Windows服务运行 从版本4.0开始，您可以在安装过程中将MongoDB安装和配置为 Windows服务，并在成功安装后启动MongoDB服务。使用配置文件 \\bin\\mongod.cfg配置MongoDB 。 将社区版MongoDB作为Windows服务启动 要启动/重新启动MongoDB服务，请使用服务控制台： 在服务控制台中，找到MongoDB服务。 右键单击MongoDB服务，然后单击启动。 要开始使用MongoDB，请将mongo.exe shell 连接到正在运行的MongoDB实例。要进行连接，请打开具有管理权限的命令解释器并运行： 复制 “ C：\\ Program Files \\ MongoDB \\ Server \\ 4.2 \\ bin \\ mongo.exe” 有关mongo.exe shell的更多信息，例如连接到在不同主机和/或端口上运行的MongoDB实例，请参阅mongo Shell。 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅 插入文档 查询文档 更新文档 删除文档 将社区版MongoDB作为Windows服务停止 要停止/暂停MongoDB服务，请使用服务控制台： 在服务控制台中，找到MongoDB服务。 右键单击MongoDB服务，然后单击“ 停止”（或“ 暂停”）。 将社区版MongoDB作为Windows服务删除 要删除MongoDB服务，请首先使用服务控制台停止该服务。然后以管理员身份打开Windows命令提示符/解释器（cmd.exe），然后运行以下命令： 复制 sc.exe delete MongoDB 从命令解释器运行MongoDB社区版 您可以从Windows命令提示符/解释器（cmd.exe）而不是作为服务运行MongoDB社区版。 以管理员身份打开Windows命令提示符/解释器（cmd.exe）。 重要 您必须以管理员身份打开命令解释器 。 创建数据库目录。 创建MongoDB存储数据的数据目录。MongoDB的默认数据目录路径是 \\data\\db 启动MongoDB的驱动上的绝对路径 。 在命令解释器中，创建数据目录： 复制 cd C:\\ md \"\\data\\db\" 启动您的MongoDB数据库。 要启动MongoDB，请运行mongod.exe。 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongod.exe\" --dbpath=\"c:\\data\\db\" 该--dbpath选项指向您的数据库目录。 如果MongoDB数据库服务器正常运行，则 命令解释器将显示： 复制 [initandlisten] waiting for connections 重要 根据 Windows主机上的 Windows Defender防火墙设置，Windows可能会显示“ 安全警报”对话框，提示C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongod.exe的“某些功能” 在网络上进行通信被阻止。要解决此问题： 点击专用网络，例如我的家庭或工作网络。 点击允许访问。 要了解有关安全性和MongoDB的更多信息，请参阅“ 安全性文档”。 连接到MongoDB。 要将mongo.exe shell 连接到MongoDB实例，请打开另一个 具有管理权限的命令解释器，然后运行： 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongo.exe\" 有关连接mongo.exe shell 的更多信息，例如连接到在不同主机和/或端口上运行的MongoDB实例，请参阅The mongo Shell。 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 其他注意事项 默认为localhost绑定 默认情况下，MongoDB在启动时将bindIp设置为 127.0.0.1，绑定到localhost网络接口。这意味着mongod.exe只能接受来自同一计算机上运行的客户端的连接。除非将此值设置为有效的网络接口，否则远程客户端将无法连接到mongod.exe，并且mongod.exe不能初始化副本集。 可以配置以下值： 在MongoDB配置文件中使用bindIp，或 通过命令行参数 --bind_ip 警告 绑定到非本地主机（例如，可公共访问）的IP地址之前，请确保已保护群集免受未经授权的访问。有关安全建议的完整列表，请参阅“ 安全清单”。至少应考虑 启用身份验证并 强化网络基础架构。 有关配置bindIp的更多信息，请参见 IP绑定。 版本发布和 .msi 如果您使用Windows安装程序（.msi） 安装了MongoDB，.msi将在其发行系列（例如4.2.1到4.2.2）中自动升级。 升级完整版本系列（例如4.0至4.2）需要重新安装。 将MongoDB二进制文件添加到系统路径 本教程中的所有命令行示例均作为MongoDB二进制文件的绝对路径提供。您可以将C:\\Program Files\\MongoDB\\Server\\4.2\\bin添加到系统路径中，然后省略MongoDB二进制文件的完整路径。 译者：汪子豪 update：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/01-install-community/03-install-mongodb-on-windows/01-install-mongodb-on-windows-unattended.html":{"url":"02-installation/01-install-community/03-install-mongodb-on-windows/01-install-mongodb-on-windows-unattended.html","title":"Install using msiexec.exe","keywords":"","body":" Install using msiexec.exe ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using msiexec.exe Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise.html":{"url":"02-installation/02-install-enterprise.html","title":"安装MongoDB企业版","keywords":"","body":" 安装MongoDB企业版 这些文档提供了安装MongoDB企业版的说明。 MongoDB企业版可供MongoDB企业版订户使用，并包括其他一些功能，包括对SNMP监视，LDAP身份验证，Kerberos身份验证和系统事件审核的支持。 注意 由于SERVER-29352，macOS上的MongoDB Enterprise 不包括对SNMP的支持。 在Linux上安装 在基于Linux的系统上安装MongoDB企业版的正式版本。 在macOS上安装 在macOS上安装MongoDB企业版的正式版本 在Windows上安装 使用.msi 安装程序在Windows上安装MongoDB企业版。 使用Docker安装 安装MongoDB企业版Docker容器。 ← 使用msiexec.exe在Windows上安装MongoDB社区在Linux上安装MongoDB Enterprise → 原文链接：https://docs.mongodb.com/v4.2/administration/install-enterprise/ 译者：小芒果 参见 原文 - Install MongoDB Enterprise Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux.html","title":"Install on Linux","keywords":"","body":" Install on Linux ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Linux Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/01-install-mongodb-enterprise-on-red-hat.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/01-install-mongodb-enterprise-on-red-hat.html","title":"Install on Red Hat","keywords":"","body":" Install on Red Hat ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Red Hat Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/01-install-mongodb-enterprise-on-red-hat/01-install-mongodb-enterprise-on-red-hat-tarball.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/01-install-mongodb-enterprise-on-red-hat/01-install-mongodb-enterprise-on-red-hat-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/02-install-mongodb-enterprise-on-ubuntu.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/02-install-mongodb-enterprise-on-ubuntu.html","title":"Install on Ubuntu","keywords":"","body":" Install on Ubuntu ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Ubuntu Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/02-install-mongodb-enterprise-on-ubuntu/01-install-mongodb-enterprise-on-ubuntu-tarball.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/02-install-mongodb-enterprise-on-ubuntu/01-install-mongodb-enterprise-on-ubuntu-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/03-install-mongodb-enterprise-on-debian.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/03-install-mongodb-enterprise-on-debian.html","title":"Install on Debian","keywords":"","body":" Install on Debian ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Debian Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/03-install-mongodb-enterprise-on-debian/01-install-mongodb-enterprise-on-debian-tarball.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/03-install-mongodb-enterprise-on-debian/01-install-mongodb-enterprise-on-debian-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/04-install-mongodb-enterprise-on-suse.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/04-install-mongodb-enterprise-on-suse.html","title":"Install on SUSE","keywords":"","body":" Install on SUSE ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on SUSE Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/04-install-mongodb-enterprise-on-suse/01-install-mongodb-enterprise-on-suse-tarball.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/04-install-mongodb-enterprise-on-suse/01-install-mongodb-enterprise-on-suse-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/05-install-mongodb-enterprise-on-amazon.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/05-install-mongodb-enterprise-on-amazon.html","title":"Install on Amazon","keywords":"","body":" Install on Amazon ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install on Amazon Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/01-install-enterprise-linux/05-install-mongodb-enterprise-on-amazon/01-install-mongodb-enterprise-on-amazon-tarball.html":{"url":"02-installation/02-install-enterprise/01-install-enterprise-linux/05-install-mongodb-enterprise-on-amazon/01-install-mongodb-enterprise-on-amazon-tarball.html","title":"Install using .tgz Tarball","keywords":"","body":" Install using .tgz Tarball ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using .tgz Tarball Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/02-install-mongodb-enterprise-on-os-x.html":{"url":"02-installation/02-install-enterprise/02-install-mongodb-enterprise-on-os-x.html","title":"Install on macOS","keywords":"","body":" 在Mac OS安装MongoDB企业版 在本页面 概述 注意事项 安装MongoDB企业版 运行MongoDB企业版 附加信息 MONGODB ATLAS MongoDB Atlas 是MongoDB公司提供的MongoDB云服务，无需安装开销，并提供免费的入门套餐。 概述 使用本教程，可以使用下载的.tgztarball 在macOS上手动安装MongoDB 4.2企业版 。 MongoDB Enterprise Edition 在某些平台上可用，并且包含对与安全性和监视相关的多种功能的支持。 MongoDB版本 本教程将安装MongoDB 4.2企业版。要安装其他版本的MongoDB企业版，请使用此页面左上角的版本下拉菜单选择该版本的文档。 注意事项 平台支持 MongoDB 4.2企业版支持macOS 10.12或更高版本。 有关更多信息，请参见支持的平台。 生产注意事项 在生产环境中部署MongoDB之前，请考虑 生产说明文档，该文档提供了生产MongoDB部署的性能注意事项和配置建议。 安装MongoDB企业版 请按照以下步骤从 .tgz中手动安装MongoDB Enterprise Edition。 下载压缩包。 从以下链接下载MongoDB企业版tgztarball： ➤ MongoDB的下载中心 在“ 版本”下拉列表中，选择要下载的MongoDB版本。 在平台下拉列表中，选择macOS。 在包下拉列表中，选择tgz。 点击下载。 从下载的档案中提取文件。 复制 tar -zxvf mongodb-macos-x86_64-enterprise-4.2.8.tgz 如果您的网络浏览器在下载过程中自动将文件解压缩，则文件将以.tar结尾。 确保二进制文件在PATH环境变量列出的目录中。 MongoDB二进制文件位于tarballbin/目录中。您可以： 将二进制文件复制到PATH 变量中列出的目录中，例如/usr/local/bin（根据需要更新 /path/to/the/mongodb-directory/安装目录） 复制 sudo cp /path/to/the/mongodb-directory/bin/* /usr/local/bin/ 从PATH变量中列出的目录创建指向二进制文件的符号链接，例如/usr/local/bin（根据需要更新 /path/to/the/mongodb-directory/安装目录）： 复制 sudo ln -s /path/to/the/mongodb-directory/bin/* /usr/local/bin/ 运行MongoDB企业版 请按照以下步骤运行MongoDB企业版。这些说明假定您使用的是默认设置。 创建数据目录。 首次启动MongoDB之前，必须创建该mongod进程将向其写入数据的目录。 例如，要创建/usr/local/var/mongodb目录： 复制 sudo mkdir -p /usr/local/var/mongodb 重要 从macOS 10.15 Catalina开始，Apple限制访问MongoDB默认/data/db数据目录。在macOS 10.15 Catalina上，您必须使用其他数据目录，例如 /usr/local/var/mongodb。 创建日志目录。 您还必须创建该mongod进程将在其中写入其日志文件的目录： 例如，要创建/usr/local/var/log/mongodb目录： 复制 sudo mkdir -p /usr/local/var/log/mongodb 设置数据和日志目录的权限。 确保正在运行的用户帐户mongod对这两个目录具有读写权限。如果您以自己的用户帐户运行mongod，并且刚刚在上面创建了两个目录，则用户应该已经可以访问它们。否则，您可以用chown来设置所有权，以替换适当的用户： 复制 sudo chown my_mongodb_user /usr/local/var/mongodb sudo chown my_mongodb_user /usr/local/var/log/mongodb 运行MongoDB。 要运行MongoDB，请在系统提示符下运行mongod过程，从上方提供dbpath和logpath 两个参数，并在后台fork该参数运行mongod。另外，您也可以选择在 配置文件中存储dbpath，logpath，fork值和许多其他的参数。 使用命令行参数运行mongod 在系统提示符下运行该mongod过程，直接在命令行上提供三个必需的参数： 复制 mongod --dbpath / usr / local / var / mongodb --logpath /usr/local/var/log/mongodb/mongo.log --fork 使用配置文件运行mongod 在系统提示符下运行mongod过程，并使用config参数提供配置文件的路径 ： 复制 mongod --config /usr/local/etc/mongod.conf MACOS阻止MONGOD打开 mongod安装后，macOS可能无法运行。如果在启动时收到安全错误，mongod 显示无法识别或验证开发人员，请执行以下操作以授予mongod运行权限： 打开系统偏好设置 选择“ 安全性和隐私”窗格。 在常规选项卡下，单击关于mongod消息右侧的按钮，根据您的macOS版本标记为“始终打开” 或“ 始终允许”。 验证MongoDB已成功启动。 验证MongoDB已成功启动： 复制 ps aux | grep -v grep | grep mongod 如果看不到mongod进程正在运行，请检查日志文件中是否有任何错误消息。 开始使用MongoDB。 在相同的主机上启动mongo shell 作为mongod。您可以在不使用任何命令行选项的情况下运行mongo shell ，以使用默认端口27017连接到在本地主机上运行的mongod： 复制 mongo MACOS阻止MONGOD打开 mongod安装后，macOS可能无法运行。如果在启动时收到安全错误，mongod 显示无法识别或验证开发人员，请执行以下操作以授予mongod运行权限： 打开系统偏好设置 选择“ 安全性和隐私”窗格。 在常规选项卡下，单击关于mongod消息右侧的按钮，根据您的macOS版本标记为“始终打开” 或“ 始终允许”。 有关使用mongo shell 连接的更多信息，例如连接到mongod在其他主机和/或端口上运行的实例，请参阅mongo Shell。 为了帮助您开始使用MongoDB，MongoDB提供了各种驱动程序版本的入门指南。有关可用版本，请参阅 入门。 其他信息 默认为localhost绑定 默认情况下，MongoDB在启动时将bindIp设置为 127.0.0.1，该绑定到localhost网络接口。这意味着mongod只能接受来自同一计算机上运行的客户端的连接。除非将此值设置为有效的网络接口，否则远程客户端将无法连接到mongod，并且mongod不能初始化副本集。 可以配置以下值： 在MongoDB配置文件中使用bindIp，或 通过命令行参数 --bind_ip 警告 绑定到非本地主机（例如，可公共访问）的IP地址之前，请确保已保护群集免受未经授权的访问。有关安全建议的完整列表，请参阅“ 安全清单”。至少应考虑 启用身份验证并 强化网络基础架构。 有关配置的更多信息bindIp，请参见 IP绑定。 ← 使用.tgz Tarball在Amazon Linux上安装MongoDB Enterprise在Windows上安装MongoDB企业版 → 原文链接：https://docs.mongodb.com/v4.2/tutorial/install-mongodb-enterprise-on-os-x/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/03-install-mongodb-enterprise-on-windows.html":{"url":"02-installation/02-install-enterprise/03-install-mongodb-enterprise-on-windows.html","title":"Install on Windows","keywords":"","body":" 在Windows安装MongoDB企业版 在本页面 概述 注意事项 安装MongoDB企业版 从命令解释器启动MongoDB企业版 将企业版MongoDB作为Windows服务启动 将企业版MongoDB作为Windows服务停止 将企业版MongoDB作为Windows服务删除 其他注意事项 MONGODB ATLAS MongoDB Atlas 是MongoDB公司提供的MongoDB云服务，无需安装开销，并提供免费的入门套餐。 概述 使用本教程，可以使用默认安装向导在Windows上安装MongoDB 4.2企业版。 MongoDB企业版 在某些平台上可用，并且包含对与安全性和监视相关的多种功能的支持。 MongoDB版本 本教程将安装MongoDB 4.2企业版。要安装其他版本的MongoDB企业版，请使用此页面左上角的版本下拉菜单选择该版本的文档。 安装方法 本教程使用默认安装向导在Windows上安装MongoDB。或者，您可以选择使用msiexec.exe命令行（cmd.exe）以无人参与的方式在Windows上安装MongoDB 。这对于希望使用自动化部署MongoDB的系统管理员很有用。 ➤有关说明，请参阅使用msiexec.exe在Windows上安装MongoDB企业版 。 注意事项 平台支持 MongoDB 4.2 Enterprise Edition 在x86_64体系结构上支持Windows 的以下 64位版本 ： Windows Server 2019 Windows 10 / Windows Server 2016 Windows 8.1 / Windows Server 2012 R2 Windows 8 / Windows Server 2012 Windows 7 / Windows Server 2008 R2 MongoDB仅支持这些平台的64位版本。 有关更多信息，请参见支持的平台。 生产注意事项 在生产环境中部署MongoDB之前，请考虑 生产说明文档，该文档提供了生产MongoDB部署的性能注意事项和配置建议。 安装MongoDB企业版 前提条件 Windows 10之前的Windows版本上的用户必须在安装MongoDB之前安装以下更新： ➤ Windows系统Universal C运行时更新 Windows 10，Server 2016和Server 2019上的用户不需要此更新。 程序 请按照以下步骤使用Windows安装向导安装MongoDB Enterprise Edition。安装过程将同时安装MongoDB二进制文件和默认配置文件 \\bin\\mongod.cfg。 下载安装程序。 从以下链接下载MongoDB社区安装程序.msi： ➤ MongoDB的下载中心 在“ 版本”下拉列表中，选择要下载的MongoDB版本。 在平台下拉菜单中，选择Windows。 在Package下拉列表中，选择msi。 点击下载。 遵循MongoDB企业版安装向导。 该向导将引导您完成MongoDB和MongoDB Compass的安装。 选择安装类型 您可以选择“ 完整”（建议大多数用户使用）或“ 自定义”安装类型。“ 完整设置”选项会将MongoDB和MongoDB工具安装到默认位置。使用“ 自定义 安装”选项可以指定要安装的可执行文件以及安装位置。 服务配置 从MongoDB 4.0开始，您可以在安装过程中将MongoDB设置为Windows服务，也可以仅安装二进制文件。 MongoDB服务 MongoDB 以下内容将MongoDB安装并配置为Windows服务。 从MongoDB 4.0开始，您可以在安装过程中将MongoDB配置和启动为Windows服务，并在成功安装后启动MongoDB服务。 选择“ 将MongoD作为服务安装”。 选择以下任一项： 以网络服务用户身份运行服务（默认） 这是Windows内置的Windows用户帐户 或者 以本地或域用户身份运行服务 对于现有的本地用户帐户，请为“ 帐户域”指定一个句点（即.），并为该用户指定“ 帐户名”和“ 帐户密码 ”。 对于现有的域用户，请为该用户指定“ 帐户域”，“ 帐户名称”和“ 帐户密码 ”。 服务名称。指定服务名称。默认名称为MongoDB。如果您已经具有使用指定名称的服务，则必须选择另一个名称。 数据目录。指定数据目录，它对应于 --dbpath。如果目录不存在，安装程序将创建该目录并设置对服务用户的目录访问权限。 日志目录。指定日志目录，它对应于 --logpath。如果目录不存在，安装程序将创建该目录并设置对服务用户的目录访问权限。 安装MongoDB Compass 对于Windows 8或更高版本，您可以让向导安装 MongoDB Compass。要安装Compass，请选择Install MongoDB Compass（默认）。注意安装脚本需要PowerShell 3.0或更高版本。如果您使用Windows 7，请取消单击 Install MongoDB Compass。您可以从下载中心手动下载Compass。 准备就绪后，点击安装。 运行MongoDB安装程序。 例如，从Windows资源管理器/文件资源管理器中： 转到下载MongoDB安装程序的目录（.msi文件）。默认情况下，这是您的Downloads目录。 双击.msi文件。 如果您将MongoDB安装为Windows服务 成功安装后将启动MongoDB服务[1]。 要开始使用MongoDB，请将mongo.exe shell 连接到正在运行的MongoDB实例。要么： 在Windows资源管理器/文件资源管理器中，转到目录C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\，然后单击[mongo.exe] (https://docs.mongodb.com/v4.2/reference/program/mongo/bin.mongo)。 或者，使用管理权限打开命令解释器并运行： 复制 “ C：\\ Program Files \\ MongoDB \\ Server \\ 4.2 \\ bin \\ mongo.exe” 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 [1] 使用配置文件\\bin\\mongod.cfg配置MongoDB实例 。 如果您没有将MongoDB安装为Windows服务 如果您仅安装了可执行文件而没有将MongoDB作为Windows服务安装，则必须手动启动MongoDB实例。 有关启动 MongoDB实例的说明，请参阅从命令解释器启动MongoDB企业版。 从命令解释器启动MongoDB企业版 创建数据库目录。 创建MongoDB存储数据的数据目录。MongoDB的默认数据目录路径\\data\\db是您从中启动MongoDB的驱动器上的绝对路径 。 在命令解释器中，创建数据目录： 复制 cd C:\\ md \"\\data\\db\" 启动您的MongoDB数据库。 要启动MongoDB，请运行mongod.exe。 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongod.exe\" --dbpath=\"c:\\data\\db\" 该--dbpath选项指向您的数据库目录。 如果MongoDB数据库服务器正常运行，则 命令解释器将显示： 复制 [initandlisten] waiting for connections 重要 根据 Windows主机上的 Windows Defender防火墙设置，Windows可能会显示“ 安全警报”对话框，显示C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongod.exe的“某些功能” 在网络上进行通信被阻止。要解决此问题： 点击专用网络，例如我的家庭或工作网络。 点击允许访问。 要了解有关安全性和MongoDB的更多信息，请参阅“ 安全性文档”。 连接到MongoDB。 要将mongo.exeshell 连接到MongoDB实例，请打开另一个 具有管理权限的命令解释器，然后运行： 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongo.exe\" 有关连接mongo.exe shell 的更多信息，例如连接到在其他主机和/或端口上运行的MongoDB实例，请参阅mongo Shell。 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 将MongoDB企业版作为Windows服务启动 从版本4.0开始，您可以在安装过程中将MongoDB安装和配置为 Windows服务，并在成功安装后启动MongoDB服务。 要启动/重新启动MongoDB服务，请使用服务控制台： 在服务控制台中，找到MongoDB服务。 右键单击MongoDB服务，然后单击启动。 要开始使用MongoDB，请将mongo.exe shell 连接到正在运行的MongoDB实例。要进行连接，请打开具有管理权限的命令解释器并运行： 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongo.exe\" 有关连接mongo.exe shell 的更多信息，例如连接到在其他主机和/或端口上运行的MongoDB实例，请参阅mongo Shell。 有关CRUD（创建，读取，更新，删除）操作的信息，请参阅： 插入文档 查询文档 更新文档 删除文档 您也可以从命令行手动管理服务。要从命令行启动MongoDB服务，请以管理员身份打开Windows命令提示符/解释器（cmd.exe），然后运行以下命令： 启动MongoDB服务。 关闭所有其他命令提示符，然后调用以下命令： 复制 net start MongoDB 验证MongoDB已成功启动。 检查您的MongoDB日志文件是否存在以下行： [initandlisten] waiting for connections on port 27017 您可能会在过程输出中看到非严重警告。只要您在MongoDB日志中看到此消息，就可以在对MongoDB进行初始评估时安全地忽略这些警告。 连接到MongoDB服务器。 要通过mongo.exe shell 连接到MongoDB ，请打开另一个Command Interpreter。 复制 \"C:\\Program Files\\MongoDB\\Server\\4.2\\bin\\mongo.exe\" 将企业版MongoDB作为Windows服务停止 要停止/暂停MongoDB服务，请使用服务控制台： 在服务控制台中，找到MongoDB服务。 右键单击MongoDB服务，然后单击“ 停止”（或“ 暂停”）。 您也可以从命令行管理服务。要从命令行停止MongoDB服务，请以管理员身份打开Windows命令提示符/解释器（cmd.exe），然后运行以下命令： 复制 net stop MongoDB 将企业版MongoDB作为Windows服务删除 要删除MongoDB服务，请首先使用服务控制台停止该服务。然后以管理员身份打开Windows命令提示符/解释器 （cmd.exe），然后运行以下命令： 复制 sc.exe delete MongoDB 其他注意事项 默认为localhost绑定 默认情况下，MongoDB在启动时将bindIp设置为 127.0.0.1，该绑定到localhost网络接口。这意味着mongod.exe只能接受来自同一计算机上运行的客户端的连接。除非将此值设置为有效的网络接口，否则远程客户端将无法连接到mongod.exe，并且mongod.exe不能初始化副本集。 可以配置以下值： 在MongoDB配置文件中使用bindIp，或 通过命令行参数 --bind_ip 警告 绑定到非本地主机（例如，可公共访问）的IP地址之前，请确保已保护群集免受未经授权的访问。有关安全建议的完整列表，请参阅“ 安全清单”。至少应考虑 启用身份验证并 强化网络基础架构。 有关配置bindIp的更多信息，请参见 IP绑定。 点发布和.msi 如果您使用Windows安装程序（.msi）安装了MongoDB ，它将.msi在其发行系列（例如4.2.1到4.2.2）中自动升级。 升级完整版本系列（例如4.0至4.2）需要重新安装。 将MongoDB二进制文件添加到系统路径 本教程中的所有命令行示例均作为MongoDB二进制文件的绝对路径提供。您可以添加C:\\Program Files\\MongoDB\\Server\\4.2\\bin到系统路径中，然后省略MongoDB二进制文件的完整路径。 原文链接：https://docs.mongodb.com/v4.2/tutorial/install-mongodb-enterprise-on-windows/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/03-install-mongodb-enterprise-on-windows/01-install-mongodb-enterprise-on-windows-unattended.html":{"url":"02-installation/02-install-enterprise/03-install-mongodb-enterprise-on-windows/01-install-mongodb-enterprise-on-windows-unattended.html","title":"Install using msiexec.exe","keywords":"","body":" Install using msiexec.exe ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Install using msiexec.exe Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/02-install-enterprise/04-install-mongodb-enterprise-with-docker.html":{"url":"02-installation/02-install-enterprise/04-install-mongodb-enterprise-with-docker.html","title":"Install with Docker","keywords":"","body":" 使用Docker安装MongoDB企业版 重要 将容器与MongoDB结合使用的推荐解决方案是： 为了进行开发和测试，请使用 MongoDB社区Docker容器。 对于MongoDB企业版生产安装，请通过MongoDB Ops Manager使用Kubernetes 。 注意 此过程使用Docker的官方mongo image，该镜像由Docker社区而非 MongoDB支持。 如果以上推荐的解决方案无法满足您的需求，请按照本教程中的步骤手动将Docker 安装到 MongoDB企业版。 注意事项 Docker的完整描述超出了本文档的范围。本页面假定您具有Docker的先验知识。 本文档仅描述了如何在Docker上安装MongoDB企业版，并且不会替换Docker上的其他资源。我们鼓励您在将Docker安装到MongoDB 企业版之前，彻底熟悉Docker及其相关主题。 重要 此过程使用Docker的官方mongo image，该镜像由Docker社区而非 MongoDB支持。它仅支持在其存储库中列出的主要版本，只有每个主要版本有特定的次版本。次要版本可以在每个主要版本的文件夹中的Dockerfile中找到。 使用企业版MongoDB创建Docker镜像 下载用于企业版MongoDB的Docker构建文件。 安装 Docker并设置 Docker Hub帐户后， 使用以下命令从Docker Hub mongo项目下载构建文件 。设置MONGODB_VERSION为您选择的主要版本。 DOCKER HUB MONGO项目 MongoDB 不维护Docker Hub mongo项目。任何支持请求都应发送给Docker。 复制 export MONGODB_VERSION=4.0 curl -O --remote-name-all https://raw.githubusercontent.com/docker-library/mongo/master/$MONGODB_VERSION/{Dockerfile,docker-entrypoint.sh} 构建Docker容器。 使用下载的构建文件来创建围绕企业版MongoDB的Docker容器镜像。将您的Docker Hub用户名设置为DOCKER_USERNAME。 复制 export DOCKER_USERNAME=username chmod 755 ./docker-entrypoint.sh docker build --build-arg MONGO_PACKAGE=mongodb-enterprise --build-arg MONGO_REPO=repo.mongodb.com -t $DOCKER_USERNAME/mongo-enterprise:$MONGODB_VERSION . 测试您的镜像。 在Docker容器中本地运行mongod并检查版本，使用以下命令： 复制 docker run --name mymongo -itd $DOCKER_USERNAME/mongo-enterprise:$MONGODB_VERSION docker exec -it mymongo /usr/bin/mongo --eval \"db.version()\" 这应该输出MongoDB的shell和服务器版本。 将镜像推送到Docker Hub （可选）您可以将Docker镜像推送到远程存储库（例如Docker Hub），以在其他主机上使用该镜像。如果将镜像推送到Docker Hub，则可以在要通过Docker安装企业版MongoDB的每台主机上运行docker pull。有关使用docker pull的完整指导，请在此处参考其文档 。 检查您的本地镜像。 以下命令显示您的本地Docker镜像： 复制 docker images 您应该在命令输出中看到您的企业版MongoDB镜像。如果不这样做，请尝试使用企业版MongoDB创建Docker镜像。 推送至Docker Hub。 将您的本地企业版MongoDB镜像推送到您的远程Docker Hub帐户。 复制 docker login docker push $DOCKER_USERNAME/mongo-enterprise:$MONGODB_VERSION 如果您登录Docker Hub站点，则应该看到存储库下面列出的镜像。 原文链接：https://docs.mongodb.com/v4.2/tutorial/install-mongodb-enterprise-with-docker/ 译者：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/03-upgrade-community-to-enterprise.html":{"url":"02-installation/03-upgrade-community-to-enterprise.html","title":"将社区版MongoDB升级到企业版MongoDB","keywords":"","body":" 将社区版MongoDB升级到企业版MongoDB MongoDB企业版提供了MongoDB社区版中未提供的各种功能，例如： 内存存储引擎 审计 Kerberos身份验证 LDAP代理身份验证和 LDAP授权 静态加密 本部分中的文档提供了从社区版MongoDB升级到企业版MongoDB的说明。 重要 不要使用这些说明升级到另一个发行版本。要升级发行版本，请参阅相应的发行升级说明，例如Upgrade to MongoDB 4.2。 部署方式 教程 单节点 升级到MongoDB Enterprise（单节点） 副本集 升级到MongoDB Enterprise（副本集） 分片集群 升级到MongoDB Enterprise（分片集群） ← 使用Docker安装企业版MongoDB升级到企业版MongoDB（单节点） → 原文链接：https://docs.mongodb.com/v4.2/administration/upgrade-community-to-enterprise/ 译者：小芒果 参见 原文 - Upgrade MongoDB Community to MongoDB Enterprise Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/03-upgrade-community-to-enterprise/01-upgrade-to-enterprise-standalone.html":{"url":"02-installation/03-upgrade-community-to-enterprise/01-upgrade-to-enterprise-standalone.html","title":"Upgrade to MongoDB Enterprise (Standalone)","keywords":"","body":" Upgrade to MongoDB Enterprise (Standalone) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade to MongoDB Enterprise (Standalone) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/03-upgrade-community-to-enterprise/02-upgrade-to-enterprise-replica-set.html":{"url":"02-installation/03-upgrade-community-to-enterprise/02-upgrade-to-enterprise-replica-set.html","title":"Upgrade to MongoDB Enterprise (Replica Set)","keywords":"","body":" Upgrade to MongoDB Enterprise (Replica Set) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade to MongoDB Enterprise (Replica Set) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"02-installation/03-upgrade-community-to-enterprise/03-upgrade-to-enterprise-sharded-cluster.html":{"url":"02-installation/03-upgrade-community-to-enterprise/03-upgrade-to-enterprise-sharded-cluster.html","title":"Upgrade to MongoDB Enterprise (Sharded Cluster)","keywords":"","body":" Upgrade to MongoDB Enterprise (Sharded Cluster) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade to MongoDB Enterprise (Sharded Cluster) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo.html":{"url":"03-mongo.html","title":"Mongo Shell","keywords":"","body":" The mongo Shell 在本页面 启动mongo Shell并连接到MongoDB 使用mongo Shell 制表符完成和其他键盘快捷键 mongorc.js文件 退出Shell mongo shell是MongoDB的交互式JavaScript接口。您可以使用mongo shell查询和更新数据以及执行管理操作。 mongo shell作为MongoDB Server安装的一部分包含在内。 MongoDB还提供mongo shell作为独立软件包。如何下载独立的mongo shell软件包： 1.打开下载中心。对于mongo Enterprise Shell，选择MongoDB Enterprise Server选项卡。 2.从下拉列表中选择您的首选版本和操作系统。 3.选择要根据您的系统下载的安装包： 系统 下载包 Win 选择ZIP以下载包含mongo shell的安装包 Mac 选择TGZ以下载包含mongo shell的安装包 Linux 选择shell以下载包含mongo shell的安装包 安装并启动MongoDB之后，将mongo shell连接到正在运行的MongoDB实例。 启动mongo Shell并连接到MongoDB 前提条件 在尝试启动mongo shell之前，请确保MongoDB正在运行。 打开终端窗口（或Windows的命令提示符），然后转/bin 目录。 cd /bin [success] Note 将 / bin添加到PATH环境变量中，可以键入mongo，而不必转到 / bin目录或指定二进制文件的完整路径。 默认端口上的本地MongoDB实例 您可以在不使用任何命令行选项的情况下运行mongo shell，以使用默认端口27017连接到在本地主机上运行的MongoDB实例： mongo 非默认端口上的本地MongoDB实例 要显式指定端口，请包括--port命令行选项。例如，要使用非默认端口28015连接到在localhost上运行的MongoDB实例，请执行以下操作： 非默认端口上的本地MongoDB实例 要显式指定端口，请包括--port命令行选项。例如，要使用非默认端口28015连接到在localhost上运行的MongoDB实例，请执行以下操作： mongo --port 28015 远程主机上的MongoDB实例 要明确指定主机名或端口： 您可以指定一个连接字符串。例如：要连接到在远程主机上运行的MongoDB实例，请执行以下操作： mongo \"mongodb://mongodb0.example.com:28015\" 您可以使用命令行选项--host host>:port>。例如，要连接到在远程主机上运行的MongoDB实例，请执行以下操作： mongo --host mongodb0.example.com:28015 您可以使用--hosthost>和--port port> 命令行选项。例如，要连接到在远程主机上运行的MongoDB实例，请执行以下操作： mongo --host mongodb0.example.com --port 28015 具有身份验证的MongoDB实例 要连接到MongoDB实例，需要进行身份验证： 您可以在连接字符串中指定用户名，身份验证数据库以及可选的密码。例如：以alice用户身份连接并认证到远程MongoDB实例： [success] Note 如果未在连接字符串中指定密码，则shell程序将提示您输入密码。 mongo \"mongodb://alice@mongodb0.examples.com:28015/?authSource=admin\" 您可以使用--usernameuser> 和--password, --authenticationDatabase 命令行选项。 例如，以alice用户身份连接并认证到远程MongoDB实例： [success] Note 如果您指定--password而不输入用户密码，则shell程序将提示您输入密码。 mongo --username alice --password --authenticationDatabase admin --host mongodb0.examples.com --port 28015 连接到MongoDB复制集 要连接到复制集： 您可以在连接字符串中指定复制集名称和成员 mongo \"mongodb://mongodb0.example.com.local:27017,mongodb1.example.com.local:27017,mongodb2.example.com.local:27017/?replicaSet=replA\" 如果使用DNS Seedlist 链接格式，则可以指定连接字符串： mongo \"mongodb+srv://server.example.com/\" [success] Note 对于连接，使用+ srv连接字符串修饰符会自动将ssl选项设置为true。 您可以从 --host /:,:,... 命令行选项中指定复制集名称和成员。 例如，要连接到名为replA的复制集，请执行以下操作： mongo --host replA/mongodb0.example.com.local:27017,mongodb1.example.com.local:27017,mongodb2.example.com.local:27017 TLS/SSL 连接 关于TLS/SS连接： 您可以在连接字符串中指定ssl = true选项。 mongo \"mongodb://mongodb0.example.com.local:27017,mongodb1.example.com.local:27017,mongodb2.example.com.local:27017/?replicaSet=replA&ssl=true\" 如果使用DNS Seedlist 链接格式，则可以包括+srv连接字符串修饰符： mongo \"mongodb+srv://server.example.com/\" [success] Note 对于连接，使用+srv连接字符串修饰符会自动将ssl选项设置为true。 您可以指定--ssl命令行选项。 例如，要连接到名为replA的复制集，请执行以下操作： mongo --ssl --host replA/mongodb0.example.com.local:27017,mongodb1.example.com.local:27017,mongodb2.example.com.local:27017 另：有关连接示例中使用的选项以及其他选项的更多信息，请参阅(mongo参考和 启动mongo的示例)。 使用mongoShell 要显示您正在使用的数据库，请键入db： db 该操作应返回test 数据库名，这是默认数据库。 要切换数据库，请发出use db>帮助器，如以下示例所示： use 另请参见db.getSiblingDB()方法，以从当前数据库访问其他数据库，而无需切换当前数库上下文（即db）。 要列出用户可用的数据库，可使用：show dbs 您可以切换到不存在的数据库。首次将数据存储在数据库中（例如通过创建集合）时，MongoDB会创建数据库。 例如，以下代码在insertOne（）操作期间创建数据库myNewDatabase和集合 myCollection： use myNewDatabase db.myCollection.insertOne( { x: 1 } ); 是mongo shell中可用的方法之一。 db是指当前数据库。 myCollection是集合的名称。 如果mongo shell不接受集合的名称，则可以使用替代的 db.getCollection()语法。例如，如果集合名称包含空格或连字符，以数字开头或与内置函数冲突： db.getCollection(\"3 test\").find() db.getCollection(\"3-test\").find() db.getCollection(\"stats\").find() mongo shell提示符每行的限制为4095个字符（code points）。 如果您输入的行中包含4095个以上的字符（code points），则Shell将截断它。 有关mongo shell中MongoDB基本操作的更多文档，请参阅： Getting Started Guide Insert Documents Query Documents Update Documents Delete Documents mongo Shell Methods 如果部署使用访问控制运行，则该操作将根据用户权限返回不同的值。 有关详细信息，请参见listDatabases Behavior。 格式化打印结果 db.collection.find()方法是用于从集合中检索文档的JavaScript方法。 db.collection.find()方法将游标返回到结果。 但是，在mongo shell中，如果未使用var关键字将返回的游标分配给变量，则该游标会自动迭代最多20次，来打印与查询匹配的前20个文档。 mongo shell将提示 输入it以使其再次迭代20次。 要格式化打印结果，可以将.pretty()添加到操作中，如下所示： db.myCollection.find().pretty() 此外，您可以在mongo shell中使用以下显式打印方法： print() to print without formatting print(tojson()) to print with JSON formatting and equivalent to printjson() printjson() to print with JSON formatting and equivalent to print(tojson()) 有关在mongo shell中处理光标的更多信息和示例，请参阅terate a Cursor in the mongo。 另请参阅Cursor Help ，以获取mongo shell中的游标帮助列表。 mongo Shell中的多行操作 如果您以开括号（'（'），大括号（'{'）或开括号（'['）结束一行，则后续行以省略号（“ ...”）开头，直到您 输入相应的右括号（'）'，右括号（'}'）或右括号（']'）。 mongo shell在评估代码之前等待右括号，右括号或右括号，如以下示例所示： >if ( x > 0 ) { ... count++; ... print (x); ... } 如果输入两个空行，则可以退出行继续模式，如以下示例所示： > if (x > 0 ... ... > 制表符完成和其他键盘快捷键 shell支持键盘快捷键。 例如： 使用向上/向下箭头键滚动浏览命令历史记录。有关.dbshell文件的更多信息，请参见.dbshell 文档。 使用Tab>来自动完成或列出完成可能性，如以下示例中所示，该示例使用Tab>来完成以字母'c'开头的方法名称： db.myCollection.c 因为有许多以字母'c'开头的收集方法，所以Tab>将列出以'c'开头的各种方法。 有关快捷键的完整列表，请参见：Shell 快捷命令（Shell Keyboard Shortcuts）。 mongorc.js文件 启动时，mongo将在用户的HOME目录中检查名为.mongorc.js的JavaScript文件。 如果找到，mongo会在首次显示提示之前解释.mongorc.js的内容。如果您使用舍shell程序来评估JavaScript文件或表达式，或者通过在命令行上使用--eval选项，或者通过将.js文件指定给mongo，则mongo将在JavaScript完成处理后读取.mongorc.js文件。 您可以使用--norc选项防止加载.mongorc.js。 退出Shell 要退出shell，请键入quit（）或使用 快捷方式。 另可参考： Getting Started Guide mongo Reference Page 译者：王恒 金江 校对：杨帅 参见 原文 - The mongo Shell Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo/01-configure-mongo-shell.html":{"url":"03-mongo/01-configure-mongo-shell.html","title":"配置mongo Shell","keywords":"","body":" 配置mongo Shell 在本页面 自定义提示 在mongo shell中使用外部编辑器 改变mongo shell(batchSize) [success] Note 下面的文档是MongoDB服务器下载.中包含的mongo shell。有关新的MongoDB Shell ，mongosh的信息，请参考mongosh文档。 要了解这两种shell的区别，请参阅Comparison of the mongo Shell and mongosh. 自定义提示 您可以通过在 mongo shell中设置变量prompt来修改提示符的内容。prompt变量可以保存字符串和JavaScript代码。如果prompt包含一个返回字符串的函数，mongo 可以在每个提示符中显示动态信息。 您可以在.mongorc.js 文件中添加提示逻辑，以在每次启动mongo shell时设置提示。 自定义提示以显示操作数 例如，要使用当前会话中发出的操作数创建mongo shell提示，请在mongo shell中定义以下变量： cmdCount = 1; prompt = function() { return (cmdCount++) + \"> \"; } 提示将展示类似于以下内容： 1> 2> 3> 自定义提示以显示数据库和主机名 要以 @ $的形式创建mongo shell`提示，请定义以下变量： host = db.serverStatus().host; prompt = function() { return db+\"@\"+host+\"$ \"; } 提示将类似于以下内容： test@myHost1$ 自定义提示以显示时间和文档计数 要创建一个包含系统正常运行时间和当前数据库中文档数的mongo shell提示，请在mongo shell中定义以下提示变量： prompt = function(){ return \"Uptime:\"+db.serverStatus().uptime+\" Documents:\"+db.stats().objects+\" > \"; } 提示符将类似于以下内容： Uptime:5897 Documents:6 > 在mongo shell中使用外部编辑器 您可以通过在启动mongo shell之前设置EDITOR 环境变量，这样就可以在 mongo shell中使用自己的编辑器。 export EDITOR=vim mongo 进入mongo shell后，您可以通过输入edit variable>或edit function>使用指定的编辑器进行编辑，如以下示例所示： 1.定义一个函数myFunction： function myFunction () { } 2.使用编辑器编辑函数： edit myFunction 该命令将打开vim编辑会话。 完成编辑后，保存并退出vim编辑会话。 3.在mongo shell中，键入myFunction以查看函数定义： myFunction 展示的是已经保存编辑后的结果: function myFunction() { print(\"This was edited\"); } [success] Note 当mongo shell解释在外部编辑器中编辑的代码时，它可能会修改函数中的代码，具体取决于JavaScript编译器。 例如，mongo可以将1 + 1转换为2或删除注释。 实际更改仅影响代码的外观，并且会根据所使用的JavaScript版本而有所不同，但不会影响代码的语义。 改变mongo shell(batchSize) db.collection.find()方法是用于从集合中检索文档的JavaScript方法。db.collection.find()方法将游标返回到结果。 但是，在mongo shell中，如果未使用var关键字将返回的游标分配给变量，则该游标会自动迭代最多20次，来打印与查询匹配的前20个文档。 mongo shell将提示 输入it以使其再次迭代20次。 您可以设置DBQuery.shellBatchSize属性，以更改文档数默认值20，如以下示例中将其设置为10： DBQuery.shellBatchSize = 10; 译者：王恒 金江 校对：杨帅 参见 原文 - Configure the mongo Shell Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo/02-access-mongo-shell-help.html":{"url":"03-mongo/02-access-mongo-shell-help.html","title":"使用 mongo Shell帮助","keywords":"","body":" 使用 mongo Shell帮助 在本页面 命令行帮助 shell帮助 数据库帮助 表级别帮助 游标级别帮助 包装对象帮助 [success] Note 下面的文档是MongoDB服务器下载.中包含的mongo shell。有关新的MongoDB Shell ，mongosh的信息，请参考mongosh文档。 要了解这两种shell的区别，请参阅Comparison of the mongo Shell and mongosh. 除了《 MongoDB中文手册》中的文档外，mongo shell在其“在线”帮助系统中提供了一些其他信息。 本文档概述了访问此帮助信息的过程。 命令行帮助 要查看选项列表和启动mongo shell相关的帮助，请从命令行使用--help选项： mongo --help Shell帮助 当需要查看帮助列表时，请在mongoshell中键入help ： help 数据库帮助 在mongo shell中： 当需要查看服务器上的数据库列表，请使用show dbs命令： show dbs show database是show dbs的别名 当需要查看可在db对象上使用的方法的帮助列表，请调用db.help()方法： db.help() 当需要查看在 shell中查看某些方法的具体实现，请键入不带括号(())的db.，如以下示例所示，它将返回方法db.updateUser()的实现： db.updateUser 如果部署使用访问控制运行，则该操作将根据用户权限返回不同的值。 有关详细信息，请参见listDatabases行为。 表级别帮助 在mongo shell中： 要查看当前数据库中的集合列表，请使用show collections命令： show collections 另可参考：show collections 要查看收集对象上可用方法的帮助（例如db.），请使用db..help()方法： db.collection.help() 可以是存在的集合的名称，尽管您可以指定不存在的集合。 要查看收集方法的实现，请键入不带括号(())的db..名称，如以下示例所示，它将返回save()方法的实现： db.collection.save 游标相关帮助 在mongo shell中使用find()方法执行读取操作时，可以使用各种游标方法来修改find()行为，并可以使用各种JavaScript方法来处理从find()方法返回的游标。 要列出可用的修饰符和游标处理方法，请使用db.collection.find().help()命令： db.collection.find().help() 可以是存在的集合的名称，尽管您可以指定不存在的集合。 要查看cursor方法的实现，请输入不带括号(())的db..find().名称，如以下示例所示，它将返回toArray()方法的实现： db.collection.find().toArray 处理游标的一些有用方法是: hasNext()检查光标是否还有更多文档要返回。 next()返回下一个文档，并将光标位置向前移动一个。 迭代整个游标，并将应用于光标返回的每个文档。期望一个参数，该参数对应于每次迭代的文档。 有关迭代游标和从游标中检索文档的示例，请参见 cursor handling。有关所有可用的游标方法，另请参见Cursor。 包装对象帮助 要获取mongo shell中可用的包装器类的列表，例如BinData()，请在mongo shell中键入help misc： help misc 另可参考：mongo Shell Methods 译者：王恒 金江 校对：杨帅 参见 原文 - Access the mongo Shell Help Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo/03-write-scripts-for-the-mongo-shell.html":{"url":"03-mongo/03-write-scripts-for-the-mongo-shell.html","title":"为mongo Shell编写脚本","keywords":"","body":" 为mongo Shell编写脚本 在本页面 打开新连接 交互式mongo与脚本mongo的区别 脚本编写 [success] Note 下面的文档是MongoDB服务器下载.中包含的mongo shell。有关新的MongoDB Shell ，mongosh的信息，请参考mongosh文档。 要了解这两种shell的区别，请参阅Comparison of the mongo Shell and mongosh. 您可以为mongo shell编写JavaScript 的脚本，来处理MongoDB中的数据或执行管理操作。 本章节介绍了通过mongo shell编写的JavaScript的方法 来访问 Mongodb的方式。 打开新连接 在mongo shell或JavaScript文件中，您可以使用Mongo()构造函数实例化数据库连接： Mongo() new Mongo() new Mongo() 请考虑以下示例，该示例实例化与在默认端口上的localhost上运行的MongoDB实例的新连接，并使getDB()方法将全局db变量设置为myDatabase： conn = new Mongo(); db = conn.getDB(\"myDatabase\"); 如果连接到已经开启了访问控制的MongoDB实例，则可以使用db.auth() 方法进行身份验证。此外，您可以使用connect()方法连接到MongoDB实例。 以下示例使用非默认端口27020连接到在localhost上运行的MongoDB实例，并设置全局db变量： db = connect(\"localhost:27020/myDatabase\"); 另可参考：mongo Shell Methods 交互式mongo与脚本mongo的区别 [success] Note 从4.2版开始，mongo shell提供了isInteractive() 方法，该方法返回一个布尔值，该值指示mongo shell是在交互模式还是脚本模式下运行。 为mongo shell编写脚本时，请考虑以下事项： 要设置db全局变量，请使用getDB() 方法或onnect()方法。您可以将数据库引用分配给db以外的其他变量。 mongo shell中的写操作默认情况下使用{ w: 1 }的写入策略。 如果执行批量操作，请使用Bulk()方法。 有关更多信息，请参见：Write Method Acknowledgements）。 您不能在JavaScript文件中使用任何shell帮助程序（例如，使用，show dbs等），因为它们不是有效的JavaScript。下表将最常见的mongo shell助手映射到其JavaScript等效项： Shell帮助 等价JavaScript show dbs, show databases db.adminCommand('listDatabases') use db = db.getSiblingDB('') show collections db.getCollectionNames() show users db.getUsers() show roles db.getRoles({showBuiltinRoles: true}) show log db.adminCommand({ 'getLog' : '' }) show logs db.adminCommand({ 'getLog' : '*' }) it cursor = db.collection.find()if ( cursor.hasNext() ){ cursor.next();} 在交互模式下， mongo 打印操作结果，包括所有游标的内容。 在脚本中，使用JavaScript print()函数或 mongo 特定的printjson()函数，该函数返回格式化的JSON。 例子: 要在mongo shell脚本中打印结果游标中的所有项目，请使用以下惯用法： cursor = db.collection.find(); while ( cursor.hasNext() ) { printjson( cursor.next() ); } 脚本编写 在系统提示下，使用mongo 评估JavaScript。 --eval选项 使用--eval选项 让Mongo来执行一个JavaScript片段，如下所示： mongo test --eval \"printjson(db.getCollectionNames())\" 这将使用连接到在本地主机接口上的端口27017上运行的mongod 或mongos实例的mongo shell返回db.getCollectionNames() 的输出。 执行一个JavaScript文件 您可以在mongo shell中指定.js文件，然后mongo将直接执行JavaScript。 考虑以下示例： mongo localhost:27017/test myjsfile.js 此操作在mongo shell中执行myjsfile.js脚本，该脚本连接到可通过端口27017上的localhost接口访问的mongod实例上的测试数据库。或者，您可以使用Mongo()构造函数在javascript文件中指定mongodb连接参数。 有关更多信息，请参见：打开新连接 。 您可以使用load()函数从mongo shell中执行.js文件，如下所示： load(\"myjstest.js\") 此函数加载并执行myjstest.js文件。 load()方法接受相对路径和绝对路径。 如果mongo shell的当前工作目录为/ data / db，而myjstest.js位于/ data / db / scripts目录中，则mongo shell中的以下调用将是等效的： load(\"scripts/myjstest.js\") load(\"/data/db/scripts/myjstest.js\") [success] Note load（）函数没有搜索路径。 如果所需的脚本不在当前工作目录或完整的指定路径中，则mongo将无法访问该文件。 译者：王恒 校对：杨帅 参见 原文 - Write Scripts for the mongo Shell Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo/04-shell-types.html":{"url":"03-mongo/04-shell-types.html","title":"mongo Shell中的数据类型","keywords":"","body":" mongo Shell中的数据类型 在本页面 类型 Date ObjectId NumberLong NumberInt NumberDecimal 在mongo Shell中检查类型 instanceof typeof [success] Note 下面的文档是MongoDB服务器下载.中包含的mongo shell。有关新的MongoDB Shell ，mongosh的信息，请参考mongosh文档。 要了解这两种shell的区别，请参阅Comparison of the mongo Shell and mongosh. **MongoDB BSON 支持除JSON本身支持类型之外的其他数据类型。 驱动程序以宿主语言为这些数据类型提供本机支持，而mongoshell还提供了一些帮助程序类来支持在mongo JavaScript shell中使用这些数据类型。 有关更多信息，请参阅Extended JSON引用。 类型 Date mongo shell提供了多种返回日期的方法，这些方法可以是字符串，也可以是Date对象： Date() 方法，以字符串形式返回当前日期。 new Date() 构造函数，该构造函数使用ISODate()包装器返回Date对象。 ISODate() 构造函数，该构造函数使用ISODate()包装器返回Date对象。 ​ 在内部，Date对象存储为带符号的64位整数，表示自Unix纪元（1970年1月1日）以来的毫秒数。 并非所有的数据库操作和驱动程序都支持完整的64位范围。 您可以安全地处理年份，年份范围在0到9999之间。以字符串类型返回日期 以字符串类型返回日期，要用到Data()方法，如下所示： var myDateString = Date(); 要打印变量的值，请在shell中键入变量名称，如下所示： myDateString myDataString值的结果如下： Wed Dec 19 2012 01:03:25 GMT-0500 (EST) 要验证类型，请使用typeof运算符，如下所示： typeof myDateString 该操作返回值为 String Return Date mongo shell使用ISODate帮助程序包装Date类型的对象； 但是，对象仍为日期类型。 下面的示例使用新的Date()构造函数和ISODate()构造函数来返回Date对象。 var myDate = new Date(); var myDateInitUsingISODateWrapper = ISODate(); 您也可以将new运算符与ISODate()构造函数一起使用。要打印变量的值，请在shell中键入变量名称，如下所示： myDate 结果是包装在ISODate() 帮助器中的myDate的Date值： ISODate(\"2012-12-19T06:01:17.171Z\") 要验证类型，请使用instanceof运算符，如下所示： myDate instanceof Date myDateInitUsingISODateWrapper instanceof Date 这两个操作均返回true ObjectID mongo shell提供了围绕ObjectId 数据类型的ObjectId()封装类。 要生成新的ObjectId，请在mongo shell中使用以下操作： new ObjectId 参考：ObjectId NumberLong mongo shell默认情况下会将所有数字视为浮点型。mongo shell提供了NumberLong() 包装器来处理64位整数。 NumberLong() 封装接受long作为字符串： NumberLong(\"2090845886852\") 以下示例使用NumberLong（）的封装写入集合： db.collection.insertOne( { _id: 10, calc: NumberLong(\"2090845886852\") } ) db.collection.updateOne( { _id: 10 }, { $set: { calc: NumberLong(\"2555555000000\") } } ) db.collection.updateOne( { _id: 10 }, { $inc: { calc: NumberLong(5) } } ) 检索文档以验证： db.collection.findOne( { _id: 10 } ) 在返回的文档中，calc字段包含一个NumberLong对象： { \"_id\" : 10, \"calc\" : NumberLong(\"2555555000005\") } 如果使用$inc通过浮点数递增包含NumberLong对象的字段的值，则数据类型将更改为浮点值，如以下示例所示： 1.使用$inc 将calc字段增加 5，mongo shell将其视为浮点数： db.collection.updateOne( { _id: 10 }, { $inc: { calc: 5 } } ) 2.检索更新的文档： db.collection.findOne( { _id: 10 } ) 在更新的文档中，calc字段包含一个浮点值： { \"_id\" : 10, \"calc\" : 2555555000010 } NumberInt mongo shell默认情况下会将所有数字视为浮点值。 mongo shell提供NumberInt()构造函数来显式指定32位整数。 NumberDecimal 始于3.4版本mongo shell默认将所有数字视为64位浮点双精度值。 mongo shell提供了NumberDecimal()构造函数来显式指定基于128位的基于十进制的浮点值，该值能够精确地模拟十进制舍入。 此功能适用于处理货币数据的应用程序，例如金融、税收和科学计算。十进制BSON类型使用IEEE 754十进制128浮点编号格式，该格式支持34个十进制数字（即有效数字）和-6143至+6144的指数范围。NumberDecimal（）构造函数接受十进制值作为字符串： NumberDecimal(\"1000.55\") 该值存储在数据库中，如下所示： NumberDecimal(\"1000.55\") NumberDecimal()构造函数还接受mongo shell中的双精度值（即不带引号），尽管不建议这样做，因为这样做可能会丢失精度。 构造函数创建基于二进制的双精度表示形式的基于十进制的参数（可能会丢失精度），然后将该值转换为精度为15位数字的十进制值。 下面的示例隐式地将值作为双精度值传递，并显示如何以15位精度创建值： NumberDecimal(1000.55) 该值存储在数据库中，如下所示： NumberDecimal(\"1000.55000000000\") 下面的示例隐式地将该值作为双精度值传递，并说明如何发生精度损失： NumberDecimal(9999999.4999999999) 该值存储在数据库中，如下所示： NumberDecimal(\"9999999.50000000\") [success] Note 要将十进制数据类型与MongoDB驱动程序一起使用，请确保使用支持该格式的驱动程序版本。 相等和排序顺序 比较十进制类型的值，并根据其实际数字值与其他数字类型进行排序。 基于二进制的double类型的数值通常具有基于十进制值的近似表示，并且可能不完全等于其十进制表示，因此在检查十进制值的相等性时，请使用NumberDecimal()构造函数。 考虑以下示例以及带有数字集合中的以下文档： { \"_id\" : 1, \"val\" : NumberDecimal( \"9.99\" ), \"description\" : \"Decimal\" } { \"_id\" : 2, \"val\" : 9.99, \"description\" : \"Double\" } { \"_id\" : 3, \"val\" : 10, \"description\" : \"Double\" } { \"_id\" : 4, \"val\" : NumberLong(10), \"description\" : \"Long\" } { \"_id\" : 5, \"val\" : NumberDecimal( \"10.0\" ), \"description\" : \"Decimal\" } 将下表中的查询插入db.numbers.find（）方法时，将返回以下结果： 查询 结果 { “val”: 9.99 } { “_id”: 2, “val”: 9.99, “description”: “Double” } { “val”: NumberDecimal( “9.99” ) } { “_id”: 1, “val”: NumberDecimal( “9.99” ), “description”: “Decimal” } { val: 10 } { “_id”: 3, “val”: 10, “description”: “Double” }{ “_id”: 4, “val”: NumberLong(10), “description”: “Long” }{ “_id”: 5, “val”: NumberDecimal( “10.0” ), “description”: “Decimal” } { val: NumberDecimal( “10” ) } { “_id”: 3, “val”: 10, “description”: “Double” }{ “_id”: 4, “val”: NumberLong(10), “description”: “Long” }{ “_id”: 5, “val”: NumberDecimal( “10.0” ), “description”: “Decimal” } 第一个查询 {“ val”：9.99} 隐式搜索9.99的双精度表示形式，该表示形式不等于该值的十进制表示形式。 NumberDecimal() 构造函数用于查询以9.99十进制表示的文档。 排除双精度类型的值，因为它们与9.99的十进制表示形式的确切值不匹配。 查询整数时，将返回所有数字类型的匹配值。 例如，查询10的双精度表示将在结果中包含10.0的十进制表示，反之亦然。 检查十进制类型 要测试十进制类型，请使用$type运算符，其字符串别名为“decimal”或19（十进制类型的数字代码）。 db.inventory.find( { price: { $type: \"decimal\" } } ) 在mongo Shell中检查类型 为了确定字段的类型，mongo shell提供了instanceof和typeof运算符。 instanceof instanceof返回一个布尔值，以测试值是否是某种类型的实例。 例如，以下操作测试_id字段是否为ObjectId类型的实例： mydoc._id instanceof ObjectId 该操作返回true。 typeof typeof返回字段的类型。 例如，以下操作返回_id字段的类型： typeof mydoc._id 在这种情况下，typeof将返回更通用的object 类型，而不是ObjectId类型。 译者：王恒 校对：杨帅 参见 原文 - Data Types in the mongo Shell Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"03-mongo/05-mongo-shell.html":{"url":"03-mongo/05-mongo-shell.html","title":"mongo Shell 快速参考","keywords":"","body":" mongo Shell 快速参考 在本页面 mongo Shell命令历史 命令行选项 命令助手 Shell基本JavaScript操作 键盘快捷键 查询 错误检查方法 行政命令助手 打开其他连接 多样式 其他资源 [success] Note 下面的文档是MongoDB服务器下载.中包含的mongo shell。有关新的MongoDB Shell ，mongosh的信息，请参考mongosh文档。 要了解这两种shell的区别，请参阅Comparison of the mongo Shell and mongosh. mongo Shell命令历史 您可以使用上下箭头键检索在 mongo shell中发布的先前命令。 命令历史记录存储在〜/ .dbshell文件中。 有关更多信息，请参见.dbshell 。 命令行选项 mongo shell可以使用许多选项启动。 有关所有可用选项的详细信息，请参见mongo shell 页面。 下表显示了mongo的一些常用选项： 选项 说明 --help 显示命令行选项 --nodb 在不连接数据库的情况下启动mongo shell。要稍后连接，请参阅Opening New Connections。 --shell 与JavaScript文件（即file.js>]）结合使用，以在运行JavaScript文件后在mongo shell中继续。有关示例，请参见 JavaScript file。 命令助手 mongoshell提供了各种帮助。下表显示了一些常见的帮助方法和命令： 帮助方法和命令 描述 help() 打印当前数据库的列表 db.help() 打印当前数据库的所有角色的列表，包括用户定义的角色和内置角色。 db..help() 打印耗时1毫秒或更长时间的五个最新操作。 有关更多信息，请参见数据库分析器上的文档。 show dbs 打印所有可用数据库的列表。该操作对应于listDatabases命令。 如果部署使用访问控制运行，则该操作将根据用户权限返回不同的值。 有关详细信息，请参见 listDatabases。 usedb> 将当前数据库切换到db>。 mongo shell变量db设置为当前数据库。 show collections 打印当前数据库的所有集合的列表。另可参考：show collections show users 打印当前数据库列表 show roles 打印当前数据库的所有角色的列表，包括用户定义角色和内置角色。 show profile 打印耗时1毫秒或更长时间的五个最新操作。 有关更多信息，请参见 database profiler。 show databases 打印所有可用数据库的列表。该操作对应于 listDatabases 命令。 如果部署使用访问控制运行，则该操作将根据用户权限返回不同的值。 有关详细信息，请参见 listDatabases。 load() 执行一个JavaScript文件。 有关更多信息，请参见 Write Scripts for the mongo Shell。 Shell基本JavaScript操作 mongo shell提供了用于数据库操作的JavaScript API 。 在mongo shell中，db是引用当前数据库的变量。该变量自动设置为默认数据库测试，或者在use db>切换当前数据库时设置。 下表显示了一些常见的JavaScript操作： JavaScript数据库操作 说明 db.auth() 如果以安全模式运行，请对用户进行身份验证。 coll = db.collection> 将当前数据库中的特定集合设置为变量coll，如以下示例所示：coll = db.myCollection;您可以使用变量在myCollection上执行操作，如以下示例所示：coll.find(); db.collection.find() 查找集合中的所有文档并返回一个游标。有关更多信息和示例，请参见db.collection.find（）和查询文档。有关在mongo shell中处理游标的信息，请参阅在mongo Shell中迭代游标。 db.collection.insertOne() 将新文档插入集合中。 db.collection.insertMany() 将多个新文档插入集合中。 db.collection.updateOne() 更新集合中的单个现有文档。 db.collection.updateMany() 更新集合中的多个现有文档。 db.collection.save() 插入新文档或更新集合中的现有文档。 db.collection.deleteOne() 从集合中删除单个文档。 db.collection.deleteMany() 从集合中删除多个文档 db.collection.drop() 完全删除或除去集合。 db.collection.createIndex() 如果索引不存在，则在集合上创建一个新索引；否则，该操作无效。 db.getSiblingDB() 使用相同的连接返回对另一个数据库的引用，而无需显式切换当前数据库。 这允许跨数据库查询。 有关在shell中执行操作的更多信息，请参见： MongoDB CRUD Operations mongo Shell Methods 键盘快捷键 shell提供了大多数键盘快捷键，类似于bash shell或Emacs中的快捷键。 对于某些功能，mongo 提供了多个键绑定，以适应几种熟悉的范例。 下表列举了 mongo shell支持的按键： 按键 功能 Up-arrow 以前的历史 Down-arrow 下一个历史 Home 行起点 End 行尾 Tab 自动完成 Left-arrow 后退字符 Right-arrow 向前字符 Ctrl-left-arrow 后向词 Ctrl-right-arrow 前向词 Meta-left-arrow 后向词 Meta-right-arrow 前向词 Ctrl-A 上线 Ctrl-B 向后字符 Ctrl-C 退出 Ctrl-D 删除字符（或退出） Ctrl-E 行结束 Ctrl-F 转发字符 Ctrl-G 中止 Ctrl-J 接受线 Ctrl-K 杀死线 Ctrl-L 清除屏幕 Ctrl-M 接受线 Ctrl-N 下一个历史记录 Ctrl-P 以前的历史记录 Ctrl-R 反向搜索历史 Ctrl-S 正向搜索历史 Ctrl-T 转置字符 Ctrl-U 丢弃Unix线 Ctrl-W Unix单词清除 Ctrl-Y 拉动 Ctrl-Z 挂起（作业控制在Linux中有效） Ctrl-H (i.e. Backspace) 向后删除字符 Ctrl-I (i.e. Tab) 完成 Meta-B 后退词 Meta-C 大写词 Meta-D 杀死命令 Meta-F 转发字 Meta-L 小写词 Meta-U 大写词 Meta-Y yank-pop Meta-[Backspace] 撤销杀死命令 Meta- 历史开始 Meta-> 历史结束 查询 在mongo shell中，使用find() 和findOne() 方法执行读取操作。find()方法返回一个游标对象，mongo shell对其进行迭代以在屏幕上打印文档。 默认情况下，mongo 打印前20个结果。mongo shell将提示用户“输入”以继续迭代接下来的20个结果。下表提供了mongo shell中的一些常见读取操作： 读取操作 说明描述 db.collection.find() 在集合中找到符合query>条件的文档。 如果未指定query>条件或该条件为空（即{}），则读取操作将选择集合中的所有文档。以下示例在用户集合中选择name字段等于“ Joe”的文档：coll = db.users;coll.find( { name: \"Joe\" } );有关指定query>条件的更多信息，请参见：Specify Equality Condition. db.collection.find(, ) 查找符合query>条件的文档，并仅返回projection>中的特定字段。以下示例从集合中选择所有文档，但仅返回名称字段和_id字段。 除非明确指定不返回，否则始终返回_id。coll = db.users;coll.find（{}，{name：true}）;有关指定projection>的更多信息，请参见Project Fields to Return from Query.。 db.collection.find().sort() 以指定的sort order>返回结果。以下示例从集合中选择所有文档，并返回按名称字段升序+1排序的结果。 使用-1降序：coll = db.users;coll.find（）。sort（{name：1}）; db.collection.find().sort( order>) 以指定的sort order>返回符合query>条件的文档。 db.collection.find( ... ).limit( ) 将结果限制为n>行。 如果只需要一定数量的行以获得最佳性能，则强烈建议使用。 db.collection.find( ... ).skip( ) 跳过n>个结果。 db.collection.count() 返回集合中的文档总数。 db.collection.find().count() 返回与查询匹配的文档总数。count()忽略limit()和skip().例如，如果有100条记录匹配，但限制为10，则count()将返回100。这比迭代自己的速度更快，但仍然需要时间。 db.collection.findOne() 查找并返回一个文档。 如果找不到，则返回null。以下示例在用户集合中选择一个名称与“ Joe”匹配的文档：coll = db.users;coll.findOne（{name：“ Joe”}）;在内部，findOne()方法是带有limit(1)的find()方法。 有关更多信息和示例，请参阅Query Documents 。 请参阅Query and Projection Operators。 错误检查方法 mongo shell write方法将Write Concern直接集成到方法执行中，并返回一个WriteResult()对象，该对象包含操作结果，包括所有写错误和写关注错误。 行政命令助手 下表列出了一些支持数据库管理的常用方法： JavaScript数据库管理 方法说明 db.fromColl.renameCollection() 将集合从fromColl重命名为toColl>。 请参阅Naming Restrictions。 db.getCollectionNames() 获取当前数据库中所有集合的列表。 db.dropDatabase() 删除当前数据库。 另请参见administrative database methods以获取方法的完整列表。 打开其他连接 您可以在mongo shell中创建新的连接。下表显示了创建连接的方法： JavaScript连接创建方法 说明 db = connect(\"host>/dbname>\") 打开一个新的数据库连接。 conn = new Mongo()db = conn.getDB(\"dbname\") 使用新的Mongo（）打开与新服务器的连接。使用连接的getDB（）方法选择数据库。 另请参阅 Opening New Connections以获取有关从mongo shell打开新连接的更多信息。 多样式 下表显示了一些其他方法： 方法 描述 Object.bsonsize(document>) Prints the BSON size of a document> in bytes 其他资源 考虑以下解决mongo shell及其接口的参考资料： mongo mongo Shell Methods Database Commands Aggregation Reference Getting Started Guide 另外，MongoDB源代码存储库包括一个jstests目录，该目录包含许多mongo shell脚本。 译者：王恒 校对：杨帅 参见 原文 - mongo Shell Quick Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud.html":{"url":"04-crud.html","title":"增删改查操作","keywords":"","body":"增删改查操作 在本页面 创建操作 读取操作 更新操作 删除操作 批量写入 CURD操作指的是文档的创建、读、更新以及删除操作。 创建操作 创建或插入操作会将新文档添加到集合中。 如果该集合当前不存在，则插入操作将创建该集合。 MongoDB提供以下将文档插入集合的方法： db.collection.insertOne() 3.2版中的新功能 db.collection.insertMany() 3.2版中的新功能 在MongoDB中，插入操作针对单个集合。 MongoDB中的所有写操作都是单个文档级别的原子操作。 有关示例，请参见插入文档。 读取操作 读取操作从集合中检索文档； 即查询集合中的文档。 MongoDB提供了以下方法来从集合中读取文档： db.collection.find() 您可以指定查询过滤器或条件以标识要返回的文档。 有关示例，请参见： 查询文件 查询嵌入/嵌套文档 查询数组 查询嵌入式文档数组 更新操作 更新操作会修改集合中的现有文档。 MongoDB提供了以下更新集合文档的方法： db.collection.updateOne() 3.2版中的新功能 db.collection.updateMany() 3.2版中的新功能 db.collection.replaceOne() 3.2版中的新功能 在MongoDB中，更新操作针对单个集合。 MongoDB中的所有写操作都是单个文档级别的原子操作。 您可以指定标准或过滤器，以标识要更新的文档。 这些过滤器使用与读取操作相同的语法。 有关示例，请参见更新文档。 删除操作 删除操作从集合中删除文档。 MongoDB提供以下删除集合文档的方法： db.collection.deleteOne() 3.2版中的新功能 db.collection.deleteMany() 3.2版中的新功能 在MongoDB中，删除操作只针对单个集合。MongoDB中的所有写操作都是单个文档级别的原子 操作。 你可以指定查询过滤器或条件来标识要更新的文档，这里的过滤器和读操作的语法是一致的。 有关示例，请参见删除文档。 批量写入 MongoDB提供了批量执行写入操作的功能。有关详细信息，请参见批量写入操作。 译者：刘翔 杨帅 校对：徐雷 杨帅 王恒 参见 原文 - MongoDB CRUD Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/01-insert-documents.html":{"url":"04-crud/01-insert-documents.html","title":"插入文档","keywords":"","body":" 插入文档 该页面提供了MongoDB中插入操作的示例。 建立集合 如果该集合当前不存在，则插入操作将创建该集合。 插入一个文件 db.collection.insertOne()将单个文档插入集合中。 以下示例将一个新文档插入库存集合。 如果文档未指定_id字段，则MongoDB将具有ObjectId值的_id字段添加到新文档中。 请参阅插入行为。 db.inventory.insertOne( { item: \"canvas\", qty: 100, tags: [\"cotton\"], size: { h: 28, w: 35.5, uom: \"cm\" } } ) insertOne()返回一个文档，其中包含新插入的文档的_id字段值。有关返回文档的示例，请参阅db.collection.insertOne() reference引用。 要检索刚刚插入的文档，查询集合: db.inventory.find( { item: \"canvas\" } ) 插入多个文件 3.2版中的新功能 db.collection.insertMany()可以将多个文档插入一个集合中。 将文档数组传递给该方法。 下面的示例将三个新文档插入库存集合。 如果文档未指定_id字段，则MongoDB向每个文档添加带有ObjectId值的_id字段。 请参阅 插入行为。 db.inventory.insertMany([ { item: \"journal\", qty: 25, tags: [\"blank\", \"red\"], size: { h: 14, w: 21, uom: \"cm\" } }, { item: \"mat\", qty: 85, tags: [\"gray\"], size: { h: 27.9, w: 35.5, uom: \"cm\" } }, { item: \"mousepad\", qty: 25, tags: [\"gel\", \"blue\"], size: { h: 19, w: 22.85, uom: \"cm\" } } ]) 返回包含新插入的文档_id字段值的文档。 有关示例，请参见参考。 要检索插入的文档，查询集合: db.inventory.find( {} ) 插入行为 集合创建 如果该集合当前不存在，则插入操作将创建该集合。 _id Field 在MongoDB中，存储在集合中的每个文档都需要一个唯一的_id字段作为主键。 如果插入的文档省略_id字段，则MongoDB驱动程序会自动为_id字段生成ObjectId。 这也适用于通过upsert：true通过更新操作插入的文档。 原子性 MongoDB中的所有写操作都是单个文档级别的原子操作。 有关MongoDB和原子性的更多信息，请参见原子性和事务. 写确认书 对于写入问题，您可以指定从MongoDB请求的写入操作的确认级别。 有关详细信息，请参见写关注。 另可参考： db.collection.insertOne() db.collection.insertMany() Additional Methods for Inserts 译者：杨帅 校对：杨帅 参见 原文 - Insert Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/01-insert-documents/01-insert-methods.html":{"url":"04-crud/01-insert-documents/01-insert-methods.html","title":"插入方法","keywords":"","body":" 插入方法 MongoDB 提供了以下方法将文件插入集合： db.collection.insertOne() 将单个文档插入到集合中。 db.collection.insertMany() db.collection.insertMany()将多个文件插入集合中。 db.collection.insert() db.collection.insert()将单个文档或多个文档插入到集合中。 插入的其他方法 以下方法还可以向集合中添加新文档： 与upsert: true选项一起使用时db.collection.update()。 与upsert: true选项一起使用时db.collection.updateOne()。 与upsert: true选项一起使用时db.collection.updateMany()。 与upsert: true选项一起使用时db.collection.findAndModify()。 与upsert: true选项一起使用时db.collection.findOneAndUpdate()。 与upsert: true选项一起使用时db.collection.findOneAndReplace()。 db.collection.save(). db.collection.bulkWrite(). 有关更多信息和示例，请参阅方法的各个 reference 页面。 译者：杨帅 校对：杨帅 参见 原文 - Insert Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents.html":{"url":"04-crud/02-query-documents.html","title":"查询文档","keywords":"","body":" 查询文档 这个页面提供了使用mongo shell中的db.collection.find()方法的查询操作示例。此页上的示例使用inventory集合。要填充inventory集合，请运行以下操作: db.inventory.insertMany([ { item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"A\" }, { item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }, { item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }, { item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" } ]); 选择集合中的所有文档 要选择集合中的所有文档，请将空文档作为查询过滤器参数传递给find方法。 查询过滤器参数确定选择条件： db.inventory.find( {} ) 此操作对应于以下SQL语句： SELECT * FROM inventory 有关该方法的语法的更多信息，请参见find()。 指定平等条件 要指定相等条件，请在查询筛选文档使用field>：value>表达式： { : , ... } 下面的示例从inventory中选择状态等于\" D\"的所有文档： db.inventory.find( { status: \"D\" } ) 此操作对应于以下SQL语句： SELECT * FROM inventory WHERE status = \"D\" 使用查询运算符指定条件 查询过滤器文档可以使用查询运算符以以下形式指定条件： { : { : }, ... } 下面的例子从状态等于\" A\"或\" D\"的inventory集合中检索所有文档: db.inventory.find( { status: { $in: [ \"A\", \"D\" ] } } ) [success] Note 尽管可以使用$or 操作符表示此查询，但在对同一字段执行相等性检查时，请使用 $in操作符而不是$or操作符。 该操作对应于以下SQL语句： SELECT * FROM inventory WHERE status in (\"A\", \"D\") 有关MongoDB查询运算符的完整列表，请参阅查询和投影运算符文档。 指定和条件 复合查询可以为集合文档中的多个字段指定条件。逻辑和连词隐式地连接复合查询的子句，以便查询在集合中选择符合所有条件的文档。 下面的示例 inventory 状态为\"A\"且数量小于($lt) 30的库存集合中的所有文档: db.inventory.find( { status: \"A\", qty: { $lt: 30 } } ) 该操作对应于以下SQL语句: SELECT * FROM inventory WHERE status = \"A\" AND qty 有关其他MongoDB比较运算符，请参阅比较运算符 。 指定或条件 使用$or操作符，可以指定一个复合查询，用逻辑OR连词连接每个子句，以便查询在集合中选择至少匹配一个条件的文档。 下面的示例retrieve状态为“A”或qty小于($lt)30的集合中的所有文档: db.inventory.find( { $or: [ { status: \"A\" }, { qty: { $lt: 30 } } ] } ) 该操作对应于以下SQL语句: SELECT * FROM inventory WHERE status = \"A\" OR qty [success] Note 使用比较运算符的查询需要使用括号类型。 指定和以及或条件 在下面的例子中，复合查询文档选择状态为“A”且qty小于($lt) 30或item以字符p开头的集合中的所有文档: db.inventory.find( { status: \"A\", $or: [ { qty: { $lt: 30 } }, { item: /^p/ } ] } ) 该操作对应于以下SQL语句: SELECT * FROM inventory WHERE status = \"A\" AND ( qty [success] Note MongoDB支持正则表达式$regex查询来执行字符串模式匹配。 附加查询教程 有关其他查询示例，请参见： Query on Embedded/Nested Documents Query an Array Query an Array of Embedded Documents Project Fields to Return from Query Query for Null or Missing Fields 行为 游标 db.collection.find()方法将游标 返回到匹配的文档。 读取隔离 3.2版中的新功能 对于复制集 和复制集分片的读取，读取关注允许客户端为其读取选择隔离级别。 有关更多信息，请参见阅读关注。 附加方法 以下方法也可以从集合中读取文档： db.collection.findOne 在聚合管道中，$match 管道步骤提供对MongoDB查询的访问. [success] Note db.collection.findOne()方法还执行读取操作以返回单个文档。在内部，db.collection.findOne()方法是 db.collection.find() 方法，限制为1。 译者：杨帅 校对：杨帅 参见 原文 - Query Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/01-query-embedded-documents.html":{"url":"04-crud/02-query-documents/01-query-embedded-documents.html","title":"查询嵌入/嵌套文档","keywords":"","body":" 查询嵌入/嵌套文档 本页提供使用mongo shell中的db.collection.find()方法对嵌入式/嵌套文档进行查询操作的示例。 此页面上的示例使用inventory收集。 要填充inventory收集，请运行以下命令： db.inventory.insertMany( [ { item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"A\" }, { item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }, { item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }, { item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" } ]); 匹配嵌入/嵌套文档 要在作为嵌入/嵌套文档的字段上指定相等条件，请使用查询筛选文档{field>：value>}，其中value>是要匹配的文档。 例如，以下查询选择字段大小等于文档{h：14，w：21，uom：“ cm”}的所有文档： db.inventory.find( { size: { h: 14, w: 21, uom: \"cm\" } } ) 整个嵌入式文档上的相等匹配要求与指定的value>文档完全匹配，包括字段顺序。 例如，以下查询与inventory中的任何文档都不匹配： db.inventory.find( { size: { w: 21, h: 14, uom: \"cm\" } } ) 查询嵌套字段 要在嵌入式/嵌套文档中的字段上指定查询条件，请使用点符号（“ field.nestedField”）。 [success] Note 使用点符号查询时，字段和嵌套字段必须在引号内。 在嵌套字段上指定相等匹配 以下示例选择嵌套在size字段中的uom字段等于“ in”的所有文档： db.inventory.find( { \"size.uom\": \"in\" } ) 使用查询运算符指定匹配 查询筛选器文档可以使用查询操作符 以以下形式指定条件: { : { : }, ... } 以下查询在size字段中嵌入的字段h上使用小于运算符($lt) ： db.inventory.find( { \"size.h\": { $lt: 15 } } ) 指定AND条件 以下查询选择嵌套字段h小于15，嵌套字段uom等于“ in”，状态字段等于“ D”的所有文档： db.inventory.find( { \"size.h\": { $lt: 15 }, \"size.uom\": \"in\", status: \"D\" } ) 附加查询教程 有关其他查询示例，请参见： Query Documents Query an Array Query an Array of Embedded Documents 译者：杨帅 校对：杨帅 参见 原文 - Query on Embedded/Nested Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/02-query-arrays.html":{"url":"04-crud/02-query-documents/02-query-arrays.html","title":"查询数组","keywords":"","body":" 查询数组 本页提供使用mongo shell中的db.collection.find()方法对数组字段进行查询操作的示例。 此页面上的示例使用inventory收集。 要填充inventory收集，请运行以下命令： db.inventory.insertMany([ { item: \"journal\", qty: 25, tags: [\"blank\", \"red\"], dim_cm: [ 14, 21 ] }, { item: \"notebook\", qty: 50, tags: [\"red\", \"blank\"], dim_cm: [ 14, 21 ] }, { item: \"paper\", qty: 100, tags: [\"red\", \"blank\", \"plain\"], dim_cm: [ 14, 21 ] }, { item: \"planner\", qty: 75, tags: [\"blank\", \"red\"], dim_cm: [ 22.85, 30 ] }, { item: \"postcard\", qty: 45, tags: [\"blue\"], dim_cm: [ 10, 15.25 ] } ]); 匹配数组 要在数组上指定相等条件，请使用查询文档{field>：value>}，其中value>是要匹配的精确数组，包括元素的顺序。 下面的示例查询所有文档，其中字段标签值是按指定顺序恰好具有两个元素\"red\" 和\"blank\"的数组： db.inventory.find( { tags: [\"red\", \"blank\"] } ) 相反，如果您希望找到一个同时包含元素“ red”和“ blank”的数组，而不考虑顺序或该数组中的其他元素，请使用$all运算符： db.inventory.find( { tags: { $all: [\"red\", \"blank\"] } } ) 查询数组中的元素 要查询数组字段是否包含至少一个具有指定值的元素，请使用过滤器{field>：value>}，其中value>是元素值。 以下示例查询所有文档，其中tag是一个包含字符串“ red”作为其元素之一的数组： db.inventory.find( { tags: \"red\" } ) 要在数组字段中的元素上指定条件，请在query filter document中使用query operators ： { : { : , ... } } 例如，以下操作查询数组dim_cm包含至少一个值大于25的元素的所有文档。 db.inventory.find( { dim_cm: { $gt: 25 } } ) 为数组元素指定多个条件 在数组元素上指定复合条件时，可以指定查询，以使单个数组元素满足这些条件，或者数组元素的任何组合均满足条件。 使用数组元素上的复合过滤条件查询数组 以下示例查询文档，其中dim_cm数组包含某种组合满足查询条件的元素； 例如，一个元素可以满足大于15的条件，而另一个元素可以满足小于20的条件，或者单个元素可以满足以下两个条件： db.inventory.find( { dim_cm: { $gt: 15, $lt: 20 } } ) 查询满足多个条件的数组元素 使用$elemMatch运算符可在数组的元素上指定多个条件，以使至少一个数组元素满足所有指定的条件。 以下示例查询在dim_cm数组中包含至少一个同时大于($gt)22和小于 ($lt) 30的元素的文档： db.inventory.find( { dim_cm: { $elemMatch: { $gt: 22, $lt: 30 } } } ) 通过数组索引位置查询元素 使用点表示法，可以为元素在数组的特定索引或位置处指定查询条件。 该数组使用基于零的索引。 [success] Note 使用点符号查询时，字段和嵌套字段必须在引号内。 以下示例查询数组dim_cm中第二个元素大于25的所有文档： db.inventory.find( { \"dim_cm.1\": { $gt: 25 } } ) 通过数组长度查询数组 使用$size运算符可按元素数量查询数组。 例如，以下选择数组tags具有3个元素的文档. db.inventory.find( { \"tags\": { $size: 3 } } ) 附加查询教程 有关其他查询示例，请参见： Query Documents Query on Embedded/Nested Documents Query an Array of Embedded Documents 译者：杨帅 校对：杨帅 参见 原文 - Query an Array Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/03-query-array-of-documents.html":{"url":"04-crud/02-query-documents/03-query-array-of-documents.html","title":"查询嵌入式文档数组","keywords":"","body":" 查询嵌入式文档数组 本页提供使用mongo shell中的db.collection.find()方法对嵌套文档数组进行查询操作的示例。 此页面上的示例使用inventory收集。 要填充inventory收集，请运行以下命令： db.inventory.insertMany( [ { item: \"journal\", instock: [ { warehouse: \"A\", qty: 5 }, { warehouse: \"C\", qty: 15 } ] }, { item: \"notebook\", instock: [ { warehouse: \"C\", qty: 5 } ] }, { item: \"paper\", instock: [ { warehouse: \"A\", qty: 60 }, { warehouse: \"B\", qty: 15 } ] }, { item: \"planner\", instock: [ { warehouse: \"A\", qty: 40 }, { warehouse: \"B\", qty: 5 } ] }, { item: \"postcard\", instock: [ { warehouse: \"B\", qty: 15 }, { warehouse: \"C\", qty: 35 } ] } ]); 查询嵌套在数组中的文档 下面的示例选择库存数组中的元素与指定文档匹配的所有文档： db.inventory.find( { \"instock\": { warehouse: \"A\", qty: 5 } } ) 整个嵌入式/嵌套文档上的相等匹配要求与指定文档（包括字段顺序）完全匹配。 例如，以下查询与inventory中的任何文档都不匹配： db.inventory.find( { \"instock\": { qty: 5, warehouse: \"A\" } } ) 在文档数组中的字段上指定查询条件 在嵌入文档数组中的字段上指定查询条件 如果您不知道嵌套在数组中的文档的索引位置，请使用点(.)和嵌套文档中的字段名称来连接数组字段的名称。 下面的示例选择所有inventory数组中包含至少一个嵌入式文档的嵌入式文档，这些文档包含值小于或等于20的字段qty： db.inventory.find( { 'instock.qty': { $lte: 20 } } ) 使用数组索引来查询嵌入式文档中的字段 使用点表示法，可以为文档中特定索引或数组位置的字段指定查询条件。 该数组使用基于零的索引。 [success] Note 使用点表示法查询时，字段和索引必须在引号内。 下面的示例选择所有库存文件，其中库存数组的第一个元素是包含值小于或等于20的字段qty的文档： 下面的例子选择了所有instock数组的第一个元素是一个包含值小于或等于20的字段qty的文档: db.inventory.find( { 'instock.0.qty': { $lte: 20 } } ) 为文档数组指定多个条件 在嵌套在文档数组中的多个字段上指定条件时，可以指定查询，以使单个文档满足这些条件，或者数组中文档的任何组合(包括单个文档)都满足条件。 单个嵌套文档在嵌套字段上满足多个查询条件 使用$elemMatch 运算符可在一组嵌入式文档上指定多个条件，以使至少一个嵌入式文档满足所有指定条件。 下面的示例查询instock数组中至少有一个嵌入式文档的文档，这些文档包含数量等于5的字段和数量等于A的字段仓库： db.inventory.find( { \"instock\": { $elemMatch: { qty: 5, warehouse: \"A\" } } } ) 下面的示例查询instock数组中至少有一个嵌入式文档的文档，该嵌入式文档的qty字段大于10且小于或等于20： db.inventory.find( { \"instock\": { $elemMatch: { qty: { $gt: 10, $lte: 20 } } } } ) 元素组合满足标准 如果数组字段上的复合查询条件未使用[$ $elemMatch 运算符，则查询将选择其数组包含满足条件的元素的任意组合的那些文档。 例如，以下查询匹配文档，其中嵌套在instock阵列中的任何文档的数量字段大于10，并且阵列中任何文档（但不一定是同一嵌入文档）的数量字段小于或等于20： db.inventory.find( { \"instock.qty\": { $gt: 10, $lte: 20 } } ) 以下示例查询instock数组中至少一个包含数量等于5的嵌入式文档和至少一个包含等于A的字段仓库的嵌入式文档（但不一定是同一嵌入式文档）的文档： db.inventory.find( { \"instock.qty\": 5, \"instock.warehouse\": \"A\" } ) 附加查询教程 有关其他查询示例，请参见： Query an Array Query Documents Query on Embedded/Nested Documents 译者：杨帅 校对：杨帅 参见 原文 - Query an Array of Embedded Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/04-project-fields-from-query-results.html":{"url":"04-crud/02-query-documents/04-project-fields-from-query-results.html","title":"从查询返回的项目字段","keywords":"","body":" 从查询返回的项目字段 默认情况下，MongoDB中的查询返回匹配文档中的所有字段。 要限制MongoDB发送给应用程序的数据量，可以包含一个projection 文档以指定或限制要返回的字段。 本页提供使用mongo shell中的db.collection.find()方法进行projection 的查询操作示例。 此页面上的示例使用inventory收集。 要填充inventory收集，请运行以下命令： db.inventory.insertMany( [ { item: \"journal\", status: \"A\", size: { h: 14, w: 21, uom: \"cm\" }, instock: [ { warehouse: \"A\", qty: 5 } ] }, { item: \"notebook\", status: \"A\", size: { h: 8.5, w: 11, uom: \"in\" }, instock: [ { warehouse: \"C\", qty: 5 } ] }, { item: \"paper\", status: \"D\", size: { h: 8.5, w: 11, uom: \"in\" }, instock: [ { warehouse: \"A\", qty: 60 } ] }, { item: \"planner\", status: \"D\", size: { h: 22.85, w: 30, uom: \"cm\" }, instock: [ { warehouse: \"A\", qty: 40 } ] }, { item: \"postcard\", status: \"A\", size: { h: 10, w: 15.25, uom: \"cm\" }, instock: [ { warehouse: \"B\", qty: 15 }, { warehouse: \"C\", qty: 35 } ] } ]); 返回匹配文档中的所有字段 如果未指定projection文档，则 db.collection.find()方法将返回匹配文档中的所有字段。 下面的例子返回inventory集合中状态为“A”的所有文档中的所有字段: db.inventory.find( { status: \"A\" } ) 该操作对应于以下SQL语句： SELECT * from inventory WHERE status = \"A\" 仅返回指定的字段和_id字段 通过将投影文档中的field>设置为1，投影可以显式包括多个字段。 以下操作返回与查询匹配的所有文档。在结果集中，只有项目、状态和_id字段(默认情况下)在匹配的文档中返回。 db.inventory.find( { status: \"A\" }, { item: 1, status: 1 } ) 该操作对应于以下SQL语句： SELECT _id, item, status from inventory WHERE status = \"A\" 禁止_id Field 您可以通过在投影中将_id字段设置为0来从结果中删除，如下面的示例所示: db.inventory.find( { status: \"A\" }, { item: 1, status: 1, _id: 0 } ) 该操作对应于以下SQL语句: SELECT item, status from inventory WHERE status = \"A\" [success] Note 除了_id字段之外，您不能在projection文档中合并包含和排除语句。 返回除了被排除的字段之外的所有字段 您可以使用projection来排除特定的字段，而不是列出要在匹配的文档中返回的字段。下面的例子将返回匹配文档中除了status和instock字段之外的所有字段: db.inventory.find( { status: \"A\" }, { status: 0, instock: 0 } ) 注意 除了_id字段之外，您不能在projection文档中合并包含和排除语句。 返回嵌入式文档中的特定字段 您可以返回嵌入式文档中的特定字段。 使用点表示法引用嵌入式字段，并在投影文档中将其设置为1。 以下示例返回： _id字段(默认情况下返回). 项目字段. 状态字段. 大小文档中的uom字段. uom字段仍然嵌入在size文档中。 db.inventory.find( { status: \"A\" }, { item: 1, status: 1, \"size.uom\": 1 } ) 从MongoDB 4.4开始，你也可以使用嵌套的形式指定嵌入的字段，例如{item: 1, status: 1, size: {uom: 1}}。 禁止嵌入文档中的特定字段 您可以隐藏嵌入式文档中的特定字段。 使用点表示法引用projection文档中的嵌入字段并将其设置为0。 以下示例指定一个投影，以排除size文档内的uom字段。 其他所有字段均在匹配的文档中返回： db.inventory.find( { status: \"A\" }, { \"size.uom\": 0 } ) 从MongoDB 4.4开始，你也可以使用嵌套的形式指定嵌入的字段，例如{size: {uom: 0}}。 数组中嵌入式文档的Projection 使用点表示法可将特定字段projection在嵌入数组的文档中。 以下示例指定要返回的projection： _id字段（默认情况下返回） 项目字段 状态字段 instock数组中嵌入的文档中的数量字段 db.inventory.find( { status: \"A\" }, { item: 1, status: 1, \"instock.qty\": 1 } ) 返回数组中的项目特定数组元素 对于包含数组的字段，MongoDB提供以下用于操纵数组的投影运算符:$elemMatch，$slice和$。 以下示例使用$sliceprojection运算符返回instock数组中的最后一个元素： db.inventory.find( { status: \"A\" }, { item: 1, status: 1, instock: { $slice: -1 } } ) $elemMatch，$slice和$是projection要包含在返回数组中的特定元素的唯一方法。 例如，您不能使用数组索引来投影特定的数组元素。 例如 {“ instock.0”：1}projection不会projection第一个元素的数组。 额外的注意事项 从MongoDB 4.4开始，MongoDB对projections施加了额外的限制。有关详细信息，请参阅Projection Restrictions 。 另请参考： Projection Query Documents 译者：杨帅 校对：杨帅 参见 原文 - Project Fields to Return from Query Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/05-query-for-null-fields.html":{"url":"04-crud/02-query-documents/05-query-for-null-fields.html","title":"查询空字段或缺少字段","keywords":"","body":" 查询空字段或缺少字段 MongoDB中不同的查询操作符对待null值是不同的。 该页面提供了使用mongo shell中的db.collection.find()方法查询空值的操作示例。 此页面上的示例使用库存收集。 要填充库存收集，请运行以下命令： 这个页面提供了使用mongo shell中的 db.collection.find()方法查询null值的操作示例。此页上的示例使用 inventory 集合。要填充 inventory集合，请运行以下操作: db.inventory.insertMany([ { _id: 1, item: null }, { _id: 2 } ]) 平等过滤器 {item：null}查询匹配包含值是null的item字段或不包含item字段的文档。 db.inventory.find( { item: null } ) 该查询返回集合中的两个文档。 类型检查 {item：{$ type：10}}查询只匹配包含item字段值为null的文档； 即item字段的值为BSON Type为Null（类型编号10）： db.inventory.find( { item : { $type: 10 } } ) 该查询仅返回item字段值为null的文档。 存在检查 以下示例查询不包含字段的文档。 {item：{$ exists：false}}查询与不包含item字段的文档匹配： db.inventory.find( { item : { $exists: false } } ) 该查询仅返回不包含项目字段的文档。 另请参考： $type 和$exists运算符的参考文档。 译者：杨帅 校对：杨帅 参见 原文 - Query for Null or Missing Fields Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/02-query-documents/06-iterate-a-cursor.html":{"url":"04-crud/02-query-documents/06-iterate-a-cursor.html","title":"在mongo Shell中迭代游标","keywords":"","body":" 在mongo Shell中迭代游标 在本页面 手动迭代游标 迭代器索引 游标行为 游标信息 方法返回一个游标。 要访问文档，您需要迭代游标。 但是，在mongo shell中，如果未使用var关键字将返回的游标分配给变量，则该游标将自动迭代多达20次，以打印结果中的前20个文档。 以下示例描述了手动迭代游标以访问文档或使用迭代器索引的方法。 手动迭代游标 在mongo shell中，当使用var关键字将find() 方法返回的游标分配给变量时，游标不会自动进行迭代。 您可以在shell程序中调用cursor变量以进行多达20次迭代并打印匹配的文档，如以下示例所示： var myCursor = db.users.find( { type: 2 } ); myCursor 您还可以使用游标方法next()来访问文档，如以下示例所示： var myCursor = db.users.find( { type: 2 } ); while (myCursor.hasNext()) printjson(myCursor.next()); } 作为一种替代的打印操作，请考虑使用printjson()辅助方法替换print(tojson())： var myCursor = db.users.find( { type: 2 } ); while (myCursor.hasNext()) { printjson(myCursor.next()); } 您可以使用游标方法forEach()来迭代游标并访问文档，如下例所示: var myCursor = db.users.find( { type: 2 } ); myCursor.forEach(printjson); 有关游标方法的更多信息，请参阅JavaScript游标方法和 driver程序文档。 迭代器索引 在 mongo shell中，可以使用 toArray() 方法来迭代游标并以数组形式返回文档，如下所示： var myCursor = db.inventory.find( { type: 2 } ); var documentArray = myCursor.toArray(); var myDocument = documentArray[3]; toArray() 方法将游标返回的所有文档加载到RAM中； toArray() 方法耗尽游标。 另外，某些驱动程序通过使用游标上的索引(即cursor [index])来提供对文档的访问。 这是先调用toArray() 方法，然后在结果数组上使用索引的快捷方式。 考虑以下示例： var myCursor = db.users.find( { type: 2 } ); var myDocument = myCursor[1]; myCursor [1]等效于以下示例： myCursor.toArray() [1]; 游标行为 关闭非活动游标 默认情况下，服务器将在闲置10分钟后或客户端用尽光标后自动关闭游标。 要在mongo shell中覆盖此行为，可以使用cursor.noCursorTimeout()方法： var myCursor = db.users.find().noCursorTimeout(); 设置noCursorTimeout选项后，您必须使用cursor.close()手动关闭游标，或者用尽游标的结果。 有关设置noCursorTimeout选项的信息，请参见驱动程序文档。 游标隔离 当游标返回文档时，其他操作可能会与查询交错。 光标批次 MongoDB服务器批量返回查询结果。批处理中的数据量不会超过最大BSON文档大小。若要覆盖批处理的默认大小，请参见batchSize() 和 limit(). 3.4版中的新增功能：find(), aggregate(), listIndexes, 和 listCollections类型的操作每批返回最多16 MB。 batchSize() 可以强制使用较小的限制，但不能强制使用较大的限制。 默认情况下，find()和aggregate()操作的初始批处理大小为101个文档。随后针对结果游标发出的getMore操作没有默认的批处理大小，因此它们仅受16 MB消息大小的限制。 对于包含不带索引的排序操作的查询，服务器必须在返回任何结果之前将所有文档加载到内存中以执行排序。 当您遍历游标并到达返回批处理的末尾时，如果还有更多结果，cursor.next() 将执行getMore操作以检索下一个批处理。要查看在迭代游标时批处理中剩余多少文档，可以使用objsLeftInBatch()方法，如以下示例所示： var myCursor = db.inventory.find(); var myFirstDocument = myCursor.hasNext() ? myCursor.next() : null; myCursor.objsLeftInBatch(); 游标信息 db.serverStatus() 方法返回包含度量标准字段的文档。 指标字段包含一个带有以下信息的metrics.cursor 字段： 自上次服务器重新启动以来超时的游标数 设置了选项DBQuery.Option.noTimeout的打开游标的数量，以防止一段时间不活动后发生超时 “固定”打开游标的数量 打开的游标总数 考虑以下示例，该示例调用db.serverStatus() 方法并从结果中访问索引字段，然后从指标字段访问游标字段： db.serverStatus().metrics.cursor 结果是以下文档： { \"timedOut\" : \"open\" : { \"noTimeout\" : , \"pinned\" : , \"total\" : } } 另可参考： db.serverStatus() 译者：杨帅 校对：杨帅 参见 原文 - Iterate a Cursor in the mongo Shell Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/03-update-documents.html":{"url":"04-crud/03-update-documents.html","title":"更新文档","keywords":"","body":" 更新文档 此页面使用以下 mongo shell方法： db.collection.updateOne(filter>, update>, options>) db.collection.updateMany(filter>, update>, options>) db.collection.replaceOne(filter>, update>, options>) 此页面上的示例使用库存收集。 要创建和/或填充清单集合，请运行以下命令： 此页上的示例使用inventory集合。要创建和/或填充inventory集合，请运行以下操作: db.inventory.insertMany( [ { item: \"canvas\", qty: 100, size: { h: 28, w: 35.5, uom: \"cm\" }, status: \"A\" }, { item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"mat\", qty: 85, size: { h: 27.9, w: 35.5, uom: \"cm\" }, status: \"A\" }, { item: \"mousepad\", qty: 25, size: { h: 19, w: 22.85, uom: \"cm\" }, status: \"P\" }, { item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"P\" }, { item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }, { item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }, { item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" }, { item: \"sketchbook\", qty: 80, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"sketch pad\", qty: 95, size: { h: 22.85, w: 30.5, uom: \"cm\" }, status: \"A\" } ] ); 更新集合中的文档 为了更新文档，MongoDB提供了更新操作符（例如$set）来修改字段值。 要使用更新运算符，请将以下形式的更新文档传递给更新方法： { : { : , ... }, : { : , ... }, ... } 如果字段不存在，则某些更新操作符（例如$set）将创建该字段。 有关详细信息，请参见各个更新操作员参考。 [success] Note 从MongoDB 4.2开始，MongoDB可以接受聚合管道来指定要进行的修改而不是更新文档。 有关详细信息，请参见方法参考页。 更新单个文档 下面的示例在inventory集合上使用db.collection.updateOne()方法更新项目等于“ paper”的第一个文档： db.inventory.updateOne( { item: \"paper\" }, { $set: { \"size.uom\": \"cm\", status: \"P\" }, $currentDate: { lastModified: true } } ) 更新操作： 使用$set 运算符将size.uom字段的值更新为“ cm”，将状态字段的值更新为“ P”， 使用$currentDate运算符将lastModified字段的值更新为当前日期。 如果lastModified字段不存在，则$currentDate将创建该字段。 有关详细信息，请参见$currentDate。 更新多个文档 3.2版中的新功能 以下示例在清单集合上使用db.collection.updateMany()方法来更新数量小于50的所有文档： db.inventory.updateMany( { \"qty\": { $lt: 50 } }, { $set: { \"size.uom\": \"in\", status: \"P\" }, $currentDate: { lastModified: true } } ) 更新操作： 使用$set运算符将size.uom字段的值更新为“ in”，将状态字段的值更新为“ P”. 使用 $currentDate 运算符将lastModified字段的值更新为当前日期。如果lastModified字段不存在，则$currentDate 将创建该字段。有关详细信息，请参见$currentDate 。 更换文档 要替换_id字段以外的文档的全部内容，请将一个全新的文档作为第二个参数传递给db.collection.replaceOne()。 当替换一个文档时，替换文档必须只包含字段/值对;即不包括更新操作符表达式。 替换文档可以具有与原始文档不同的字段。在替换文档中，由于_id字段是不可变的，因此可以省略_id字段。但是，如果您确实包含_id字段，则它必须与当前值具有相同的值。 下面的示例替换了inventory集合中的第一个文件，其中项为\"paper\": db.inventory.replaceOne( { item: \"paper\" }, { item: \"paper\", instock: [ { warehouse: \"A\", qty: 60 }, { warehouse: \"B\", qty: 40 } ] } ) 行为 原子性 MongoDB中的所有写操作都是单个文档级别上的原子操作。有关MongoDB和原子性的更多信息，请参见原子性和事务。 _id Field 设置后，您将无法更新_id字段的值，也无法将现有文档替换为具有不同_id字段值的替换文档。 字段顺序 除以下情况外，MongoDB会在执行写操作后保留文档字段的顺序： _id字段始终是文档中的第一个字段。 包含字段名称renaming 的更新可能导致文档中字段的重新排序。 增补选项 如果updateOne(), updateMany(), or replaceOne() 包含upsert：true，并且没有文档与指定的过滤器匹配，则该操作将创建一个新文档并将其插入。 如果存在匹配的文档，则该操作将修改或替换一个或多个匹配的文档。 有关创建的新文档的详细信息，请参见各个方法的参考页。 写确认书 对于写入问题，您可以指定从MongoDB请求的写入操作的确认级别。 有关详细信息，请参见写关注。 另请参考： Updates with Aggregation Pipeline db.collection.updateOne() db.collection.updateMany() db.collection.replaceOne() Additional Methods 译者：杨帅 校对：杨帅 参见 原文 - Update Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/03-update-documents/01-update-documents-with-aggregation-pipeline.html":{"url":"04-crud/03-update-documents/01-update-documents-with-aggregation-pipeline.html","title":"聚合管道更新","keywords":"","body":" 聚合管道更新 从MongoDB 4.2开始，您可以将聚合管道用于更新操作。 通过更新操作，聚合管道可以包括以下阶段： $addFields $set $project $unset $replaceRoot $replaceWith 使用聚合管道允许使用表达性更强的update语句，比如根据当前字段值表示条件更新，或者使用另一个字段的值更新一个字段。 例1 创建一个示例students学生集合（如果该集合当前不存在，则插入操作将创建该集合）： db.students.insertMany([ { _id: 1, test1: 95, test2: 92, test3: 90, modified: new Date(\"01/05/2020\") }, { _id: 2, test1: 98, test2: 100, test3: 102, modified: new Date(\"01/05/2020\") }, { _id: 3, test1: 95, test2: 110, modified: new Date(\"01/04/2020\") } ]) 要验证，请查询集合： db.students.find() 以下db.collection.updateOne()操作使用聚合管道使用_id更新文档：3： db.students.updateOne( { _id: 3 }, [ { $set: { \"test3\": 98, modified: \"$$NOW\"} } ] ) 具体地说，管道包括$set阶段，该阶段将test3字段（并将其值设置为98）添加到文档中，并将修改后的字段设置为当前日期时间。 对于当前日期时间，该操作将聚合变量NOW 用于（以访问变量，以$$为前缀并用引号引起来）。 要验证更新，您可以查询集合： db.students.find().pretty() 例2 创建一个示例students2集合(如果该集合当前不存在，则插入操作将创建该集合): db.students2.insertMany([ { \"_id\" : 1, quiz1: 8, test2: 100, quiz2: 9, modified: new Date(\"01/05/2020\") }, { \"_id\" : 2, quiz2: 5, test1: 80, test2: 89, modified: new Date(\"01/05/2020\") }, ]) 要验证，请查询集合： db.students2.find() 以下db.collection.updateMany() 操作使用聚合管道来标准化文档的字段（即,集合中的文档应具有相同的字段）并更新修改后的字段： db.students2.updateMany( {}, [ { $replaceRoot: { newRoot: { $mergeObjects: [ { quiz1: 0, quiz2: 0, test1: 0, test2: 0 }, \"$$ROOT\" ] } } }, { $set: { modified: \"$$NOW\"} } ] ) 具体来说，管道包括： $replaceRoot 阶段，带有 $mergeObjects表达式，可为quiz1，quiz2，test1和test2字段设置默认值。 聚集变量ROOT 指的是正在修改的当前文档（以访问变量，以$$为前缀并用引号引起来）。 当前文档字段将覆盖默认值。 $set 阶段用于将修改的字段更新到当前日期时间。 对于当前日期时间，该操作将聚合变量NOW用于（以访问变量，以$$为前缀并用引号引起来）。 要验证更新，您可以查询集合： db.students2.find() 例3 创建一个示例students3集合（如果该集合当前不存在，则插入操作将创建该集合）： db.students3.insert([ { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"modified\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"modified\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"modified\" : ISODate(\"2019-01-01T00:00:00Z\") } ]); 要验证，请查询集合： db.students3.find() 以下 db.collection.updateMany()操作使用聚合管道以计算的平均成绩和字母成绩更新文档。 db.students3.updateMany( { }, [ { $set: { average : { $trunc: [ { $avg: \"$tests\" }, 0 ] }, modified: \"$$NOW\" } }, { $set: { grade: { $switch: branches: [ { case: { $gte: [ \"$average\", 90 ] }, then: \"A\" }, { case: { $gte: [ \"$average\", 80 ] }, then: \"B\" }, { case: { $gte: [ \"$average\", 70 ] }, then: \"C\" }, { case: { $gte: [ \"$average\", 60 ] }, then: \"D\" } ], default: \"F\" } } } } ] ) 具体来说，管道包括： $set阶段来计算测试数组元素的截断平均值，并将修改后的字段更新为当前日期时间。 要计算截断的平均值，此阶段使用$avg和$trunc 表达式。 对于当前日期时间，该操作将聚合变量NOW 用于(以访问变量，以$$为前缀并用引号引起来). 一个$set 阶段，用于使用$switch 表达式根据平均值添加年级字段。 要验证更新，您可以查询集合： db.students3.find() 例4 创建一个示例students4集合(如果该集合当前不存在，则插入操作将创建该集合)： db.students4.insertMany([ { \"_id\" : 1, \"quizzes\" : [ 4, 6, 7 ] }, { \"_id\" : 2, \"quizzes\" : [ 5 ] }, { \"_id\" : 3, \"quizzes\" : [ 10, 10, 10 ] } ]) 要验证，请查询集合： db.students4.find() 以下db.collection.updateOne()操作使用聚合管道将测验分数添加到具有_id的文档中：2： db.students4.updateOne( { _id: 2 }, [ { $set: { quizzes: { $concatArrays: [ \"$quizzes\", [ 8, 6 ] ] } } } ] ) 要验证，请查询集合： db.students4.find() 例5 创建一个示例temperatures集合，其中包含摄氏温度(如果该集合当前不存在，则插入操作将创建该集合)： db.temperatures.insertMany([ { \"_id\" : 1, \"date\" : ISODate(\"2019-06-23\"), \"tempsC\" : [ 4, 12, 17 ] }, { \"_id\" : 2, \"date\" : ISODate(\"2019-07-07\"), \"tempsC\" : [ 14, 24, 11 ] }, { \"_id\" : 3, \"date\" : ISODate(\"2019-10-30\"), \"tempsC\" : [ 18, 6, 8 ] } ]) 要验证，请查询集合： db.temperatures.find() 以下db.collection.updateMany()操作使用聚合管道以华氏度中的相应温度更新文档： db.temperatures.updateMany( { }, [ { $addFields: { \"tempsF\": { $map: { input: \"$tempsC\", as: \"celsius\", in: { $add: [ { $multiply: [\"$$celsius\", 9/5 ] }, 32 ] } } } } } ] ) 具体来说，管道由$addFields阶段组成，以添加一个新的数组字段tempsF，其中包含华氏温度。 要将tempsC数组中的每个摄氏温度转换为华氏温度，该阶段将$map表达式与$add和 $multiply表达式一起使用。 要验证更新，您可以查询集合： db.temperatures.find() 其他例子 有关其他示例，另请参见各种更新方法页面： db.collection.updateOne db.collection.updateMany db.collection.update() db.collection.findOneAndUpdate() db.collection.findAndModify() Bulk.find.update() Bulk.find.updateOne() Bulk.find.upsert() 译者：杨帅 校对：杨帅 参见 原文 - Updates with Aggregation Pipeline Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/03-update-documents/02-update-methods.html":{"url":"04-crud/03-update-documents/02-update-methods.html","title":"更新方法","keywords":"","body":" 更新方法 MongoDB提供了以下方法来更新集合中的文档： db.collection.updateOne() 即使多个文档可能与指定的过滤器匹配，最多更新与指定的过滤器匹配的单个文档。3.2版中的新功能 db.collection.updateMany() 更新所有与指定过滤器匹配的文档。3.2版中的新功能 db.collection.replaceOne() 即使多个文档可能与指定过滤器匹配，也最多替换一个与指定过滤器匹配的文档。3.2版中的新功能 db.collection.update() 更新或替换与指定过滤器匹配的单个文档，或更新与指定过滤器匹配的所有文档。默认情况下，db.collection.update()方法更新单个文档。 要更新多个文档，请使用multi选项。 附加方法 以下方法还可以更新集合中的文档： db.collection.findOneAndReplace(). db.collection.findOneAndUpdate(). db.collection.findAndModify(). db.collection.save(). db.collection.bulkWrite(). 有关更多方法和示例，请参见各个方法的参考页。 译者：杨帅 校对：杨帅 参见 原文 - Update Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/04-remove-documents.html":{"url":"04-crud/04-remove-documents.html","title":"删除文档","keywords":"","body":" 删除文档 此页面使用以下mongo shell方法 db.collection.deleteMany() db.collection.deleteOne() 此页面上的示例使用inventory收集。 要填充inventory收集，请运行以下命令： db.inventory.insertMany( [ { item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"P\" }, { item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }, { item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }, { item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" }, ] ); 删除所有文档 要删除集合中的所有文档，请将空的filter文档{}传递给db.collection.deleteMany() 方法。 以下示例从inventory收集中删除所有文档： db.inventory.deleteMany({}) 该方法返回具有操作状态的文档。 有关更多信息和示例，请参见deleteMany(). 删除所有符合条件的文档 您可以指定标准或过滤器，以标识要删除的文档。 filter使用与读取操作相同的语法。 要指定相等条件，请在查询过滤器文档:中使用field>：value>表达式： { : , ... } 查询过滤器文档可以使用查询操作符 以以下形式指定条件: { : { : }, ... } 要删除所有符合删除条件的文档，请将filter参数传递给deleteMany()方法。 以下示例从状态字段等于“ A”的inventory集合中删除所有文档： db.inventory.deleteMany({ status : \"A\" }) 该方法返回具有操作状态的文档。 有关更多信息和示例，请参见deleteMany(). 仅删除一个符合条件的文档 要删除最多一个与指定过滤器匹配的文档(即使多个文档可以与指定过滤器匹配)，请使用db.collection.deleteOne()方法。 下面的示例删除状态为“ D”的第一个文档： db.inventory.deleteOne( { status: \"D\" } ) 删除行为 索引 即使从集合中删除所有文档，删除操作也不会删除索引。 原子性 MongoDB中的所有写操作都是单个文档级别的原子操作。 有关MongoDB和原子性的更多信息，请参见原子性和事务。 写确认 对于写入问题，您可以指定从MongoDB请求的写入操作的确认级别。 有关详细信息，请参见 写关注。 另请参考： db.collection.deleteMany() db.collection.deleteOne() Additional Methods 译者：杨帅 校对：杨帅 参见 原文 - Delete Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/04-remove-documents/01-delete-methods.html":{"url":"04-crud/04-remove-documents/01-delete-methods.html","title":"删除方法","keywords":"","body":" 删除方法 MongoDB提供以下删除集合文档的方法： db.collection.deleteOne() 即使多个文档可能与指定过滤器匹配，也最多删除一个与指定过滤器匹配的文档。3.2版中的新功能 db.collection.deleteMany() 删除所有与指定过滤器匹配的文档。3.2版中的新功能 db.collection.remove() 删除单个文档或与指定过滤器匹配的所有文档。 附加方法 以下方法也可以从集合中删除文档: db.collection.findOneAndDelete(). findOneAndDelete()提供排序选项。该选项允许删除按指定 order 排序的第一个文档。 db.collection.findAndModify(). db.collection.findAndModify() 提供了一个排序选项。 该选项允许删除按指定顺序排序的第一个文档. db.collection.bulkWrite(). 有关更多方法和示例，请参见各个方法的参考页。 译者：杨帅 校对：杨帅 参见 原文 - Delete Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/05-bulk-write-operations.html":{"url":"04-crud/05-bulk-write-operations.html","title":"批量写入操作","keywords":"","body":" 批量写入操作 在本页面 总览 有序 VS 无序操作 bulkWrite()方法 批量插入分片集合的策略 总览 MongoDB使客户端能够批量执行写操作。 批量写入操作会影响单个集合。 MongoDB允许应用程序确定批量写入操作所需的可接受的确认级别。 3.2版本新增 db.collection.bulkWrite()方法提供了执行批量插入，更新和删除操作的能力。对于批量插入而言，MongoDB也支持db.collection.insertMany(). 有序 VS 无序操作 批量写操作可以是有序的，也可以无序的。 使用操作的有序列表，MongoDB串行地执行操作。 如果在某个单独的写操作的处理过程中发生错误，MongoDB将直接返回而不再继续处理列表中任何剩余的写操作。 请参考有序的批量写入. 使用无序的操作列表，MongoDB可以并行地执行操作，但是不能保证此行为。 如果某个单独的写操作的处理过程中发生错误，MongoDB将继续处理列表中剩余的写操作。 请参考无序的批量写入。 在分片集合上执行有序的批量写操作通常比执行无序批量写操作要慢。这是因为对于有序列表而言，每个操作都必须等待上一个操作完成后才能执行。 默认情况下，bulkWrite() 执行有序的写入。 要指定无序的写入，请在选项文档中设置ordered：false。 请参考操作的执行. bulkWrite()方法 bulkWrite()支持如下操作： insertOne updateOne updateMany replaceOne deleteOne deleteMany 每个写操作都以数组中的文档形式被传递给[bulkWrite() 例如，下面执行多个写操作: characters集合包含以下文档: { \"_id\" : 1, \"char\" : \"Brisbane\", \"class\" : \"monk\", \"lvl\" : 4 }, { \"_id\" : 2, \"char\" : \"Eldon\", \"class\" : \"alchemist\", \"lvl\" : 3 }, { \"_id\" : 3, \"char\" : \"Meldane\", \"class\" : \"ranger\", \"lvl\" : 3 } 接下来的bulkWrite()将在此集合上执行批量写入的操作。 try { db.characters.bulkWrite( [ { insertOne : { \"document\" : { \"_id\" : 4, \"char\" : \"Dithras\", \"class\" : \"barbarian\", \"lvl\" : 4 } } }, { insertOne : { \"document\" : { \"_id\" : 5, \"char\" : \"Taeln\", \"class\" : \"fighter\", \"lvl\" : 3 } } }, { updateOne : { \"filter\" : { \"char\" : \"Eldon\" }, \"update\" : { $set : { \"status\" : \"Critical Injury\" } } } }, { deleteOne : { \"filter\" : { \"char\" : \"Brisbane\"} } }, { replaceOne : { \"filter\" : { \"char\" : \"Meldane\" }, \"replacement\" : { \"char\" : \"Tanys\", \"class\" : \"oracle\", \"lvl\" : 4 } } } ] ); } catch (e) { print(e); } 该操作将返回如下的结果： { \"acknowledged\" : true, \"deletedCount\" : 1, \"insertedCount\" : 2, \"matchedCount\" : 2, \"upsertedCount\" : 0, \"insertedIds\" : { \"0\" : 4, \"1\" : 5 }, \"upsertedIds\" : { } } 想了解更多例子，请参考bulkWrite() 示例. 批量插入分片集合的策略 大容量插入操作(包括初始数据插入或例程数据导入)可能会影响分片集群的性能。对于批量插入，考虑以下策略: 对分片集合进行预拆分 如果分片集合为空，则该集合只有一个存储在单个分片上的初始数据块，MongoDB必须花一些时间来接收数据，创建拆分并将拆分的块分发到其他分片上。为了避免这种性能开销，您可以对分片集合进行预拆分，请参考 分片集群中的数据块拆分中的描述。 对mongos的无序写入 要提高对分片集群的写入性能，请使用带有可选参数ordered:false的bulkWrite()方法。mongos 会尝试同时将写入发送到多个分片。对于空集合，请首先按照分片集群中的数据块拆分中描述的进行集合的预拆分。 避免单调插入带来的瓶颈 如果您的分片键再插入过程中时单调增加的，那么所有插入的数据都会插入到该分片集合的最后一个数据块中，也就是说会落到某单个分片上。因此，集群的插入能力将永远不会超过该单个跟片的插入性能（木桶的短板原理）。 如果插入量大于单个分片可以处理的数据量，并且无法避免单调增加的分片键，那么可以考虑对应用程序进行如下修改： 翻转分片键的二进制位。这样可以保留信息的同时避免插入顺序与递增插入值之间的关联性。 交换第一个和最后16比特来实现“随机”插入。 示例 下面的C++例子中，交换生成的BSON ObjectIds的前导和后16位字，使它们不再单调递增。 using namespace mongo; OID make_an_id() { OID x = OID::gen(); const unsigned char *p = x.getData(); swap( (unsigned short&) p[0], (unsigned short&) p[10] ); return x; } void foo() { // create an object BSONObj o = BSON( \"_id\" 另请参考 分片键来获得如何选择分片键的相关信息。另请参考【分片键】（尤其是其中【选择分片键】的相关章节） 关于选择分片键的信息。还请参阅分片键内部(特别是，选择一个切分键)。 译者：杨帅 刘翔 校验：杨帅 参见 原文 - Bulk Write Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/06-retryable-writes.html":{"url":"04-crud/06-retryable-writes.html","title":"可重试写入","keywords":"","body":" 可重试写入 在本页面 前提条件 可重试写入和多文档交易 启用可重试写入 可重试的写操作 行为 3.6版的新功能 可重试写入允许MongoDB驱动程序在遇到网络错误或在复制集或分片群集中找不到正常的主操作时自动重试特定的写操作一次。 前提条件 可重试写入具有以下要求： 支持的部署Topologie ​ 可重试写入需要 复制集或分片群集，并且不支持独立实例。 支持的存储引擎 ​ 可重试写入需要支持文档级锁定的存储引擎，例如WiredTiger或内存中 存储引擎。 3.6+ MongoDB驱动程序 客户端需要为MongoDB 3.6或更高版本更新的MongoDB驱动程序： Java 3.6+Python 3.6+C 1.9+ C 2.5+Node 3.0+Ruby 2.5+ Perl 2.0+PHPC 1.4+Scala 2.2+ MongoDB版本 集群中每个节点的MongoDB版本必须为3.6或更高，集群中每个节点的featureCompatibilityVersion必须为3.6或更高。有关featureCompatibilityVersion标志的更多信息，请参见setFeatureCompatibilityVersion。 写确认书 Write Concern为0的写操作是不可重试的。 可重试写入和多文档交易 版本4.0中的新功能 事务提交和中止操作是可重试的写操作。如果提交操作或中止操作遇到错误，MongoDB驱动程序将重试操作一次，而不管retryWrites是否被设置为false。 有关交易的更多信息，请参见Transactions。 启用可重试写入 MongoDB驱动程序 官方的MongoDB 3.6和4.0兼容驱动程序需要在连接字符串中包含retryWrites=true选项，以启用该连接的可重试写操作。 官方的MongoDB 4.2兼容驱动程序在默认情况下启用了可重试写。升级到与4.2兼容的驱动程序，要求可重试写的应用程序可能会忽略retryWrites=true选项。升级到与4.2兼容的驱动程序，要求禁用可重试写的应用程序必须在连接字符串中包含retryWrites=false。 Mongo shell 要在mongo shell中启用可重试写入，请使用--retryWrites命令行选项： mongo --retryWrites 可重试的写操作 当发出已确认的写关注时，可以重试以下写操作; 例如,Write Concern不能为{w：0}。 [success] Note 事务中的写操作不能单独重试。 方法 说明 db.collection.insertOne()db.collection.insert()db.collection.insertMany() 插入操作 db.collection.updateOne()db.collection.replaceOne()db.collection.save()db.collection.update() where multi is false 单文档更新操作。 db.collection.deleteOne()db.collection.remove() where justOne is true 单个文档删除操作 db.collection.findAndModify()db.collection.findOneAndDelete()db.collection.findOneAndReplace()db.collection.findOneAndUpdate() findAndModify操作。所有findAndModify操作都是单个文档操作。 db.collection.bulkWrite() 具有以下写操作：. insertOne. updateOne. replaceOne. deleteOne 只包含单文档写操作的批量写操作。可重试的大容量操作可以包括指定的写操作的任何组合，但不能包括任何多文档写操作，比如updateMany。 Bulk operations for:. Bulk.find.removeOne(). Bulk.find.replaceOne(). Bulk.find.replaceOne() 仅由单文档写操作组成的批量写操作。可重试的大容量操作可以包括指定的写操作的任何组合，但不能包括任何多文档写操作，比如update，它为multi选项指定true。 分片键值更新 从MongoDB 4.2开始，您可以通过发布可重试写入或事务处理中的单文档update / findAndModify操作来更新文档的分片键值(除非分片键字段是不可变的_id字段)。 有关详细信息，请参见更改文档的分片键值.。 MongoDB 4.2将重试遇到重复密钥异常的某些单文档upsert（更新使用upsert：true和multi：false）。 有关条件，请参阅 Duplicate Key Errors on Upsert . 在MongoDB 4.2之前，MongoDB不会重试遇到重复键错误的upsert操作。 行为 持续的网络错误 MongoDB可重试写只做一次重试尝试。这有助于解决暂时的网络错误和复制集选举，但不能解决持久的网络错误。 故障转移期 如果驱动程序在目标复制集中或分片集群分片中找不到正常的主服务器，则驱动程序在重试之前会等待serverSelectionTimeoutMS毫秒来确定新的主服务器。可重试写操作不会处理故障转移周期超过serverSelectionTimeoutMS的实例。 [warning] Warning 如果客户端应用程序在发出写操作后的时间超过localLogicalSessionTimeoutMinutes，那么当客户端应用程序开始响应时(无需重新启动)，可能会重试并再次应用写操作。 Upsert上的重复键错误 MongoDB 4.2将重试单文档的upsert操作(即:upsert: true和multi: false)由于重复的键错误而失败，只有当操作满足以下所有条件: 目标集合具有导致重复键错误的唯一索引。 更新匹配条件为： 单个相等谓词 { \"fieldA\" : \"valueA\" }， 相等谓词的逻辑 { \"fieldA\" : \"valueA\", \"fieldB\" : \"valueB\" } 唯一索引键模式中的字段集与更新查询谓词中的字段集匹配。 更新操作不会修改查询谓词中的任何字段。 下表包含服务器可以或不能在重复键错误时重试的upsert操作示例： 唯一索引键模式            更新操作                           可重试 { _id ： 1 } db.collName.updateOne( { _id : ObjectId(\"1aa1c1efb123f14aaa167aaa\") }, { $set : { fieldA : 25 } }, { upsert : true } ) 是 { fieldA ： 1 } db.collName.updateOne( { fieldA : { $in : [ 25 ] } }, { $set : { fieldB : \"someValue\" } }, { upsert : true } ) 是 { fieldA：1， fieldB ：1} db.collName.updateOne( { fieldA : 25, fieldB : \"someValue\" }, { $set : { fieldC : false } }, { upsert : true } ) 是 { fieldA ： 1 } db.collName.updateOne( { fieldA : { $lte : 25 } }, { $set : { fieldC : true } }, { upsert : true } ) 没有查询谓词fieldA不等于 { fieldA ： 1 } db.collName.updateOne( { fieldA : { $in : [ 25 ] } }, { $set : { fieldA : 20 } }, { upsert : true } ) 没有更新操作修改查询谓词中指定的字段。 { _id ： 1 } db.collName.updateOne( { fieldA : { $in : [ 25 ] } }, { $set : { fieldA : 20 } }, { upsert : true } ) 没有查询谓词字段集（fieldA）与索引关键字字段集（）不匹配_id。 { fieldA ： 1 } db.collName.updateOne( { fieldA : 25, fieldC : true }, { $set : { fieldD : false } }, { upsert : true } ) 没有这组查询谓词的字段（fieldA，fieldC）不匹配组索引键的字段（fieldA） 在MongoDB 4.2之前，MongoDB可重试写不支持由于重复的键错误而失败的重试更新。 诊断程序 版本3.6.3中的新功能 serverStatus命令及其mongo shell帮助程序 db.serverStatus() 在transactions节中包含有关可重试写入的统计信息。 针对本地数据库的可重试写入 官方的MongoDB 4.2系列驱动程序默认情况下启用重试写入。 除非明确禁止重试写入，否则写入本地数据库的应用程序在升级到4.2系列驱动程序时将遇到写入错误。 要禁用可重试写入，请在MongoDB集群的连接字符串中指定retryWrites=false 。 译者：杨帅 校对：杨帅 参见 原文 - Retryable Writes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/07-retryable-reads.html":{"url":"04-crud/07-retryable-reads.html","title":"可重试读取","keywords":"","body":" 可重试读取 在本页面 前提条件 启用可重试读取 可重试的读取操作 行为 可重试读取允许MongoDB驱动程序在遇到某些网络或服务器错误时，可以一次自动重试某些读取操作。 前提条件 最小驱动程序版本 ​ 官方MongoDB驱动兼容MongoDB服务器4.2和以后支持重试读取。 ​ 有关官方MongoDB驱动程序的更多信息，请参阅 MongoDB驱动程序。 最低服务器版本 ​ 如果连接到MongoDB Server 3.6或更高版本，驱动程序只能重试读取操作。 启用可重试读取 官方MongoDB驱动程序兼容MongoDB服务器4.2和以后默认启用可重试读取。要显式禁用可重试读取，请在部署的连接字符串中中指定retryReads=false。 在mongoshell不支持重试读取。 可重试的读取操作 MongoDB驱动程序支持重试以下读取操作。列表引用了每个方法的通用描述。对于特定的语法和用法，请遵循该方法的驱动程序文档。 方法 内容描述 Collection.aggregate Collection.count Collection.countDocuments Collection.distinct Collection.estimatedDocumentCount Collection.find Database.aggregate CRUD API读取操作. 对于Collection.aggregate和Database.aggregate，驱动程序只能重试不包括写阶段的聚合管道，如$out或$merge。 Collection.watch Database.watch MongoClient.watch 更改流操作 MongoClient.listDatabases Database.listCollections Collection.listIndexes 枚举操作 GridFS操作由Collection.find （例如GridFSBucket.openDownloadStream）支持 GridFS文件下载操作 MongoDB驱动程序可能包括对其他操作的可重试支持，比如帮助方法或包装可重试读操作的方法。根据驱动程序文档 确定方法是否显式支持可重试读取。 也可以看看: 可重试读规范:支持的读取操作. 不支持的读取操作 以下操作不支持可重试的读取： db.collection.mapReduce() getMore 传递给通用Database.runCommand帮助器的任何读命令，它与读或写命令无关。 行为 持久性网络错误 MongoDB可重试读取只做一次重试尝试。这有助于解决暂时的网络错误或复制集选举，但不能解决持久的网络错误。 故障转移期间 在重试读取操作之前，驱动程序使用read命令的原始读取首选项执行服务器选择。如果驱动程序不能选择使用原始读取首选项进行重试的服务器，则驱动程序返回原始错误。 驱动程序在执行服务器选择之前等待serverSelectionTimeoutMS毫秒。可重试读取不会处理在等待serverSelectionTimeoutMS后不存在合格服务器的实例。 译者：杨帅 校对：杨帅 参见 原文 - Retryable Reads Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/08-sql-comparison.html":{"url":"04-crud/08-sql-comparison.html","title":"SQL到MongoDB的映射图表","keywords":"","body":" SQL到MongoDB的映射图表 在本页面 术语和概念 可执行性文件 例子 进一步阅读 除了下面的图表之外，您可能需要考虑有关MongoDB的常见问题的常见问题部分。 术语和概念 下表介绍了各种SQL术语和概念以及相应的MongoDB术语和概念。 SQL术语/概念 MongoDB术语/概念 database database table collection row document or BSON document column field index index table joins $lookup, 嵌入文档 primary key（指定任何唯一的列或列组合作为主键。） primary key（在MongoDB中，主键自动设置为_id字段。） aggregation (e.g. group by) aggregation pipelineSee the SQL to Aggregation Mapping Chart. SELECT INTO NEW_TABLE $outSee the SQL to Aggregation Mapping Chart. MERGE INTO TABLE $merge (Available starting in MongoDB 4.2)See the SQL to Aggregation Mapping Chart. Transactions transactions在许多情况下，非规范化数据模型（嵌入式文档和数组）将继续是您数据和用例的最佳选择，而不是多文档事务。也就是说，在许多情况下，对数据进行适当的建模将最大程度地减少对多文档交易的需求。 可执行文件 下表展示了一些数据库可执行文件和相应的MongoDB可执行文件。这个表格并不是详尽无遗的。 MongoDB MySQL Oracle Informix DB2 Database Server mongod mysqld oracle IDS DB2 Server Database Client mongo mysql sqlplus DB-Access DB2 Client 例子 下表展示了各种SQL语句和相应的MongoDB语句。表中的例子假设以下条件: SQL示例假设有一个名为people的表。 MongoDB示例假设一个名为people的集合，它包含以下原型的文档: { _id: ObjectId(\"509a8fb2f3f4948bd2f983a0\"), user_id: \"abc123\", age: 55, status: 'A' } 创建和修改 下表展示了与表级操作相关的各种SQL语句以及相应的MongoDB语句。 SQL Schema语句 MongoDB Schema语句 CREATE TABLE people ( id MEDIUMINT NOT NULL AUTO_INCREMENT, user_id Varchar(30), age Number, status char(1), PRIMARY KEY (id)) 隐式创建的第一个insertOne()或insertMany()操作。如果没有指定_id字段，则会自动添加主键_id。db.people.insertOne( { user_id: \"abc123\", age: 55, status: \"A\" } )但是，您也可以显式地创建一个集合:db.createCollection(\"people\") ALTER TABLE peopleADD join_date DATETIME 集合不描述或不强制其文件结构； 即在集合级别没有结构上的更改。但是，在文档级别，updateMany()操作可以使用$set运算符将字段添加到现有文档中。db.people.updateMany( { }, { $set: { join_date: new Date() } }) ALTER TABLE peopleDROP COLUMN join_date 集合不描述或不强制其文件结构； 即在集合级别没有结构上的更改。但是，在文档级别，updateMany()操作可以使用$unset运算符将字段添加到现有文档中。db.people.updateMany( { }, { $unset: { \"join_date\": \"\" } }) CREATE INDEX idx_user_id_ascON people(user_id) db.people.createIndex( { user_id: 1 } ) CREATE INDEX idx_user_id_asc_age_descON people(user_id, age DESC) db.people.createIndex( { user_id: 1, age: -1 } ) DROP TABLE people db.people.drop() 有关使用的方法和运算符的更多信息，请参见： db.collection.insertOne() db.collection.updateMany() $set db.collection.insertMany() db.collection.createIndex() $unset db.createCollection() db.collection.drop() 另看： Databases and Collections Documents Indexes Data Modeling Concepts 插入 下表显示了与将记录插入表和相应的MongoDB语句有关的各种SQL语句。 SQL INSERT语句 MongoDB insertOne() Statements INSERT INTO people(user_id, age, status)VALUES (\"bcd001\", 45, \"A\") db.people.insertOne( { user_id: \"bcd001\", age: 45, status: \"A\" }) 有关更多信息，请参见db.collection.insertOne()。 也可以看看： Insert Documents db.collection.insertMany() Databases and Collections Documents 选择 下表展示了与从表中读取记录相关的各种SQL语句以及相应的MongoDB语句。 注意 除非通过投影明确排除，否则[find()方法始终在返回的文档中包含_id字段。 下面的某些SQL查询可能包含一个_id字段来反映这一点，即使该字段未包含在相应的find()查询中也是如此。 SQL SELECT 语句 MongoDB find() 语句 SELECT *FROM people db.people.find() SELECT id, user_id, statusFROM people db.people.find( { }, { user_id: 1, status: 1 }) SELECT user_id, statusFROM people db.people.find( { }, { user_id: 1, status: 1, _id: 0 }) SELECT FROM people*WHERE status = \"A\" db.people.find( { status: \"A\" }) SELECT user_id, statusFROM peopleWHERE status = \"A\" db.people.find( { status: \"A\" }, { user_id: 1, status: 1, _id: 0 }) SELECT FROM people*WHERE status != \"A\" db.people.find( { status: { $ne: \"A\" } }) SELECT FROM peopleWHERE status = \"A\"*AND age = 50 db.people.find( { status: \"A\", age: 50 }) SELECT FROM peopleWHERE status = \"A\"*OR age = 50 db.people.find( { $or: [ { status: \"A\" } , { age: 50 } ] }) SELECT FROM people*WHERE age > 25 db.people.find( { age: { $gt: 25 } }) SELECT FROM people*WHERE age db.people.find( { age: { $lt: 25 } }) SELECT FROM peopleWHERE age > 25*AND age db.people.find( { age: { $gt: 25, $lte: 50 } }) SELECT FROM peopleWHERE user_id *like \"%bc%\" db.people.find( { userid: /bc/ } )_ordb.people.find( { user_id: { $regex: /bc/ } } ) SELECT FROM peopleWHERE user_id *like \"bc%\" db.people.find( { userid: /^bc/ } )_ordb.people.find( { user_id: { $regex: /^bc/ } } ) SELECT FROM peopleWHERE status = \"A\"ORDER BY user_id *ASC db.people.find( { status: \"A\" } ).sort( { user_id: 1 } ) SELECT FROM peopleWHERE status = \"A\"ORDER BY user_id *DESC db.people.find( { status: \"A\" } ).sort( { user_id: -1 } ) SELECT COUNT()*FROM people db.people.count()ordb.people.find().count() SELECT COUNT(user_id)FROM people db.people.count( { userid: { $exists: true } } )_ordb.people.find( { user_id: { $exists: true } } ).count() SELECT COUNT()FROM people*WHERE age > 30 db.people.count( { age: { $gt: 30 } } )ordb.people.find( { age: { $gt: 30 } } ).count() SELECT DISTINCT(status)FROM people db.people.aggregate( [ { $group : { _id : \"$status\" } } ] )or, for distinct value sets that do not exceed the BSON size limitdb.people.distinct( \"status\" ) SELECT FROM people*LIMIT 1 db.people.findOne()ordb.people.find().limit(1) SELECT FROM people*LIMIT 5SKIP 10 db.people.find().limit(5).skip(10) EXPLAIN SELECT FROM people*WHERE status = \"A\" db.people.find( { status: \"A\" } ).explain() 有关使用的方法和运算符的更多信息，请参见： .db.collection.find() .$ne .db.collection.distinct() .$and .db.collection.findOne() .$or .limit() .$gt .skip() .$lt .explain() .$exists .sort() .$lte .count() .$regex 另看： Query Documents Query and Projection Operators mongo Shell Methods 更新记录 下表显示了与更新表中的现有记录和相应的MongoDB语句有关的各种SQL语句。 SQL Update Statements MongoDB updateMany() Statements UPDATE peopleSET status = \"C\"WHERE age > 25 db.people.updateMany( { age: { $gt: 25 } }, { $set: { status: \"C\" } }) UPDATE peopleSET age = age + 3WHERE status = \"A\" db.people.updateMany( { status: \"A\" } , { $inc: { age: 3 } }) 有关示例中使用的方法和运算符的更多信息，请参见： db.collection.updateMany() $gt $set $inc 另看： Update Documents Update Operators db.collection.updateOne() db.collection.replaceOne() 删除记录 下表显示了与从表中删除记录和相应的MongoDB语句有关的各种SQL语句。 SQL Delete Statements MongoDB deleteMany() Statements DELETE FROM peopleWHERE status = \"D\" db.people.deleteMany( { status: \"D\" } ) DELETE FROM people db.people.deleteMany({}) 获得更多信息，请参见：db.collection.deleteMany(). 另看： Delete Documents db.collection.deleteOne() 进一步阅读 如果您正在考虑将SQL应用程序迁移到MongoDB，请下载《 MongoDB应用程序现代化指南》。 下载内容包括以下资源： 演示使用MongoDB进行数据建模的方法 白皮书涵盖了从RDBMS数据模型迁移到MongoDB的最佳实践和注意事项 参考MongoDB模式及其等效RDBMS 应用程序现代化记分卡 译者：杨帅 校对：杨帅 参见 原文 - SQL to MongoDB Mapping Chart Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/09-text-search.html":{"url":"04-crud/09-text-search.html","title":"文本搜索","keywords":"","body":" 文本搜索 在本页面 总览 例子 语言支持 MONGODB ATLAS搜索 Atlas搜索可以很容易地在MongoDB数据上构建快速、基于相关性的搜索功能。今天就在MongoDB Atlas,上试试吧，我们的完全托管数据库是一种服务。 总览 MongoDB支持执行字符串内容的文本搜索的查询操作。 为了执行文本搜索，MongoDB使用文本索引和$text运算符。 [success] Note 视图不支持文本搜索 例子 此示例演示了如何在仅指定文本字段的情况下构建文本索引并使用它来coffee shops。 使用以下文档创建一个集合存储： db.stores.insert( [ { _id: 1, name: \"Java Hut\", description: \"Coffee and cakes\" }, { _id: 2, name: \"Burger Buns\", description: \"Gourmet hamburgers\" }, { _id: 3, name: \"Coffee Shop\", description: \"Just coffee\" }, { _id: 4, name: \"Clothes Clothes Clothes\", description: \"Discount clothing\" }, { _id: 5, name: \"Java Shopping\", description: \"Indonesian goods\" } ] ) 文字索引 MongoDB提供了文本索引来支持对字符串内容的文本搜索查询。文本索引可以包含值为字符串或字符串元素数组的任何字段。 要执行文本搜索查询，您必须在集合上有一个文本索引。一个集合只能有一个文本搜索索引，但是该索引可以覆盖多个字段。 例如，您可以在mongo shell中运行以下命令，以允许在名称和描述字段中进行文本搜索： db.stores.createIndex( { name: \"text\", description: \"text\" } ) $text运算符 使用$text查询操作符对具有文本索引的集合执行文本索引。 $text 将使用空格和大多数标点作为分隔符对搜索字符串进行标记，并在搜索字符串中对所有这些标记执行逻辑或操作。 例如，您可以使用以下查询来查找包含“coffee”、“shop”和“java”列表中任何术语的所有商店: db.stores.find( { $text: { $search: \"java coffee shop\" } } ) 准确的短语 您还可以通过将短语包装在双引号中来搜索精确的短语。如果$search字符串包含一个短语和单个术语，文本搜索将只匹配包含该短语的文档。 例如，以下将查找包含“coffee shop”的所有文档： db.stores.find( { $text: { $search: \"\\\"coffee shop\\\"\" } } ) 更多信息参见：请看Phrases. 期限排除 要排除一个单词，可以在前面加上一个“-”字符。例如，要查找所有包含“java”或“shop”但不包含“coffee”的商店，请使用以下方法: db.stores.find( { $text: { $search: \"java shop -coffee\" } } ) 排序 默认情况下，MongoDB将以无序的顺序返回结果。但是，文本搜索查询将为每个文档计算一个相关性分数，该分数指定文档与查询的匹配程度。 为了排序的结果在相关性分数的顺序，你必须明确项目$meta textScore字段和排序: db.stores.find( { $text: { $search: \"java coffee shop\" } }, { score: { $meta: \"textScore\" } } ).sort( { score: { $meta: \"textScore\" } } ) 文本搜索也可以在聚合管道中使用。 语言支持 MongoDB支持多种语言的文本搜索。 有关支持的语言列表，请参见文本搜索语言。 译者：杨帅 校对：杨帅 参见 原文 - Text Search Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/09-text-search/01-link-text-indexes.html":{"url":"04-crud/09-text-search/01-link-text-indexes.html","title":"文本索引","keywords":"","body":" 文本索引 MongoDB提供了文本索引来支持对字符串内容的文本搜索查询。text索引可以包含值为字符串或字符串元素数组的任何字段。 要执行文本搜索查询，您必须在集合上有一个text索引。一个集合只能有一个文本搜索索引，但是该索引可以覆盖多个字段。 例如，你可以运行以下在一个mmongo shell允许文本搜索的名称和描述字段: db.stores.createIndex( { name: \"text\", description: \"text\" } ) 有关文本索引的完整引用，包括行为、标记和属性，请参阅Text Indexes部分。 译者：杨帅 校对：杨帅 参见 原文 - Text Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/09-text-search/02-text-search-operators.html":{"url":"04-crud/09-text-search/02-text-search-operators.html","title":"文本搜索运算符","keywords":"","body":" 文本搜索运算符 在本页面 查询框架 聚合框架 [success] Note 视图不支持文本搜索。 查询框架 使用$text查询操作符对具有文本索引的集合执行文本搜索。 $text将使用空格和大多数标点作为分隔符对搜索字符串进行标记，并在搜索字符串中对所有这些标记执行逻辑或操作。 例如，您可以使用以下查询来查找包含“coffee”、“shop”和“java”列表中任何术语的所有商店: db.stores.find( { $text: { $search: \"java coffee shop\" } } ) 使用$meta查询操作符获取每个匹配文档的相关性分数并进行排序。例如，要按相关性排序一份coffee shops 列表，运行以下命令: db.stores.find( { $text: { $search: \"coffee shop cake\" } }, { score: { $meta: \"textScore\" } } ).sort( { score: { $meta: \"textScore\" } } ) 有关 $text 和$meta 操作符的更多信息，包括限制和行为，请参见: $text 参考页面 $text 查询示例 $meta projection operator 聚合框架 在使用聚合框架时，使用$match 和$text 表达式来执行文本搜索查询。要按照相关性评分对结果排序，请在$sort 阶段使用$meta聚合操作符 有关聚合框架中文本搜索的更多信息和示例，请参见聚合管道中的文本搜索.。 译者：杨帅 校对：杨帅 参见 原文 - Text Search Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/09-text-search/03-text-search-in-aggregation.html":{"url":"04-crud/09-text-search/03-text-search-in-aggregation.html","title":"聚合管道中的文本搜索","keywords":"","body":" 聚合管道中的文本搜索 在本页面： 限制条件 文字分数 计算包含单词的文章的总浏览量 返回结果按文本搜索分数排序 文字分数匹配 指定用于文本搜索的语言 在聚合管道中，可以在$match 阶段使用$text查询运算符来进行文本搜索。 限制条件 有关常规的$text 运算符限制，请参见运算符限制。 此外，聚合管道中的文本搜索具有以下限制： 包含$text的$match阶段必须是管道中的第一个阶段。 文本运算符在阶段只能出现一次。 文本运算符表达式不能出现在$or 或$not 表达式中。 默认情况下，文本搜索不会按匹配分数的顺序返回匹配的文档。在$sort阶段使用$meta聚合表达式。 文字分数 $text操作符为索引字段中包含搜索词的每个文档分配一个分数。分数表示文档与给定文本搜索查询的相关性。分数可以是$sort管道规范的一部分，也可以是投影表达式的一部分。{$meta: \"textScore\"}表达式提供处理$text操作的信息。有关访问投射或排序分数的详细信息，请参阅$meta 。 元数据仅在包含 $text 操作的$match阶段之后可用。 例子 以下示例假定集合articles在字段subject上具有文本索引： db.articles.createIndex( { subject: \"text\" } ) 计算包含单词的文章的总浏览量 下面的聚合在$match阶段搜索术语cake，并在$group 阶段计算匹配文档的总视图。 db.articles.aggregate( [ { $match: { $text: { $search: \"cake\" } } }, { $group: { _id: **null**, views: { $sum: \"$views\" } } } ] ) 返回结果按文本搜索分数排序 要根据文本搜索分数进行排序，在$sort 阶段包含{$meta: \"textScore\"} 表达式。下面的示例匹配术语cake或tea，按textScore降序排序，并且只返回结果集中的title字段。 db.articles.aggregate( [ { $match: { $text: { $search: \"cake tea\" } } }, { $sort: { score: { $meta: \"textScore\" } } }, { $project: { title: 1, _id: 0 } } ] ) 指定的元数据决定排序顺序。例如，“textScore”元数据按降序排序。有关元数据的更多信息以及覆盖元数据的默认排序顺序的示例，请参见$meta。 文字分数匹配 “textScore”元数据可用于包括$text 操作的$match 阶段之后的投影、排序和条件。 下面的示例匹配术语cake或tea，投影标题和分数字段，然后只返回分数大于1.0的文档。 db.articles.aggregate( [ { $match: { $text: { $search: \"cake tea\" } } }, { $project: { title: 1, _id: 0, score: { $meta: \"textScore\" } } }, { $match: { score: { $gt: 1.0 } } } ] ) 指定用于文本搜索的语言 下面的聚合在$match 阶段中以西班牙语搜索包含术语saber而不是术语claro的文档，并计算$group 阶段中匹配文档的总视图。 db.articles.aggregate( [ { $match: { $text: { $search: \"saber -claro\", $language: \"es\" } } }, { $group: { _id: null, views: { $sum: \"$views\" } } } ] ) ​ 译者：杨帅 校对：杨帅 参见 原文 - Text Search in the Aggregation Pipeline Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/09-text-search/04-text-search-languages.html":{"url":"04-crud/09-text-search/04-text-search-languages.html","title":"文本搜索语言","keywords":"","body":" 文本搜索语言 文本索引 和$text 运算符可用于下列语言，并接受两个字母的ISO 639-1语言代码或语言名称的长形式: 语言名称 ISO 639-1(双字母代码) danish da dutch nl english en finnish fi french fr german de hungarian hu italian it norwegian nb portuguese pt romanian ro russian ru spanish es swedish sv turkish tr [success] Note 如果指定语言值为“none”，则文本搜索使用简单的标记化，不包含停止词列表和词干分析。 另看： Specify a Language for Text Index 译者：杨帅 校对：杨帅 参见 原文 - Text Search Languages Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/10-geospatial-queries.html":{"url":"04-crud/10-geospatial-queries.html","title":"地理空间查询","keywords":"","body":" 地理空间查询 在本页面： 地理空间数据 地理空间索引 地理空间查询 地理空间模型 例子 MongoDB支持对地理空间数据的查询操作。 本节介绍MongoDB的地理空间功能。 地理空间数据 在MongoDB中，您可以将地理空间数据存储为GeoJSON 对象或遗留坐标对。 GeoJSON对象 要计算类地球体的几何形状，请将位置数据存储为GeoJSON 对象。 要指定GeoJSON数据，请使用嵌入的文档: 一个名为type的字段，用于指定GeoJSON对象类型 一个名为坐标的字段，用于指定对象的坐标。 如果指定纬度和经度坐标，请先列出经度，然后再列出纬度： 有效的经度值在-180到180之间（包括两者）。 有效的纬度值在-90到90之间（包括两者之间）。 : { type: , coordinates: } 例如，要指定GeoJSON Point:： location: { type: \"Point\", coordinates: [-73.856077, 40.848447] } 有关MongoDB支持的GeoJSON对象的列表以及示例，请参阅GeoJSON 对象。 对GeoJSON对象的MongoDB地理空间查询是在球体上计算的； MongoDB使用WGS84参考系统对GeoJSON对象进行地理空间查询。 旧版坐标对 在欧几里德平面上计算距离，请将您的位置数据存储为旧坐标对并使用2d索引。 通过将数据转换为GeoJSON Point类型，MongoDB支持通过2dsphere索引对旧坐标对进行球面计算。 要将数据指定为旧版坐标对，可以使用数组(首选)或嵌入式文档。 通过数组指定(首选)： : [ , ] 如果指定纬度和经度坐标，请先列出经度，然后再列出纬度； 即： : [, ] 有效的经度值在[-180 180]。 有效的纬度值在[-90 90]。 通过嵌入式文档指定： : { : , : } 如果指定纬度和经度坐标，第一个字段必须包含经度值，而第二个字段必须包含纬度值;即。 : { : , : } 有效的经度值在[-180 180]。 有效的纬度值在[-90 90]。 为了指定旧版坐标对，数组比嵌入式文档更可取，因为某些语言不能保证关联地图的排序。 地理空间索引 MongoDB提供以下地理空间索引类型以支持地理空间查询。 2dsphere 索引支持查询，该查询可在类似地球的球体上计算几何形状。 要创建2dsphere索引，请使用db.collection.createIndex()方法并指定字符串文字“ 2dsphere”作为索引类型： db.collection.createIndex( { : \"2dsphere\" } ) 其中location field>是其值为GeoJSON对象或旧版坐标对的字段。 有关2dsphere索引的更多信息，请参见2dsphere索引。 2d 索引支持在二维平面上计算几何的查询.尽管索引可以支持在球上进行计算的$nearSphere查询，但如果可能，请对球面查询使用2dsphere索引。 要创建2d索引，请使用db.collection.createIndex()方法，将location字段指定为键，并将字符串文字“ 2d”指定为索引类型： db.collection.createIndex( { : \"2d\" } ) 其中location field>是一个值为旧版坐标对的字段。 有关2d索引的更多信息，请参见2d 索引。 地理空间索引和分片集合 分片集合时，不能将地理空间索引用作分片键。但是，可以通过使用不同的字段作为分片键在分片集合上创建地理空间索引。 分片集合支持以下地理空间操作： $geoNear聚集阶段 $near和$nearSphere查询运算符(从MongoDB 4.0开始). 从MongoDB 4.0开始，分片集合支持$near 和 $nearSphere查询。 在早期的MongoDB版本中，分片集合不支持$near 和 $nearSphere 查询。相反，对于分片群集，必须使用$geoNear聚合阶段或geoNear命令（在MongoDB 4.0及更低版本中可用）。 您还可以使用$geoWithin和$geoIntersect查询分片群集的地理空间数据。 涵盖查询 地理空间索引不能覆盖查询。 地理空间查询 [success] Note 对于球形查询，请使用2dsphere索引结果。 将2d索引用于球形查询可能会导致错误的结果，例如将2d索引用于环绕两极的球形查询。 地理空间查询操作符 MongoDB提供以下地理空间查询操作符： 名字 说明 $geoIntersects 选择与GeoJSON几何形状相交的几何形状。 2dsphere索引支持$geoIntersects. $geoWithin 选择边界GeoJSON几何图形内的几何图形。2dsphere和2d索引支持$geoWithin. $near 返回球体上某个点附近的地理空间对象。 需要地理空间索引。 2dsphere和2d索引支持$near. $nearSphere 返回接近球体上某一点的地理空间对象。需要地理空间索引。2dsphere和2d索引支持$nearSphere. 有关更多细节(包括示例)，请参见个别参考页面。 地理空间聚集阶段 MongoDB提供以下地理空间聚合管道阶段： 步骤 说明 $geoNear 根据与地理空间点的接近程度返回有序的文档流。 合并了地理空间数据的$match, $sort, 和 $limit功能。 输出文档包括附加距离字段，并且可以包括位置标识符字段。$geoNear需要一个地理空间索引。 有关更多详细信息(包括示例)，请参见$geoNear参考页。 地理空间模型 MongoDB地理空间查询可以解释平面或球体上的几何。 2dsphere索引仅支持球形查询（即解释球形表面几何形状的查询）。 2d索引支持平面查询（即解释平面上的几何图形的查询）和某些球形查询。 虽然2d索引支持某些球形查询，但是将2d索引用于这些球形查询可能会导致错误。 如果可能，请对球形查询使用2dsphere索引。 下表列出了每个地理空间操作所使用的地理空间查询运算符，受支持的查询： 操作方式 球面/平面查询 笔记 $near (GeoJSON centroid point in this line and the following line, 2dsphere index) 球形 另请参见 $nearSphere 运算符，该运算符与GeoJSON和2dsphere索引一起使用时提供相同的功能。 $near (legacy coordinates, 2d index) 平面 $nearSphere (GeoJSON point, 2dsphere index) 球形 提供与使用GeoJSON点和2dsphere索引的$ near操作相同的功能。对于球形查询，最好使用$ nearSphere而不是$ near运算符，后者在名称中显式指定球形查询。 $nearSphere (legacy coordinates, 2d index) 球形 请改用GeoJSON 点。 $geoWithin : { $geometry: … } 球形 $geoWithin : { $box: … } 平面 $geoWithin : { $polygon: … } 平面 $geoWithin : { $center: … } 平面 $geoWithin : { $centerSphere: … } 球形 $geoIntersects 球形 $geoNear aggregation stage (2dsphere index) 球形 $geoNear aggregation stage (2d index) 平面 例子 用以下文档创建一个集合places: db.places.insert( { name: \"Central Park\", location: { type: \"Point\", coordinates: [ -73.97, 40.77 ] }, category: \"Parks\" } ); db.places.insert( { name: \"Sara D. Roosevelt Park\", location: { type: \"Point\", coordinates: [ -73.9928, 40.7193 ] }, category: \"Parks\" ); db.places.insert( { name: \"Polo Grounds\", location: { type: \"Point\", coordinates: [ -73.9375, 40.8303 ] }, category: \"Stadiums\"} ); 以下操作在location字段上创建2dsphere索引： db.places.createIndex( { location: \"2dsphere\" } ) 以下查询使用$near运算符返回距指定GeoJSON点至少1000米，最多5000米的文档，并按从最近到最远的顺序排序： db.places.find( { location: { $near: { $geometry: { type: \"Point\", coordinates: [ -73.9667, 40.78 ] }, $minDistance: 1000, $maxDistance: 5000 } } } ) 以下操作使用geoNear聚合操作返回与查询过滤器{category：“ Parks”}匹配的文档，这些文档按从最接近指定GeoJSON点的最近到最远的顺序排序： db.places.aggregate( [ { $geoNear: { near: { type: \"Point\", coordinates: [ -73.9667, 40.78 ] }, spherical: **true**, query: { category: \"Parks\" }, distanceField: \"calcDistance\" } } ]) 译者：杨帅 校对：杨帅 参见 原文 - Geospatial Queries Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/10-geospatial-queries/01-geospatial-tutorial.html":{"url":"04-crud/10-geospatial-queries/01-geospatial-tutorial.html","title":"用地理空间查询查找餐馆","keywords":"","body":" 用地理空间查询查找餐馆 在本页面 总览 失真 搜索餐厅 总览 MongoDB的地理空间索引使您可以高效地对包含地理空间形状和点的集合执行空间查询。为了展示地理空间要素的功能并比较不同的方法，本教程将指导您完成为简单地理空间应用程序编写查询的过程。 本教程将简要介绍地理空间索引的概念，然后演示它们在$geoWithin, $geoIntersects, 和 $nearSphere.中的用法。 假设您正在设计一个移动应用程序，以帮助用户找到纽约市的餐馆。该应用程序必须： 使用$geoIntersects确定用户当前所在的社区 使用$geoWithin显示附近的餐馆数量， 使用$nearSphere在用户指定距离内查找餐馆 本教程将使用2dsphere索引来查询有关球形几何的数据。 有关球面和平面几何的更多信息，请参见Geospatial Models. 失真 由于将三维球体（例如地球）投影到平面上的性质，当在地图上可视化时，球形几何形状将显得失真。 例如，以经度纬度点(0,0), (80,0), (80,80), and (0,80). 定义的球形正方形的规格为例。下图描述了此区域覆盖的区域： 搜索餐厅 前提条件 从https://raw.githubusercontent.com/mongodb/docs-assets/geospatial/neighborhoods.json和https://raw.githubusercontent.com/mongodb/docs-assets/geospatial/restaurants.json下载示例数据集。它们分别包含收藏餐馆和社区。 下载数据集后，将它们导入数据库： mongoimport -c=restaurants mongoimport -c=neighborhoods 地理空间索引，几乎总是可以提高$geoWithin and $geoIntersects 查询的性能。 由于此数据是地理数据，因此请使用mongo shell在每个集合上创建2dsphere索引： db.restaurants.createIndex({ location: \"2dsphere\" }) db.neighborhoods.createIndex({ geometry: \"2dsphere\" }) 探索数据 从mongo shell中检查新创建的餐厅集合中的条目： db.restaurants.findOne() 该查询返回如下文档： { location: type: \"Point\", coordinates: [-73.856077, 40.848447] }, name: \"Morris Park Bake Shop\" } 该餐厅文档对应于下图所示的位置：由于本教程使用2dsphere索引，因此location字段中的几何数据必须遵循GeoJSON 格式. 现在检查neighborhoods集合中的条目： db.neighborhoods.findOne() 该查询将返回如下文档： { geometry: type: \"Polygon\", coordinates: [[ [ -73.99, 40.75 ], ... [ -73.98, 40.76 ], [ -73.99, 40.75 ] ]] }, name: \"Hell's Kitchen\" } 该几何形状对应于下图所示的区域： 找到当前的街区 假设用户的移动设备可以为用户提供相当准确的位置，那么使用$geoIntersects.很容易找到用户当前的街区。 假设用户位于经度-73.93414657和纬度40.82302903。 要找到当前邻域，您将使用GeoJSON格式的特殊$geometry字段指定一个点： db.neighborhoods.findOne({ geometry: { $geoIntersects: { $geometry: { type: \"Point\", coordinates: [ -73.93414657, 40.82302903 ] } } } }) 该查询将返回以下结果： { \"_id\" : ObjectId(\"55cb9c666c522cafdb053a68\"), \"geometry\" : \"type\" : \"Polygon\", \"coordinates\" : [ [ [ -73.93383000695911, 40.81949109558767 ], ... ] ] }, \"name\" : \"Central Harlem North-Polo Grounds\" } 查找附近的所有餐厅 您还可以查询以查找给定社区中包含的所有餐馆。 在mongo shell中运行以下命令以查找包含用户的社区，然后计算该社区内的餐馆： var neighborhood = db.neighborhoods.findOne( { geometry: { $geoIntersects: { $geometry: { type: \"Point\", coordinates: [ -73.93414657, 40.82302903 ] } } } } ) db.restaurants.find( { location: { $geoWithin: { $geometry: neighborhood.geometry } } } ).count() 该查询将告诉您，所请求的社区中有127家餐厅，如下图所示： 查找附近的餐厅 要查找点指定距离内的餐厅，可以将$geoWithin与 $centerSphere一起按未排序的顺序返回结果，或者如果需要按距离对结果进行排序，则可以将NearSphere与$maxDistance一起返回。 未排序$geoWithin 要查找圆形区域内的餐厅，请将$geoWithin与$centerSphere一起使用。 $centerSphere.是MongoDB特定的语法，它通过以弧度指定中心和半径来表示圆形区域。 $geoWithin不会以任何特定顺序返回文档，因此它可能会首先向用户显示最远的文档。 以下内容将查找距用户五英里范围内的所有餐馆： db.restaurants.find({ location: { $geoWithin: { $centerSphere: [ [ -73.93414657, 40.82302903 ], 5 / 3963.2 ] } } }) ’s的第二个参数接受以弧度为单位的半径，因此您必须将其除以以英里为单位的地球半径。 有关在距离单位之间进行转换的更多信息，请参见使用球面几何计算距离 。 用$nearSphere排序 您也可以使用$nearSphere 并以米为单位指定$maxDistance 项。 这将按照从最近到最远的排序顺序返回用户五英里范围内的所有餐馆： var METERS_PER_MILE = 1609.34 db.restaurants.find({ location: { $nearSphere: { $geometry: { type: \"Point\", coordinates: [ -73.93414657, 40.82302903 ] }, $maxDistance: 5 * METERS_PER_MILE } } }) 译者：杨帅 校对：杨帅 参见 原文 - Find Restaurants with Geospatial Queries Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/10-geospatial-queries/02-geojson.html":{"url":"04-crud/10-geospatial-queries/02-geojson.html","title":"GeoJSON对象","keywords":"","body":" GeoJSON对象 在本页面 总览 Point LineString 多边形 多点 MULTILINESTRING MultiPolygon GeometryCollection 总览 MongoDB 支持此页面上列出的 GeoJSON object 类型。 要指定 GeoJSON 数据，请使用嵌入式文档： 一个名为type的字段，用于指定GeoJSON对象类型 一个名为coordinates的字段，用于指定 object 的坐标。 如果指定纬度和经度坐标，请首先列出经度，然后列出纬度： 有效的经度值介于[-180 180]。 有效纬度值介于[-90 90]。 : { type: , coordinates: } GeoJSON objects 上的 MongoDB 地理空间查询在球体上计算; MongoDB 使用WGS84参考系统对 GeoJSON objects 进行地理空间查询。 Point 以下 example 指定了 GeoJSON 点： {type:\"Point\",coordinates:[40,5]} LineString 以下 example 指定了GeoJSONLineString： { type: \"LineString\", coordinates: [ [ 40, 5 ], [ 41, 6 ] ] } 多边形 多边形由一组 GeoJSON LinearRing坐标数组组成。这些LinearRings已关闭LineStrings。 Closed LineStrings至少有四个坐标对，并指定与第一个和最后一个坐标相同的位置。 连接曲面上两个点的 line 可能包含也可能不包含在平面上连接这两个点的同一组 co-ordinates。连接曲面上两点的 line 将是一个测地线。仔细检查点以避免共享边缘的错误，以及重叠和其他类型的交叉点。 单环多边形 以下 example 指定具有外环并且没有内环(或孔)的 GeoJSON Polygon。第一个和最后一个坐标必须 order 在 order 中才能关闭多边形： { type: \"Polygon\", coordinates: [ [ [ 0 , 0 ] , [ 3 , 6 ] , [ 6 , 1 ] , [ 0 , 0 ] ] ] } 对于具有单个环的多边形，环不能 self-intersect。 具有多个环的多边形 对于具有多个环的多边形： 第一个描述的环必须是外环。 外圈不能 self-intersect。 任何内圈必须完全由外圈包含。 内圈不能相互交叉或重叠。内圈不能共享边缘。 以下 example 表示具有内部环的 GeoJSON 多边形： { type : \"Polygon\", coordinates : [ [ [ 0 , 0 ] , [ 3 , 6 ] , [ 6 , 1 ] , [ 0 , 0 ] ], [ [ 2 , 2 ] , [ 3 , 3 ] , [ 4 , 2 ] , [ 2 , 2 ] ] ] } 多点 需要的版本 GeoJSONMultiPoint嵌入式文档编码点列表。 { type: \"MultiPoint\", coordinates: [ [ -73.9580, 40.8003 ], [ -73.9498, 40.7968 ], [ -73.9737, 40.7648 ], [ -73.9814, 40.7681 ] ] } MultiLineString 需要的版本 以下 example 指定了 GeoJSON MultiLineString: { type: \"MultiLineString\", coordinates: [ [ [ -73.96943, 40.78519 ], [ -73.96082, 40.78095 ] ], [ [ -73.96415, 40.79229 ], [ -73.95544, 40.78854 ] ], [ [ -73.97162, 40.78205 ], [ -73.96374, 40.77715 ] ], [ [ -73.97880, 40.77247 ], [ -73.97036, 40.76811 ] ] ] } MultiPolygon 需要的版本 以下 example 指定了GeoJSONMultiPolygon: { type: \"MultiPolygon\", coordinates: [ [ [ [ -73.958, 40.8003 ], [ -73.9498, 40.7968 ], [ -73.9737, 40.7648 ], [ -73.9814, 40.7681 ], [ -73.958, 40.8003 ] ] ], [ [ [ -73.958, 40.8003 ], [ -73.9498, 40.7968 ], [ -73.9737, 40.7648 ], [ -73.958, 40.8003 ] ] ] ] } GeometryCollection 需要的版本 以下 example store GeoJSON类型 GeometryCollection的坐标: { type: \"GeometryCollection\", geometries: [ { type: \"MultiPoint\", coordinates: [ [ -73.9580, 40.8003 ], [ -73.9498, 40.7968 ], [ -73.9737, 40.7648 ], [ -73.9814, 40.7681 ] ] }, { type: \"MultiLineString\", coordinates: [ [ [ -73.96943, 40.78519 ], [ -73.96082, 40.78095 ] ], [ [ -73.96415, 40.79229 ], [ -73.95544, 40.78854 ] ], [ [ -73.97162, 40.78205 ], [ -73.96374, 40.77715 ] ], [ [ -73.97880, 40.77247 ], [ -73.97036, 40.76811 ] ] ] } ] } ​ 译者：杨帅 校对：杨帅 参见 原文 - GeoJSON Objects Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern.html":{"url":"04-crud/11-read-concern.html","title":"读关注","keywords":"","body":" 读关注 在本页面 读关注级别 ReadConcern 支持 注意事项 读关注 选项允许你控制从复制集和分片集群读取数据的一致性和隔离性。 通过有效地使用写关注和读关注，你可以适当地调整一致性和可用性的保证级别，例如等待以保证更强的一致性，或放松一致性要求以提供更高的可用性。 将MongoDB驱动程序更新到MongoDB 3.2或更高版本以支持读关注。 阅读关注级别 以下为可用的读关注级别： level Description \"local\" 查询并从实例返回数据，但不能保证该数据已被写入大多数副本集成员（即可能已经回滚）。默认为： 针对主节点读。 如果读取与因果一致的会话相关联，则针对副节点读。可用性：读关注local可用于有或没有因果关系一致的会话和事务中。更多的信息，请参考\"local\"页 \"available\" 查询并从实例返回数据，但不能保证该数据已被写入大多数副本集成员（即可能已经回滚）。默认为：如果读取与因果关系一致的会话没有关联，则针对副节点读可用性：读关注available无法用于有因果关系一致的会话和事务中。对于分片群集，\"available\"读关注提供了各种读关注中尽可能最低的延迟。但是，这是以牺牲一致性为代价的，因为从分片的集合中进行读取时，\"available\"读关注会返回孤立的文档。为了避免从分片的集合中读取时返回孤立文档的风险，可使用其他读关注，如\"local\"读关注。更多的信息，请参考\"available\"页3.6版本的新功能 \"majority\" 为了满足读关注“majority”，副本集成员从其内存视图中返回多数提交点提交的数据。这样，读关注\"majority\"在性能成本上可与其他读关注相媲美。可用性：读关注\"majority\"可用于有或没有因果关系一致的会话和事务中。对于具有三名成员的主从仲裁（PSA）架构的部署，可以禁用读关注\"majority\"；但是，这对change streams（仅在MongoDB 4.0和更早版本中）和分片群集上的事务有影响。有关更多信息，请参见禁用读关注Marjority.。要求：若要使用\"majority\"的读关注级别，副本集必须使用WiredTiger存储引擎。注意：对于多文档事务中的操作，仅当事务以写关注\"majority\"提交时，读关注\"majority\"才提供其保证。否则，\"majority\"读关注不能保证其在事务中读取的数据。更多的信息，请参考\"majority\"页 \"linearizable\" 该查询返回的数据表示了这些数据在操作开始之前已成功在大多数节点确认写入。查询可能会等待并发执行的写操作传播到大多数副本集成员，然后返回结果。如果大多数副本集成员崩溃并在读操作后重新启动，则如果将writeConcernMajorityJournalDefault设置为默认状态true，则读操作返回的文档将还是有效的。将writeConcernMajorityJournalDefault设置为false时，MongoDB不会等待w: \"majority\"在确认写入之前先要写入磁盘日志。这样，如果给定副本集中大多数节点的瞬时丢失（例如崩溃和重新启动），majority写操作可能会回滚。可用性：读关注\"linearizable\"不适用于因果一致的会话和事务。你可以仅对主节点上的读操作指定为线性读关注。你不能将$out或$merge操作与读关注\"linearizable\"结合使用。也就是说，如果为db.collection.aggregate()指定为\"linearizable\"读关注，则不能在管道中使用任何的操作。要求：linearizable读关注仅保证在读操作指定了唯一标识单个文档的查询过滤器时可用。请始终将maxTimeMS与linearizable读关注一起使用，以防止大多数数据承载成员不可用。maxTimeMS确保操作不会无限期地阻塞，而是确保如果无法满足读取要求，则操作将返回错误。更多的信息，请参考\"linearizable\"页 \"snapshot\" 如果事务不是因果一致会话的一部分，写关注为\"majority\"且在事务提交后，可以确保事务操作已从多数提交数据的快照中读取。如果事务是因果一致会话的一部分，写关注为\"majority\"且在事务提交后，可以确保事务操作已从多数提交数据的快照中读取，该快照提供了与紧接事务开始之前的操作的因果一致性。读关注\"snapshot\"仅可用于多文档事务。对于分片群集上的事务，如果事务中的任何操作涉及已被禁用读关注“majority”的分片，那你就不能对该事务使用读关注\"snapshot\"。你只能对事务使用读关注\"local\"或\"majority\"。 无论读关注级别如何，节点上的最新数据都可能无法反映系统中数据的最新版本 有关每个阅读关注级别的更多信息，请参见： 读关注 \"local\" 读关注 \"available\" 读关注 \"majority\" 读关注 \"linearizable\" 读关注 \"snapshot\" ReadConcern 支持 读关注选项 对于不在多文档事务中的操作，你可以将 readConcern 级别指定为一个命令和方法的选项： readConcern: { level: } 要为 mongo shell方法 db.collection.find() 指定阅读关注级别，请使用 cursor.readConcern() 方法： db.collection.find().readConcern() 事务和可用的读关注 对于多文档事务，应在事务级别而不是在单个操作级别设置读关注。事务中的操作将使用事务级别的读关注。事务内部将忽略在集合和数据库级别设置的任何读关注。如果显式指定了事务级别的读关注点，则在事务内部也将忽略客户端级别的读关注点。 重要 不要为各个操作明确设置读关注。要设置事务的读关注，请参阅读 Read Concern/Write Concern/Read Preference。 你可以在事务开始时设置读关注： 对于多文档事务，读关注级别\"snapshot\", \"local\" 和 \"majority\"是可用的。 多文档事务中的写命令可以支持事务级别的读关注。 如果未在事务开始时指定，则事务将使用会话级的读关注，或者如果未设置，则使用客户端级的读关注。 有关等多信息，请参考 事务的读关注. 因果一致的会话和阅读相关的担忧 对于在因果一致的会话中的操作，\"local\" h和 \"majority\"级别可用。但是，为了保证因果一致性，你必须使用 \"majority\"。有关详细信息，请参见 因果一致性。 如果多文档事务与因果一致的会话相关联，则\"snapshot\" 也可用于该事务。 支持读关注的操作 下列的操作支持读关注： 重要 在为事务中的操作设置读关注时，请在事务级别而不是在单个操作级别设置读关注。不要在事务中明确的设置单独操作的读关注。更多信息，查看事务和读关注 命令/方法 \"local\" \"available\" \"majority\" \"snapshot\" \"linearizable\" count ✓ ✓ ✓ ✓ distinct ✓ ✓ ✓ ✓ ✓ find ✓ ✓ ✓ ✓ ✓ db.collection.find() via cursor.readConcern() ✓ ✓ ✓ ✓ ✓ geoSearch ✓ ✓ ✓ ✓ ✓ getMore ✓ ✓ aggregate db.collection.aggregate() ✓ ✓ ✓ ✓ ✓ Session.startTransaction() ✓ ✓ ✓ [1] 你不能将$out 或者 $merge阶段与读关注的\"linearizable\"结合使用。也就是说，如果为db.collection.aggregate()指定\"linearizable\"读关注，则不能在管道中包括任何一个阶段。 [2] 读关注\"snapshot\"仅适用于多文档事务。在事务中，不能在分片集合上使用distinct命令或其协助命令。 下列的写操作页能接受读关注，但必须是多文档事务的一部分： 重要 在为事务中的操作设置读关注时，请在事务级别而不是在单个操作级别设置读关注 Command 命令 \"local\" \"available\" \"majority\" \"snapshot\" \"linearizable\" deletedb.collection.deleteMany()db.collection.deleteOne()db.collection.remove() ✓ ✓ findAndModifydb.collection.findAndModify()db.collection.findOneAndDelete()db.collection.findOneAndReplace()db.collection.findOneAndUpdate() ✓ ✓ insertdb.collection.insert()db.collection.insertOne()db.collection.insertMany() ✓ ✓ updatedb.collection.update()db.collection.updateMany()db.collection.updateOne()db.collection.replaceOne() ✓ ✓ [3] (1, 2)读关注“SNAPSHOT”仅适用于多文档事务，并且对于事务，您可以在事务级别设置读关注。支持“SNAPSHOT”的操作对应于事务中可用的CRUD操作。有关更多信息，请参见事务和读关注 注意事项 读自己的文章 在版本3.6中更改 从MongoDB 3.6版本开始，如果写请求确认，你可以使用因果一致的会话读你自己写入的内容。 在MongoDB 3.6之前，您必须使用 { w: \"majority\" } 写关注发出写操作，然后对读操作使用 \"majority\" 或者 \"linearizable\"读关注，以确保单个线程可以读取自己的写入内容 实时顺序 结合\"majority\" 写关注，\"linearizable\" 读关注使多个线程可以在单个文档上执行读写操作，就好像单个线程实时地执行了这些操作一样。 也就是说，这些读写的对应的计划被认为是线性的。 性能比较 与\"majority\"不同，\"linearizable\" 的读关注通过从节点确认读操作正在从主节点读，该操作能够以{ w: \"majority\" }写关注来确认写入。 [4]因此，具有线性化读关注的读取可能比具有\"majority\" 或 \"local\"读关注的读慢得多。 为了避免万一大多数数据承载成员不可用，请始终将 maxTimeMS 与可线性化的读确认一起使用。maxTimeMS 确保操作不会无限期地阻塞，而是确保如果无法满足读取要求，则操作将返回错误。 例如： db.restaurants.find( { _id: 5 } ).readConcern(\"linearizable\").maxTimeMS(10000) db.runCommand( { find: \"restaurants\", filter: { _id: 5 }, readConcern: { level: \"linearizable\" }, maxTimeMS: 10000 } ) [4] 在某些情况下，副本集中的两个节点可能会短暂地认为它们是主节点，但至多，其中一个节点将能够以{ w: \"majority\" }写关注完成。 可以完成{ w: \"majority\" }写入的节点是当前主节点，另一个节点是前主节点，由于网络分区的原因，该主节点尚未意识到其降级。 发生这种情况时，尽管请求的读优先级为主节点，但连接到前主界定啊的客户端仍可能会读到过时的数据，并且最终将对前主节点新写入的进行回滚。 读操作和afterClusterTime 3.6 版本新加入 MongoDB 3.6引入了对因果一致会话的支持。 对于与因果一致的会话相关联的读操作，MongoDB 3.6引入了 afterClusterTime 读关注选项，驱动程序会自动将afterClusterTime 读关注选项设置为与因果一致的会话相关联的操作。 [warning] 重要 不要手动为读操作设置 afterClusterTime 。 MongoDB驱动程序会针对与因果一致的会话相关联的操作自动设置此值。 但是，您可以提前会话的操作时间和群集时间，以便与另一个客户端会话的操作保持一致。 有关示例，请参见示例。 为了满足 afterClusterTime 值为T的读请求， mongod 必须在其oplog到达时间T之后执行请求。如果其oplog尚未达到时间T，则 mongod 必须等待服务该请求。 使用指定的 afterClusterTime 的读操作将返回满足读关注级别要求和指定的 afterClusterTime 要求的数据。 对于与因果一致会话无关的读操作，未设置 afterClusterTime。 阅读问题出处 从4.4版本开始，MongoDB跟踪阅读关注来源，表示某个特定读取关注点的来源。您可能会在getLastError指标、读取关注错误对象和MongoDB日志中看到出处。 下表显示了可能的阅读问题provenance值及其重要性: 出处 描述 clientSupplied read关注点是在应用程序中指定的。 customDefault 读取关注点源自自定义的默认值。 参见 setDefaultRWConcern. implicitDefault 在没有其他所有读取关注规范的情况下，读取关注源自服务器。 译者：杨帅 张琦 校对：杨帅 参见 原文 - Read Isolation (Read Concern) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern/01-read-concern-local.html":{"url":"04-crud/11-read-concern/01-read-concern-local.html","title":"读关注“local”","keywords":"","body":" 读关注“local” 具有读取关注点的查询local从实例返回数据，但不保证数据已写入大多数复制集成员(即：可能会回滚)。 读取关注local是默认值： 读取针对主要的操作 如果读取与因果关系一致关联，则读取针对辅助节点的操作。 不管读关注级别如何，节点上的最新数据都可能无法反映系统中数据的最新版本。 可用性 读关注local可用于有或没有因果关系一致的会话和事务。 读关注”local“和事务 您可以在事务级别上而不是在单个操作级别上设置读取关注。要设置事务的已读关注点，请参见事务和已读关注点。 从MongoDB 4.4开始，功能兼容版本(fcv) “4.4”或更高版本，您可以在事务中创建集合和索引。如果显式地创建集合或索引，则事务必须使用read concern“\"local\"。隐式创建集合可以使用事务可用的任何读取关注点。 例子 考虑写入操作 Write0 到三个成员副本集的以下时间轴： 注意 Write0 之前的所有写操作都已成功复制到所有成员。 Writeprev 是 Write0之前的写入。 在 Write0之后没有发生其他写操作。 时间 事件 最新写 最新的多数写 t0 主要适用于Write0 主要：Write0次要1：Writeprev次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t1 Secondary1适用于Write0 主要：Write0次要1：Write0次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t2 Secondary2适用于Write0 主要：Write0次要1：Write0次要2：Write0 主要：Writeprev次要1：Writeprev次要2：Writeprev t3 Primary知道到Secondary1的复制成功，并向客户端发送确认 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t4 Primary 知道成功复制到 Secondary2 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t5 Secondary1接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Writeprev t6 Secondary2接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Write0 然后，下表总结了具有“local”读关注的读操作在T时刻看到的数据状态。 阅读目标 Time T 数据状态 Primary 在t0之后 数据反映了 Write0 Secondary1 在t1之前 数据反映了 Writeprev Secondary1 在t1之后 数据反映了 Write0 Secondary2 在t2之前 数据反映了 Writeprev Secondary2 在t2之后 数据反映了 Write0 译者：杨帅 校对：杨帅 参见 原文 - Read Concern \"local\" Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern/02-read-concern-available.html":{"url":"04-crud/11-read-concern/02-read-concern-available.html","title":"读关注“available”","keywords":"","body":" 读关注“available” version 3.6 中的新内容。 与read有关的“available”查询从实例返回数据，但不保证数据已经被写入大多数复制集成员(即可能被回滚)。 如果读操作不与因果一致的会话相关联，那么读关注“available”是对次要操作的默认读操作。 对于分片 cluster，\"available\" 读取问题为分区提供了更大的容忍度，因为它不会等待以确保一致性保证。但是，如果分片正在进行大块迁移，那么带有 \"available\"读取问题的查询可能会return孤立文档，因为“本地”读取问题与“本地”读取问题不同，它不会联系分片的主服务器或配置服务器以更新元数据。 对于unsharded集合(包括独立部署或复制集部署中的集合)，\"local\" 和 \"available\" 读取问题的行为相同。 不管read concern级别，节点上的最新数据可能不能反映系统中数据的最新版本。 也可以看看 orphanCleanupDelaySecs 可用行 读关注 available对于因果一致的会话和事务不可用。 例子 考虑写入操作 Write0 到三个成员复制集的以下时间轴： [success] Note 为了简化，本例假设: Write0 之前的所有写操作都已成功复制到所有成员。 Writeprev 是 Write0之前的写入。 在 Write0之后没有发生其他写操作。 时间 事件 最新写 最新的多数写 t0 主要适用于Write0 主要：Write0次要1：Writeprev次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t1 Secondary1适用于Write0 主要：Write0次要1：Write0次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t2 Secondary2适用于Write0 主要：Write0次要1：Write0次要2：Write0 主要：Writeprev次要1：Writeprev次要2：Writeprev t3 Primary知道到Secondary1的复制成功，并向客户端发送确认 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t4 Primary 知道成功复制到 Secondary2 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t5 Secondary1接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Writeprev t6 Secondary2接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Write0 然后，下表总结了 time读取关注的读操作在 time T处将看到的数据的 state。 阅读目标 Time T 状态的数据 Primary After t0 Data reflects Write0 Secondary1 Before t1 Data reflects Writeprev Secondary1 After t1 Data reflects Write0 Secondary2 Before t2 Data reflects Writeprev Secondary2 After t2 Data reflects Write0 译者：杨帅 校对：杨帅 参见 原文 - Read Concern \"available\" Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern/03-read-concern-majority.html":{"url":"04-crud/11-read-concern/03-read-concern-majority.html","title":"读关注“majority”","keywords":"","body":" 读关注“majority” 在本页面 性能 可用性 例子 存储引擎支持 读关注\"majority\"和事务 读关注\"majority\"和汇总 读取自己的写入 禁用读关注多数 对于多文档事务中无关的读操作，阅读问题“majority”保证所读的数据得到了大多数复制集成员的认可(即，所读的文档是持久的，并且保证不会回滚)。 对于多文档事务中的操作，只有当事务以写关注点“多数”提交时，读关注点多数才提供保证。否则，“多数”读取关注不能保证在事务中读取的数据。 不管读关注级别是什么，节点上的最新数据都可能不能反映系统中数据的最新版本。 性能 每个复制集成员在内存中维护多数提交点处的数据视图。多数提交点是由初级计算的。为了满足读取关注\"majority\"，该节点从该视图返回数据，并且性能成本与其他读取关注相当。 可用性 无论会话和事务是否一致，都可以使用读关注\"majority\"。 对于使用三成员主-副-仲裁(PSA)体系结构的部署，可以禁用读关注 \"majority\"”,然而，这对更改流(MongoDB 4.0和更早版本中只使用)和分片集群上的事务有影响。有关更多信息，请参见禁用读关注多数.。 例子 考虑写入操作 Write0 到三个成员复制集的以下时间轴： 注意 Write0 之前的所有写操作都已成功复制到所有成员。 Writeprev 是 Write0之前的写入。 在 Write0之后没有发生其他写操作。 时间 事件 最新写 最新的多数写 t0 主要适用于Write0 主要：Write0次要1：Writeprev次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t1 Secondary1适用于Write0 主要：Write0次要1：Write0次要2：Writeprev 主要：Writeprev次要1：Writeprev次要2：Writeprev t2 Secondary2适用于Write0 主要：Write0次要1：Write0次要2：Write0 主要：Writeprev次要1：Writeprev次要2：Writeprev t3 Primary知道到Secondary1的复制成功，并向客户端发送确认 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t4 Primary 知道成功复制到 Secondary2 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Writeprev次要2：Writeprev t5 Secondary1接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Writeprev t6 Secondary2接收通知(通过常规复制机制)以更新其最近 w：“多数”写入的快照 主要：Write0次要1：Write0次要2：Write0 主要：Write0次要1：Write0次要2：Write0 然后，下表总结了具有\"majority\"读关注的读取操作在时间将看到的数据状态T。 阅读目标 Time T 数据状态 Primary 在t3之前 数据反映了 Writeprev Primary 在t3之后 数据反映了 Write0 Secondary1 在t5之前 数据反映了 Writeprev Secondary1 在t5之后 数据反映了 Write0 Secondary2 在t6之前 数据反映了 Writeprev Secondary2 在t6之后 数据反映了 Write0 存储引擎支持 阅读关注“多数”是可用的WiredTiger存储引擎。 提示 serverStatus命令返回storageEngine.supportsCommittedReads字段，该字段指示存储引擎是否支持”majority“读取问题。 读关注\"majority\"和事务 [success] Note 您可以在事务级别上而不是在单个操作级别上设置读关注。要设置事务的已读关注点，请参见事务和已读关注点。 对于多文档事务中的操作，\"majority\"仅当事务以写关注“多数”提交时，读关注才提供其保证。否则， \"majority\"读取关注点不能保证事务中读取的数据。 读关注\"majority\"和汇总 从MongoDB 4.2开始，您可以为包含$out阶段的聚合指定读取关注 level \"majority\"。 在MongoDB 4.0和更早版本中，您不能包括将读取关注用于聚合的$out 阶段\"majority\"。 读取自己的写入 更改了 version 3.6. 从 MongoDB 3.6 开始，如果写请求确认，则可以使用因果关系一致来读取您自己的写入。 在MongoDB 3.6之前，您必须发出具有写入关注点的写入操作， 然后 对读取操作使用或关注读取，以确保单个线程可以读取自己的写入。{ w: \"majority\" }\"majority\"\"linearizable\". 在MongoDB 3.6之前，你必须使用{ w: \"majority\" } 写关注点来发布写操作，然后使用\"majority\"或\"linearizable\" 的读关注点来执行读操作，以确保单个线程可以读取自己的写操作。 禁用读关注多数 适用于3成员主-副-仲裁器体系结构 \"majority\"如果您具有具有主要-次要仲裁器（PSA）体系结构的三成员复制集或具有三成员PSA分片的分片群集，则可以禁用读关注。 [success] Note 如果您使用的是 3-member PSA 以外的部署，则无需禁用多数读关注。 对于三成员PSA架构，缓存压力将增加，如果任何承载数据的节点是关闭的。为了防止存储缓存压力使PSA架构的部署无法被锁定，您可以通过设置以下任一项来禁用read concern: --enableMajorityReadConcern的命令行选项false。 replication.enableMajorityReadConcern配置文件设置为false。 要检查是否已禁用“大多数”的读关注，您可以db.serverStatus()在mongod实例上运行 并检查该storageEngine.supportsCommittedReads字段。如果为false，则禁用“大多数”关注。 [warning] 重要 通常，除非必要，否则请避免禁用\"majority\" 读取问题。但是，如果您的 three-member 复制集具有 主-副-仲裁(PSA)体系结构 或带有 three-member PSA 分片的分片 cluster，请禁用以防止存储缓存压力导致部署无法运行。 禁用“多数”读取问题会禁用对改变流的支持。 变更流 禁用\"majority\"读取关注会禁用对MongoDB 4.0及更早版本的变更流的支持。对于MongoDB 4.2+，禁用读取关注\"majority\"不会影响变更流的可用性。 事务次数 禁用\"majority\"读取关注会影响对分片群集上事务的支持 。特别： \"snapshot\"如果事务涉及已禁用读取关注“多数”的分片，则该事务不能使用读取关注。 如果事务的任何读或写操作写入多个分片错误，则该事务涉及已禁用读取关注的分片\"majority\"。 但是，它不影响复制集上的事务。对于复制集上的事务，即使禁用了读关注，也可以为多文档事务指定读关注\"majority\"（或\"snapshot\" 或\"local\"）\"majority\"。 回滚的注意事项 禁用\"majority\"读关注可以防止修改索引的collMod 命令回滚。如果需要回滚此类操作，则必须将受影响的节点与主节点重新同步。 参见 原文 - Read Concern \"majority\" Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern/04-read-concern-linearizable.html":{"url":"04-crud/11-read-concern/04-read-concern-linearizable.html","title":"读关注“linearizable”","keywords":"","body":" 读关注“linearizable” 3.4版本中的新功能。 该查询返回的数据反映了在开始读操作之前完成的所有成功的经过多数确认的写操作。在返回结果之前，查询可以等待并发执行的写传播到大多数复制集成员。 如果大多数复制集成员在读取操作后崩溃并重新启动，则如果writeConcernMajorityJournalDefault设置为true的默认 state，则读取操作返回的文档是持久的。 当writeConcernMajorityJournalDefault设置为false时，MongoDB 不会等待 w: \"majority\"写入在确认写入之前写入磁盘上日志。因此，majority写操作可能会在给定复制集中的大多数节点的瞬时丢失(即. 崩溃和重启)的事件中回滚。 您可以仅为主节点上的读操作指定可线性化的读关注。 可线性化读取关注保证仅在读取操作指定唯一标识单个文档的查询过滤器时才适用。 提示 如果大多数数据承载成员不可用，请始终使用带有线性化读取问题的maxTimeMS。 maxTimeMS确保操作不会无限期地阻塞，而是确保在无法满足读取关注时操作返回错误。 因果一致的会话 对于因果一致会话，读关注linearizable不可用。 聚集限制 不能将$out 或 $merge 阶段与read关注点线性化结合使用。也就是说，如果您为db.collection.aggregate()指定了\"linearizable\"读关注，则不能在管道中包含这两个阶段。 实时订单 结合\"majority\"写关注， \"linearizable\"读关注使多个线程可以在单个文档上执行读写操作，就好像单个线程实时执行了这些操作一样。也就是说，这些读写的相应计划被认为是线性的。 读取自己的写入 更改了3.6版本. 从 MongoDB 3.6 开始，如果写请求确认，则可以使用 因果关系一致来读取您自己的写入。 在MongoDB 3.6之前，你必须使用 { w: \"majority\" } 写关注点来发布写操作，然后使用\"majority\" 或\"linearizable\" 的读关注点来执行读操作，以确保单个线程可以读取自己的写操作。 性能比较 与“多数”不同，“可线性化”的读关注点向辅助成员确认读操作是从能够用 { w: \"majority\" } 写关注点确认写操作的主成员读取的。这样，线性化的读取可能比“多数”或“局部”读取要慢得多。 与\"majority\"不同，\"linearizable\"的读关注点向辅助成员确认读操作是从能够用 { w: \"majority\" }写关注点确认写操作的主成员读取的。[1] 这样，线性化的读取可能比 \"majority\" 或 \"local\"读取要慢得多。 总是使用可线性化读取关注的maxTimeMS，以防大多数数据承载成员不可用。maxTimeMS确保了操作不会无限期地阻塞，相反，它确保了如果读问题不能实现，操作会返回一个错误。 例如： db.restaurants.find( { _id: 5 } ).readConcern(\"linearizable\").maxTimeMS(10000) db.runCommand( { find: \"restaurants\", filter: { _id: 5 }, readConcern: { level: \"linearizable\" }, maxTimeMS: 10000 } ) [1] 在某些情况下，一个复制集中的两个节点可能暂时认为它们是主节点，但它们中的一个最多能够完成{ w: \"majority\" }写关注点的写操作。能够完成{ w: \"majority\" }写操作的节点是当前主节点，而另一个节点是前主节点，它还没有意识到降级，通常是由于网络分区。当发生这种情况时，连接到前主服务器的客户机可能会观察到陈旧的数据，尽管已经请求了读首选项主服务器，并且对前主服务器的新写操作最终将回滚。 译者：杨帅 校对：杨帅 参见 原文 - Read Concern \"linearizable\" Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/11-read-concern/05-read-concern-snapshot.html":{"url":"04-crud/11-read-concern/05-read-concern-snapshot.html","title":"读关注点\"snapshot\"","keywords":"","body":" 读关注点\"snapshot\" 版本4.0中的新功能 读取关注“snapshot”只对多文档事务可用。 如果事务不是因果一致会话的一部分，那么在事务提交时，写关注点为\"majority\"，事务操作就保证已经从多数提交数据的快照中读取了数据。 如果事务是因果一致会话的一部分，那么在事务提交时，write concern为\"majority\"，事务操作保证已经从多数提交数据的快照中读取，该快照提供了与事务开始前的操作因果一致的数据。 操作 有关接受阅读关注的所有操作的列表，请参阅 支持读关注的操作。 阅读关注和事务 多文档事务支持阅读关注 \"snapshot\"以及\"local\"和 \"majority\"。 [success] Note 您可以在事务级别上而不是在单个操作级别上设置读取关注。要设置事务的已读关注点，请参见事务和已读关注点。 对于分片群集上的事务，如果事务中的任何操作涉及已禁用读关注度“多数”的分片，则不能\"snapshot\"对事务使用读关注度。您只能使用已读关注\"local\"或\"majority\"用于事务。如果使用读取关注\"snapshot\"，则事务错误并中止。有关更多信息，请参见 禁用阅读关注多数。 译者：杨帅 校对：杨帅 参见 原文 - Read Concern \"snapshot\" Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/12-write-concern.html":{"url":"04-crud/12-write-concern.html","title":"写关注","keywords":"","body":" 写关注 在本页面 编写关注规范 确认行为 因果一致的会话和写问题 计算关注的多数 写关注描述了MongoDB请求对独立mongod或复制集或分片群集进行写操作的确认级别。在分片群集中，mongos实例会将写关注事项传递给分片。 [success] Note 对于多文档事务，可以在事务级别而不是在单个操作级别设置写关注。不要为事务中的各个写操作显式设置写关注点。 编写关注规范 写关注可包括以下字段： { w ： ， j ： ， wtimeout ： } 使用w选项来请求确认写入操作已传播到指定数量的mongod 实例或mongod具有指定标签的实例。 该j选项要求确认写操作已被写入到磁盘上的杂志，和 该wtimeout选项来指定一个时间限制，以防止无限期阻塞写操作。 w 选项 w选项请求确认写操作已传播到指定数量的mongod实例或具有指定标记的mongod实例。 使用w选项，可以使用以下w:value>写入问题： 值 描述 请求确认写操作已传播到指定数量的mongod实例。例如：w: 1请求确认写入操作已传播到mongod复制集中的独立副本或主副本。是MongoDB的默认写关注点。 如果在写操作已复制到任何辅助数据库之前主数据库已降级，则可以回滚数据。w: 1``w: 0不要求确认写入操作。但是，可能会将有关套接字异常和网络错误的信息返回给应用程序。如果在写操作已复制到任何辅助数据库之前主数据库已降级，则可以回滚数据 。w: 0如果指定但包括j：true，则优先使用 j：true来请求独立或复制集主副本的确认。w: 0mongodw大于1则需要来自主数据库的确认以及满足指定写入问题所需的尽可能多的数据承载辅助数据库的确认。例如，考虑一个具有一个主要成员和两个次要成员的3成员复制集。指定将需要主数据库和辅助数据库之一的确认。指定将需要主要和次要确认。w: 2``w: 3注意Hidden， delayed和 priority 0 成员可以确认写操作。w:延迟的辅助副本可以在不早于configure的情况下返回写确认slaveDelay。有关实例何时确认写入的信息，请参见确认行为mongod。 \"majority\" 请求确认写入操作已传播到所计算的大多数含数据投票成员（即具有的members[n\\].votes大于的主要和次要成员 0）。例如，考虑一个具有3个投票成员的复制集，即Primary-Secondary-Secondary（PSS）。对于此复制集， 计算出的多数为2，并且写入必须传播到主要对象和一个辅助对象，以向客户端确认写入问题。注意隐藏， 延迟和优先级为0的 成员（members[n\\].votes大于0 可以确认\"majority\"写入操作）。延迟的辅助副本可以在不早于configure的情况下返回写确认slaveDelay。在写操作返回确认给客户端之后，客户端可以使用readConcern 读取该写操作的结果 。w: \"majority\"\"majority\"有关实例何时确认写入的信息，请参见确认行为mongod。 请求确认写操作已传播到tagged满足中定义的自定义写关注点的成员 settings.getLastErrorModes。有关示例，请参阅“ 自定义多数据中心写入问题”。如果自定义写入问题仅需要在写入操作复制到任何辅助数据库之前先要求主要数据库和主要数据库降级的确认，则可以回滚数据。有关 实例何时确认写入的信息，请参见确认行为mongod。 也可以看看 默认的MongoDB读问题/写问题 复制集协议版本 j 选项 该j选项要求MongoDB确认写入操作已写入磁盘日志中。 j 如果为，则请求确认w：中指定的 实例已写入磁盘日志中。本身并不能保证不会因副本集主故障转移而回滚写操作。j: truemongodj: true在版本3.2中进行了更改：使用时，MongoDB仅在请求数量的成员（包括主要成员）写入日志后才返回。不管w：写入关注点如何，副本集中以前的写入关注点只要求主记录写到日志。j: truej: true [success] Note 指定一个写入关注点，该关注点包含到正在运行且没有日志记录的 实例中会产生错误。j: truemongod 如果启用日记功能，则可能暗示。的 副本集配置设置确定的行为。有关详细信息，请参见 确认行为。w: \"majority\"j: truewriteConcernMajorityJournalDefault. 如果日志是启用的，w: \"majority\" 可能意味着j：true。writeConcernMajorityJournalDefault 复制集配置设置决定了行为。有关详细信息，请参阅确认行为 。 wtimeout 此选项指定写入问题的 time 限制(以毫秒为单位)。 wtimeout仅适用于大于1的w值。 wtimeout导致写入操作返回到指定限制后的错误，即使所需的写入关注最终会成功。当这些写操作 return 时，MongoDB 不会撤消在写入关注超过wtimeout time 限制之前执行的成功数据修改。 如果未指定wtimeout选项且写入关注的 level 无法实现，则写入操作将无限期阻止。指定0的wtimeout value 等同于没有wtimeout选项的写入问题。 确认行为 当mongod实例确认写操作时 w选项和 j 选项决定。 独立 独立mongod应用程序在应用了内存中的写入之后或写入磁盘日志后会确认写入操作。下表列出了独立服务器的确认行为以及相关的写入问题： j 未指定 j:true j:false w: 1 在记忆中 磁盘日志 在内存中 w: \"majority\" 磁盘日志（如果与日志一起运行） 磁盘日志 在内存中 [success] Note 随着writeConcernMajorityJournalDefault设置为false，MongoDB的不等待 写入承认写之前被写入到磁盘上的日志。这样，在给定副本集中的大多数节点出现瞬时丢失（例如崩溃和重新启动）的情况下，写操作可能会回滚。w: \"majority\"majority 复制集 指定给w的值确定返回成功之前必须确认写入的复制集成员的数量。对于每个合格的复制集成员，j 选项确定成员是在内存中应用写操作之后还是在写到磁盘日志上之后是否确认写。 w: \"majority\" 复制集的任何带有数据的投票成员都可以对\"majority\"写操作进行写确认。 下表列出了成员何时可以基于j值确认写入： j是不确定的 确认取决于writeConcernMajorityJournalDefault的值:如果为true，确认需要对磁盘上的日志进行写入操作(j: true)writeConcernMajorityJournalDefault默认为true如果为false，确认需要在内存中进行写入操作(j: false)。 j: true 确认需要对磁盘日志进行写入操作。 j: false 确认需要在内存中进行写入操作。 [success] Note 行为细节,参见 w: \"majority\" Behavior. w: number> 复制集的任何承载数据的成员都可以参与w：写操作的写确认。 下表列出了成员何时可以基于j值确认写入： j 未指定 确认需要在内存中进行写操作(j: false)。 j: true 确认需要将操作写入磁盘日志。 j: false 确认需要在内存中进行写操作。 注意 隐藏， 延迟和优先级为0 的成员可以确认w:写操作。 延迟的辅助程序可以不早于配置的slaveDelay返回写确认。 因果一致的会话和写问题 使用因果一致的客户机会话，客户机会话仅在以下情况下保证因果一致性： 相关的读取操作使用\"majority\"读取关注，并且 相关的写操作使用\"majority\" 写关注。 有关详细信息，请参见因果一致性。 w: \"majority\" 的行为 writeConcernMajorityJournalDefault设置为false，MongoDB不等待w: \"majority\" 写入被写入到磁盘日志之前，确认写入，因此，在给定复制集中的大多数节点出现短暂损失(例如崩溃和重新启动)时，大多数写操作可能会回滚。 隐藏的, 延迟的, and priority 0的成员，成员数为[n]。投票大于0可以确认\"majority\" ”写操作。 计算关注的多数 提示 从版本4.2.1开始，rs.status()返回writeMajorityCount包含计算出的多数数的 字段。 写入关注的多数\"majority\"由以下值中的较小者计算得出： 所有投票成员（包括仲裁员）中的大多数 所有带有数据的投票成员的数量。 [warning] 警告 如果计算出的多数数等于所有带有数据的投票成员的人数（例如，由3个成员组成的主要-次要仲裁员部署），则写关注 \"majority\"可能会超时，或者如果有数据的投票成员则永远不会得到承认掉线或无法到达。如果可能，请使用带有数据的投票成员而不是仲裁者。 例如，考虑： 具有3个投票成员的复制集，主要-次要（PSS）： 所有投票成员中大多数为2。 所有有数据投票的成员人数为3。 计算得出的多数为2，最小值为2和3。写入必须传播到主要对象和辅助对象之一，\"majority\"以向客户端确认写入问题。 复制集包含3个投票成员，主要-次要仲裁员（PSA） 所有投票成员中大多数为2。 所有有数据投票的成员人数为2。 计算得出的多数为2，为2和2的最小值。由于该写操作只能应用于数据承载成员，因此该写操作必须传播到主要对象和辅助对象，\"majority\"以向客户端确认写问题。 提示 避免在a (p - a)或其他拓扑结构中使用“多数”写关注点，这些拓扑结构要求所有支持数据的投票成员都可用来确认写操作。想要使用“majority”写关注点的持久性保证的客户应该部署不需要所有数据承载投票成员可用的拓扑(例如P-S-S)。 写问题出处 从4.4版本开始，MongoDB跟踪写关注点的来源，它表示一个特定的写关注点的来源。您可能会在getLastError 指标、write concern error对象和MongoDB日志中看到显示出处的信息。 下表显示了可能的写问题provenance值及其重要性: Provenance Description clientSupplied 写关注点是在应用程序中指定的。 customDefault 写关注点源自自定义的默认值。参见setDefaultRWConcern. getLastErrorDefaults 写关系起源于复制集的设置getLastErrorDefaults字段。 implicitDefault 在没有其他所有写关注规范的情况下，写关注源自服务器。 译者：杨帅 张琦 校对：杨帅 参见 原文 - Write Acknowledgement (Write Concern) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud.html":{"url":"04-crud/13-crud.html","title":"MongoDB CRUD 概念","keywords":"","body":" MongoDB CRUD 概念 本节包含与MongoDB中的CRUD操作相关的其他概念的信息。 原子性，一致性和分布式操作 原子性和事务 阅读隔离度，一致性和近效性 分布式查询 通过findAndModify进行线性化读取 查询计划，性能和分析 查询计划 查询优化 分析查询性能 写操作性能 其它 Tailable 游标 也可以看看： 事务 译者：杨帅 校对：杨帅 参见 原文 - MongoDB CRUD Concepts Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/01-write-operations-atomicity.html":{"url":"04-crud/13-crud/01-write-operations-atomicity.html","title":"原子性和事务","keywords":"","body":" 原子性和事务 在本页面 原子性 多文档事务 并发控制 原子性 在MongoDB中，写操作在单个文档级别上是原子的，即使该操作修改了单个文档中嵌入的多个文档。 多文档交易 当单个写操作（例如 db.collection.updateMany()）修改多个文档时，对每个文档的修改是原子性的，但整个操作不是原子性的。 当执行多文档写操作时，无论是通过单个写操作还是通过多个写操作，其他操作都可能会交错。 对于需要原子性地读写多个文档（在单个或多个集合中）的情况，MongoDB支持多文档事务： 在版本4.0中，MongoDB支持复制集上的多文档事务。 在版本4.2中，MongoDB引入了分布式事务，它增加了对分片群集上多文档事务的支持，并合并了对复制集上多文档事务的现有支持。 有关MongoDB中事务的详细信息，请参阅 事务页面。 [warning] 重要 在大多数情况下，多文档事务比单文档写入带来更大的性能成本，而多文档事务的可用性不应该取代有效的模式设计。对于许多场景， 非规范化数据模型（嵌入式文档和数组）将继续是数据和用例的最佳选择。也就是说，对于许多场景，适当地对数据建模将最小化对多文档事务的需求。 有关其他事务使用注意事项(如运行时限制和oplog大小限制)，请参见 生产注意事项。 并发控制 并发控制允许多个应用程序同时运行，而不会导致数据不一致或冲突。 一种方法是在只能具有唯一值的字段上创建唯一索引。这样可以防止插入或更新创建重复数据。在多个字段上创建唯一索引以强制字段值的组合具有唯一性。有关用例的示例，请参见update()和Unique Index以及findAndModify()和Unique Index。 另一种方法是在查询谓词中为写操作指定字段的期望当前值。 也可以看看： 阅读隔离度，一致性和近效性 译者：杨帅 校对：杨帅 参见 原文 - Atomicity and Transactions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/02-read-isolation-consistency-recency.html":{"url":"04-crud/13-crud/02-read-isolation-consistency-recency.html","title":"读取隔离、一致性和近效性","keywords":"","body":" 读取隔离、一致性和近效性 在本页面 隔离保证 单调写 实时顺序 因果一致性 隔离保证 读取未提交 根据读取的关注点，客户端可以在持久写入之前看到写入的结果： 不考虑一个写操作的写关注，其他客户端使用local或者available的读关注级别都可以看到写操作的结果。 使用local或available读取关注级别的客户端可以读取数据，这些数据随后可能会在副本集故障转移期间回滚。 对于多文档事务中的操作，当事务提交时，在事务中进行的所有数据更改都将保存并在事务外部可见。也就是说，一个事务在回滚其他事务时将不会提交其某些更改。 在提交事务之前，在事务外部看不到在事务中进行的数据更改。 但是，当事务写入多个分片时，并非所有外部读取操作都需要等待已提交事务的结果在所有分片上可见。例如，如果提交了一个事务，并且在分片A上可以看到写1，但是在分片B上还看不到写2，则外部一个读关注级别为local的读操作可以读取写1的结果而看不到写2。 读未提交是默认的隔离级别，适用于mongod独立实例以及复制集和分片群集。 读取未提交和单个文档原子性 对于单个文档，写操作是原子性的。 即，如果写操作正在更新文档中的多个字段，则读操作将永远不会看到仅更新了某些字段的文档。 但是，尽管客户端可能看不到部分更新的文档，但读未提交意味着并发读取操作仍可以在使更改持久之前看到更新的文档。 对于以独立模式部署的 mongod 实例，对单个文档的一组读写操作是线性的。 使用复制集时，只有在没有回滚的情况下，对单个文档的一组读取和写入操作才是线性的。 读取未提交和多文档写入 当单个写入操作（例如 db.collection.updateMany()）修改多个文档时，每个文档的修改都是原子的，但整个操作不是原子的。 当单个写入操作（例如db.collection.updateMany()）修改多个文档时，每个文档的修改都是原子的，但整个操作不是原子的。 当执行多文档写操作时，无论是通过单个写操作还是通过多个写操作，其他操作都可能会交错。 对于需要原子性地读写多个文档（在单个或多个集合中）的情况，MongoDB支持多文档事务： 4.0版本中，MongoDB支持副本集内的多文档事务。 4.2版本中，MongoDB引入了分布式事务，从而增加了对分片群集上多文档事务的支持，并结合了对副本集上多文档事务的现有支持。 关于MongoDB事务的细节，请参考事务页。 [warning] 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性并不能替代有效的架构设计。 在许多情况下，非结构化化数据模型(嵌入式文档和数组)将继续是您的数据和用例的最佳选择。 也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 关于其他事务使用方面的注意事项(比如运行时显示和oplog大小限制等)，请参考生产注意事项. 在不隔离多文档写入操作的情况下，MongoDB表现出以下行为： 非时间点(Non-point-in-time)读取操作。假设读取操作在时间t1开始并开始读取文档。然后，写操作在稍后的某个时间t2提交对其中一个文档的更新。读操作可能会看到文档的更新后版本，因此看不到数据的point-in-time快照。 非可序列化的操作。假设读取操作在时间t1读取文档d1，而写入操作在稍后的时间t3更新d1。这引入了读写依赖性，因此，如果要序列化操作，则读取操作必须先于写入操作。但是还假设写操作在时间t2更新文档d2，而读取操作随后在稍后的时间t4读取d2。这就引入了写-读依赖关系，它将要求读操作在可序列化时间表中在写操作之后进行。有一个依赖循环，使可序列化成为不可能。 读取操作可能会丢失在读取操作过程中更新的匹配文档。 游标快照 在某些情况下，MongoDB游标可以多次返回同一个文档。 当游标返回文档时，其他操作可能会与查询交错。 如果其中某些操作更改了查询使用的索引上的索引字段； 那么光标将多次返回同一文档。 如果您的集合中有一个或多个从未修改过的字段，则可以在此字段或这些字段上使用唯一索引，这样查询将最多返回每个文档一次。 使用hint()查询可显式强制查询使用该唯一索引。 单调写 默认的，对于standalone和复制集，MongoDB提供单调写入保证。 对于分片集群的单调写入，参考因果一致性。 实时顺序 3.4后新引入 对于主节点上的读取和写入操作，如果将读关注设置为linearizable，将写关注设置为majority，那么这种读写模型组合可以使多个线程可以在单个文档上执行读写操作，就好像单个线程实时执行了这些操作一样 ; 也就是说，这些读写的相应计划被认为是线性的。 亦可参考： 因果一致性 因果一致性 3.6后新引入 如果操作在逻辑上取决于先前的操作，则这些操作之间存在因果关系。 例如，基于指定条件删除所有文档的写入操作和验证删除操作的后续读取操作具有因果关系。 在因果一致的会话中，MongoDB按照尊重因果关系的顺序执行因果操作，并且客户观察到与因果关系一致的结果。 客户端会话与因果一致性保证 为了提供因果一致性，MongoDB 3.6在客户端会话中启用因果一致性。 因果一致的会话表示具有majority的读关注级别的读操作和具有majority的写关注级别的写操作的关联序列具有因果关系，这由它们的顺序反映出来。 应用程序必须确保一次只有一个线程在客户端会话中执行这些操作。 对于因果相关的操作： 客户端开始一个客户端会话 [warning] 重要 客户端会话仅在以下情况下保证因果一致性： 读取操作的读关注级别为majority；即返回数据已被大多数副本集成员确认并且是持久化的。 写操作的写关注级别为majority；即要求确认该操作已应用于副本集中大多数可投票成员。 关于因果一致性和多种读关注级别/写关注级别，请参考因果一致性和读/写关注级别。 当客户端发出具有majority读关注和majority写关注的读取序列时，客户端将会话信息包含在每个操作中。 对于与会话相关联的每个具有majority读关注的读取操作和具有majority写关注的写入操作，即使操作出错，MongoDB也会返回操作时间和集群时间。 客户端会话跟踪操作时间和群集时间。 [success] 注意 对于未确认的（w：0）写操作，MongoDB不返回操作时间和群集时间。未经确认的写入并不表示任何因果关系。 尽管MongoDB在客户端会话中返回读操作和已确认写操作的操作时间和集群时间，但是只有具有majority读关注的读取操作和具有majority写关注的写入操作才能保证因果一致性。 有关详细信息，请参见因果一致性和读/写关注级别。 相关的客户端会话会跟踪这两个时间字段。 [success] 注意 不同会话之间的操作可以因果一致。 MongoDB驱动程序和mongo Shell提供了推进客户端会话的操作时间和集群时间的方法。 因此，客户端可以推进一个客户端会话的群集时间和操作时间，使其与另一客户端会话的操作保持一致。 因果一致性保证 下表列出了因果一致会话为具有majority读关注的读取操作和具有majority写关注点的写入操作提供的因果一致性保证。 保证 描述 写后读 读操作可以正确读到之前写的结果。 单调读 多个读操作会返回一样的比如在一个会话中“- 写操作1在写操作2前，- 读操作1在读操作2前，并且，- 读操作1返回了写操作2的结果那么读操作2并不会返回写操作1的结果。 单调写 写操作按顺序进行。比如，如果会话中写操作1在写操作2前，数据在写操作2的状态必须是写操作1完成后的状态。其他写入操作可以在写操作1和写操作2之间进行交错，但写操作2不可能在写操作1之前进行。 读后写 写操作在读操作后执行。 即，写入时的数据状态必须包含之前的读取操作的数据状态。 读偏好 这些保证适用于MongoDB部署的所有成员。 例如，如果在因果关系一致的会话中发出具有majority写关注级别的写操作，然后发出一个具有majority读关注级别的从节点（即，读偏好为secondary）读操作，则读取操作将反映写入操作后的数据库状态。 隔离性 因果一致的会话内的操作与会话外的操作不是隔离的。 如果并发写操作在会话的写操作和读取操作之间交错，则会话的读操作可能返回反映会话写操作之后发生的写操作的结果。 MongoDB驱动 提示： 应用程序必须确保一次只有一个线程在客户端会话中执行这些操作。 客户端需要使用MongoDB 3.6或更高版本的MongoDB驱动程序： Java 3.6+ C 2.5+ Perl 2.0+ Python 3.6+ Node 3.0+ PHPC 1.4+ C 1.9+ Ruby 2.5+ Scala 2.2+ 示例 重要** 因果一致性会话只能保证对于读关注级别为majority以及写关注级别为majority的读取操作的因果一致性。 考虑一个维护各种项目的当前和历史数据的items集合。 只有历史数据的end日期为非空。 如果项目的sku值更改，则具有旧sku值的文档需要使用end日期进行更新，此后，将使用当前sku值插入新文档。 客户端可以使用因果一致的会话来确保更新在插入之前发生。 (以python为例，其他实例查看原链接) with client.start_session(causal_consistency=True) as s1: current_date = datetime.datetime.today() items = client.get_database( 'test', read_concern=ReadConcern('majority'), write_concern=WriteConcern('majority', wtimeout=1000)).items items.update_one( {'sku': \"111\", 'end': None}, {'$set': {'end': current_date}}, session=s1) items.insert_one( {'sku': \"nuts-111\", 'name': \"Pecans\", 'start': current_date}, session=s1) 如果另一个客户端需要读取所有当前的sku值，则可以将集群时间和操作时间推进到另一个会话的集群时间和操作时间，以确保该客户端与另一个会话有因果关系，并在两次写入之后读取： with client.start_session(causal_consistency=True) as s2: s2.advance_cluster_time(s1.cluster_time) s2.advance_operation_time(s1.operation_time) items = client.get_database( 'test', read_preference=ReadPreference.SECONDARY, read_concern=ReadConcern('majority'), write_concern=WriteConcern('majority', wtimeout=1000)).items for item in items.find({'end': None}, session=s2): print(item) 限制 以下生成内存数据结构的操作并不是因果一致性的： 操作 备注 collStats $collStats with latencyStats option. $currentOp 如果操作和一个因果一致性的客户端会话相关，则会返回错误。 createIndexes dbHash MongoDB4.2以后的版本才支持 dbStats getMore 如果操作和一个因果一致性的客户端会话相关，则会返回错误。 $indexStats mapReduce MongoDB4.2以后的版本才支持 ping 如果操作和一个因果一致性的客户端会话相关，则会返回错误。 serverStatus 如果操作和一个因果一致性的客户端会话相关，则会返回错误。 validate MongoDB4.2以后的版本才支持 原文链接：https://docs.mongodb.com/manual/core/read-isolation-consistency-recency/ 译者：刘翔 杨帅 校对：徐雷 参见 原文 - Read Isolation, Consistency, and Recency Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/02-read-isolation-consistency-recency/01-causal-consistency-read-write-concerns.html":{"url":"04-crud/13-crud/02-read-isolation-consistency-recency/01-causal-consistency-read-write-concerns.html","title":"因果一致性和读写问题","keywords":"","body":" 因果一致性和读写问题 通过MongoDB的因果一致性客户端会话，读写问题的不同组合可提供不同的 因果一致性保证。如果定义因果一致性以表示耐久性，则下表列出了各种组合提供的特定保证： 阅读关注 写关注 阅读自己的文章 单调读 单调写 写跟读 \"majority\" \"majority\" ✅ ✅ ✅ ✅ \"majority\" { w: 1 } ✅ ✅ \"local\" { w: 1 } \"local\" \"majority\" ✅ 如果因果一致性表示持久性，那么从表中可以看出，只有具有\"majority\"读关注度的读取操作和具有\"majority\"写关注度的写入操作才能保证所有四个因果一致性保证。也就是说， 因果一致的客户端会话只能保证以下方面的因果一致性： \"majority\"关注阅读操作；也就是说，读取操作将返回大多数复制集成员已确认且持久的数据。 \"majority\"关注写操作；也就是说，写操作要求确认该操作已应用于大多数复制集的有投票权的成员。 如果因果一致性并不意味着持久性(即，写操作可能会回滚)，则具有写顾虑的写操作也可以提供因果一致性。{ w: 1 } [success] 注意 在某些情况下(但不一定在所有情况下)，读和写关注点的其他组合也可以满足所有四个因果一致性保证。 读关注点\"majority\"和写关注点 \"majority\"确保即使在复制集中的两个成员短暂地认为它们是主要的情况下(例如，使用网络分区)，这四个因果一致性保证也成立 。尽管两个主数据库都可以完成写操作，但是只有一个主数据库能够完成写操作。{ w: 1 }\"majority\". 例如，考虑网络分区划分五个成员复制集的情况： 场景 为了说明读写关注点要求，在以下情况下，客户端向客户端发出了一系列操作，并对复制集进行了读写关注点的各种组合： 阅读关注“多数”并写关注“多数” 阅读关注“多数”并发表关注{w：1} 阅读关注“本地”，写关注“多数” 阅读关注“本地”并写关注{w：1} 阅读关注\"majority\"和写关注\"majority\" 在因果一致的会话中使用读取关注\"majority\"和写入关注 \"majority\"可提供以下因果一致性保证： ✅自己读✅单调读read单调写✅写跟随读 方案1（读关注\"majority\"和写关注\"majority\"） 在具有两个主操作的过渡期内，由于只有Pnew操作才能满足写关注的写操作，因此客户机会话可以成功发出以下操作序列：{ w: \"majority\" } 序列 例 1.write1\"majority\" 到 新的关注Pnew2.read1>与读关心\"majority\"到S23.write2\"majority\"到新的关注Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 ✅ 自己写 read1从S2读取数据，该数据反映了write1之后的状态。read2从S1读取数据，该数据反映了write1之后是write2之后的状态。 ✅ 单调读 read2从S3中读取反映read1之后状态的数据。 ✅ 单调写 write2更新Pnew数据，以反映write1之后的状态。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的数据状态（即，较早的状态反映read1读取的数据）。 方案2（读取关注“多数”和写入关注“多数”） 考虑一个替代序列，其中具有读关注的read1\"majority\"路由到S1： 序列 例 1.write1\"majority\" 到 新的关注Pnew2.read1>与读关心\"majority\"到S23.write2\"majority\"到新的关注Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 在这个序列中，read1在Pold上的多数提交点提前之前不能返回。在Pold和S1能够与复制集的其余部分通信之前，这是不可能发生的;此时，Pold已经退出(如果还没有)，两个成员从副本集中的其他成员同步(包括write1)。 ✅ 自己写 read1反映了write11之后的数据状态，尽管在网络分区已修复并且该成员已与副本集的其他成员进行同步之后。read2从S3读取数据，该数据反映了write11之后是write2之后的状态。 ✅ 单调读 read2从S3读取数据，该数据反映read1之后的状态（即，较早的状态反映在read1读取的数据中）。 ✅ 单调写 write2更新Pnew数据，以反映write1之后的状态。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的数据状态（即，较早的状态反映read1读取的数据）。 读关注\"majority\"和写关注{w: 1} 如果因果一致性暗示持久性，则在因果一致性会话中使用读关注\"majority\"和写关注 可提供以下因果一致性保证：{ w: 1 } ❌自己读 ✅单调读read单调写. ✅写跟随读 如果因果一致性并不意味着持久性： ✅自己读. ✅单调读read单调写. ✅写跟随读 方案3（“关注多数”和“关注关注” ）{w: 1} 在过渡期内有两个初选，因为无论Pold与Pnew能满足与写入 的写入关注，一个客户端会话可以成功地发出以下的操作序列，但不是因果关系一致，如果一致因果意味着耐久性：{ w: 1 } 序列 例 1.write1与写入关注 到 { w: 1 }Pold2.read11与读关心\"majority\"到S23.write2到新的关注{ w: 1 }Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 按照这个顺序 直到Pnew上的大多数提交点超过了write1的时间，read1才会返回。 直到Pnew上的大多数提交点超过了write2的时间，read2才能返回。 当网络分区恢复时，write1将回滚。 ➤ 如果因果一致性意味着持久性 ❌ 自己写 read1从S2读取的数据不反映write1之后的状态。 ✅ 单调读 read2从S3读取数据，该数据反映read1之后的状态（即，较早的状态反映在read1读取的数据中）。 ❌ 单调写 write2更新了Pnew数据，而不会反映write1之后的状态。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的状态（即，较早的状态反映read1读取的数据）。 ➤ 如果因果一致性并不意味着持久性 ✅ 自己写 read1从S2读取数据，返回反映与write1等效的状态的数据，然后回退write1。 ✅ 单调读 read2从S3读取数据，该数据反映read1之后的状态（即，较早的状态反映在read1读取的数据中）。 ✅ 单调写 write2更新了Pnew的数据，这等效于write1之后回退写1的数据。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的状态（即，较早的状态反映read1读取的数据）。 方案4（“关注多数”和“关注关注” ）{w: 1} 考虑一个替代序列，其中具有读关注的读1\"majority\"路由到S1： 序列 例 1.write1与写入关注 到 { w: 1 }Pold2.read11与读关心\"majority\"到S13.write2到新的关注{ w: 1 }Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 按此顺序： 直到S1上的大多数提交点提高，read1才能返回。在Pold和S1能够与复制集的其他成员进行通信之前，这是不可能发生的。此时，Pold已经退出(如果还没有)，write1将从Pold和S1回滚，两个成员将与复制集的其他成员同步。 ➤ 如果因果一致性意味着持久性 ❌ 自己写 read1读取的数据不反映已回退的write1的结果。 ✅ 单调读 read2从S3读取数据，该数据反映read1之后的状态（即，其较早的状态反映read1读取的数据）。 ❌ 单调写 write2更新关于Pnew的数据，该数据不反映write1之后的状态，该write1在write2之前但已回滚。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的状态（即，其较早的状态反映read1读取的数据）。 ➤ 如果因果一致性并不意味着持久性 ✅ 自己写 read1返回反映write1最终结果的数据，因为write1最终会回滚。 ✅ 单调读 read2从S3读取数据，该数据反映read1之后的状态（即，其较早的状态反映read1读取的数据）。 ✅ 单调写 write2更新Pnew上的数据，这等效于write1之后回退write1的数据。 ✅ 写跟随读 write2更新Pnew数据，以反映read1之后的状态（即，其较早的状态反映read1读取的数据）。 读关注\"local\"和写关注{w: 1} 在因果一致的会话中使用读关注\"local\"和写关注 不能保证因果一致性。{ w: 1 } ❌自己读. ❌单调读read单调写. ❌写跟随读 在某些情况下（但不一定在所有情况下），此组合可以满足所有四个因果一致性保证。 方案5（“本地关注”和“关注关注” ）{w: 1} 在这个短暂的时期，因为无论Pold与 Pnew能满足与写入的写入关注，一个客户端会话可以发出以下的操作序列成功，但不是因果关系是一致的：{ w: 1 } 序列 例 1.write1与写入关注到 { w: 1 }Pold2.read11与读关心\"majority\"到S13.write2到新的关注{ w: 1 }Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 ❌自己写 read2从S3读取数据，该数据仅反映write2之后的状态，而不反映write1 之后是write2的状态。 ❌单调读 read2从S3读取数据，该数据不反映read1之后的状态（即，较早的状态不反映read1读取的数据）。 ❌单调写 write2更新了Pnew数据，而不会反映write1之后的状态。 ❌写跟随读 write2更新Pnew的数据，该数据不反映read1之后的状态（即，较早的状态不反映read1读取的数据）。 读关注\"local\"和写关注\"majority\" 在因果一致的会话中使用读取关注\"local\"和写入关注 \"majority\"可提供以下因果一致性保证： ❌自己读 ❌单调读read单调写 ❌写跟随读 在某些情况下（但不一定在所有情况下），此组合可以满足所有四个因果一致性保证。 方案6（“关注本地”和“关注多数”） 在此过渡期间，因为只有Pnew才能完成与 写入有关的写入，所以客户机会话可以成功发出以下操作序列，但因果关系不一致：{ w: \"majority\" } 序列 例 1.write1\"majority\" 到 新的关注Pnew2.read1>与读关心\"majority\"到S13.write2\"majority\"到新的关注Pnew 4.read2与读取关注\"majority\"到S3 对于项目A，更新qty为50。阅读项目A。对于qty小于或等于的项目50，更新restock到true。阅读项目A。 ❌阅读自己的文章。 read1从S1读取不反映write11后状态的数据。 ❌单调读。 read2从S3读取数据，该数据不反映read1之后的状态（即，较早的状态不反映read1读取的数据）。 ✅单调写 write2更新Pnew数据，以反映write1之后的状态。 ❌写跟随阅读。 write2更新Pnew的数据，该数据不反映read1之后的状态（即，较早的状态不反映read1读取的数据）。 译者：杨帅 校对：杨帅 参见 原文 - Causal Consistency and Read and Write Concerns Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/03-distributed-queries.html":{"url":"04-crud/13-crud/03-distributed-queries.html","title":"分布式查询","keywords":"","body":" 分布式查询 在本页面 读取复制集的操作 在复制集上进行写操作 读取分片群集的操作 在分片群集上写操作 读取复制集的操作 默认情况下，客户端读取复制集的主副本;但是，客户端可以指定一个读首选项 ，以便对其他成员进行直接读操作。例如，客户端可以配置读取偏好，从二级或从最近的成员读取到: 减少多数据中心部署中的延迟， 通过分配高读取量（相对于写入量）来提高读取吞吐量， 执行备份操作，和/或 允许读取直到选择一个新的主节点。 来自复制集的次要成员的读取操作可能无法反映主要数据库的当前状态。将读取操作定向到不同服务器的读取首选项可能会导致非单调读取。 在3.6版中进行了更改：从MongoDB 3.6开始，客户端可以使用因果一致的会话，这提供了各种保证，包括单调读取。 您可以基于每个连接或每个操作配置读取首选项。有关读取首选项或读取首选项模式的更多信息，请参见读取首选项和 读取首选项模式。 在复制集上进行写操作 在复制集,中，所有的写操作都指向集合的主节点。主服务器应用写操作并将操作记录在主服务器的操作日志或oplog上。oplog是对数据集的可重复操作序列。集合中的次要成员不断复制oplog，并在一个异步进程中将这些操作应用到自己身上。 有关复制集和写入操作的更多信息，请参见复制和 写入问题。 读取分片群集的操作 分片集群允许您以一种对应用程序几乎透明的方式在mongod实例集群之间划分数据集。有关分片集群的概述，请参阅本手册的分片部分。 对于分片群集，应用程序向mongos与该群集关联的实例之一发出操作 。 当分片群集上的读取操作定向到特定分片时，效率最高。分片集合的查询应包含集合的分片键。当查询包含分片键时，mongos可以使用配置数据库中的群集元数据将查询路由到分片。 如果查询不包含分片键，则mongos必须将查询定向到集群中的所有分片。这些分散的收集查询可能效率很低。在较大的群集上，分散收集查询对于常规操作是不可行的。 对于复制集分片，从复制集的辅助成员进行的读取操作可能无法反映主副本的当前状态。将读取操作定向到不同服务器的读取首选项可能会导致非单调读取。 [success] 注意 从MongoDB 3.6开始， 客户端可以使用因果一致的 会话，从而提供各种保证，包括单调读取。 分片复制集的所有成员(不仅是主节点)都维护有关块元数据的元数据。如果不使用读取关注点，这将防止从辅助节点读取返回孤立的数据\"available\"。在较早的版本中，无论是否关注读操作，从辅助对象进行的读操作都可能返回孤立的文档。 有关分片群集中读取操作的更多信息，请参见 mongos和Shard Keys 部分。 在分片群集上写操作 对于分片群集中的分片集合，该 mongos指令将写操作从应用程序定向到负责数据集特定部分的分片。在mongos使用来自集群的元数据 的配置数据库以路由写操作到适当的分片。 MongoDB根据分片键的值将分片集合中的数据划分为范围。然后，MongoDB将这些块分配为分片。分片键决定块到分片的分布。这可能会影响集群中的写操作的性能。 [warning] 重要 影响单个文档的 更新操作必须包含分片键 或_id 字段。如果具有分片键，则影响多个文档的更新在某些情况下会更有效，但可以广播到所有分片。 如果分片键的值在每次插入时增加或减少，则所有插入操作都将针对单个分片。结果，单个分片的容量成为分片簇的插入容量的限制。 欲了解更多信息，请参阅分片和 批量写入操作。 ​ 也可以看看： ​ 可重试写入 译者：杨帅 校对：杨帅 参见 原文 - Distributed Queries Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/04-perform-findAndModify-linearizable-reads.html":{"url":"04-crud/13-crud/04-perform-findAndModify-linearizable-reads.html","title":"通过findAndModify可线性读取","keywords":"","body":" 通过findAndModify可线性读取 概述 从复制集读取数据时，可能会读取过时(即可能并不能反映所有写道,发生前读操作)或不持久(即数据可能反映了写的状态还没有得到多数或复制集成员因此可以回滚)的数据，这取决于所使用的读取关注点。 从3.4版本开始，MongoDB引入了可线性化的读关注点，它返回的是持久的数据，不会过时。可线性化的读关注保证仅适用于读操作指定了唯一标识单个文档的查询筛选器。 本教程概述了一个替代过程，对于使用MongoDB 3.2的部署，该过程使用db.collection.findAndModify()来读取不过时且不能回滚的数据。对于MongoDB 3.4，尽管可以应用概述的过程，但请参阅“线性化”)阅读问题。 可线性通过findAndModify读取 此过程用于db.collection.findAndModify()读取不过期且无法回滚的数据。为此，该过程使用findAndModify()具有写关注的方法来修改文档中的伪字段。具体来说，该过程要求： db.collection.findAndModify()使用完全匹配查询，并且必须存在唯一索引 才能满足该查询。 findAndModify()必须实际修改文档；即导致文档更改。 findAndModify()必须使用写关注 。{ w: \"majority\" } [warning] 重要 “仲裁读取”过程比单纯使用读取问题要花费大量成本，\"majority\"因为它会导致写入延迟而不是读取延迟。仅在绝对不过期的情况下才应使用此技术。 前提条件 本教程从名为products的集合中读取内容。使用以下操作初始化集合。 db.products.insert( [ { _id: 1, sku: \"xyz123\", description: \"hats\", available: [ { quantity: 25, size: \"S\" }, { quantity: 50, size: \"M\" } ], _dummy_field: 0 }, { _id: 2, sku: \"abc123\", description: \"socks\", available: [ { quantity: 10, size: \"L\" } ], _dummy_field: 0 }, { _id: 3, sku: \"ijk123\", description: \"t-shirts\", available: [ { quantity: 30, size: \"M\" }, { quantity: 5, size: \"L\" } ], _dummy_field: 0 } ] ) 该集合中的文档包含一个虚拟字段_dummy_field，该字段 db.collection.findAndModify()在本教程中将通过递增 。如果该字段不存在，则该db.collection.findAndModify()操作会将字段添加到文档中。该字段的目的是确保db.collection.findAndModify()对文档进行修改。 程序 1.创建一个唯一索引。 在将用于指定db.collection.findAndModify()操作中完全匹配的字段上创建唯一索引。 本教程将在sku现场使用完全匹配。这样，在sku字段上创建唯一索引。 db.products.createIndex( { sku: 1 }, { unique: true } ) 2.使用findAndModify读取提交的数据。 使用该db.collection.findAndModify()方法对要阅读的文档进行简单更新，然后返回修改后的文档。需要写关注。要指定要阅读的文档，必须使用唯一索引支持的完全匹配查询。{ w: \"majority\" } 下面的findAndModify()操作在唯一索引的字段sku上指定精确匹配，并增加匹配文档中名为_dummy_field的字段。虽然不是必需的，但该命令的写操作还包括一个5000毫秒的wtimeout值，以防止在写操作不能传播到大多数投票成员时永远阻塞操作。 var updatedDocument = db.products.findAndModify( { query: { sku: \"abc123\" }, update: { $inc: { _dummy_field: 1 } }, new: true, writeConcern: { w: \"majority\", wtimeout: 5000 } } ); 即使在副本集中的两个节点认为它们是主节点的情况下，也只有一个节点能够用w: \"majority\".完成写操作。因此，只有当客户机连接到真正的主服务器来执行操作时，具有“多数”写关注点的findAndModify()方法才会成功。 由于仲裁读取过程只会增加文档中的虚拟字段，因此您可以安全地重复调用 findAndModify()，根据需要调整 wtimeout。 译者：杨帅 校对：杨帅 参见 原文 - Linearizable Reads via findAndModify Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/05-query-plans.html":{"url":"04-crud/13-crud/05-query-plans.html","title":"查询计划","keywords":"","body":" 查询计划 在本页面 计划缓存条目状态 queryHash planCacheKey 可用性 对于查询，MongoDB查询优化器在给定可用索引的情况下选择并缓存效率最高的查询计划。最有效的查询计划的评估是基于查询执行计划在查询计划评估候选计划时执行的“工作单元”(works)的数量。 关联的计划缓存条目用于具有相同查询形状的后续查询。 计划缓存条目状态 从MongoDB 4.2开始，缓存条目与状态关联： State Description 失踪 缓存中不存在此形状的条目。对于查询，如果形状的缓存条目状态为 Missing：1.对候选计划进行评估并选出一个获胜的计划。2.所选计划将以非活动状态及其工作值添加到缓存中。。 不活跃 缓存中的条目是此形状的占位符条目。也就是说，计划者已经看到了形状并计算了其成本（works价值）并存储为占位符条目，但查询形状不用于生成查询计划。对于查询，如果形状的缓存条目状态非活动：1.对候选计划进行评估并选出一个获胜的计划。2.所选计划的工作值与非活动条目的工作值进行比较。如果所选计划的works值为：小于或等于非活动条目的，所选计划将替换占位符“不 活动”条目，并具有“ 活动”状态。如果在替换发生之前，“ 非活动”条目变为“ 活动”(例如，由于其他查询操作)，则仅当新活动条目的works值大于所选计划时，才会替换该新活动条目。大于非活动条目的数量，不活动的条目仍然存在，但其工作值增加。 活性 缓存中的条目用于中奖计划。计划者可以使用该条目来生成查询计划。对于查询，如果形状的缓存条目状态为 Active：活动条目用于生成查询计划。计划者还评估条目的性能，如果条目的 works值不再符合选择标准，它将转换为非活动状态。 有关触发对计划缓存进行更改的其他方案，请参阅计划缓存刷新。 查询计划和高速缓存信息 要查看给定查询的查询计划信息，可以使用 db.collection.explain()或cursor.explain()。 从MongoDB 4.2开始，您可以使用$planCacheStats 聚合阶段来查看集合的计划缓存信息。 计划缓存刷新 如果mongod 重新启动或关闭，查询计划缓存将不会保留。此外： 索引或收集删除之类的目录操作会清除计划缓存。 最近最少使用（LRU）高速缓存替换机制将清除最近最少访问的高速缓存条目，而不管其状态如何。 用户还可以： 使用PlanCache.clear()方法手动清除整个计划缓存 。 使用PlanCache.clearPlansByQuery()方法手动清除特定的计划缓存条目 。 也可以看看 queryHash和planCacheKey queryHash和planCacheKey queryHash 为了帮助识别具有相同查询形状的慢速查询，从MongoDB 4.2开始，每个查询形状都与一个queryHash相关联。queryHash是一个十六进制字符串，表示查询形状的散列，并且只依赖于查询形状。 [success] 注意 与任何hash函数一样，两个不同的查询形状可能会导致相同的hash值。但是，不同查询形状之间不会发生哈希冲突。 planCacheKey 为了更深入地了解缓存查询计划，MongoDB 4.2引入了 planCacheKey. planCacheKey 是与查询关联的计划缓存条目的键的hash值。 [success] 注意 与queryHash不同，planCacheKey是查询形状和当前可用的形状索引的函数。也就是说，如果添加/删除了支持查询形状的索引，planCacheKey值可能会改变，而queryHash值不会改变。 例如，考虑一个具有以下索引的foo集合: db.foo.createIndex( { x: 1 } ) db.foo.createIndex( { x: 1, y: 1 } ) db.foo.createIndex( { x: 1, z: 1 }, { partialFilterExpression: { x: { $gt: 10 } } } ) 集合上的以下查询具有相同的形状: db.foo.explain().find( { x: { $gt: 5 } } ) // Query Operation 1 db.foo.explain().find( { x: { $gt: 20 } } ) // Query Operation 2 对于这些查询，带有部分过滤表达式 的索引可以支持查询操作2，但不支持查询操作1。由于支持查询操作1的索引与查询操作2不同，这两个查询具有不同的planCacheKey。 如果删除了其中一个索引，或者添加了一个新的索引{x: 1, a: 1}，那么用于这两个查询操作的planCacheKey将会改变。 可用性 queryHash和planCacheKey是可用的在: explain() output字段： queryPlanner.queryHash和 queryPlanner.planCacheKey 记录慢查询时，探查器日志消息 和诊断日志消息（即mongod / mongos日志消息）。 $planCacheStats聚合阶段（MongoDB 4.2中的新增功能） PlanCache.listQueryShapes()方法/planCacheListQueryShapes命令 PlanCache.getPlansByQuery()方法/planCacheListPlans命令 索引筛选器 索引筛选器确定优化器为查询形状评估哪些索引。查询形状由查询、排序和投影规范的组合组成。如果存在针对给定查询形状的索引筛选器，则优化器仅考虑筛选器中指定的那些索引。 当存在查询形状的索引过滤器时，MongoDB会忽略hint()。要查看MongoDB是否为查询形状应用了索引筛选器，请检查db.collection.explain()或cursor.explain() 方法的indexFilterSet字段。 索引过滤器仅影响优化器评估的索引；对于给定的查询形状，优化器仍然可以选择将集合扫描作为获胜计划。 索引过滤器在服务器进程的持续时间内存在，并且在关闭后不会持续存在。MongoDB还提供了手动删除过滤器的命令。 因为索引过滤器会覆盖优化器和hint()方法的预期行为，所以请谨慎使用索引过滤器。 见planCacheListFilters， planCacheClearFilters和planCacheSetFilter。 ​ 也可以看看： ​ 索引策略 译者：杨帅 校对：杨帅 参见 原文 - Query Plans Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/06-query-optimization.html":{"url":"04-crud/13-crud/06-query-optimization.html","title":"查询优化","keywords":"","body":" 查询优化 在本页面 创建索引以支持读取操作 查询选择性 覆盖查询 索引通过减少查询操作需要处理的数据量来提高读操作的效率。这简化了与在MongoDB中完成查询相关的工作。 创建索引以支持读取操作 如果应用程序查询特定字段或字段集上的集合，那么查询字段上的索引或字段集上的复合索引可以防止查询扫描整个集合来查找和返回查询结果。有关索引的更多信息，请参阅MongoDB中索引中完整文档。 例子 应用程序查询类型字段上的库存集合。类型字段的值是用户驱动的。 var typeValue = ; db.inventory.find( { type: typeValue } ); 要提高此查询的性能，请向type字段上的inventory集合添加升序或降序索引。在mongo shell中，您可以使用db.collection.createIndex()方法创建索引: db.inventory.createIndex( { type: 1 } ) 这个索引可以防止上述类型查询扫描整个集合返回结果。 要使用索引分析查询的性能，请参阅 分析查询性能。 除了优化读取操作外，索引还可以支持排序操作并允许更有效地利用存储。有关索引创建的更多信息，请参见 db.collection.createIndex()和 索引。 对于单字段索引，升序和降序之间的选择并不重要。对于复合索引，选择很重要。有关更多详细信息，请参见索引顺序。 查询选择性 查询选择性指的是查询谓词排除或过滤集合中的文档的能力。查询选择性可以决定查询是否能够有效地使用索引，甚至根本不使用索引。 选择性更强的查询匹配的文档比例更小。例如，唯一_id字段上的相等匹配具有很高的选择性，因为它最多只能匹配一个文档。 选择性较低的查询匹配较大比例的文档。选择性较低的查询不能有效地使用索引，甚至根本不能使用索引。 例如，不等操作符$nin和 $ne的选择性不是很强，因为它们通常匹配索引的很大一部分。因此，在许多情况下，带有索引的$nin或 $ne查询的执行性能可能不比必须扫描集合中所有文档的$nin或 $ne查询好。 正则表达式的选择性取决于表达式本身。有关详细信息，请参见正则表达式和索引使用。regular expressions 覆盖查询 覆盖查询是可以使用索引完全满足而不需要检查任何文档的查询。当下列所有情况都适用时，索引将 覆盖查询： 查询 中的所有字段都是索引的一部分。 结果中返回的所有字段都在同一索引中。 查询中没有字段等于null(即{“field”:null}或{“field”:{$eq: null}})。 例如，一个集合inventory在type和item字段上具有以下索引 ： db.inventory.createIndex( { type: 1, item: 1 } ) 该索引将涵盖以下操作，该操作在type和item字段上查询 并仅返回该item字段： db.inventory.find( { type: \"food\", item:/^c/ }, { item: 1, _id: 0 } ) 为了让指定的索引覆盖查询，投影文档必须显式地指定_id: 0来从结果中排除_id字段，因为索引不包括_id字段。 3.6版本的改变:索引可以覆盖对嵌入文档中的字段的查询。 例如，考虑一个userdata集合，它具有以下形式的文档: { _id: 1, user: { login: \"tester\" } } 该集合具有以下索引： { \"user.login\": 1 } 该索引将涵盖以下查询：{ \"user.login\": 1 } db.userdata.find( { \"user.login\": \"tester\" }, { \"user.login\": 1, _id: 0 } ) 要为嵌入式文档中的字段建立索引，请使用点符号。 多键覆盖 从3.6开始，如果索引跟踪哪个或哪个字段导致索引为多键，那么多键索引可以覆盖对非数组字段的查询。在MongoDB 3.4或更高版本的存储引擎(MMAPv1除外)上创建的多键索引跟踪该数据。 多键索引不能覆盖对数组字段的查询。 性能 因为索引包含查询所需的所有字段，所以MongoDB既可以匹配查询条件 ，又可以仅使用索引返回结果。 仅查询索引要比查询索引之外的文档快得多。索引键通常比它们编目的文档小，索引通常在RAM中可用，或按顺序位于磁盘上。 局限性 索引字段的限制 地理空间索引不能 覆盖查询。 多键索引不能覆盖对数组字段的查询。 也可以看看 多键覆盖 分片集合的限制 在MongoDB中3.0开始，索引不能覆盖在查询 分片的时候对一个运行集合 mongos，如果指数不包含片键，除了具有以下不同的_id指标：如果在分片集合的查询只规定了一个条件_id字段并仅返回该_id字段，即使该 字段不是分片键，_id索引也可以覆盖针对mongos该_id字段的查询。 在以前的版本中，在对mongos运行时，索引不能覆盖 对分片集合的查询。 解释 要确定查询是否为覆盖查询，请使用 db.collection.explain()或explain() 方法，然后查看结果。 db.collection.explain()提供有关其他操作执行的信息，例如db.collection.update()。有关db.collection.explain()详细信息，请参见 。 有关更多信息，请参见度量索引使用。 译者：杨帅 校对：杨帅 参见 原文 - Query Optimization Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/06-query-optimization/01-evaluate-operation-performance.html":{"url":"04-crud/13-crud/06-query-optimization/01-evaluate-operation-performance.html","title":"评估当前运营的绩效","keywords":"","body":" 评估当前运营的绩效 在本页面 使用数据库分析器来计算针对数据库的操作 使用db.currentOp()来评估mongod业务 使用explain来评估查询性能 以下各节介绍了用于评估操作性能的技术。 使用数据库分析器来计算针对数据库的操作 MongoDB提供了一个数据库分析器，它显示针对数据库的每个操作的性能特征。使用分析器定位任何运行缓慢的查询或写操作。例如，您可以使用此信息来确定要创建什么索引。 从MongoDB 4.2开始，用于读写操作的profiler条目和诊断日志消息(即mongod/mongos日志消息)包括: queryHash帮助识别具有相同查询形状的慢速查询 。 planCacheKey为深入了解查询计划缓存提供慢速查询。 从版本4.2(也可以从4.0.6开始使用)开始，复制集的次要成员现在会记录花费超过慢操作阈值的oplog条目。这些缓慢的oplog消息被记录在REPL组件下的诊断日志中，并应用文本op: 取num>ms。这些较慢的oplog条目仅依赖于较慢的操作阈值。它们不依赖于日志级别(系统或组件级别)、分析级别或较慢的操作采样率。分析器不会捕获很慢的oplog条目。 有关更多信息，请参见Database Profiler。 使用db.currentOp()到评估mongod业务 该db.currentOp()方法报告mongod实例上正在运行的当前操作。 使用explain来评估查询性能 在cursor.explain()与db.collection.explain() 方法返回关于查询执行的信息，如MongoDB的选择以满足查询和执行统计数据的指标。您可以在queryPlanner 模式，executionStats模式或 allPlansExecution模式下运行这些方法，以控制返回的信息量。 https://docs.mongodb.com/manual/reference/program/mongo/bin.mongo) 例子 要在名为records的集合中查询与表达式{a: 1}匹配的文档时使用cursor.explain()，在mongo shell中使用类似于下面的操作: db.records.find( { a: 1 } ).explain(\"executionStats\") 从MongoDB 4.2开始，explain输出包括: queryHash帮助识别具有相同查询形状的慢速查询。 planCacheKey为深入了解查询计划缓存提供慢速查询。 欲了解更多信息，请参阅解释结果， cursor.explain()，db.collection.explain()，和 分析查询性能。 译者：杨帅 校对：杨帅 参见 原文 - Evaluate Performance of Current Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/06-query-optimization/02-optimize-query-performance-with-indexes-and-projections.html":{"url":"04-crud/13-crud/06-query-optimization/02-optimize-query-performance-with-indexes-and-projections.html","title":"优化查询性能","keywords":"","body":" 优化查询性能 在本页面 创建索引以支持查询 限制查询结果数以减少网络需求 使用投影仅返回必要的数据 使用$hint选择一个特定的索引 使用增量运算符在服务器端执行操作 创建索引以支持查询 对于常见的查询，请创建索引。如果一个查询搜索多个字段，请创建一个复合索引。扫描索引比扫描集合快得多。索引结构小于文档参考，并按顺序存储参考。 例子 如果你有一个包含博客帖子的帖子集合，并且你经常发出一个查询，对author_name字段排序，那么你可以通过在author_name字段上创建一个索引来优化查询: db.posts.createIndex( { author_name : 1 } ) 索引还可以提高对给定字段进行常规排序的查询的效率。 例子 如果您定期发出查询排序的timestamp字段，然后您可以优化查询创建一个索引的timestamp字段: 创建此索引： db.posts.createIndex( { timestamp : 1 } ) 优化此查询： db.posts.find().sort( { timestamp : -1 } ) 因为MongoDB可以按升序和降序读取索引，所以单键索引的方向并不重要。 索引支持查询，更新操作以及聚合管道的某些阶段 。 在以下情况下，BinData更有效地将类型为索引的键存储在索引中： 二进制子类型的值在0-7或128-135的范围内，并且 字节数组的长度为：0、1、2、3、4、5、6、7、8、10、12、14、16、20、24或32。 限制查询的结果数以减少网络需求 MongoDB 游标以多个文档为一组返回结果。如果知道所需结果的数量，则可以通过发出该limit() 方法来减少对网络资源的需求。 这通常与排序操作结合使用。例如，如果您只需要从查询到posts 集合的10个结果，则可以发出以下命令： db.posts.find().sort( { timestamp : -1 } ).limit(10) 有关限制结果的更多信息，请参见 limit() 使用投影仅返回必要的数据 当您仅需要文档中字段的子集时，可以通过仅返回所需的字段来获得更好的性能： 例如，如果在查询中的posts集合，你只需要timestamp，title，author，和abstract领域，你会发出以下命令： 复制复制的 db 。职位。find （ {}， { timestamp ： 1 ， title ： 1 ， author ： 1 ， abstract ： 1 } ）。排序（ { 时间戳 ： - 1 } ） 有关使用投影的更多信息，请参见 要从查询返回的项目字段。 使用$hint选择一个特定的指数 在大多数情况下，查询优化器为特定操作选择最佳索引。但是，您可以使用hint()方法强制MongoDB使用特定索引。使用 hint()以支持性能测试，或在某些查询，您必须选择包含在几个索引中的一个或多个字段。 使用增量运算符在服务器端执行操作 使用MongoDB的$inc操作符递增或递减文档中的值。操作符在服务器端增加字段的值，作为选择文档、在客户端进行简单修改然后将整个文档写入服务器的替代方法。$inc操作符还可以帮助避免竞争条件，当两个应用程序实例查询一个文档、手动增加一个字段并同时将整个文档保存回来时，可能会出现竞争条件。 译者：杨帅 校对：杨帅 参见 原文 - Optimize Query Performance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/06-query-optimization/03-write-performance.html":{"url":"04-crud/13-crud/06-query-optimization/03-write-performance.html","title":"写操作性能","keywords":"","body":" 写操作性能 在本页面 索引 储存性能 索引 集合上的每个索引都会给写操作的性能增加一些负担。 对于集合上的每个操作insert或delete写入操作，MongoDB从目标集合的每个索引中插入或删除相应的文档键。根据受update影响的键，更新操作可能导致对集合上的索引子集进行更新。 [success] 注意 如果写操作中涉及的文档包含在索引中，则MongoDB仅更新稀疏索引或 部分索引。 一般来说，索引为读操作提供的性能收益抵得上插入损失。但是，为了尽可能优化写性能，在创建新索引和评估现有索引时要小心，以确保您的查询实际使用这些索引。 有关索引和查询，请参见查询优化。有关索引的更多信息，请参见索引和 索引策略。 储存性能 硬件 存储系统的功能为MongoDB的写操作性能创建了一些重要的物理限制。与驱动器的存储系统相关的许多独特因素都会影响写入性能，包括随机访问模式，磁盘缓存，磁盘预读和RAID配置。 对于随机工作负载，固态驱动器（SSD）的性能可比旋转硬盘（HDD）高100倍或更多。 ​ 请看: ​ 生产说明中有关其他硬件和配置选项的建议。 日记 为了在崩溃时提供持久性，MongoDB使用预写日志记录到磁盘日志上。MongoDB首先将内存中的更改写入磁盘上的日志文件。如果MongoDB在对数据文件进行更改之前终止或遇到错误，MongoDB可以使用日志文件对数据文件应用写操作。 虽然日志提供的持久性保证通常超过了额外写操作的性能成本，但考虑一下日志和性能之间的以下交互: 如果日志和数据文件位于同一块设备上，则数据文件和日志可能必须竞争有限数量的可用I / O资源。将日志移动到单独的设备可能会增加写操作的容量。 如果应用程序指定了包括J选项的写关注点，mongod将减少日志写之间的持续时间，这会增加总体写负载。 日志写入之间的持续时间可以使用commitIntervalMs运行时选项进行配置 。减少日志提交之间的时间间隔将增加写入操作的数量，这可能会限制MongoDB的写入操作能力。增加日志提交之间的时间量可能会减少写操作的总数，但也会增加在发生故障的情况下日志不会记录写操作的机会。 有关日志记录的其他信息，请参见日志记录。 译者：杨帅 校对：杨帅 参见 原文 - Write Operation Performance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/06-query-optimization/04-explain-results.html":{"url":"04-crud/13-crud/06-query-optimization/04-explain-results.html","title":"解释结果","keywords":"","body":" 解释结果 在本页面 解释输出 queryPlanner executionStats serverInfo 3.0格式变更 集合扫描与索引使用 覆盖查询 索引交集 $or 表达 为了返回查询计划的信息和查询计划的执行统计信息，MongoDB提供: db.collection.explain()方法， cursor.explain()方法， 该explain命令。 explain结果将查询计划呈现为一个阶段树。 \"winningPlan\" : { \"stage\" : , ... \"inputStage\" : { \"stage\" : , ... \"inputStage\" : { \"stage\" : , ... } } }, 每个阶段将其结果(即文档或索引键)传递给父节点。叶节点访问集合或索引。内部节点操作子节点产生的文档或索引键。根节点是MongoDB派生结果集的最后一个阶段。 阶段描述了操作；例如 COLLSCAN 用于收集扫描 IXSCAN 用于扫描索引键 FETCH 用于检索文件 SHARD_MERGE 用于合并分片的结果 SHARDING_FILTER 用于从分片中筛选出孤立文档 解释输出 以下各节列出了该explain操作返回的一些关键字段。 注意 字段列表并不意味着详尽无遗，而只是强调了早期解释版本中的一些关键字段更改。 输出格式在各个发行版之间可能有所更改。 queryPlanner queryPlanner信息详细说明了查询优化器选择的计划。 未分片集合 分片集合 explain.queryPlanner 包含有关查询优化器选择查询计划的信息 。 explain.queryPlanner.``namespace 一个字符串，它指定.要对其运行查询的名称空间（即 ）。 explain.queryPlanner.``indexFilterSet 一个布尔值，指定MongoDB是否对查询形状应用了索引过滤器。 explain.queryPlanner.``queryHash 一个十六进制字符串，代表查询形状的哈希， 并且仅取决于查询形状。 queryHash可以帮助识别具有相同查询形状的慢查询（包括写操作的查询过滤器）。 注意 与任何散列函数一样，两个不同的查询形状可能导致相同的散列值。但是，不同查询形状之间不太可能出现哈希冲突。 只有当值为true且仅应用于聚合管道操作中的explain时，该字段才会出现。当为true时，由于管道已被优化，所以在输出中不会出现聚合阶段信息。 新版本4.2 explain.queryPlanner.winningPlan ​ 详细说明查询优化器选择的计划的文档。MongoDB将计划呈现为一个阶段树;例如，一个阶段可以有一个inputStage，如果该阶段有 多个子阶段，则可以有inputStage。 ​ explain.queryPlanner.winningPlan.stage ​ 表示舞台名称的字符串。 ​ 每个阶段由特定于该阶段的信息组成。例如，IXSCAN阶段将包括索引边界以及特定于索引扫描的其他数据。如果一个阶段有一个子 阶段或多个子阶段，那么这个阶段将有一个inputStage或inputStage。 ​ explain.queryPlanner.winningPlan.inputStage ​ 描述子阶段的文档，它向父阶段提供文档或索引键。如果父阶段只有一个子阶段，则会显示该字段。 ​ explain.queryPlanner.winningPlan.inputStages ​ 一系列描述子阶段的文档。子阶段将文档或索引键提供给父阶段。如果父级具有多个子节点，则该字段存在。例如，$或表达式的阶 段或索引交集会消耗来自多个源的输入。 ​ explain.queryPlanner.rejectedPlans ​ 查询优化器考虑和拒绝的候选计划的数组。如果没有其他候选计划，则该数组可以为空。 executionStats 返回的executionStats信息详细说明了获胜计划的执行情况。为了包括 executionStats在结果中，您必须在以下任一位置运行解释： 执行状态 allPlansExecution 详细模式。使用allPlansExecution模式包括在计划选择期间捕获的部分执行数据。 未分片集合 分片集合 explain.executionStats.executionStages ​ 以阶段树的形式详细说明获奖计划的完成执行情况；即一个阶段可以有一个inputStage或多个 inputStages。 ​ explain.executionStats.executionStages.works ​ 指定查询执行阶段执行的“工作单位”的数量。查询执行将其工作分为几个小单元。“工作单元”可能包括检查单个索引键，从集合中获 取单个文档，对单个文档应用投影或进行内部簿记。 ​ explain.executionStats.executionStages.advanced ​ 在此阶段返回到其父阶段的中间结果数，或将其前进。 ​ explain.executionStats.executionStages.needTime ​ 没有将中间结果提前到其父阶段的工作周期数（请参阅参考资料 explain.executionStats.executionStages.advanced）。例 如，索引扫描阶段可能会花费一个工作周期来寻找索引中的新位置，而不是返回索引键。 ​ 这个工作周期将计入explain.executionStats.executionStages.needTime而非计入 ​ explain.executionStats.executionStages.advanced。 ​ explain.executionStats.executionStages.needYield ​ 存储层请求查询阶段挂起处理并产生其锁的次数。 ​ explain.executionStats.executionStages.saveState ​ 查询阶段挂起处理并保存其当前执行状态的次数，例如，为准备产生锁而做的准备。 ​ explain.executionStats.executionStages.restoreState ​ 查询阶段恢复保存的执行状态的次数，例如，在恢复之前已产生的锁之后。 ​ explain.executionStats.executionStages.isEOF ​ 指定执行阶段是否已到达流的末尾： ​ 如果true或1，则执行阶段已到达流的末尾。 ​ 如果false或0，则阶段可能仍会返回结果。例如，考虑一个具有限制的查询，其执行阶段由查询LIMIT的输入阶段组 ​ 成IXSCAN。如果查询返回的值超过指定的限制，则该LIMIT阶段将报告，但其基础阶段将报告。isEOF: 1IXSCANisEOF: 0 ​ explain.executionStats.executionStages.inputStage.keysExamined ​ 对于扫描索引的查询执行阶段（例如IXSCAN）， keysExamined是在索引扫描过程中检查的入站和出站键的总数。如果索引扫描 由单个连续范围的键组成，则仅需要检查入站键。如果索引范围由几个键范围组成，则索引扫描执行过程可能会检查越界键，以便 从一个范围的末尾跳到下一个范围的末尾。 考虑以下示例，其中有一个字段索引， x并且集合包含100个文档，其x值从1到100： db.keys.find( { x : { $in : [ 3, 4, 50, 74, 75, 90 ] } } ).explain( \"executionStats\" ) ​ 查询将扫描键3和4。然后它将扫描键5，检测它是否超出范围，并跳到下一个键50。 ​ 继续这个过程，查询扫描键3、4、5、50、51、74、75、76、90和91。键5,51,76和91是仍在检查的超出范围的 ​ 键。keysExamined的值为10。 ​ explain.executionStats.executionStages.inputStage.docsExamined ​ 指定在查询执行阶段扫描的文档数量。 ​ 用于COLLSCAN阶段，以及从集合检索文档的阶段(例如FETCH) ​ explain.executionStats.executionStages.inputStage.seeks ​ 版本3.4中的新特性:仅用于索引扫描(IXSCAN)阶段。 ​ 为了完成索引扫描，我们必须将索引游标查找到新位置的次数。 explain.executionStats.allPlansExecution ​ 包含在计划选择阶段捕获的胜出计划和被否决计划的部分执行信息。只有当explain在所有计划执行冗长模式下运行时，该字段才 会出现。 serverInfo 未分片集合 分片集合 对于未分片的集合，explain返回serverInfoMongoDB实例的以下 信息： “ serverInfo”：{ “ host”：， “ port”：， “ version”：， “ gitVersion”： } 对于分片集合，explain返回serverInfo每个访问的分片的，并返回的 顶级 serverInfo对象mongos。 \"queryPlanner\" : { ... \"winningPlan\" : { \"stage\" : , \"shards\" : [ { \"shardName\" : , \"connectionString\" : , \"serverInfo\" : { \"host\" : , \"port\" : , \"version\" : , \"gitVersion\" : }, ... } ... ] } }, \"serverInfo\" : { // serverInfo for mongos \"host\" : , \"port\" : , \"version\" : , \"gitVersion\" : } 3.0格式变更 从MongoDB 3.0开始，结果的格式和字段explain 与以前的版本已更改。以下列出了一些主要区别。 集合扫描与索引使用 如果查询计划者选择了集合扫描，则解释结果将包括一个COLLSCAN阶段。 如果查询计划者选择了索引，则说明结果包括一个 IXSCAN阶段。该阶段包括诸如索引键样式，遍历方向和索引边界之类的信息。 在以前的MongoDB版本中，cursor.explain()返回的 cursor字段值为： BasicCursor 用于收集扫描， BtreeCursor [] 用于索引扫描。 有关收集扫描和索引扫描的执行统计信息的更多信息，请参见分析查询性能。 覆盖查询 当索引涵盖查询时，MongoDB既可以匹配查询条件，也可以仅使用索引键返回结果；即MongoDB无需检查集合中的文档即可返回结果。 当索引覆盖查询时，解释结果的IXSCAN 阶段不是该阶段的后代FETCH，而在 executionStats中，totalDocsExaminedis是0。 在MongoDB的早期版本中，cursor.explain()返回该 indexOnly字段以指示索引是否覆盖查询。 索引交集 对于索引交叉计划，结果将包括一个AND_SORTED阶段或一个AND_HASH 包含inputStages详细描述索引的数组的阶段。例如： { “ stage” ： “ AND_SORTED” ， “ inputStages” ： [ { “ stage” ： “ IXSCAN” ， ... }， { “ stage” ： “ IXSCAN” ， ... } ] } 在以前的MongoDB版本中，cursor.explain()返回cursor值为index交集的 字段。Complex Plan $or表达式 如果MongoDB对$or表达式使用索引，则结果将包括OR带有inputStages详细索引的数组的阶段 ；例如： 复制复制的 { “ stage” ： “ OR” ， “ inputStages” ： [ { “ stage” ： “ IXSCAN” ， ... }， { “ stage” ： “ IXSCAN” ， ... }， ... ] } 在MongoDB的早期版本中，cursor.explain()返回clauses详细说明索引的 数组。 分类阶段 如果MongoDB可以使用索引扫描来获取请求的排序顺序，则结果将不包含SORT阶段。否则，如果MongoDB无法使用索引进行排序，则explain结果将包括一个 SORT阶段。 在MongoDB 3.0之前，cursor.explain()返回此 scanAndOrder字段以指定MongoDB是否可以使用索引顺序返回排序的结果。 译者：杨帅 校对：杨帅 参见 原文 - Explain Results Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/07-analyze-query-plan.html":{"url":"04-crud/13-crud/07-analyze-query-plan.html","title":"分析查询性能","keywords":"","body":" 分析查询性能 在本页面 评估查询的性能 该 cursor.explain(\"executionStats\") 和db.collection.explain(\"executionStats\")方法提供了有关查询的性能统计信息。这些统计信息可用于衡量查询是否以及如何使用索引。 db.collection.explain() 提供关于其他操作(如db.collection.update())执行的信息。详细信息请参见db.collection.explain() 评估查询的性能 考虑一个包含以下文件的收集清单: { \"_id\" : 1, \"item\" : \"f1\", type: \"food\", quantity: 500 } { \"_id\" : 2, \"item\" : \"f2\", type: \"food\", quantity: 100 } { \"_id\" : 3, \"item\" : \"p1\", type: \"paper\", quantity: 200 } { \"_id\" : 4, \"item\" : \"p2\", type: \"paper\", quantity: 150 } { \"_id\" : 5, \"item\" : \"f3\", type: \"food\", quantity: 300 } { \"_id\" : 6, \"item\" : \"t1\", type: \"toys\", quantity: 500 } { \"_id\" : 7, \"item\" : \"a1\", type: \"apparel\", quantity: 250 } { \"_id\" : 8, \"item\" : \"a2\", type: \"apparel\", quantity: 400 } { \"_id\" : 9, \"item\" : \"t2\", type: \"toys\", quantity: 50 } { \"_id\" : 10, \"item\" : \"f4\", type: \"food\", quantity: 75 } 没有索引的查询 以下查询检索的文档中，quantity字段的值在100到200之间，包括: db.inventory.find( { quantity: { $gte: 100, $lte: 200 } } ) 查询返回以下文档: { \"_id\" : 2, \"item\" : \"f2\", \"type\" : \"food\", \"quantity\" : 100 } { \"_id\" : 3, \"item\" : \"p1\", \"type\" : \"paper\", \"quantity\" : 200 } { \"_id\" : 4, \"item\" : \"p2\", \"type\" : \"paper\", \"quantity\" : 150 } 要查看所选的查询计划，请将cursor.explain(\"executionStats\")游标方法链接到find命令的末尾: db.inventory.find( { quantity: { $gte: 100, $lte: 200 } } ).explain(\"executionStats\") explain() 返回以下结果： { \"queryPlanner\" : { \"plannerVersion\" : 1, ... \"winningPlan\" : { \"stage\" : \"COLLSCAN\", ... } }, \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 3, \"executionTimeMillis\" : 0, \"totalKeysExamined\" : 0, \"totalDocsExamined\" : 10, \"executionStages\" : { \"stage\" : \"COLLSCAN\", ... }, ... }, ... } queryPlanner.winningPlan.stage显示 COLLSCAN以指示收集扫描。 收集扫描表明， mongod必须逐个文档扫描整个收集文档以识别结果。这通常是昂贵的操作，并且可能导致查询缓慢。 executionStats.nReturned显示3表示查询匹配并返回三个文档。 executionStats.totalKeysExamined显示0 以指示这是查询未使用索引。 executionStats.totalDocsExamined屏幕显示10 MongoDB必须扫描十个文档（即集合中的所有文档）才能找到三个匹配的文档。 匹配文档的数量和检查文档的数量之间的差异可能表明，为了提高效率，查询可能会受益于索引的使用。 查询与索引 为了支持对quantity字段的查询，请在quantity字段上添加索引: db.inventory.createIndex( { quantity: 1 } ) 要查看查询计划统计信息，请使用explain(“executionStats”)方法: db.inventory.find( { quantity: { $gte: 100, $lte: 200 } } ).explain(\"executionStats\") 该explain()方法返回以下结果: { \"queryPlanner\" : { \"plannerVersion\" : 1, ... \"winningPlan\" : { \"stage\" : \"FETCH\", \"inputStage\" : { \"stage\" : \"IXSCAN\", \"keyPattern\" : { \"quantity\" : 1 }, ... } }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 3, \"executionTimeMillis\" : 0, \"totalKeysExamined\" : 3, \"totalDocsExamined\" : 3, \"executionStages\" : { ... }, ... }, ... } queryPlanner.winningPlan.inputStage.stage显示 IXSCAN以指示索引的使用。 executionStats.nReturned 显示3表示查询匹配并返回三个文档。 executionStats.totalKeysExamined显示3 以指示MongoDB扫描了三个索引条目。检查的键数与返回的文档数匹配，这意味着mongod只需检查索引键即可返回结果。在 mongod没有扫描所有的文件，只有三个匹配文档不得不被拉入内存中。这导致非常有效的查询。 executionStats.totalDocsExamined屏幕显示3 MongoDB扫描了三个文档。 如果没有索引，查询将扫描包含10个文档的整个集合，以返回3个匹配的文档。查询还必须扫描每个文档的全部内容，可能会将它们拉到内存中。这将导致昂贵的查询操作，并且可能会很慢。 当使用索引运行时，查询扫描了3个索引项和3个文档，以返回3个匹配的文档，从而产生一个非常高效的查询。 比较索引的性能 要手动比较使用多个索引的查询的性能，可以将 hint()方法与explain()方法结合使用。 考虑以下查询: db.inventory.find( { quantity: { $gte: 100, $lte: 300 }, type: \"food\" } ) 查询返回以下文档: { \"_id\" : 2, \"item\" : \"f2\", \"type\" : \"food\", \"quantity\" : 100 } { \"_id\" : 5, \"item\" : \"f3\", \"type\" : \"food\", \"quantity\" : 300 } 要支持查询，添加复合索引。对于复合索引，字段的顺序很重要。 例如，添加以下两个复合索引。第一个索引首先按数量字段排序，然后按类型字段排序。第二个索引首先按类型排序，然后是quantity字段。 db.inventory.createIndex( { quantity: 1, type: 1 } ) db.inventory.createIndex( { type: 1, quantity: 1 } ) 评估第一个索引对查询的影响: db.inventory.find( { quantity: { $gte: 100, $lte: 300 }, type: \"food\" } ).hint({ quantity: 1, type: 1 }).explain(\"executionStats\") explain()方法返回如下输出: { \"queryPlanner\" : { ... \"winningPlan\" : { \"stage\" : \"FETCH\", \"inputStage\" : { \"stage\" : \"IXSCAN\", \"keyPattern\" : { \"quantity\" : 1, \"type\" : 1 }, ... } } }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 2, \"executionTimeMillis\" : 0, \"totalKeysExamined\" : 5, \"totalDocsExamined\" : 2, \"executionStages\" : { ... } }, ... } MongoDB扫描了5个索引键(executionStats.totalKeysExamined)以返回2个匹配的文档(executionStats.nReturned)。 评估第二个索引对查询的影响: db.inventory.find( { quantity: { $gte: 100, $lte: 300 }, type: \"food\" } ).hint({ type: 1, quantity: 1 }).explain(\"executionStats\") explain()方法返回如下输出: { \"queryPlanner\" : { ... \"winningPlan\" : { \"stage\" : \"FETCH\", \"inputStage\" : { \"stage\" : \"IXSCAN\", \"keyPattern\" : { \"type\" : 1, \"quantity\" : 1 }, ... } }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 2, \"executionTimeMillis\" : 0, \"totalKeysExamined\" : 2, \"totalDocsExamined\" : 2, \"executionStages\" : { ... } }, ... } MongoDB扫描了2个索引键(executionStats.totalKeysExamined)以返回2个匹配的文档(executionStats.nReturned)。 对于这个示例查询，复合索引{type: 1, quantity: 1}比复合索引{quantity: 1, type: 1}更有效。 ​ 也可以看看 ​ 查询优化，查询计划， 优化查询性能， 索引策略 译者：杨帅 校对：杨帅 参见 原文 - Analyze Query Performance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"04-crud/13-crud/08-tailable-cursors.html":{"url":"04-crud/13-crud/08-tailable-cursors.html","title":"Tailable游标","keywords":"","body":" Tailable游标 默认情况下，当客户端使用完游标中的所有结果时，MongoDB将自动关闭游标。但是，对于有上限的集合，您可以使用一个可定制的游标，该游标在客户端穷尽初始游标的结果后保持打开状态。可跟踪游标在概念上等同于带-f选项的tail Unix命令(即“follow”模式)。在客户端向有上限的集合中插入新的额外文档之后，可定制游标将继续检索文档。 在具有高写量的有上限集合上使用可定制游标，因为索引不实用。例如，MongoDB复制使用可跟踪的游标跟踪主服务器的oplog. [success] 注意 如果查询位于索引字段上，则不要使用可跟踪游标，而是使用常规游标。跟踪查询返回的索引字段的最后一个值。要检索新添加的文档，使用查询条件中索引字段的最后一个值再次查询集合，如下面的示例所示: db..find( { indexedField: { $gt: } } ) 考虑以下与可跟踪游标相关的行为: 可跟踪游标不使用索引，并按自然顺序返回文档。 由于可tailable游标不使用索引，因此查询的初始扫描可能开销较大;但是，在最初耗尽游标之后，后续对新添加文档的检索就不那么昂贵了。 可跟踪游标可能会死亡或无效，如果有下列情况: 查询返回不匹配。 游标返回集合“末尾”的文档，然后应用程序删除该文档。 一个已死亡游标的id为0。 请参阅驱动程序文档，以获取特定于驱动程序的方法以指定可跟踪游标。 译者：杨帅 校对：杨帅 参见 原文 - Tailable Cursors Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation.html":{"url":"05-aggregation.html","title":"聚合","keywords":"","body":" 聚合 在本页面 聚合管道 Map-Reduce 单用途聚合操作 附加功能和行为 聚合操作处理数据记录和 return 计算结果。聚合操作将来自多个文档的值组合在一起，并且可以对分组数据执行各种操作以返回单个结果。 MongoDB 提供了三种执行聚合的方法：聚合管道，map-reduce function和单一目的聚合方法。 聚合管道 MongoDB 的Aggregation framework是以数据处理管道的概念为蓝本的。文档进入多阶段管道，将文档转换为聚合结果。例如： 在这个例子中： db.orders.aggregate([ { $match: { status: \"A\" } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } } ]) 第一阶段：$match阶段按status字段过滤文档，并将status等于\"A\"的文档传递到下一阶段。 第二阶段：$group阶段按cust_id字段将文档分组，以计算每个唯一值cust_id的金额总和。 最基本的管道阶段提供过滤器，其操作类似于查询和修改输出文档格式的文档转换。 其他管道操作提供了用于按特定字段对文档进行分组和排序的工具，以及用于汇总包括文档数组在内的数组内容的工具。另外，管道阶段可以将运算符用于诸如计算平均值或连接字符串之类的任务。 管道使用MongoDB中的原生操作提供有效的数据聚合，并且是MongoDB中数据聚合的首选方法。 聚合管道可以在分片集合 sharded collection上运行。 聚合管道可以使用索引来改善其某些阶段的性能。此外，聚合管道具有内部优化阶段。有关详细信息，请参阅管道操作和索引和聚合管道优化。 Map-Reduce MongoDB 还提供map-reduce操作来执行聚合。通常，map-reduce 操作有两个阶段：一个 map 阶段，它处理每个文档并为每个输入文档发出一个或多个对象，以及将map操作的输出组合在一起的reduce阶段。可选地，map-reduce 可以具有最终化阶段以对结果进行最终修改。与其他聚合操作一样，map-reduce 可以指定查询条件以选择输入文档以及对结果排序和限制。 Map-reduce 使用自定义 JavaScript 函数来执行 map 和 reduce操作，以及可选的 finalize 操作。与聚合管道相比，自定义JavaScript提供了很大的灵活性，但通常情况下，map-reduce比聚合管道效率低，而且更复杂。 Map-reduce 可以在分片集合 sharded collection上运行。 Map-reduce 操作也可以输出到分片集合。有关详细信息，请参阅聚合管道和分片集合和Map-Reduce 和 Sharded Collections。 [success] 注意 从 MongoDB 2.4 开始，在 map-reduce 操作中无法访问某些mongoshell 函数和属性。 MongoDB 2.4 还支持多个 JavaScript 操作以在同一时间运行。在 MongoDB 2.4 之前，JavaScript code 在单个线程中执行，引发了 map-reduce 的并发问题。 单用途聚合操作 MongoDB 还提供 db.collection.estimatedDocumentCount(), db.collection.count()和db.collection.distinct()。 所有这些操作都聚合来自单个集合的文档。虽然这些操作提供了对常见聚合过程的简单访问，但它们缺乏聚合管道和 map-reduce 的灵活性和功能。 附加功能和行为 有关聚合管道 map-reduce 和特殊组功能的特性比较，请参阅聚合命令比较。 译者：李冠飞 校对：李冠飞 参见 原文 - Aggregation Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline.html":{"url":"05-aggregation/01-aggregation-pipeline.html","title":"聚合管道","keywords":"","body":" 聚合管道 在本页面 管道 管道表达式 聚合管道行为 注意事项 聚合管道是用于数据聚合的框架，其模型基于数据处理管道的概念。文档进入多阶段管道，将文档转换为聚合结果。例如： 在这个例子中 db.orders.aggregate([ { $match: { status: \"A\" } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } } ]) 第一阶段：$match阶段按status字段过滤文档，并将status等于\"A\"的文档传递到下一阶段。 第二阶段：$group阶段按cust_id字段将文档分组，以计算每个cust_id唯一值的金额总和。 管道 MongoDB 聚合管道由多个阶段组成。每个阶段在文档通过管道时转换文档。管道阶段不需要为每个输入文档生成一个输出文档; 如：某些阶段可能会生成新文档或过滤掉文档。 Pipeline阶段可以与外管道出现多次$out，$merge和 $geoNear阶段。有关所有可用阶段的列表，请参见 聚合管道阶段。 MongoDB 在mongo shell 中提供db.collection.aggregate()方法，在聚合管道中提供聚合命令。 对于聚合管道的 example 用法，请考虑使用用户首选项数据进行聚合和使用 Zip Code 数据集进行聚合。 从MongoDB 4.2开始，您可以使用聚合管道在以下位置进行更新： 命令 Mongoshall方法 findAndModify db.collection.findOneAndUpdate（）db.collection.findAndModify（） pdate db.collection.updateOne（）db.collection.updateMany（）db.collection.update（）Bulk.find.update（）Bulk.find.updateOne（）Bulk.find.upsert（） [success] 也可以看看 聚合管道更新 管道表达式 某些管道阶段将管道表达式作为操作数。管道表达式指定要应用于输入文档的转换。表达式具有文档结构，可以包含其他表达式。 管道表达式只能对管道中的当前文档进行操作，并且不能引用其他文档中的数据：表达式操作提供文档的内存转换。 通常，表达式是无状态的，只有在聚合过程看到表达式时才计算，只有一个例外：累加器表达式。 在$group阶段中使用的累加器在记录管道中的进程时维护它们的状态(如： 总计，最大值，最小值和相关数据)。 Mongodb 3.2的变化：$project阶段有一些累加器可用;但是，在$project阶段使用时，累加器不会跨文档维护它们的状态。 有关表达式的更多信息，请参阅表达式。 聚合管道行为 在 MongoDB 中，管道命令在单个集合上运行，从逻辑上将整个集合传递到聚合管道。为了尽可能优化操作，请使用以下策略以避免扫描整个集合。 管道运算符和索引 MongoDB的query planner分析聚合管道，以确定是否可以使用索引来改善管道性能。例如，以下管道阶段可以利用索引： [success] 注意 以下管道阶段并不代表可以使用索引的所有阶段的完整列表。 $match 如果$match阶段出现在管道的开始，该阶段可以使用索引来过滤文档。 $sort 只要前面没有$project，$unwind或 $group阶段，$sort阶段可以使用索引。 $group 如果满足下列所有的条件，$group阶段有时可以使用的索引来查找每一个组中的第一文档： $group阶段之前是一个$sort 阶段，该阶段对字段进行分组 在分组的字段上有一个索引，它与排序顺序匹配 $group阶段中使用的唯一累加器是 $first 有关示例，请参见优化以返回每个组的第一个文档。 $geoNear $geoNear管道运算符利用地理空间索引。在使用时$geoNear， $geoNear管道操作必须出现在聚合管道的第一阶段出现。 Mongodb 3.2 版本的改变：从MongoDB 3.2开始，索引可以覆盖聚合管道。在MongoDB 2.6和3.0中，索引无法覆盖聚合管道，因为即使管道使用索引，聚合仍需要访问实际文档。 早期过滤 如果聚合操作仅需要集合中的数据子集，请使用$match，$limit和$skip阶段来限制在管道开头输入的文档。当放置在管道的开头时，$match操作使用合适的索引来仅扫描集合中的匹配文档。 在管道的开头放置$match管道阶段后跟$sort阶段在逻辑上等同于具有排序的单个查询并且可以使用索引。如果可能，将$match 操作符放在管道的开头。 附加功能 聚合管道具有内部优化阶段，为 operators 的某些序列提供改进的 performance。有关详细信息，请参阅聚合管道优化。 聚合管道支持对分片集合的操作。见聚合管道和分片集合。 聚合管道优化 聚合管道限制 聚合管道和分片集合 使用 Zip Code 数据集进行聚合 Example with User Preference Data 注意事项 分片集合 聚合管道支持对分片集合的操作。请参阅聚合管道和分片集合。聚合管道与Map-Reduce的比较 聚合管道为map-reduce提供了一种替代方案，并且对于map-reduce的复杂性可能没有保障的聚合任务，它可能是首选的解决方案。 限制 聚合管道对值类型和结果大小有一些限制。有关聚合管道的限制和限制的详细信息，请参见聚合管道限制。 管道优化 管道优化聚合管道具有内部优化阶段，可为某些操作符序列提供改进的性能。有关详细信息，请参阅聚合管道优化。 译者：李冠飞 刘翔 校对：李冠飞 参见 原文 - Aggregation Pipeline Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/01-aggregation-pipeline-optimization.html":{"url":"05-aggregation/01-aggregation-pipeline/01-aggregation-pipeline-optimization.html","title":"聚合管道优化","keywords":"","body":" 聚合管道优化 在本页面 投影优化 管道序列优化 管道聚结优化 例子 聚合管道操作具有优化阶段，该阶段试图重塑管道以改善性能。 要查看优化程序如何转换特定聚合管道，请在db.collection.aggregate()方法中包含explain选项。 优化可能会在不同版本之间发生变化。 投影优化 聚合管道可以确定它是否仅需要文档中的字段的子集来获得结果。如果是这样，管道将只使用那些必需的字段，减少通过管道的数据量。 管道序列优化 ($project or $unset or $addFields or $set) + $match 序列优化 对于包含投影阶段($project或$unset或$addFields或$set)后跟$match阶段的聚合管道，MongoDB 将$match阶段中不需要在投影阶段计算的值的任何过滤器移动到投影前的新$match阶段。 如果聚合管道包含多个投影 and/or $match阶段，MongoDB 会为每个$match阶段执行此优化，将每个$match过滤器移动到过滤器不依赖的所有投影阶段之前。 考虑以下阶段的管道： { $addFields: { maxTime: { $max: \"$times\" }, minTime: { $min: \"$times\" } } }, { $project: { _id: 1, name: 1, times: 1, maxTime: 1, minTime: 1, avgTime: { $avg: [\"$maxTime\", \"$minTime\"] } } }, { $match: { name: \"Joe Schmoe\", maxTime: { $lt: 20 }, minTime: { $gt: 5 }, avgTime: { $gt: 7 } } } 优化器将$match阶段分成四个单独的过滤器，一个用于$match查询文档中的每个键。然后优化器将每个筛选器移动到尽可能多的投影阶段之前，根据需要创建新的$match阶段。鉴于此示例，优化程序生成以下优化管道： { $match: { name: \"Joe Schmoe\" } }, { $addFields: { maxTime: { $max: \"$times\" }, minTime: { $min: \"$times\" } } }, { $match: { maxTime: { $lt: 20 }, minTime: { $gt: 5 } } }, { $project: { _id: 1, name: 1, times: 1, maxTime: 1, minTime: 1, avgTime: { $avg: [\"$maxTime\", \"$minTime\"] } } }, { $match: { avgTime: { $gt: 7 } } } $match过滤器{ avgTime: { $gt: 7 } }取决于$project阶段来计算avgTime字段。 $project阶段是此管道中的最后一个投影阶段，因此avgTime上的$match过滤器无法移动。 maxTime和minTime字段在$addFields阶段计算，但不依赖于$project阶段。优化器为这些字段上的过滤器创建了一个新的$match阶段，并将其放在$project阶段之前。 $match过滤器{ name: \"Joe Schmoe\" }不使用在$project或$addFields阶段计算的任何值，因此它在两个投影阶段之前被移动到新的$match阶段。 [success] 注意 优化后，过滤器{ name: \"Joe Schmoe\" }位于管道开头的$match阶段。这具有额外的好处，即允许聚合在最初查询集合时在name字段上使用索引。有关更多信息，请参见管道操作符和索引。 $sort + $match 序列优化 如果序列中带有$sort后跟$match，则$match会移动到$sort之前，以最大程度的减少要排序的对象的数量。例如，如果管道包含以下阶段： { $sort: { age : -1 } }, { $match: { status: 'A' } } 在优化阶段，优化程序将序列转换为以下内容： { $match: { status: 'A' } }, { $sort: { age : -1 } } $redact + $match 序列优化 如果可能，当管道的$redact阶段紧在$match阶段之后时，聚合有时可以在$redact阶段之前添加$match阶段的一部分。如果添加的$match阶段位于管道的开头，则聚合可以使用索引以及查询集合来限制进入管道的文档数。有关更多信息，请参见管道操作符和索引。 例如，如果管道包含以下阶段： { $redact: { $cond: { if: { $eq: [ \"$level\", 5 ] }, then: \"$$PRUNE\", else: \"$$DESCEND\" } } }, { $match: { year: 2014, category: { $ne: \"Z\" } } } 优化器可以在$redact阶段之前添加相同的$match阶段： { $match: { year: 2014 } }, { $redact: { $cond: { if: { $eq: [ \"$level\", 5 ] }, then: \"$$PRUNE\", else: \"$$DESCEND\" } } }, { $match: { year: 2014, category: { $ne: \"Z\" } } } $project/ $unset + $skip序列优化 3.2版本中的新功能。 当有一个$project或$unset之后跟有$skip序列时，$skip 会移至$project之前。例如，如果管道包括以下阶段： { $sort: { age : -1 } }, { $project: { status: 1, name: 1 } }, { $skip: 5 } 在优化阶段，优化器将序列转换为以下内容： { $sort: { age : -1 } }, { $skip: 5 }, { $project: { status: 1, name: 1 } } 管道聚合优化 如果可能，优化阶段将一个管道阶段合并到其前身。通常，合并发生在任何序列重新排序优化之后。 $sort + $limit合并 Mongodb 4.0版本的改变。 当一个$sort先于$limit，优化器可以聚结$limit到$sort，如果没有中间阶段的修改文件（例如，使用数$unwind，$group）。如果有管道阶段会更改和阶段之间的文档数，则MongoDB将不会合并$limit到 。$sort$sort$limit 例如，如果管道包括以下阶段： { $sort : { age : -1 } }, { $project : { age : 1, status : 1, name : 1 } }, { $limit: 5 } 在优化阶段，优化器将序列合并为以下内容： { \"$sort\" : { \"sortKey\" : { \"age\" : -1 }, \"limit\" : NumberLong(5) } }, { \"$project\" : { \"age\" : 1, \"status\" : 1, \"name\" : 1 } } 这样，排序操作就可以仅在执行过程中保持最高n结果，这n是指定的限制，MongoDB仅需要将n项目存储在内存中 [1]。有关更多信息，请参见$ sort运算符和内存。 用$skip进行序列优化 如果$skip在$sort 和$limit阶段之间有一个阶段，MongoDB将合并 $limit到该$sort阶段并增加该 $limit值$skip。有关示例，请参见 $ sort + $ skip + $ limit序列。 [1]当优化仍将适用 allowDiskUse是true与n项目超过 聚集内存限制。 $limit+ $limit合并 当$limit紧接着另一个时 $limit，两个阶段可以合并为一个阶段 $limit，其中限制量为两个初始限制量中的较小者。例如，管道包含以下序列： { $limit: 100 }, { $limit: 10 } 然后，第二$limit级可以聚结到第一 $limit阶段，并导致在单个$limit 阶段，即限制量10是两个初始极限的最小100和10。 { $limit: 10 } $skip+ $skip合并 当$skip紧跟另一个$skip，这两个阶段可合并成一个单一的$skip，其中跳过量为总和的两个初始跳过量。例如，管道包含以下序列： { $skip: 5 }, { $skip: 2 } 然后，第二$skip阶段可以合并到第一 $skip阶段，并导致单个$skip 阶段，其中跳过量7是两个初始限制5和的总和2。 { $skip: 7 } $match+ $match合并 当一个$match紧随另一个紧随其后时 $match，这两个阶段可以合并为一个单独 $match的条件 $and。例如，管道包含以下序列： { $match: { year: 2014 } }, { $match: { status: \"A\" } } 然后，第二$match阶段可以合并到第一 $match阶段，从而形成一个$match 阶段 { $match: { $and: [ { \"year\" : 2014 }, { \"status\" : \"A\" } ] } } $lookup + $unwind 合并 3.2版中的新功能。 当a $unwind立即紧随其后 $lookup，并且在 领域$unwind运行时，优化程序可以将其合并 到阶段中。这样可以避免创建较大的中间文档。as$lookup$unwind$lookup 例如，管道包含以下序列： { $lookup: { from: \"otherCollection\", as: \"resultingArray\", localField: \"x\", foreignField: \"y\" } }, { $unwind: \"$resultingArray\"} 优化器可以将$unwind阶段合并为 $lookup阶段。如果使用explain 选项运行聚合，则explain输出将显示合并阶段： { $lookup: { from: \"otherCollection\", as: \"resultingArray\", localField: \"x\", foreignField: \"y\", unwinding: { preserveNullAndEmptyArrays: false } } } 例子 $limit $skip $limit $skip 序列 止于Mongodb4.0 管道包含一系列交替的$limit和$skip阶段： { $limit: 100 }, { $skip: 5 }, { $limit: 10 }, { $skip: 2 } $skip $limit 序列优化反转{ $skip: 5 }和{ $limit: 10 }阶段的位置并增加限制量： { $limit: 100 }, { $limit: 15}, { $skip: 5 }, { $skip: 2 } 然后，优化器将两个$limit阶段合并为一个$limit阶段，将两个$skip阶段合并为一个$skip阶段。结果序列如下： { $limit: 15 }, { $skip: 7 } 有关详细信息，请参阅$limit $limit 合并和$skip $skip 合并。 [success] 可以看看 db.collection.aggregate()中的说明选项 译者：李冠飞 校对：李冠飞 参见 原文 - Aggregation Pipeline Optimization Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/02-aggregation-pipeline-limits.html":{"url":"05-aggregation/01-aggregation-pipeline/02-aggregation-pipeline-limits.html","title":"Aggregation Pipeline Limits","keywords":"","body":" Aggregation Pipeline Limits ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Aggregation Pipeline Limits Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/03-aggregation-pipeline-sharded-collections.html":{"url":"05-aggregation/01-aggregation-pipeline/03-aggregation-pipeline-sharded-collections.html","title":"聚合管道和分片集合","keywords":"","body":" 聚合管道和分片集合 在本页面 行为 优化 聚合管道支持对分片集合的操作。本节介绍特定于聚合管道和分片集合的行为。 行为 Mongodb 3.2 版本的改变 如果管道以 shard key 上的精确$match开头，则整个管道仅在匹配的分片上运行。以前，管道将被拆分，合并它的工作必须在主分片上完成。 对于必须在多个分片上运行的聚合操作，如果操作不需要在数据库的主分片上运行，则这些操作将会将结果路由到随机分片以合并结果，以避免该数据库的主分片超载。 $out阶段和$lookup阶段需要在数据库的主分片上运行。 优化 在将聚合管道分成两部分时，管道被拆分以确保分片在考虑优化的情况下执行尽可能多的阶段。 要查看管道是如何拆分的，请在db.collection.aggregate()方法中包含explain选项。 优化可能会在不同版本之间发生变化。 译者：李冠飞 校对：李冠飞 参见 原文 - Aggregation Pipeline and Sharded Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/04-aggregation-zip-code-data-set.html":{"url":"05-aggregation/01-aggregation-pipeline/04-aggregation-zip-code-data-set.html","title":"使用 Zip Code 数据集进行聚合","keywords":"","body":" 使用 Zip Code 数据集进行聚合 在本页面 数据模型 Data Model aggregate()方法 返回人口超过 1000 万的国家 按 State 返回平均城市人口 按 State 返回最大和最小城市 本文档中的示例使用zipcodes集合。该系列可在以下网址获得：media.mongodb.org/zips.json。使用mongoimport将此数据集加载到mongod实例中。 数据模型 zipcodes集合中的每个文档都具有以下形式： { \"_id\": \"10280\", \"city\": \"NEW YORK\", \"state\": \"NY\", \"pop\": 5574, \"loc\": [ -74.016323, 40.710537 ] } _id字段将 zip code 保存为 string。 city字段包含 city name。一个城市可以有多个与之关联的 zip code，因为城市的不同部分可以各自具有不同的 zip code。 state字段包含两个字母 state 缩写。 pop字段包含人口。 loc字段将位置保存为纬度经度对。 aggregate()方法 以下所有示例都使用mongo shell 中的aggregate()帮助程序。 aggregate()方法使用聚合管道将文档处理为聚合结果。 聚合管道由多个阶段组成，每个阶段在文档沿着管道传递时都会对其进行处理。文档按顺序通过各个阶段。 mongo shell 中的aggregate()方法在聚合数据库命令提供了一个包装器。有关用于数据聚合操作的更惯用的界面，请参阅驱动的文档。 返回人口超过 1000 万的国家 以下聚合操作将返回总人口超过 1000 万的所有州： db.zipcodes.aggregate( [ { $group: { _id: “$state“, totalPop: { $sum: “$pop“ } } }, { $match: { totalPop: { $gte: 10*1000*1000 } } } ] ) 在此 example 中，聚合管道包含$group阶段，后跟$match阶段： 阶段按state字段对zipcode集合的文档进行分组，为每个 state 计算totalPop字段，并为每个唯一的 state 输出文档。 新的 per-state 文档有两个字段：_id字段和totalPop字段。 _id字段包含state的 value即： group by field。 totalPop字段是一个计算字段，包含每个 state 的总人口。要计算 value，$group使用$sum operator 为每个 state 添加填充字段(pop)。 在$group阶段之后，管道中的文档类似于以下内容： { “_id“ : “AK“, “totalPop“ : 550043 } $match阶段过滤这些分组文档，仅输出totalPop value 大于或等于 1000 万的文档。 $match阶段不会更改匹配的文档，但会不加修改地输出匹配的文档。 此聚合操作的等效SQL是： SELECT state, SUM(pop) AS totalPop FROM zipcodes GROUP BY state HAVING totalPop >= (10*1000*1000) [success] 也可以看看 $group，$match，$sum 按 State 返回平均城市人口 以下聚合操作返回每个 state 中城市的平均人口数： db.zipcodes.aggregate( [ { $group: { _id: { state: “$state“, city: “$city“ }, pop: { $sum: “$pop“ } } }, { $group: { _id: “$_id.state“, avgCityPop: { $avg: “$pop“ } } } ] ) 在这个 example 中，聚合管道包含$group阶段，后跟另一个$group阶段： 第一个阶段通过city和state的组合对文档进行分组，使用$sum表达式计算每个组合的总体，并为每个city和state组合输出一个文档。 [1] 在管道中的这个阶段之后，文档类似于以下内容： { “_id“ : { “state“ : “CO“, “city“ : “EDGEWATER“ }, “pop“ : 13154 } 第二个$group阶段通过_id.state字段(i.e._id文档中的state字段)对管道中的文档进行分组，使用$avg表达式计算每个 state 的平均城市人口(avgCityPop)，并为每个 state 输出一个文档。 此聚合操作产生的文档类似于以下内容： { “_id“ : “MN“, “avgCityPop“ : 5335 } [success] 也可以看看 $group，$sum，$avg 按 State 返回最大和最小城市 以下聚合操作按每个 state 的填充返回最小和最大的城市： db.zipcodes.aggregate( [ { $group:{ _id: { state: “$state“, city: “$city“ }, pop: { $sum: “$pop“ } } }, { $sort: { pop: 1 } }, { $group:{ _id : “$_id.state“, biggestCity: { $last: “$_id.city“ }, biggestPop: { $last: “$pop“ }, smallestCity: { $first: “$_id.city“ }, smallestPop: { $first: “$pop“ } } }, // the following $project is optional, and // modifies the output format. { $project:{ _id: 0, state: “$_id“, biggestCity: { name: “$biggestCity“, pop: “$biggestPop“ }, smallestCity: { name: “$smallestCity“, pop: “$smallestPop“ } } } ] ) 在此 example 中，聚合管道包含$group阶段，$sort阶段，另一个$group阶段和$project阶段： 第一个$group阶段通过city和state的组合对文档进行分组，计算每个组合的pop值的和，并为每个city和state组合输出一个文档。 在管道的这个阶段，文档类似于以下内容： { “_id“ : { “state“ : “CO“, “city“ : “EDGEWATER“ }, “pop“ : 13154 } $sort阶段通过pop field value 对管道中的文档进行排序，从最小到最大; 即：通过增加 order。此操作不会更改文档。 下一个$group阶段按_id.state字段(即：_id文档中的state字段)对 now-sorted 文档进行分组，并为每个 state 输出一个文档。 该阶段还为每个 state 计算以下四个字段。使用$last表达式，$group operator 创建biggestCity和biggestPop字段，用于存储人口和人口最多的城市。使用$first表达式，$group operator 创建smallestCity和smallestPop字段，用于存储人口和人口最少的城市。 在管道的这个阶段，文件类似于以下内容： { “_id“ : “WA“, “biggestCity“ : “SEATTLE“, “biggestPop“ : 520096, “smallestCity“ : “BENGE“, “smallestPop“ : 2 } 最后的$project阶段将_id字段重命名为state，并将biggestCity，biggestPop，smallestCity和smallestPop移动到biggestCity和smallestCity嵌入文档中。 此聚合操作的输出文档类似于以下内容： { “state“ : “RI“, “biggestCity“ : { “name“ : “CRANSTON“, “pop“ : 176404 }, “smallestCity“ : { “name“ : “CLAYVILLE“, “pop“ : 45 } } [1] 一个城市可以有多个与之关联的 zip code，因为城市的不同部分可以各自具有不同的 zip code。 译者：李冠飞 校对：李冠飞 参见 原文 - Example with ZIP Code Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/05-aggregation-with-user-preference-data.html":{"url":"05-aggregation/01-aggregation-pipeline/05-aggregation-with-user-preference-data.html","title":"使用用户首选项数据进行聚合","keywords":"","body":" 使用用户首选项数据进行聚合 在本页面 数据模型 规范化和排序文档 返回按月加入订单的用户名 返回每月的联接总数 Return 五个 Common“喜欢” 数据模型 考虑一个假设的体育俱乐部，其数据库包含一个users集合，用于跟踪用户的加入日期，运动偏好，并将这些数据存储在类似于以下内容的文档中： { _id : “jane“, joined : ISODate(“2011-03-02“), likes : [“golf“, “racquetball“] } { _id : “joe“, joined : ISODate(“2012-07-02“), likes : [“tennis“, “golf“, “swimming“] } 规范化和排序文档 以下操作以大写和字母 order 返回用户名。聚合包括users集合中所有文档的用户名。您可以这样做以规范化用户名以进行处理。 db.users.aggregate([ { $project : { name:{$toUpper:“$_id“} , _id:0 } }, { $sort : { name : 1 } } ]) users集合中的所有文档都通过管道传递，该管道包含以下操作： $project 操作： 创建一个名为name的新字段。 使用$toUpper operator 将_id的 value 转换为大写。然后$project创建一个名为name的新字段来保存此 value。 抑制id字段。除非明确禁止，否则$project将默认通过_id字段。 operator 按name字段对结果进行排序。 聚合的结果类似于以下内容： { \"name\" : \"JANE\" }, { \"name\" : \"JILL\" }, { \"name\" : \"JOE\" } 返回按月加入订单的用户名 以下聚合操作返回按其加入的月份排序的用户名。这种聚合可以帮助生成会员续订通知。 db.users.aggregate([ { $project : { month_joined : { $month : “$joined“ }, name : “$_id“, _id : 0 } }, { $sort : { month_joined : 1 } } ]) 管道通过以下操作传递users集合中的所有文档： $project operator： 创建两个新字段：month_joined和name。 从结果中抑制id。除非明确禁止，否则aggregate()方法包含_id。 $month operator 将joined字段的值转换为月份的 integer 表示。然后$project operator 将这些值分配给month_joined字段。 $sort operator 按month_joined字段对结果进行排序。 该操作返回类似于以下内容的结果： { “month_joined“ : 1, “name“ : “ruth“ }, { “month_joined“ : 1, “name“ : “harold“ }, { “month_joined“ : 1, “name“ : “kate“ }, { “month_joined“ : 2, “name“ : “jill“ } 返回每月的联接总数 以下操作显示了一年中每个月加入的人数。您可以将此汇总数据用于招聘和营销策略。 db.users.aggregate([ { $project : { month_joined : { $month : “$joined“ } } } , { $group : { _id : {month_joined:“$month_joined“} , number : { $sum : 1 } } }, { $sort : { “_id.month_joined“ : 1 } } ]) 管道通过以下操作传递users集合中的所有文档： $project operator 创建一个名为month_joined的新字段。 $month operator 将joined字段的值转换为月份的 integer 表示。然后$project operator 将值分配给month_joined字段。 $group operator 收集具有给定month_joined value 的所有文档，并计算该 value 的文档数量。具体来说，对于每个唯一 value，$group创建一个包含两个字段的新“per-month”文档： _id，包含带有month_joined字段及其 value 的嵌套文档。 number，这是一个生成的字段。对于包含给定month_joined value 的每个文档，$sum operator 将此字段递增 1。 $sort operator 根据month_joined字段的内容对$group创建的文档进行排序。 此聚合操作的结果类似于以下内容： { “_id“ : { “month_joined“ : 1 }, “number“ : 3 }, { “_id“ : { “month_joined“ : 2 }, “number“ : 9 }, { “_id“ : { “month_joined“ : 3 }, “number“ : 5 } Return 五个 Common“喜欢” 以下聚合收集数据集中前五个最“喜欢”的活动。这种分析有助于规划和未来发展。 db.users.aggregate([ { $unwind : “$likes“ }, { $group : { _id : “$likes“ , number : { $sum : 1 } } }, { $sort : { number : -1 } }, { $limit : 5 } ]) 管道从users集合中的所有文档开始，并通过以下操作传递这些文档： $unwind operator 分隔likes array 中的每个 value，并为 array 中的每个元素创建源文档的新 version。 [success] 例子 给出来自用户集合的以下文档： { _id : \"jane\", joined : ISODate(\"2011-03-02\"), likes : [\"golf\", \"racquetball\"] } $unwind运算符将创建下列文件： { _id : “jane“, joined : ISODate(“2011-03-02“), likes : “golf“ } { _id : “jane“, joined : ISODate(“2011-03-02“), likes : “racquetball“ } $group operator 收集likes字段具有相同 value 的所有文档，并计算每个分组。有了这些信息，$group创建了一个包含两个字段的新文档： _id，其中包含likes value。 number，这是一个生成的字段。对于包含给定likes value 的每个文档，$sum operator 将此字段递增 1。 $sort operator 按字段在 reverse order 中对这些文档进行排序。 $limit operator 仅包含前 5 个结果文档。 聚合的结果类似于以下内容： { “_id“ : “golf“, “number“ : 33 }, { “_id“ : “racquetball“, “number“ : 31 }, { “_id“ : “swimming“, “number“ : 24 }, { “_id“ : “handball“, “number“ : 19 }, { “_id“ : “tennis“, “number“ : 18 } 译者：李冠飞 校对：李冠飞 参见 原文 - Example with User Preference Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-pipeline/Aggregation-Pipeline-Limits.html":{"url":"05-aggregation/01-aggregation-pipeline/Aggregation-Pipeline-Limits.html","title":"聚合管道限制","keywords":"","body":" 聚合管道限制 在本页面 结果大小限制 Memory 限制 使用聚合命令的聚合操作具有以下限制。 结果大小限制 Mongodb 3.6版本的改变：MongoDB 3.6 删除聚合命令以将其结果作为单个文档返回的选项。 聚合命令可以返回一个游标或将结果存储集合中。返回游标或将结果存储在集合中时，结果集中的每个文档都受BSON 文件大小限制，目前为 16 兆字节;如果任何单个文档超过BSON 文件大小限制，该命令将产生错误。该限制仅适用于返回的文件;在管道处理期间，文档可能超过此大小。 db.collection.aggregate()方法默认返回游标。 Memory 限制 管道阶段的 RAM 限制为 100M（100*1024*1024字节）。如果某个阶段超出此限制，MongoDB 将产生错误。要允许处理大型数据集，可以在aggregate()方法中设置allowDiskUse选项。allowDiskUse选项允许大多数聚合管道操作可以将数据写入临时文件。 以下聚合操作是allowDiskUse选项的例外； 这些操作必须在内存限制内： $graphLookup阶段 $group阶段中使用的$addToSet累加器表达式（从版本4.2.3、4.0.14、3.6.17开始） $group阶段使用的$push累加器表达式(从版本4.2.3、4.0.14、3.6.17开始) 如果管道包含在aggregate()操作中观察allowDiskUse: true的其他阶段，那么allowDiskUse: true选项对这些其他阶段有效。 从MongoDB 4.2开始，如果任何聚合阶段由于内存限制而将数据写到临时文件，则分析器日志消息和诊断日志消息包括一个usedDisk指示器。 [success] 可以看看 $sort and Memory Restrictions和$group Operator and Memory。 译者：李冠飞 校对：李冠飞 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-quick-reference/SQL-to-Aggregation-Mapping-Chart.html":{"url":"05-aggregation/01-aggregation-quick-reference/SQL-to-Aggregation-Mapping-Chart.html","title":"SQL 到聚合映射图表","keywords":"","body":" SQL 到聚合映射图表 在本页面 例子 聚合管道允许 MongoDB 提供与 SQL 中许多 common 数据聚合操作相对应的本机聚合功能。 以下 table 概述了 common SQL 聚合术语，函数和概念以及相应的 MongoDB 聚合运算符： SQL 术语，函数和概念 Mongo聚合命令 WHERE $match GROUP BY $group HAVING $match SELECT $project ORDER BY $sort LIMIT $limit SUM() $sum COUNT() $sum$sortByCount join $lookup SELECT INTO NEW_TABLE $out MERGE INTO TABLE $merge （从MongoDB 4.2开始可用） 有关所有聚合管道和表达式 operators 的列表，请参阅聚合管道快速参考。 也可以看看 SQL 到 MongoDB 映射图表](SQL-to-Aggregation-Mapping-Chart.md) 例子 以下 table 提供了 SQL 聚合 statements 和相应的 MongoDB statements 的快速 reference。 table 中的示例假定以下条件： SQL 示例假设两个表orders和order_lineitem由order_lineitem.order_id和orders.id列连接。 MongoDB 示例假设一个集合orders包含以下原型的文档： { cust_id: \"abc123\", ord_date: ISODate(\"2012-11-02T17:04:11.102Z\"), status: 'A', price: 50, items: [ { sku: \"xxx\", qty: 25, price: 1 }, { sku: \"yyy\", qty: 25, price: 1 } ] } SQL语句 MongoDB语句 描述 SELECT COUNT(*) AS count FROM orders db.orders.aggregate( [ { $group: { _id: null, count: { $sum: 1 } } } ] ) 计算来自orders的所有记录 SELECT SUM(price) AS total FROM orders db.orders.aggregate( [ { $group: { _id: null, total: { $sum: \"$price\" } } } ] ) orders中对price字段求和 SELECT cust_id, SUM(price) AS total FROM orders GROUP BY cust_id db.orders.aggregate( [ { $group: { _id: \"$cust_id\", total: { $sum: \"$price\" } } } ] ) 对于每个唯一cust_id，对price字段进行求和。 SELECT cust_id, SUM(price) AS total FROM orders GROUP BY cust_id ORDER BY total db.orders.aggregate( [ { $group: { _id: \"$cust_id\", total: { $sum: \"$price\" } } }, { $sort: { total: 1 } } ] ) 对于每个唯一cust_id，求和price字段，结果按总和排序。 SELECT cust_id, ord_date, SUM(price) AS total FROM orders GROUP BY cust_id, ord_date db.orders.aggregate( [ { $group: { _id: { cust_id: \"$cust_id\", ord_date: { $dateToString: { format: \"%Y-%m-%d\", date: \"$ord_date\" }} }, total: { $sum: \"$price\" } } } ] ) 对于每个唯一的cust_id，通过ord_date分组，将price字段相加。排除 data 的 time 部分。 SELECT cust_id, count(*) FROM orders GROUP BY cust_id HAVING count(*) > 1 db.orders.aggregate( [ { $group: { _id: \"$cust_id\", count: { $sum: 1 } } }, { $match: { count: { $gt: 1 } } } ] ) 对于具有多个记录的cust_id，返回cust_id和相应的 record 计数。 SELECT cust_id, ord_date, SUM(price) AS total FROM orders GROUP BY cust_id, ord_date HAVING total > 250 db.orders.aggregate( [ { $group: { _id: { cust_id: \"$cust_id\", ord_date: { $dateToString: { format: \"%Y-%m-%d\", date: \"$ord_date\" }} }, total: { $sum: \"$price\" } } }, { $match: { total: { $gt: 250 } } } ] ) 对于每个唯一的cust_id，通过ord_date分组，仅在总和大于 250 的情况下对price字段和 return 求和。排除 date 的 time 部分 SELECT cust_id, SUM(price) as total FROM orders WHERE status = 'A' GROUP BY cust_id db.orders.aggregate( [ { $match: { status: 'A' } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$price\" } } } ] ) 对于状态为A的每个唯一cust_id，请对price字段求和。 SELECT cust_id, SUM(price) as total FROM orders WHERE status = 'A' GROUP BY cust_id HAVING total > 250 db.orders.aggregate( [ { $match: { status: 'A' } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$price\" } } }, { $match: { total: { $gt: 250 } } } ] ) 对于状态为A的每个唯一cust_id，仅对总和大于 250 的price字段和 return 求和。 SELECT cust_id, SUM(li.qty) as qty FROM orders o, order_lineitem li WHERE li.order_id = o.id GROUP BY cust_id db.orders.aggregate( [ { $unwind: \"$items\" }, { $group: { _id: \"$cust_id\", qty: { $sum: \"$items.qty\" } } } ] ) 对于每个唯一cust_id，将与订单关联的相应 line item qty字段相加。 SELECT COUNT(*) FROM (SELECT cust_id, ord_date FROM orders GROUP BY cust_id, ord_date) as DerivedTable db.orders.aggregate( [ { $group: { _id: { cust_id: \"$cust_id\", ord_date: { $dateToString: { format: \"%Y-%m-%d\", date: \"$ord_date\" }} } } }, { $group: { _id: null, count: { $sum: 1 } } } ] ) 计算不同的cust_id，ord_date分组的数量。排除 date 的 time 部分。 也可以看看 SQL 到 MongoDB 映射图表 聚合管道快速参考 db.collection.aggregate() 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/01-aggregation-quick-reference/Variables-in-Aggregation-Expressions.html":{"url":"05-aggregation/01-aggregation-quick-reference/Variables-in-Aggregation-Expressions.html","title":"聚合表达式中的变量","keywords":"","body":" 聚合表达式中的变量 在本页面 用户变量 系统变量 聚合表达式可以同时使用 user-defined 和系统变量。 变量可以容纳任何BSON 类型数据。要访问变量的 value，请使用带有前缀为 double 美元符号($$)的变量 name 的 string。 如果变量 references 一个 object，要访问 object 中的特定字段，请使用点表示法; 即： \"$$.\"。 用户变量 用户变量名称可以包含 ascii 字符[_a-zA-Z0-9]和任何 non-ascii 字符。 用户变量名必须以小写的 ascii 字母[a-z]或 non-ascii 字符开头。 系统变量 MongoDB 提供以下系统变量： 变量 描述 ROOT References 根文档，即： top-level 文档，当前正在聚合管道阶段中处理。 CURRENT Reference 聚合管道阶段中正在处理的字段路径的开始。除非另有说明，否则所有阶段都以CURRENT开头，与ROOT相同。 CURRENT可以修改。但是，由于$等同于$$CURRENT.，因此重新绑定CURRENT会改变$访问的含义。 REMOVE 一个变量，用于计算缺少的 value。允许条件排除字段。在$projection中，从输出中排除设置为变量REMOVE的字段。 有关其用法的示例，请参阅有条件地排除字段。 version 3.6 中的新内容。 DESCEND $redact表达式的允许结果之一。 PRUNE $redact表达式的允许结果之一。 KEEP $redact表达式的允许结果之一。 也可以看看 $let，$redact，$map 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce.html":{"url":"05-aggregation/02-map-reduce.html","title":"Map-Reduce","keywords":"","body":" Map-Reduce 在本页面 Map-Reduce JavaScript 函数 Map-Reduce 行为 分片集合 视图 Map-reduce 是一种数据处理范式，用于将大量数据压缩为有用的聚合结果。对于 map-reduce 操作，MongoDB 提供MapReduce数据库命令。 [success] 注意 从4.2版开始，MongoDB弃用： 用于创建新分片集合的map-reduce选项，以及用于map-reduce的分片选项。若要输出到分片集合，请先创建分片集合。MongoDB 4.2也不赞成替换现有的分片集合。 nonAtomic：false选项的显式规范。 考虑以下 map-reduce 操作： 在此 map-reduce 操作中，MongoDB 将 map 阶段应用于每个输入文档(即：集合中与查询条件匹配的文档)。 map函数会发出 key-value 对。对于具有多个值的键，MongoDB 应用 reduce 阶段，该阶段收集并压缩聚合数据。然后 MongoDB 结果存储在一个集合中。可选地，reduce 函数的输出可以通过 finalize 函数以进一步压缩或处理聚合的结果。 MongoDB 中的所有 map-reduce 函数都是JavaScript，在mongod进程中运行。 Map-reduce 操作将单个集合的文档作为输入，并且可以在开始 map 阶段之前执行任意排序和限制。 MapReduce可以将map-reduce操作的结果作为文档返回，或者可以将结果写入集合。 [success] 注意 对于大多数聚合操作，聚合管道提供更好的性能和更一致的接口。但是，map-reduce 操作提供了一些在聚合管道中目前不可用的灵活性。 Map-Reduce JavaScript 函数 在 MongoDB 中，map-reduce 操作使用自定义 JavaScript 函数将值映射或关联到一个键。如果一个键有多个值映射到它，则操作会将 键的值减少为单个对象。 自定义 JavaScript 函数的使用为 map-reduce 操作提供了灵活性。例如，在处理文档时，map 函数可以创建多个键和值映射或不创建映射。 Map-reduce 操作还可以使用自定义 JavaScript 函数对 map和reduce操作结束时的结果进行最终修改，例如执行其他计算。 在4.2.1版本开始，MongoDB的不支持在map，reduce和finalize中使用范围（即:BSON type 15）的JavaScript。要限定变量的范围，请使用scope参数。 Map-Reduce 行为 在 MongoDB 中，map-reduce 操作可以将结果写入集合或内联返回结果。如果将 map-reduce 输出写入集合，则可以对同一输入集合执行后续 map-reduce 操作，这些集合将替换，合并或reduce新结果与先前结果合并。有关详细信息和示例，请参阅MapReduce和执行增量 Map-Reduce。 在内联返回 map-reduce 操作的结果时，结果文档必须在BSON 文件大小限制范围内，当前为 16 兆字节。有关 map-reduce 操作的限制和限制的其他信息，请参阅MapReduce 参考 页面。 分片集合 MongoDB 支持分片集合上的 map-reduce 操作。 但是，从版本4.2开始，MongoDB弃用map-reduce选项来创建新的分片集合，并将 sharded选项用于map-reduce。若要输出到分片集合，请首先创建分片集合。MongoDB 4.2不建议替换现有分片集合。 见Map-Reduce and Sharded Collections。 视图 视图不支持 map-reduce 操作。 译者：李冠飞 校对：李冠飞 参见 原文 - Map-Reduce Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/01-map-reduce-sharded-collections.html":{"url":"05-aggregation/02-map-reduce/01-map-reduce-sharded-collections.html","title":"Map-Reduce 和分片集合","keywords":"","body":" Map-Reduce 和分片集合 在本页面 分片集合作为输入 分片集合作为输出 Map-reduce 支持对分片集合的操作，既可以作为输入也可以作为输出。本节介绍MapReduce特定于分片集合的操作。 分片集合作为输入 当使用分片集合作为 map-reduce 操作的输入时，mongos将自动将 map-reduce job 分派给 parallel 中的每个分片。不需要特殊选项。 mongos将等待所有分片上的作业完成。 分片集合作为输出 如果MapReduce的out字段具有sharded 值，则 MongoDB 使用_id字段将输出集合分片为分片键。 要输出到分片集合： 如果输出集合不存在，请首先创建分片集合 从版本4.2开始，MongoDB弃用map-reduce选项以 创建新的分片集合，并将该sharded 选项用于map-reduce。因此，要输出到分片集合，请首先创建分片集合。 如果您没有首先创建分片集合，则MongoDB会在_id字段上创建和分片集合。但是，建议您首先创建分片集合。 从4.2版开始，MongoDB不赞成替换现有的分片集合。 从版本4.0开始，如果输出集合已存在但未分片，则map-reduce失败。 对于新的或空的分片集合，MongoDB使用map-reduce操作的第一阶段的结果来创建在分片之间分布的初始块。 mongos并行地将映射减少后处理作业分派给拥有块的每个分片。在后处理期间，每个分片将从其他分片中提取其自身块的结果，运行最终的reduce / finalize，然后本地写入输出集合。 注意 在以后的 map-reduce 作业中，MongoDB 根据需要拆分块。 在 post-processing 期间会自动阻止输出集合的块平衡，以避免并发问题。 译者：李冠飞 校对：小芒果 参见 原文 - Map-Reduce and Sharded Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/02-map-reduce-concurrency.html":{"url":"05-aggregation/02-map-reduce/02-map-reduce-concurrency.html","title":"Map-Reduce 并发","keywords":"","body":" Map-Reduce 并发 map-reduce 操作由许多任务组成，包括从输入集合中读取，执行map function，执行reduce function，在处理期间写入临时集合以及写入输出集合。 在操作期间，map-reduce 采用以下锁定： 读取阶段采用读锁定。它产生每 100 个文件。 insert 进入临时集合会为单次写入执行写锁定。 如果输出集合不存在，则输出集合的创建将采用写入锁定。 如果输出集合存在，则输出操作(即：merge，replace，reduce)将执行写入锁定。此写锁定是 global，并阻止mongod实例上的所有操作。 注意 后处理期间的最终写锁定使结果自动显示。然而，输出操作merge和reduce可能需要时间来处理。对于merge和reduce，该 nonAtomic标志可用，从而释放写入每个输出文档之间的锁定。从MongoDB 4.2开始，不推荐使用nonAtomic: false显式设置。有关db.collection.mapReduce()更多信息，请参见参考。 译者：李冠飞 校对： 参见 原文 - Map-Reduce Concurrency Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/03-map-reduce-examples.html":{"url":"05-aggregation/02-map-reduce/03-map-reduce-examples.html","title":"Map-Reduce 例子","keywords":"","body":" Map-Reduce 例子 在本页面 返回每位客户的总价格 用每个项目的平均数量计算订单和总数量 在mongo shell 中，db.collection.mapReduce()方法是MapReduce命令周围的 wrapper。以下示例使用db.collection.mapReduce()方法： 聚合管道作为替代 聚合管道 比map-reduce提供更好的性能和更一致的接口。 各种map-reduce表达式可以使用被重写聚合管道运算符，诸如$group， $merge等 下面的示例包括聚合管道备选方案。 orders使用以下文档创建样本集合： db.orders.insertMany([ { _id: 1, cust_id: \"Ant O. Knee\", ord_date: new Date(\"2020-03-01\"), price: 25, items: [ { sku: \"oranges\", qty: 5, price: 2.5 }, { sku: \"apples\", qty: 5, price: 2.5 } ], status: \"A\" }, { _id: 2, cust_id: \"Ant O. Knee\", ord_date: new Date(\"2020-03-08\"), price: 70, items: [ { sku: \"oranges\", qty: 8, price: 2.5 }, { sku: \"chocolates\", qty: 5, price: 10 } ], status: \"A\" }, { _id: 3, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-08\"), price: 50, items: [ { sku: \"oranges\", qty: 10, price: 2.5 }, { sku: \"pears\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 4, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-18\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 5, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-19\"), price: 50, items: [ { sku: \"chocolates\", qty: 5, price: 10 } ], status: \"A\"}, { _id: 6, cust_id: \"Cam Elot\", ord_date: new Date(\"2020-03-19\"), price: 35, items: [ { sku: \"carrots\", qty: 10, price: 1.0 }, { sku: \"apples\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 7, cust_id: \"Cam Elot\", ord_date: new Date(\"2020-03-20\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 8, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-20\"), price: 75, items: [ { sku: \"chocolates\", qty: 5, price: 10 }, { sku: \"apples\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 9, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-20\"), price: 55, items: [ { sku: \"carrots\", qty: 5, price: 1.0 }, { sku: \"apples\", qty: 10, price: 2.5 }, { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 10, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-23\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" } ]) 返回每位客户的总价格 对orders集合执行map-reduce操作，以对进行分组cust_id，并计算price每个的 的总和cust_id： 定义map函数来处理每个输入文档： 在函数中，this指的是map-reduce操作正在处理的文档。 该函数将映射price到cust_id每个文档的，并发出cust_id和price对。 var mapFunction1 = function() { emit(this.cust_id, this.price); }; 使用两个参数keyCustId和定义相应的reduce函数 valuesPrices： valuesPrices是一个数组，其元素是price 由map功能发射并由分组值keyCustId。 该函数将valuesPrice数组简化为其元素的总和。 var reduceFunction1 = function(keyCustId, valuesPrices) { return Array.sum(valuesPrices); }; orders使用mapFunction1map函数和reduceFunction1 reduce函数对集合中的所有文档执行map-reduce 。 db.orders.mapReduce( mapFunction1, reduceFunction1, { out: \"map_reduce_example\" } ) 此操作将结果输出到名为的集合 map_reduce_example。如果map_reduce_example集合已经存在，则该操作将用此map-reduce操作的结果替换内容。 查询map_reduce_example集合以验证结果： db.map_reduce_example.find().sort( { _id: 1 } ) ​ 该操作返回以下文档： { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Don Quis\", \"value\" : 155 } 聚合替代 使用可用的聚合管道运算符，您可以重写map-reduce操作，而无需定义自定义函数： db.orders.aggregate([ { $group: { _id: \"$cust_id\", value: { $sum: \"$price\" } } }, { $out: \"agg_alternative_1\" } ]) $group由平台组cust_id并计算value字段（参见$sum）。该 value字段包含price每个的总计cust_id。 该阶段将以下文档输出到下一阶段： { \"_id\" : \"Don Quis\", \"value\" : 155 } { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } 然后，$out将输出写入collection agg_alternative_1。或者，您可以使用 $merge代替$out。 查询agg_alternative_1集合以验证结果： db.agg_alternative_1.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Don Quis\", \"value\" : 155 } 用每个项目的平均数量计算订单和总数量 在此示例中，您将对值大于或等于的orders所有文档在集合上执行map-reduce操作 。工序按字段分组 ，并计算每个的订单数量和总订购量。然后，该操作将为每个值计算每个订单的平均数量，并将结果合并到输出集合中。合并结果时，如果现有文档的密钥与新结果相同，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 定义map函数来处理每个输入文档： 在函数中，this指的是map-reduce操作正在处理的文档。 对于每个商品，该函数将其sku与一个新对象相关联，该对象value包含订单的countof 1和该商品qty，并发出skuand value对。 var mapFunction2 = function() { for (var idx = 0; idx 使用两个参数keySKU和定义相应的reduce函数 countObjVals： countObjVals是一个数组，其元素是映射到keySKU由map函数传递给reducer函数的分组值的对象。 该函数将countObjVals数组简化为reducedValue包含count和 qty字段的单个对象。 在中reducedVal，该count字段包含 count各个数组元素的qty字段总和，而该字段包含各个数组元素的 字段总和qty。 var reduceFunction2 = function(keySKU, countObjVals) { reducedVal = { count: 0, qty: 0 }; for (var idx = 0; idx 定义有两个参数的函数确定key和 reducedVal。该函数修改reducedVal对象以添加一个名为avg的计算字段，并返回修改后的对象： var finalizeFunction2 = function (key, reducedVal) { reducedVal.avg = reducedVal.qty/reducedVal.count; return reducedVal; }; 在执行的map-reduce操作orders使用集合mapFunction2，reduceFunction2和 finalizeFunction2功能。 db.orders.mapReduce( mapFunction2, reduceFunction2, { out: { merge: \"map_reduce_example2\" }, query: { ord_date: { $gte: new Date(\"2020-03-01\") } }, finalize: finalizeFunction2 } ); 此操作使用该query字段选择仅ord_date大于或等于的那些文档。然后将结果输出到集合 。new Date(\"2020-03-01\") map_reduce_example2 如果map_reduce_example2集合已经存在，则该操作会将现有内容与此map-reduce操作的结果合并。也就是说，如果现有文档具有与新结果相同的密钥，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 查询map_reduce_example2集合以验证结果： db.map_reduce_example2.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"apples\", \"value\" : { \"count\" : 3, \"qty\" : 30, \"avg\" : 10 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 6, \"qty\" : 58, \"avg\" : 9.666666666666666 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } 聚合替代 使用可用的聚合管道运算符，您可以重写map-reduce操作，而无需定义自定义函数： db.orders.aggregate( [ { $match: { ord_date: { $gte: new Date(\"2020-03-01\") } } }, { $unwind: \"$items\" }, { $group: { _id: \"$items.sku\", qty: { $sum: \"$items.qty\" }, orders_ids: { $addToSet: \"$_id\" } } }, { $project: { value: { count: { $size: \"$orders_ids\" }, qty: \"$qty\", avg: { $divide: [ \"$qty\", { $size: \"$orders_ids\" } ] } } } }, { $merge: { into: \"agg_alternative_3\", on: \"_id\", whenMatched: \"replace\", whenNotMatched: \"insert\" } } ] ) 该$match阶段仅选择ord_date大于或等于new Date(\"2020-03-01\")的那些文档。 该$unwinds阶段按items数组字段细分文档，以输出每个数组元素的文档。例如： { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"apples\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 8, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"pears\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 4, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-18T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 5, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-19T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } ... $group由平台组items.sku，计算每个SKU： 该qty字段。该qty字段包含qty每个订单的总数items.sku（请参阅参考资料$sum）。 orders_ids列表。该orders_ids字段包含不同顺序的列表_id的对items.sku（参见 $addToSet）。 { \"_id\" : \"chocolates\", \"qty\" : 15, \"orders_ids\" : [ 2, 5, 8 ] } { \"_id\" : \"oranges\", \"qty\" : 63, \"orders_ids\" : [ 4, 7, 3, 2, 9, 1, 10 ] } { \"_id\" : \"carrots\", \"qty\" : 15, \"orders_ids\" : [ 6, 9 ] } { \"_id\" : \"apples\", \"qty\" : 35, \"orders_ids\" : [ 9, 8, 1, 6 ] } { \"_id\" : \"pears\", \"qty\" : 10, \"orders_ids\" : [ 3 ] } 该$project阶段调整输出文档的形状以反映map-reduce的输出，该输出具有两个字段_id和 value。该$project设置： value.count到的尺寸orders_ids数组。（请参阅$size） 在value.qty到qty输入文档的数量字段。 value.avg平均每笔订购的数量。（请参阅$divide和$size） { \"_id\" : \"apples\", \"value\" : { \"count\" : 4, \"qty\" : 35, \"avg\" : 8.75 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 7, \"qty\" : 63, \"avg\" : 9 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } 最后，$merge将输出写入collection agg_alternative_3。如果现有文档的密钥_id与新结果相同，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 查询agg_alternative_3集合以验证结果： db.agg_alternative_3.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"apples\", \"value\" : { \"count\" : 4, \"qty\" : 35, \"avg\" : 8.75 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 7, \"qty\" : 63, \"avg\" : 9 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } 译者：李冠飞 校对： 参见 原文 - Map-Reduce Examples Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/04-perform-incremental-map-reduce.html":{"url":"05-aggregation/02-map-reduce/04-perform-incremental-map-reduce.html","title":"执行增量 Map-Reduce","keywords":"","body":" 执行增量 Map-Reduce 在本页面 数据设置 当前集合的初始 Map-Reduce 后续增量 Map-Reduce Map-reduce 操作可以处理复杂的聚合任务。要执行 map-reduce 操作，MongoDB 提供MapReduce命令，并在mongo shell 中提供db.collection.mapReduce() wrapper 方法。 如果 map-reduce 数据集不断增长，您可能希望执行增量 map-reduce 而不是每个 time 对整个数据集执行 map-reduce 操作。 执行增量 map-reduce： 在当前集合上运行 map-reduce job 并将结果输出到单独的集合。 如果有更多数据要进行 process，run 后续 map-reduce job： query参数指定仅匹配新文档的条件。 out参数，指定将新结果合并到现有输出集合中的reduce操作。 请考虑以下 example，其中您在sessions集合上安排 map-reduce 操作，以在每天结束时运行 run。 数据设置 sessions集合包含 log 用户每天会话的文档，例如： db.sessions.save( { userid: \"a\", ts: ISODate('2011-11-03 14:17:00'), length: 95 } ); db.sessions.save( { userid: \"b\", ts: ISODate('2011-11-03 14:23:00'), length: 110 } ); db.sessions.save( { userid: \"c\", ts: ISODate('2011-11-03 15:02:00'), length: 120 } ); db.sessions.save( { userid: \"d\", ts: ISODate('2011-11-03 16:45:00'), length: 45 } ); db.sessions.save( { userid: \"a\", ts: ISODate('2011-11-04 11:05:00'), length: 105 } ); db.sessions.save( { userid: \"b\", ts: ISODate('2011-11-04 13:14:00'), length: 120 } ); db.sessions.save( { userid: \"c\", ts: ISODate('2011-11-04 17:00:00'), length: 130 } ); db.sessions.save( { userid: \"d\", ts: ISODate('2011-11-04 15:37:00'), length: 65 } ); 当前集合的初始 Map-Reduce 运行第一个 map-reduce 操作如下： 定义 map function _将userid映射到包含字段userid，total_time，count和avg_time的 object： var mapFunction = function() { var key = this.userid; var value = { userid: this.userid, total_time: this.length, count: 1, avg_time: 0 }; emit( key, value ); }; 使用两个 arguments key和values定义相应的 reduce function 以计算总 time 和计数。 key对应于userid，values是 array，其元素对应于映射到mapFunction中userid的各个 object。 var reduceFunction = function(key, values) { var reducedObject = { userid: key, total_time: 0, count:0, avg_time:0 }; values.forEach( function(value) { reducedObject.total_time += value.total_time; reducedObject.count += value.count; }); return reducedObject; }; 使用两个 arguments key和reducedValue定义 finalize function。 function 修改reducedValue文档以添加另一个字段average并返回修改后的文档。 var finalizeFunction = function (key, reducedValue) { if (reducedValue.count > 0) reducedValue.avg_time = reducedValue.total_time / reducedValue.count; return reducedValue; }; 使用mapFunction，reduceFunction和finalizeFunction函数在session集合上执行 map-reduce。将结果输出到集合session_stat。如果session_stat集合已存在，则操作将替换内容： db.sessions.mapReduce( mapFunction, reduceFunction, { out: \"session_stat\", finalize: finalizeFunction } ) 查询session_stats集合以验证结果： db.session_stats.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"a\", \"value\" : { \"total_time\" : 200, \"count\" : 2, \"avg_time\" : 100 } } { \"_id\" : \"b\", \"value\" : { \"total_time\" : 230, \"count\" : 2, \"avg_time\" : 115 } } { \"_id\" : \"c\", \"value\" : { \"total_time\" : 250, \"count\" : 2, \"avg_time\" : 125 } } { \"_id\" : \"d\", \"value\" : { \"total_time\" : 110, \"count\" : 2, \"avg_time\" : 55 } } 后续增量 Map-Reduce 之后，随着sessions集合的增长，您可以运行其他 map-reduce 操作。对于 example，将新文档添加到sessions集合： db.sessions.save( { userid: \"a\", ts: ISODate('2011-11-05 14:17:00'), length: 100 } ); db.sessions.save( { userid: \"b\", ts: ISODate('2011-11-05 14:23:00'), length: 115 } ); db.sessions.save( { userid: \"c\", ts: ISODate('2011-11-05 15:02:00'), length: 125 } ); db.sessions.save( { userid: \"d\", ts: ISODate('2011-11-05 16:45:00'), length: 55 } ); 最终，对usersessions集合执行增量map-reduce ，但使用该query字段仅选择新文档。将结果输出到collection session_stats，但是reduce将内容与增量map-reduce的结果进行比较： db.usersessions.mapReduce( mapFunction, reduceFunction, { query: { ts: { $gte: ISODate('2020-03-05 00:00:00') } }, out: { reduce: \"session_stats\" }, finalize: finalizeFunction } ); 查询session_stats集合以验证结果： db.session_stats.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"a\", \"value\" : { \"total_time\" : 330, \"count\" : 3, \"avg_time\" : 110 } } { \"_id\" : \"b\", \"value\" : { \"total_time\" : 270, \"count\" : 3, \"avg_time\" : 90 } } { \"_id\" : \"c\", \"value\" : { \"total_time\" : 360, \"count\" : 3, \"avg_time\" : 120 } } { \"_id\" : \"d\", \"value\" : { \"total_time\" : 210, \"count\" : 3, \"avg_time\" : 70 } } 聚合替代 前提条件：将集合设置为原始状态： db.usersessions.drop(); db.usersessions.insertMany([ { userid: \"a\", start: ISODate('2020-03-03 14:17:00'), length: 95 }, { userid: \"b\", start: ISODate('2020-03-03 14:23:00'), length: 110 }, { userid: \"c\", start: ISODate('2020-03-03 15:02:00'), length: 120 }, { userid: \"d\", start: ISODate('2020-03-03 16:45:00'), length: 45 }, { userid: \"a\", start: ISODate('2020-03-04 11:05:00'), length: 105 }, { userid: \"b\", start: ISODate('2020-03-04 13:14:00'), length: 120 }, { userid: \"c\", start: ISODate('2020-03-04 17:00:00'), length: 130 }, { userid: \"d\", start: ISODate('2020-03-04 15:37:00'), length: 65 } ]) 使用可用的聚合管道运算符，您可以重写map-reduce示例，而无需定义自定义函数： db.usersessions.aggregate([ { $group: { _id: \"$userid\", total_time: { $sum: \"$length\" }, count: { $sum: 1 }, avg_time: { $avg: \"$length\" } } }, { $project: { value: { total_time: \"$total_time\", count: \"$count\", avg_time: \"$avg_time\" } } }, { $merge: { into: \"session_stats_agg\", whenMatched: [ { $set: { \"value.total_time\": { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, \"value.count\": { $add: [ \"$value.count\", \"$$new.value.count\" ] }, \"value.avg\": { $divide: [ { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, { $add: [ \"$value.count\", \"$$new.value.count\" ] } ] } } } ], whenNotMatched: \"insert\" }} ]) 通过userid$group，得出： total_time使用$sum操作 count使用$sum操作 avg_time使用$avg操作 该操作返回以下文档： { \"_id\" : \"c\", \"total_time\" : 250, \"count\" : 2, \"avg_time\" : 125 } { \"_id\" : \"d\", \"total_time\" : 110, \"count\" : 2, \"avg_time\" : 55 } { \"_id\" : \"a\", \"total_time\" : 200, \"count\" : 2, \"avg_time\" : 100 } { \"_id\" : \"b\", \"total_time\" : 230, \"count\" : 2, \"avg_time\" : 115 } 该$project阶段调整输出文档的形状以反映map-reduce的输出，该输出具有两个字段_id和 value。如果不需要镜像_idand value结构，则该阶段是可选的 。 { \"_id\" : \"a\", \"value\" : { \"total_time\" : 200, \"count\" : 2, \"avg_time\" : 100 } } { \"_id\" : \"d\", \"value\" : { \"total_time\" : 110, \"count\" : 2, \"avg_time\" : 55 } } { \"_id\" : \"b\", \"value\" : { \"total_time\" : 230, \"count\" : 2, \"avg_time\" : 115 } } { \"_id\" : \"c\", \"value\" : { \"total_time\" : 250, \"count\" : 2, \"avg_time\" : 125 } } 该$merge阶段将结果输出到 session_stats_agg集合。如果现有文档_id与新结果相同，则该操作将应用指定的管道，以根据结果和现有文档计算total_time，count和avg_time。如果是相同的，现有的文档_id中session_stats_agg，操作插入文档。 查询session_stats_agg集合以验证结果： db.session_stats_agg.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"a\", \"value\" : { \"total_time\" : 200, \"count\" : 2, \"avg_time\" : 100 } } { \"_id\" : \"b\", \"value\" : { \"total_time\" : 230, \"count\" : 2, \"avg_time\" : 115 } } { \"_id\" : \"c\", \"value\" : { \"total_time\" : 250, \"count\" : 2, \"avg_time\" : 125 } } { \"_id\" : \"d\", \"value\" : { \"total_time\" : 110, \"count\" : 2, \"avg_time\" : 55 } } 新文档添加到usersessions集合中： db.usersessions.insertMany([ { userid: \"a\", ts: ISODate('2020-03-05 14:17:00'), length: 130 }, { userid: \"b\", ts: ISODate('2020-03-05 14:23:00'), length: 40 }, { userid: \"c\", ts: ISODate('2020-03-05 15:02:00'), length: 110 }, { userid: \"d\", ts: ISODate('2020-03-05 16:45:00'), length: 100 } ]) $match在管道的开头添加一个阶段以指定日期过滤器： db.usersessions.aggregate([ { $match: { ts: { $gte: ISODate('2020-03-05 00:00:00') } } }, { $group: { _id: \"$userid\", total_time: { $sum: \"$length\" }, count: { $sum: 1 }, avg_time: { $avg: \"$length\" } } }, { $project: { value: { total_time: \"$total_time\", count: \"$count\", avg_time: \"$avg_time\" } } }, { $merge: { into: \"session_stats_agg\", whenMatched: [ { $set: { \"value.total_time\": { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, \"value.count\": { $add: [ \"$value.count\", \"$$new.value.count\" ] }, \"value.avg_time\": { $divide: [ { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, { $add: [ \"$value.count\", \"$$new.value.count\" ] } ] } } } ], whenNotMatched: \"insert\" }} ]) 查询session_stats_agg集合以验证结果： db.session_stats_agg.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"a\", \"value\" : { \"total_time\" : 330, \"count\" : 3, \"avg_time\" : 110 } } { \"_id\" : \"b\", \"value\" : { \"total_time\" : 270, \"count\" : 3, \"avg_time\" : 90 } } { \"_id\" : \"c\", \"value\" : { \"total_time\" : 360, \"count\" : 3, \"avg_time\" : 120 } } { \"_id\" : \"d\", \"value\" : { \"total_time\" : 210, \"count\" : 3, \"avg_time\" : 70 } } 可选的。为了避免$match每次运行时都必须修改聚合管道的日期条件，可以在帮助函数中定义包装聚合： updateSessionStats = function(startDate) { db.usersessions.aggregate([ { $match: { ts: { $gte: startDate } } }, { $group: { _id: \"$userid\", total_time: { $sum: \"$length\" }, count: { $sum: 1 }, avg_time: { $avg: \"$length\" } } }, { $project: { value: { total_time: \"$total_time\", count: \"$count\", avg_time: \"$avg_time\" } } }, { $merge: { into: \"session_stats_agg\", whenMatched: [ { $set: { \"value.total_time\": { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, \"value.count\": { $add: [ \"$value.count\", \"$$new.value.count\" ] }, \"value.avg_time\": { $divide: [ { $add: [ \"$value.total_time\", \"$$new.value.total_time\" ] }, { $add: [ \"$value.count\", \"$$new.value.count\" ] } ] } } } ], whenNotMatched: \"insert\" }} ]); }; 然后，要运行，您只需将开始日期传递给该updateSessionStats()函数： updateSessionStats(ISODate('2020-03-05 00:00:00')) 也可以看看 $ merge示例 按需实例化视图 译者：李冠飞 校对： 参见 原文 - Perform Incremental Map-Reduce Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/05-troubleshoot-map-function.html":{"url":"05-aggregation/02-map-reduce/05-troubleshoot-map-function.html","title":"对 Map Function 进行故障排除","keywords":"","body":" 对 Map Function 进行故障排除 map function 是一个 JavaScript function，它将 value 与 key 关联或“maps”，并在map-reduce操作期间发出 key 和 value 对。 要验证map function 发出的key和value对，请编写自己的emit function。 考虑一个包含以下原型文档的集合orders： { _id: ObjectId(\"50a8240b927d5d8b5891743c\"), cust_id: \"abc123\", ord_date: new Date(\"Oct 04, 2012\"), status: 'A', price: 250, items: [ { sku: \"mmm\", qty: 5, price: 2.5 }, { sku: \"nnn\", qty: 5, price: 2.5 } ] } 为每个文档定义_ma 功能 var map = function() { emit(this.cust_id, this.price); }; 定义emit function 以打印 key 和 value： var emit = function(key, value) { print(\"emit\"); print(\"key: \" + key + \" value: \" + tojson(value)); } 使用orders集合中的单个文档调用map function： var myDoc = db.orders.findOne( { _id: ObjectId(\"50a8240b927d5d8b5891743c\") } ); map.apply(myDoc); 验证 key 和 value 对是否符合预期。 emit key: abc123 value:250 使用orders集合中的多个文档调用map function： var myCursor = db.orders.find( { cust_id: \"abc123\" } ); while (myCursor.hasNext()) { var doc = myCursor.next(); print (\"document _id= \" + tojson(doc._id)); map.apply(doc); print(); } 验证 key 和 value 对是否符合预期。 也可以看看 mapfunction 必须满足各种要求。有关map` function 的所有要求的列表，请参阅MapReduce或mongo shell 辅助方法db.collection.mapReduce()。 译者：李冠飞 校对： 参见 原文 - Troubleshoot the Map Function Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/06-troubleshoot-reduce-function.html":{"url":"05-aggregation/02-map-reduce/06-troubleshoot-reduce-function.html","title":"排除 Reduce Function 问题","keywords":"","body":" 排除 Reduce Function 问题 在本页面 确认输出类型 确保对映射值的 Order 不敏感 确保减少 Function Idempotence reduce function 是一个 JavaScript function，它在map-reduce操作期间“减少”到单个 object 与特定 key 关联的所有值。 reduce function 必须满足各种要求。本教程有助于验证reduce function 是否符合以下条件： reduce function 必须_retject 一个 object，其类型必须与map function 发出的value的类型相同。 valuesArray中元素的 order 不应影响reduce function 的输出。 reduce function 必须是幂等的。 有关reduce function 的所有要求的列表，请参阅MapReduce或mongo shell 辅助方法db.collection.mapReduce()。 确认输出类型 您可以测试reduce function 返回的 value 与map function 发出的 value 的类型相同。 定义一个reduceFunction1 function，它接受 arguments keyCustId和valuesPrices。 valuesPrices是整数的 array： var reduceFunction1 = function(keyCustId, valuesPrices) { return Array.sum(valuesPrices); }; 定义 sample array 整数： var myTestValues = [ 5, 5, 10 ]; 使用myTestValues调用reduceFunction1： reduceFunction1('myKey', myTestValues); 验证reduceFunction1返回 integer： 20 定义一个reduceFunction2 function，它接受 arguments keySKU和valuesCountObjects。 valuesCountObjects是包含两个字段count和qty的 array 文档： var reduceFunction2 = function(keySKU, valuesCountObjects) { reducedValue = { count: 0, qty: 0 }; for (var idx = 0; idx 定义 sample array 文档： var myTestObjects = [ { count: 1, qty: 5 }, { count: 2, qty: 10 }, { count: 3, qty: 15 } ]; 使用myTestObjects调用reduceFunction2： reduceFunction2('myKey', myTestObjects); 验证reduceFunction2返回的文档中包含count和qty字段： { \"count\" : 6, \"qty\" : 30 } 确保对映射值的 Order 不敏感 reduce function 以key和values array 为参数。您可以测试reduce function 的结果不依赖于values array 中元素的 order。 定义 sample values1 array 和 sample values2 array，它们只在 array 元素的 order 中有所不同： var values1 = [ { count: 1, qty: 5 }, { count: 2, qty: 10 }, { count: 3, qty: 15 } ]; var values2 = [ { count: 3, qty: 15 }, { count: 1, qty: 5 }, { count: 2, qty: 10 } ]; 定义一个reduceFunction2 function，它接受 arguments keySKU和valuesCountObjects。 valuesCountObjects是包含两个字段count和qty的 array 文档： var reduceFunction2 = function(keySKU, valuesCountObjects) { reducedValue = { count: 0, qty: 0 }; for (var idx = 0; idx 先使用values1然后使用values2调用reduceFunction2： reduceFunction2('myKey', values1); reduceFunction2('myKey', values2); 验证reduceFunction2返回相同的结果： { \"count\" : 6, \"qty\" : 30 } 确保减少 Function Idempotence 因为 map-reduce 操作可能会为同一个 key 多次调用reduce，并且不会为工作集中的 key 的单个实例调用reduce，reduce function 必须 return 与从该值发出的 value 相同类型的 value。 map function。您可以测试reduce function process“减少”值而不影响最终的 value。 定义一个reduceFunction2 function，它接受 arguments keySKU和valuesCountObjects。 valuesCountObjects是包含两个字段count和qty的 array 文档： var reduceFunction2 = function(keySKU, valuesCountObjects) { reducedValue = { count: 0, qty: 0 }; for (var idx = 0; idx 定义 sample key： var myKey = 'myKey'; 定义 sample valuesIdempotent array，其中包含一个调用reduceFunction2 function 的元素： var valuesIdempotent = [ { count: 1, qty: 5 }, { count: 2, qty: 10 }, reduceFunction2(myKey, [ { count:3, qty: 15 } ] ) ]; 定义一个 sample values1 array，它结合了传递给reduceFunction2的值： var values1 = [ { count: 1, qty: 5 }, { count: 2, qty: 10 }, { count: 3, qty: 15 } ]; 首先使用myKey和valuesIdempotent调用reduceFunction2，然后使用myKey和values1调用reduceFunction2： reduceFunction2(myKey, valuesIdempotent); reduceFunction2(myKey, values1); 验证reduceFunction2返回相同的结果： { \"count\" : 6, \"qty\" : 30 } 译者：李冠飞 校对： 参见 原文 - Troubleshoot the Reduce Function Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/02-map-reduce/07-map-reduce-to-aggregation-pipeline.html":{"url":"05-aggregation/02-map-reduce/07-map-reduce-to-aggregation-pipeline.html","title":"Map-Reduce转换到聚合管道","keywords":"","body":" Map-Reduce转换到聚合管道 从4.4版本开始，MongoDB添加了$accumulator和$function aggregation运算符。这些运算符为用户提供了定义自定义聚合表达式的能力。使用这些操作，可以大致重写map-reduce表达式，如下表所示。 注意 可以使用聚合管道操作符(如$group、$merge等)重写各种map-reduce表达式，而不需要自定义函数。 例如，请参见map-reduce示例。 Map-Reduce到聚合管道转换表 这张表只是粗略的翻译。例如，该表显示了使用$project的mapFunction的近似转换。 然而，mapFunction逻辑可能需要额外的阶段，例如，如果逻辑包括对数组的迭代: function() { this.items.forEach(function(item){ emit(item.sku, 1); }); } 然后，聚合管道包括一个$unwind和一个$project: { $unwind: \"$items \"}, { $project: { emits: { key: { \"$items.sku\" }, value: 1 } } }, $project中的emit字段可以被命名为其他名称。为了进行可视化比较，选择了字段名称emit。 Map-Reduce Aggregation Pipeline db.collection.mapReduce( , , { query: , sort: , limit: , finalize: , out: } ) db.collection.aggregate( [ { $match: }, { $sort: }, { $limit: }, { $project: { emits: { k: , v: } } }, { $unwind: “$emits” }, { $group: { _id: “$emits.k”}, value: { $accumulator: { init: , accumulate: , accumulateArgs: [ “$emit.v”], merge: , finalize: , lang: “js” }} } }, { $out: }] ) db.collection.mapReduce( , , { query: , sort: , limit: , finalize: , out: { merge: , db: } }) db.collection.aggregate( [ { $match: }, { $sort: }, { $limit: }, { $project: { emits: { k: , v: } } }, { $unwind: “$emits” }, { $group: { _id: “$emits.k”}, value: { $accumulator: { init: , accumulate: , accumulateArgs: [ “$emit.v”], merge: , finalize: , lang: “js” }} } }, { $out: { db: , coll: } }] ) db.collection.mapReduce( , , { query: , sort: , limit: , finalize: , out: { merge: , db: } }) db.collection.aggregate( [ { $match: }, { $sort: }, { $limit: }, { $project: { emits: { k: , v: } } }, { $unwind: “$emits” }, { $group: { _id: “$emits.k”}, value: { $accumulator: { init: , accumulate: , accumulateArgs: [ “$emit.v”], merge: , finalize: , lang: “js” }} } }, { $merge: { into: { db: , coll: }, on: “_id” whenMatched: “replace”, whenNotMatched: “insert” } },] ) db.collection.mapReduce( , , { query: , sort: , limit: , finalize: , out: { merge: , db: } }) db.collection.aggregate( [ { $match: }, { $sort: }, { $limit: }, { $project: { emits: { k: , v: } } }, { $unwind: “$emits” }, { $group: { _id: “$emits.k”}, value: { $accumulator: { init: , accumulate: , accumulateArgs: [ “$emit.v”], merge: , finalize: , lang: “js” }} } }, { $merge: { into: { db: , coll: }, on: “_id” whenMatched: [ { $project: { value: { $function: { body: , args: [ “$_id”, [ “$value”, “$$new.value” ] ], lang: “js” } } } } ] whenNotMatched: “insert” } },] ) db.collection.mapReduce( , , { query: , sort: , limit: , finalize: , out: { inline: 1 } }) db.collection.aggregate( [ { $match: }, { $sort: }, { $limit: }, { $project: { emits: { k: , v: } } }, { $unwind: “$emits” }, { $group: { _id: “$emits.k”}, value: { $accumulator: { init: , accumulate: , accumulateArgs: [ “$emit.v”], merge: , finalize: , lang: “js” }} } }] ) 例子 可以使用聚合管道操作符(如$group、$merge等)重写各种map-reduce表达式，而不需要自定义函数。但是，为了说明目的，下面的例子提供了两种选择。 示例1 通过cust_id对订单集合组执行以下map-reduce操作，并计算每个cust_id的价格总和: var mapFunction1 = function() { emit(this.cust_id, this.price); }; var reduceFunction1 = function(keyCustId, valuesPrices) { return Array.sum(valuesPrices); }; db.orders.mapReduce( mapFunction1, reduceFunction1, { out: \"map_reduce_example\" } ) 备选方案1:(推荐)您可以重写操作到聚合管道，而不将map-reduce函数转换为等效的管道阶段: db.orders.aggregate([ { $group: { _id: \"$cust_id\", value: { $sum: \"$price\" } } }, { $out: \"agg_alternative_1\" } ]) 备选方案2:(仅为说明目的)下面的聚合管道提供了各种map-reduce函数的转换，使用$accumulator定义自定义函数: db.orders.aggregate( [ { $project: { emit: { key: \"$cust_id\", value: \"$price\" } } }, // equivalent to the map function { $group: { // equivalent to the reduce function _id: \"$emit.key\", valuesPrices: { $accumulator: { init: function() { return 0; }, initArgs: [], accumulate: function(state, value) { return state + value; }, accumulateArgs: [ \"$emit.value\" ], merge: function(state1, state2) { return state1 + state2; }, lang: \"js\" } } } }, { $out: \"agg_alternative_2\" } ] ) 首先，$project阶段输出带有emit字段的文档。emit字段是一个包含以下字段的文档: key包含cust_id文档的值 value包含price文档的值 { \"_id\" : 1, \"emit\" : { \"key\" : \"Ant O. Knee\", \"value\" : 25 } } { \"_id\" : 2, \"emit\" : { \"key\" : \"Ant O. Knee\", \"value\" : 70 } } { \"_id\" : 3, \"emit\" : { \"key\" : \"Busby Bee\", \"value\" : 50 } } { \"_id\" : 4, \"emit\" : { \"key\" : \"Busby Bee\", \"value\" : 25 } } { \"_id\" : 5, \"emit\" : { \"key\" : \"Busby Bee\", \"value\" : 50 } } { \"_id\" : 6, \"emit\" : { \"key\" : \"Cam Elot\", \"value\" : 35 } } { \"_id\" : 7, \"emit\" : { \"key\" : \"Cam Elot\", \"value\" : 25 } } { \"_id\" : 8, \"emit\" : { \"key\" : \"Don Quis\", \"value\" : 75 } } { \"_id\" : 9, \"emit\" : { \"key\" : \"Don Quis\", \"value\" : 55 } } { \"_id\" : 10, \"emit\" : { \"key\" : \"Don Quis\", \"value\" : 25 } } 然后，$group使用$accumulator操作符来添加发出的值: { \"_id\" : \"Don Quis\", \"valuesPrices\" : 155 } { \"_id\" : \"Cam Elot\", \"valuesPrices\" : 60 } { \"_id\" : \"Ant O. Knee\", \"valuesPrices\" : 95 } { \"_id\" : \"Busby Bee\", \"valuesPrices\" : 125 } 最后，$out将输出写入集合agg_alternative_2。或者，您可以使用$merge而不是$out。 示例2 以下字段对orders集合组的map-reduce操作，item.sku并计算每个sku的订单数量和总订购量。然后，该操作将为每个sku值计算每个订单的平均数量，并将结果合并到输出集合中。 var mapFunction2 = function() { for (var idx = 0; idx 备选方案1:(推荐)您可以重写操作到聚合管道，而不将map-reduce函数转换为等效的管道阶段: db.orders.aggregate( [ { $match: { ord_date: { $gte: new Date(\"2020-03-01\") } } }, { $unwind: \"$items\" }, { $group: { _id: \"$items.sku\", qty: { $sum: \"$items.qty\" }, orders_ids: { $addToSet: \"$_id\" } } }, { $project: { value: { count: { $size: \"$orders_ids\" }, qty: \"$qty\", avg: { $divide: [ \"$qty\", { $size: \"$orders_ids\" } ] } } } }, { $merge: { into: \"agg_alternative_3\", on: \"_id\", whenMatched: \"replace\", whenNotMatched: \"insert\" } } ] ) 备选方案2:(仅为说明目的)下面的聚合管道提供了各种map-reduce函数的转换，使用$accumulator定义自定义函数: db.orders.aggregate( [ { $match: { ord_date: {$gte: new Date(\"2020-03-01\") } } }, { $unwind: \"$items\" }, { $project: { emit: { key: \"$items.sku\", value: { count: { $literal: 1 }, qty: \"$items.qty\" } } } }, { $group: { _id: \"$emit.key\", value: { $accumulator: { init: function() { return { count: 0, qty: 0 }; }, initArgs: [], accumulate: function(state, value) { state.count += value.count; state.qty += value.qty; return state; }, accumulateArgs: [ \"$emit.value\" ], merge: function(state1, state2) { return { count: state1.count + state2.count, qty: state1.qty + state2.qty }; }, finalize: function(state) { state.avg = state.qty / state.count; return state; }, lang: \"js\"} } } }, { $merge: { into: \"agg_alternative_4\", on: \"_id\", whenMatched: \"replace\", whenNotMatched: \"insert\" } } ] ) $match阶段只选择那些ord_date大于或等于new Date(\"2020-03-01\")的文档。 $unwinds阶段按items数组字段分解文档，为每个数组元素输出一个文档。例如: { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"apples\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 8, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"pears\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 4, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-18T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 5, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-19T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } ... $project阶段输出带有emit字段的文档。emit字段是一个包含以下字段的文档: key包含items.sku值 value包含具有qty值和count值的文档 { \"_id\" : 1, \"emit\" : { \"key\" : \"oranges\", \"value\" : { \"count\" : 1, \"qty\" : 5 } } } { \"_id\" : 1, \"emit\" : { \"key\" : \"apples\", \"value\" : { \"count\" : 1, \"qty\" : 5 } } } { \"_id\" : 2, \"emit\" : { \"key\" : \"oranges\", \"value\" : { \"count\" : 1, \"qty\" : 8 } } } { \"_id\" : 2, \"emit\" : { \"key\" : \"chocolates\", \"value\" : { \"count\" : 1, \"qty\" : 5 } } } { \"_id\" : 3, \"emit\" : { \"key\" : \"oranges\", \"value\" : { \"count\" : 1, \"qty\" : 10 } } } { \"_id\" : 3, \"emit\" : { \"key\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10 } } } { \"_id\" : 4, \"emit\" : { \"key\" : \"oranges\", \"value\" : { \"count\" : 1, \"qty\" : 10 } } } { \"_id\" : 5, \"emit\" : { \"key\" : \"chocolates\", \"value\" : { \"count\" : 1, \"qty\" : 5 } } } ... $group使用$accumulator操作符来添加发出的计数和数量，并计算avg字段: { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 7, \"qty\" : 63, \"avg\" : 9 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } { \"_id\" : \"apples\", \"value\" : { \"count\" : 4, \"qty\" : 35, \"avg\" : 8.75 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } 最后，$merge将输出写入集合agg_alternative_4。如果现有文档具有与新结果相同的键_id，则操作将覆盖现有文档。如果没有具有相同密钥的现有文档，操作将插入该文档。 也可以看看聚合命令比较 译者：李冠飞 校对： 参见 原文 - Map-Reduce to Aggregation Pipeline Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation.html":{"url":"05-aggregation/03-aggregation.html","title":"聚合参考","keywords":"","body":" 聚合参考 聚合管道快速参考 聚合管道的快速参考卡。 聚合命令 数据聚合命令的引用，该命令为MongoDB的聚合功能提供接口。 聚合命令比较 MapReduce和Aggregate命令的比较。 聚合管道操作符 聚合管道操作有一个操作符集合，可用于在管道阶段中定义和操作文档。 聚合表达式中的变量 在聚合管道表达式中使用变量。 SQL 到聚合映射图表 使用MongoDB和常见SQL语句中的聚合管道和操作符概述SQL和MongoDB中的常见聚合操作。 译者：李冠飞 校对：李冠飞 参见 原文 - Aggregation Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation/01-aggregation-quick-reference.html":{"url":"05-aggregation/03-aggregation/01-aggregation-quick-reference.html","title":"聚合管道快速参考","keywords":"","body":" 聚合管道快速参考 在本页面 阶段 表达式 运算符表达式 表达式运算符的索引 有关特定运算符的详细信息，包括语法和示例，请单击特定的运算符以转到其参考页面。 阶段 阶段(db.collection.aggregate) 在db.collection.aggregate方法中，管道阶段出现在数组中。文档按顺序通过各个阶段。除$out, $merge和$geoNear阶段之外的所有阶段都可以在管道中多次出现。 db.collection.aggregate( [ { }, ... ] ) 阶段 描述 $addFields 向文档添加新字段。类似于$project，$addFields重塑了流中的每个文档;具体而言，通过向输出文档添加新字段，该文档包含输入文档和新添加字段中的现有字段。$set是$addFields的别名。 $bucket 根据指定的表达式和存储区边界，将传入的文档分组，称为bucket。 $bucketAuto 根据指定的表达式将传入的文档分类为特定数量的组(称为bucket)。自动确定bucket边界，以便将文档均匀地分配到指定数量的bucket中。 $collStats 返回有关集合或视图的统计信息。 $count 返回聚合管道此阶段的文档数量计数。 $facet 在同一组输入文档的单个阶段内处理多个聚合管道。允许创建能够在单个阶段中跨多个维度或方面描述数据的多面聚合。 $geoNear 根据与地理空间点的接近程度返回一个有序的文档流。将$match，$sort和$limit的功能合并到地理空间数据中。输出文档包括附加距离字段，并且可以包括位置标识符字段。 $graphLookup 对集合执行递归搜索。对于每个输出文档，添加一个新的数组字段，该字段包含该文档的递归搜索的遍历结果。 $group 按指定的标识符表达式对文档进行分组，并将累加器表达式(如果指定)应用于每个组。使用所有输入文档并为每个不同的组输出一个文档。输出文档只包含标识符字段和累积字段(如果指定的话)。 $indexStats 返回有关集合的每个索引的使用情况的统计信息。 $limit 将未修改的前 n 个文档传递给管道，其中 n 是指定的限制。对于每个输入文档，输出一个文档(对于前 n 个文档)或零文档(在前 n 个文档之后)。 $listSessions 列出足以传播到system.sessions集合的所有会话。 $lookup 对同一数据库中的另一个集合执行左外连接，从“已连接”集合中过滤文档以进行处理。 $match 过滤文档流以仅允许匹配的文档未经修改地传递到下一个管道阶段。 $match使用标准的 MongoDB 查询。对于每个输入文档，输出一个文档(匹配)或零文档(不匹配)。 $merge 将聚合管道的结果文档写入集合。这个阶段可以将结果合并到一个输出集合中(插入新文档、合并文档、替换文档、保留现有文档、操作失败、使用自定义更新管道处理文档)。要使用$merge阶段，它必须是管道中的最后一个阶段。version 4.2 中的新功能 $out 将聚合管道的结果文档写入集合。要使用$out阶段，它必须是管道中的最后一个阶段。 $planCacheStats 返回集合的计划缓存信息。 $project 重新整形流中的每个文档，例如添加新字段或删除现有字段。对于每个输入文档，输出一个文档。有关删除现有字段，请参见$unset。 $redact 通过基于文档本身中存储的信息限制每个文档的内容来重塑流中的每个文档。合并$project和$match的功能。可用于实现字段级修订。对于每个输入文档，输出一个或零个文档。 $replaceRoot 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶层。$replaceWith是$replaceRoot阶段的别名。 $replaceWith 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶层。$replaceWith是$replaceRoot阶段的别名。 $sample 从输入中随机选择指定数量的文档。 $set 向文档添加新字段。与$project类似，$set会重新塑造流中的每个文档；具体来说，通过向包含输入文档中的现有字段和新添加字段的输出文档添加新字段。$set是$addFields阶段的别名。 $skip 跳过前 n 个文档，其中 n 是指定的跳过编号，并将其余未修改的文档传递给管道。对于每个输入文档，输出零文档(对于前 n 个文档)或一个文档(如果在前 n 个文档之后)。 $sort 按指定的排序键重新排序文档。只有顺序改变;文件保持不变。对于每个输入文档，输出一个文档。 $sortByCount 根据指定表达式的值对传入文档进行分组，然后计算每个不同组中的文档计数。 $unionWith 执行两个集合的并集;例如，将来自两个集合的管道结果组合成一个结果集。version 4.4 中的新功能 $unset 从文档中移除/排除字段。$unset是移除字段阶段的$project stage的别名。 $unwind 解析输入文档中的数组字段，为每个元素输出一个文档。每个输出文档用一个元素值替换数组。对于每个输入文档，输出n个文档，其中n是数组元素的数量，对于空数组可以为零。 阶段(db.aggregate) 从 version 3.6 开始，MongoDB 也提供了db.aggregate方法： db.aggregate( [ { }, ... ] ) 以下阶段使用db.aggregate()方法而不是db.collection.aggregate()方法。 阶段 描述 $currentOp 返回有关 MongoDB 部署的活动 and/or 休眠操作的信息。 $listLocalSessions 列出当前连接的mongos或mongod实例上正在使用的所有活动会话。这些会话可能尚未传播到system.sessions集合。 阶段可用更新 从MongoDB 4.2开始，你可以使用聚合管道更新: 命令 mongo Shell 方法 findAndModify db.collection.findOneAndUpdate()db.collection.findAndModify() update db.collection.updateOne()db.collection.updateMany()db.collection.update()Bulk.find.update()Bulk.find.updateOne()Bulk.find.upsert() 对于更新，管道可以包括以下阶段: $addFields及其别名$set $project及其别名$unset $replaceRoot及其别名$replaceWith [success] 也可以看看 聚合管道更新 表达式 表达式可以包括字段路径，Literals，系统变量，表达对象和表达式操作符。表达式可以嵌套。 字段路径 聚合表达式使用字段路径来访问输入文档中的字段。要指定字段路径，请在字段名或虚线字段名(如果字段在嵌入的文档中)前加上美元符号$。例如，“$user”指定用户字段的字段路径，“$user.name”指定“user.name”字段的字段路径。 \"$\"等效于\"$$CURRENT.\"，其中CURRENT是系统变量，默认为当前对象的根，除非在特定阶段另有说明。 聚合变量 MongoDB提供了在表达式中使用的各种聚合系统变量。要访问变量，请在变量名前加上$$。例如: 变量 通过$$访问 简介/描述 NOW $$NOW 返回当前的日期时间值，该值在部署的所有成员之间是相同的，并在整个聚合管道中保持不变。(4.2 + 版本中可用) CLUSTER_TIME $$CLUSTER_TIME 返回当前时间戳值，该值在部署的所有成员之间是相同的，并在整个聚合管道中保持不变。仅用于复制集和分片集群。(4.2 + 版本中可用) ROOT $$ROOT 引用根文档，即：顶级文档。 CURRENT $$CURRENT 引用字段路径的开始，默认情况下该路径是ROOT，但可以更改。 REMOVE $$REMOVE 允许有条件地排除字段。(3.6 + 版本中可用) DESCEND $$DESCEND $redact表达式允许的结果之一。 PRUNE $$PRUNE $redact表达式允许的结果之一。 KEEP $$KEEP $redact表达式允许的结果之一。 有关这些变量的更详细描述，请参阅系统变量。 Literals Literals 可以是任何类型。但是，MongoDB将以美元符号$开头的字符串字面值作为字段的路径，并将表达式对象中的数值/布尔字面值作为投影标志。为了避免解析文字，可以使用$literal表达式。 表达式对象 表达式对象具有以下形式： { : , ... } 如果表达式是数值型或 boolean 型文字，MongoDB 将 literals 视为投影标志(例如： 1或true包括该字段)，仅在$project阶段有效。要避免将数值或 boolean 型文字视为投影标志，请使用$literal表达式来包装数值型或 boolean 文字型。 运算符表达式 在这个部分 算数表达式运算符 数组表达式运算符 布尔表达式运算符 比较表达式运算符 条件表达式运算符 自定义聚合表达式运算符 数据大小表达式运算符 日期表达式运算符 文字表达式运算符 对象表达式运算符 集合表达式运算符 字符串表达式运算符 文本表达式运算符 角度表达式运算符 类型表达式运算符 累加器($group) 累加器($project 和$addFields) 变量表达式运算符 运算符表达式与采用带参数的函数类似。通常，这些表达式有一个数组参数 并具有以下形式： { : [ , ... ] } 如果操作符接受单个参数，则可以省略指定参数列表的外部数组： { : } 如果参数是文字数组，为了避免解析歧义，必须将文字数组包装在$literal表达式中，或者保留指定参数列表的外部数组。 算数表达式运算符 算术表达式对数字执行数学运算。一些算术表达式也可以支持日期算术。 名称 描述 $abs 返回数字的绝对值。 $add 添加 numbers 以返回总和，或添加 numbers 和 date 以返回新的 date。如果添加 numbers 和 date，则将 numbers 视为毫秒。接受任意数量的参数表达式，但最多只能有一个表达式解析为 date。 $ceil 返回大于或等于指定数字的最小整数。 $divide 返回将第一个数除以第二个数的结果。接受两个参数表达式。 $exp 将 e 提高到指定的指数。 $floor 返回小于或等于指定数字的最大整数。 $ln 计算数字的自然对数。 $log 计算指定基数中的数字的对数。 $log10 计算以10为底的对数。 $mod 返回第一个数字除以第二个数字的余数。接受两个参数表达式。 $multiply 将数字相乘返回乘积。接受任意数量的参数表达式。 $pow 将数字提高到指定的指数。 $round 将数字四舍五入为整数或指定的小数位。 $sqrt 计算平方根。 $subtract 返回从第一个值中减去第二个值的结果。如果这两个值是数字，返回差值。如果这两个值是日期，则返回差值(以毫秒为单位)。如果这两个值是日期和一个以毫秒为单位的数字，返回结果日期。接受两个参数表达式。如果这两个值是日期和数字，请首先指定 date 参数，因为从数字中减去 date 没有意义。 $trunc 将数字截断为整数或指定的小数位。 数组表达式运算符 名称 描述 $arrayElemAt 返回指定的数组索引处的元素。 $arrayToObject 将键值对的数组转换为文档。 $concatArrays 连接数组以返回连接的数组。 $filter 选择 array 的子集以 return array 仅包含 match 过滤条件的元素。 $first 返回第一个数组元素，不同于$first累加器 $in 返回一个 boolean 值，指示指定的值是否在列表中。 $indexOfArray 搜索列表以查找指定值的出现并返回第一个匹配项的数组索引。如果未找到子字符串，则返回-1。 $isArray 确定操作数是否为数组。返回 boolean 值。 $last 返回最后一个数组元素，不同于$last累加器。 $map 将子表达式应用于数组的每个元素，并按顺序返回结果值的数组。接受命名参数。 $objectToArray 将文档转换为表示键值对的文档的数组。 $range 根据用户定义的输入输出包含整数序列的数组。 $reduce 将表达式应用于数组中的每个元素，并将它们组合为单个值。 $reverseArray 返回元素顺序相反的数组。 $size 返回数组中的元素数。接受单个表达式作为参数。 $slice 返回数组的子集。 $zip 将两个数组合并在一起。 布尔表达式运算符 Boolean 表达式将其参数表达式计算为布尔值，并返回一个boolean值作为结果。 除了false 布尔值之外，Boolean 表达式的计算结果如下：null，0和undefined值。 Boolean 表达式将所有其他值计算为true，包括非零数值和数组。 名称 描述 $and 仅当其所有表达式求值为true时才返回true。接受任意数量的参数表达式。 $not 返回与其参数表达式相反的 boolean 值。接受单个参数表达式。 $or 当其表达式的值为true时返回true。接受任意数量的参数表达式。 比较表达式运算符 比较表达式返回一个布尔值，除了$cmp，它返回一个数字。 比较表达式采用两个参数表达式并对值和类型进行比较，使用指定的 BSON 比较顺序表示不同类型的值。 名称 描述 $cmp 如果两个值相等则返回0，如果第一个 value 大于第二个值则返回1，如果第一个值小于第二个值，则返回-1。 $eq 如果值相等，则返回true。 $gt 如果第一个值大于第二个，则返回true。 $gte 如果第一个值大于或等于第二个，则返回true。 $lt 如果第一个值小于第二个，则返回true。 $lte 如果第一个值小于或等于第二个值，则返回true。 $ne 如果值不相等，则返回true。 条件表达式运算符 名称 描述 $cond 对一个表达式求值的三元运算符，并根据结果返回另外两个表达式之一的值。接受有序列表中的三个表达式或三个命名参数。 $ifNull 返回第一个表达式的非空结果，如果第一个表达式的结果为空，则返回第二个表达式的结果。Null结果包含未定义值或缺少字段的实例。接受两个表达式作为参数。第二个表达式的结果可以为null。 $switch 计算一系列用例表达。当它找到一个计算结果为true的表达式时，$switch执行一个指定的表达式并跳出控制流。 自定义聚合表达式运算符 名称 描述 $accumulator 定义一个自定义累加器函数version 4.4 新功能 $function 定义一个自定义函数version 4.4 新功能 数据大小表达式运算符 以下运算符返回数据元素的大小: 名称 描述 $binarySize 返回给定字符串或二进制数据值内容的字节大小。 $bsonSize 返回编码为BSON的给定文档(例如：bsontype对象)的字节大小。 日期表达式运算符 以下操作符返回 date 对象或 date 对象的组件： 名称 描述 $dateFromParts 给出日期的组成部分，构造一个 BSON Date 对象。 $dateFromString 将 date/time 字符串转换为 date 对象。 $dateToParts 返回包含日期组成部分的文档。 $dateToString 将 date 作为格式化的字符串返回。 $dayOfMonth 将 date 的月中某天返回为 1 到 31 之间的数字。 $dayOfWeek 将 date 的星期几返回为 1(星期日)和 7(星期六)之间的数字。 $dayOfYear 将 date 的年中日期作为 1 到 366(闰年)之间的数字返回。 $hour 将 date 的小时数作为 0 到 23 之间的数字返回。 $isoDayOfWeek 返回 ISO 8601 格式的工作日编号，范围从1(星期一)到7(星期日)。 $isoWeek 返回 ISO 8601 格式的周数，范围从1到53。 Week numbers 从1开始，周(星期一到星期日)包含年份的第一个星期四。 $isoWeekYear 以 ISO 8601 格式返回年份编号。年份从第 1 周的星期一(ISO 8601)开始，结束于上周的星期日(ISO 8601)。 $millisecond 返回 date 的毫秒数，作为 0 到 999 之间的数字。 $minute 将 date 的分钟作为 0 到 59 之间的数字返回。 $month 将 date 的月份返回为 1(1 月)和 12(12 月)之间的数字。 $second 返回 date 的秒数，作为 0 到 60 之间的数字(闰秒)。 $toDate 将值转换为日期。version 4.0 中的新功能。 $week 返回日期的周数，该数字介于0(一年的第一个星期日之前的部分周)和53(闰年)之间。 $year 将日期的年份作为数字返回(例： 2014)。 以下算术运算符可以使用日期操作数： 名称 描述 $add 添加数字和日期以返回新的日期。如果添加数字和日期，则将这些数字视为毫秒。接受任意数量的参数表达式，但一个表达式最多只能解析一个日期。 $subtract 返回从第一个值减去第二个值的结果。如果这两个值是日期，则返回差值(以毫秒为单位)。如果这两个值是日期和一个以毫秒为单位的数字，则返回结果日期。接受两个参数表达式。如果这两个值是日期和数字，请首先指定日期参数，因为从数字中减去日期没有意义。 文字表达式运算符 名称 描述 $literal 返回一个不需要解析的值。用于聚合管道可解释为表达式的值。例如，将$literal表达式用于以$开头的 string，以避免解析为字段路径。 对象表达式运算符 名称 描述 $mergeObjects 将多个文档合并为一个文档。 version 3.6 中的新内容。 $objectToArray 将文档转换为表示键值对的文档的数组。 version 3.6 中的新内容。 集合表达式运算符 Set 表达式对数组执行 set 操作，将数组视为集合。 Set 表达式忽略每个输入数组中的重复条目和元素的顺序。 如果 set 操作返回一个集合，则该操作会过滤掉结果中的重复项，以输出仅包含唯一条目的数组。输出数组中元素的顺序未指定。 如果集合包含嵌套的数组元素，则 set 表达式不会深入到嵌套的数组中，而是在最外层处计算数组。 名称 描述 $allElementsTrue 如果没有集合的元素计算为false，则返回true，否则返回false。接受单个参数表达式。 $anyElementTrue 如果集合中的任意一个元素求值为true，则返回true；否则，返回false。接受单个参数表达式。 $setDifference 返回一个集合，其中的元素出现在第一个集合中但不出现在第二个集合中；即：执行第二个集合相对于第一个集合的相对补充。接受两个参数表达式。 $setEquals 如果输入 sets 具有相同的不同元素，则返回true。接受两个或多个参数表达式。 $setIntersection 返回一个包含所有输入 sets 中出现的元素的集合。接受任意数量的参数表达式。 $setIsSubset 如果第一组的所有元素出现在第二组中，包括第一个集合和第二个集合相等时，则返回true；即：不是严格的子集。接受两个参数表达式。 $setUnion 返回包含出现在任何输入集合中的元素的集合。 字符串表达式运算符 除了$concat之外，字符串表达式只对ASCII字符的字符串具有定义良好的行为。 无论使用哪个字符，$concat行为都是定义良好的。 名称 描述 $concat 连接任意数量的 strings。 $dateFromString 将 date/time string 转换为 date object。 $dateToString 将 date 作为格式化的 string 返回。 $indexOfBytes 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 字节索引。如果未找到子字符串，则返回-1。 $indexOfCP 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 code 点索引。如果找不到子字符串，则返回-1 $split 根据分隔符将 string 拆分为子字符串。返回子字符串的 array。如果在 string 中找不到分隔符，则返回包含原始 string 的 array。 $strLenBytes 返回 string 中 UTF-8 编码字节的数量。 $strLenCP 返回 string 中 UTF-8 code 点的数量。 $strcasecmp 执行 case-insensitive string 比较并返回：如果两个 strings 相等则返回0，如果第一个 string 大于第二个，则返回1，如果第一个 string 小于第二个，则返回-1。 $substr 已过时。使用$substrBytes或$substrCP。 $substrBytes 返回 string 的子字符串。从 string 中指定的 UTF-8 字节索引(zero-based)处的字符开始，并继续指定的字节数。 $substrCP 返回 string 的子字符串。从 string 中指定的 UTF-8 code point(CP)索引(zero-based)处的字符开始，并继续指定的 code 点数。 $toLower 将 string 转换为小写。接受单个参数表达式。 $toUpper 将 string 转换为大写。接受单个参数表达式。 文本表达式运算符 名称 描述 $meta 访问文本搜索元数据。 角度表达式运算符 名称 描述 $type 返回该字段的 BSON 数据类型。 [](s 累加器($group) 可以在$group阶段使用，累加器是 operators，它们在文档通过管道时保持其 state(例： 总计，最大值，最小值和相关数据)。 当在$group阶段用作累加器时，这些 operators 将单个表达式作为输入，为每个输入文档计算一次表达式，并为共享相同 group key 的 group 文档保持其阶段。 名称 描述 $addToSet 返回每个 group 的唯一表达式值的 array。 _Oray 元素的 Order 是未定义的。 $avg 返回数值的平均值。忽略 non-numeric 值。 $first 从每个 group 的第一个文档返回一个 value。仅当文档位于已定义的 order 中时才定义 Order。 $last 从每个 group 的最后一个文档返回一个 value。仅当文档位于已定义的 order 中时才定义 Order。 $max 返回每个 group 的最高表达式 value。 $mergeObjects 返回通过组合每个 group 的输入文档创建的文档。 $min 返回每个 group 的最低表达式 value。 $push 返回每个 group 的表达式值的 array。 $stdDevPop 返回输入值的总体标准偏差。 $stdDevSamp 返回输入值的 sample 标准偏差。 $sum 返回数值的总和。忽略 non-numeric 值。 累加器($project 和$addFields) 一些可用作$group阶段累加器的运算符也可用于$project和$addFields阶段，但不能用作累加器。在$project和$addFields阶段使用时，这些 operators 不会维护它们的 state，并且可以将单个参数或多个 arguments 作为输入。 更改了 version 3.2. 以下累加器 operators 也可用于$project和$addFields阶段。 名称 描述 $avg 返回每个文档的指定表达式或表达式列表的平均值。忽略 non-numeric 值。 $max 返回每个文档的指定表达式或表达式列表的最大值 $min 返回每个文档的指定表达式或表达式列表的最小值 $stdDevPop 返回输入值的总体标准偏差。 $stdDevSamp 返回输入值的 sample 标准偏差。 $sum 返回数值的总和。忽略 non-numeric 值。 变量表达式运算符 名称 描述 $let 定义在子表达式范围内使用的变量，并返回子表达式的结果。接受命名参数。 接受任意数量的参数表达式。 表达式运算符的索引 $abs$add$addToSet$allElementsTrue$and$anyElementTrue$arrayElemAt$arrayToObject$avg$cmp$concat$concatArrays$cond$dateFromParts$dateToParts$dateFromString$dateToString $dayOfMonth$dayOfWeek$dayOfYear$divide$eq$exp$filter$first$floor$gt$gte$hour$ifNull$in$indexOfArray$indexOfBytes$indexOfCP$isArray $isoDayOfWeek$isoWeek$isoWeekYear$last$let$literal$ln$log$log10$lt$lte$map$max$mergeObjects$meta$min$millisecond $minute$mod$month$multiply$ne$not$objectToArray$or$pow$push$range$reduce$reverseArray$second$setDifference$setEquals$setIntersection$setIsSubset$setUnion$size $slice$split$sqrt$stdDevPop$stdDevSamp$strcasecmp$strLenBytes$strLenCP$substr$substrBytes$substrCP$subtract$sum$switch$toLower$toUpper$trunc$type$week$year$zip 译者：李冠飞 校对： 参见 原文 - Aggregation Pipeline Quick Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation/02-interface.html":{"url":"05-aggregation/03-aggregation/02-interface.html","title":"Aggregation Commands","keywords":"","body":" Aggregation Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Aggregation Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation/03-aggregation-commands-comparison.html":{"url":"05-aggregation/03-aggregation/03-aggregation-commands-comparison.html","title":"聚合命令比较","keywords":"","body":" 聚合命令比较 在本页面 聚合命令比较表 [success] 建议 从4.4版开始，MongoDB添加$accumulator和 $function运算符。使用 $accumulator和$function， mapReduce可以使用聚合运算符重写表达式。 即使是4.4版本之前，一些map-reduce表达式也可以使用改写其他聚合管道运算符，如$group， $merge等。 聚合命令比较表 以下表格简要概述了 MongoDB 聚合命令的特点。 Aggregate / db.collection.aggregate() MapReduce / db.collection.mapReduce() 描述 旨在提高聚合任务的性能和可用性的具体目标。 使用“管道”方法，其中 objects 在通过一系列管道操作符(如$group，$match和$sort)时进行转换。 有关管道运算符的更多信息，请参见聚合管道操作符。 实现 Map-Reduce 聚合以处理大型数据集。 主要特点 可以根据需要重复管道操作符。 管道运算符不需要为每个输入文档生成一个输出文档。 还可以生成新文档或过滤掉文档。通过在版本4.2中添加$merge，可以创建按需的物化视图，在该视图中可以逐步运行管道来更新输出集合的内容。$merge可以将结果(插入新文档、合并文档、替换文档、保留现有文档、使操作失败、使用自定义更新管道处理文档)合并到现有集合中。 除了分组操作之外，还可以执行复杂的聚合任务以及对不断增长的数据集执行增量聚合。 见Map-Reduce 例子和执行增量 Map-Reduce。 灵活性 从4.4版开始，可以使用$accumulator和$function定义自定义聚合表达式。在以前的版本中，只能使用聚合管道支持的运算符和表达式。 但是，可以使用$project 管道运算符添加计算字段，创建新的虚拟子对象以及将子字段提取到结果的顶层。有关更多信息，请参阅$project以及聚合管道操作符，以了解有关所有可用管道操作符的更多信息。 自定义map，reduce和finalize JavaScript 函数为聚合逻辑提供了灵活性。 有关功能的详细信息和限制，请参阅MapReduce。 输出结果 以游标的形式返回结果。如果管道包含$out阶段或$merge阶段，则游标为空。使用$out，您可以完全替换现有的输出集合或输出到新的集合。详情见$out。使用$merge，您可以输出到新的或现有的集合。对于现有的cllections，可以指定如何将结果合并到输出集合中(插入新文档、合并文档、替换文档、保留现有文档、使操作失败、使用自定义更新管道处理文档)。有关详细信息，请参见$merge。 返回各种选项的结果(内联，新集合，合并，替换，减少)。有关输出选项的详细信息，请参阅MapReduce。 分片 支持非分片和分片输入集合。$merge可以输出到非分片或分片集合。 支持非分片和分片输入集合。 更多信息 聚合管道db.collection.aggregate()aggregate Map-Reducedb.collection.mapReduce()mapReduce 也可以看看 Map-Reduce to Aggregate 译者：李冠飞 校对：李冠飞 参见 原文 - Aggregation Commands Comparison Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation/04-aggregation-variables.html":{"url":"05-aggregation/03-aggregation/04-aggregation-variables.html","title":"Variables in Aggregation Expressions","keywords":"","body":" Variables in Aggregation Expressions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Variables in Aggregation Expressions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"05-aggregation/03-aggregation/05-sql-aggregation-comparison.html":{"url":"05-aggregation/03-aggregation/05-sql-aggregation-comparison.html","title":"聚合命令","keywords":"","body":" 聚合命令 在本页面 聚合命令 聚合方法 [success] 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定的运算符以转到其参考页面。 聚合命令 名称 描述 aggregate 使用聚合框架执行聚合任务，例如 group。 count 计算集合或视图中的文档数。 distinct 显示在集合或视图中为指定 key 找到的不同值。 mapReduce 对大型数据集执行map-reduce聚合。 聚合方法 名称 描述 db.collection.aggregate() 提供对聚合管道的访问。 db.collection.mapReduce() 对大型数据集执行map-reduce聚合。 译者：李冠飞 校对：李冠飞 参见 原文 - SQL to Aggregation Mapping Chart Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling.html":{"url":"06-data-modeling.html","title":"数据模式","keywords":"","body":"数据建模 在 MongoDB 中的数据具有灵活的模式。集合默认情况下并不会限制每个文档都遵循同样的数据结构。这种灵活性为您提供了各种数据建模选择，以匹配您的应用程序及其性能要求。本章内容说明如下： 数据建模介绍MongoDB中数据建模的介绍。 模式验证 MongoDB提供了在更新和插入过程中进行模式验证的能力。 数据建模概念 核心文档，详细介绍了您在确定数据模型时必须做出的决定，并讨论了应考虑的因素。 数据模型示例和模式 您可以用来构建MongoDB文档的可能数据模型示例。 数据模型参考 为MongoDB应用开发者提供数据建模的参考资料。 参见 原文 - Data Models 译者：雪星 (snomiao@gmail.com) 于 2020-10-27 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/01-data-modeling-introduction.html":{"url":"06-data-modeling/01-data-modeling-introduction.html","title":"数据建模介绍","keywords":"","body":" 数据建模介绍 在本页中 灵活的模式 文档结构 写操作原子性 数据使用和性能 扩展阅读 数据建模的关键挑战是平衡应用程序的需求、数据库引擎的性能特征和数据检索模式。在设计数据模型时，始终考虑数据的应用程序使用（即数据的查询、更新和处理）以及数据本身的固有结构。 灵活的模式 与SQL数据库不同，在SQL数据库中，在插入数据之前必须确定并声明表的架构，MongoDB的 集合，默认情况下，集合不需要其文档 有相同的模式。即： 单个集合中的文档不需要具有相同的字段集，并且字段的数据类型可以在集合中的各个文档之间有所不同。 若要更改集合中文档的结构（如添加新字段、删除现有字段或将字段值更改为新类型），请将文档更新为新结构。 这种灵活性有助于将文档映射到实体或对象。每个文档都可以匹配所表示实体的数据字段，即使该文档与集合中的其他文档有很大的差异。 但实际上，集合中的文档共享类似的结构，您可以强制执行文档验证规则用于在更新和插入操作期间的集合。请参阅模式验证详细情况。 文档结构 为MongoDB应用程序设计数据模型的关键决策是围绕文档的结构以及应用程序如何表示数据之间的关系。MongoDB允许将相关数据嵌入到单个文档中。 嵌入数据方式 嵌入式文档通过在单个文档结构中存储相关数据来捕获数据之间的关系。MongoDB文档使得在文档中的字段或数组中嵌入文档结构成为可能。这些非规范化数据模型允许应用程序在单个数据库操作中检索和操作相关数据。 对于MongoDB中的许多用例，非规范化数据模型是最优的。 参见嵌入式数据模型为嵌入文档的优点和缺点建模。 引用数据方式 引用通过包含从一个文档到另一个文档的链接或引用来存储数据之间的关系。应用程序可以解析这些参考访问相关数据。一般来说，这些是“标准化”数据模型。 参见 规范化数据模型 了解使用参考的优点和缺点。 写操作原子性 单文档原子性 在MongoDB中，写操作在单个文档的级别上是原子的，即使该操作修改了单个文档中的多个嵌入文档。 带有嵌入数据的非规范化数据模型将所有相关数据合并到单个文档中，而不是跨多个文档和集合进行规范化。这个数据模型有助于原子操作。 当一次写入操作（例如db.collection.updateMany())修改多个文档，每个文档的修改是原子的，但整个操作不是原子的。 在执行多文档写入操作时，无论是通过单个写入操作还是通过多个写入操作，其他操作都可能交叉进行。 对于需要对多个文档（在单个或多个集合中）进行原子性读写的情况，MongoDB支持多文档事务： 在4.0版中，MongoDB支持副本集上的多文档事务。 在4.2版中，MongoDB引入了分布式事务，增加了对分片集群上多文档事务的支持，并结合了对副本集上多文档事务的现有支持。 有关MongoDB中事务的详细信息，请参阅事务章节。 多文档事务 对于需要对多个文档（在单个或多个集合中）进行原子性读写的情况，MongoDB支持多文档事务： 在4.0版中，MongoDB支持副本集上的多文档事务。 在4.2版中，MongoDB引入了分布式事务，增加了对分片集群上多文档事务的支持，并结合了对副本集上多文档事务的现有支持。 有关MongoDB中事务的详细信息，请参阅事务章节。 注意事项: 在大多数情况下，多文档事务比单文档写入带来更高的性能成本，而且多文档事务的可用性不应替代有效的模式设计。对于许多情况，非规范化数据模型（嵌入文档和数组）将继续是数据和用例的最佳选择。也就是说，对于许多场景，对数据进行适当的建模将最大限度地减少对多文档事务的需求。 有关其他事务使用注意事项（如运行时限制和oplog大小限制），另请参阅生产注意事项. 另请参见: 原子性注意事项 数据使用和性能 设计数据模型时，请考虑应用程序将如何使用数据库。例如，如果您的应用程序只使用最近插入的文档，请考虑使用Capped Collections. 或者，如果应用程序需要的主要是对集合的读取操作，则添加索引以支持常见查询可以提高性能。 见操作因素和数据模型有关影响数据模型设计的这些和其他操作注意事项的详细信息。 扩展阅读 有关MongoDB数据建模的更多信息，请下载MongoDB应用程序现代化指南。 下载包括以下资源： 用MongoDB实现数据建模的方法论 白皮书涵盖了从RDBMS数据模型迁移到MongoDB的最佳实践和考虑事项 参考MongoDB模式及其等价的RDBMS概念 应用程序现代化记分卡 ← 数据模型 模式验证 → 原文链接：https://docs.mongodb.com/manual/core/data-modeling-introduction/ 译者：张鹏 参见 原文 - Data Modeling Introduction Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/02-schema-validation.html":{"url":"06-data-modeling/02-schema-validation.html","title":"模式验证","keywords":"","body":" 模式验证 在本页中 指定验证规则 JSON模式 其他查询表达式 行为 限制 绕过文档验证 附加信息 版本3.2中的新功能 MongoDB提供了在更新和插入期间执行模式验证的功能。 指定验证规则 验证规则基于每个集合。 要在创建新集合时指定验证规则，请使用db.createCollection()使用validator选项。 若要将文档验证添加到现有集合，请使用collMod带有 validator 选项的命令。 MongoDB还提供了以下相关选项： validationLevel 选项，该选项确定MongoDB在更新期间对现有文档应用验证规则的严格程度，以及 validationAction 选项，该选项确定MongoDB是否应显示错误并拒绝违反验证规则的文档，或 warn 日志中的违反行为，但允许无效文档。 JSON模式 版本3.6中的新功能 从3.6版开始，MongoDB支持JSON模式验证。要指定JSON模式验证，请使用 $jsonSchema 操作validator表达式中的运算符。 注意 推荐使用JSON模式执行模式验证。 例如，以下示例使用JSON模式指定验证规则： db.createCollection(\"students\", { validator: { $jsonSchema: { bsonType: \"object\", required: [ \"name\", \"year\", \"major\", \"address\" ], properties: { name: { bsonType: \"string\", description: \"must be a string and is required\" }, year: { bsonType: \"int\", minimum: 2017, maximum: 3017, description: \"must be an integer in [ 2017, 3017 ] and is required\" }, major: { enum: [ \"Math\", \"English\", \"Computer Science\", \"History\", null ], description: \"can only be one of the enum values and is required\" }, gpa: { bsonType: [ \"double\" ], description: \"must be a double if the field exists\" }, address: { bsonType: \"object\", required: [ \"city\" ], properties: { street: { bsonType: \"string\", description: \"must be a string if the field exists\" }, city: { bsonType: \"string\", \"description\": \"must be a string and is required\" } } } } } } }) 有关详细信息，请参见 $jsonSchema。 其他查询表达式 除了使用$jsonSchema 操作查询运算符，MongoDB支持使用 其他查询运算符 查询选择器，除了$near，$nearSphere， $text，和 $where 运算符。 例如，以下示例使用查询表达式指定验证器规则： db.createCollection( \"contacts\", { validator: { $or: [ { phone: { $type: \"string\" } }, { email: { $regex: /@mongodb\\.com$/ } }, { status: { $in: [ \"Unknown\", \"Incomplete\" ] } } ] } } ) 另请参见 查询运算符 行为 在更新和插入期间进行验证。将验证添加到集合时，现有文档在修改之前不会进行验证检查。 现有文档 validationLevel 选项确定MongoDB应用验证规则的操作： 如果 validationLevel 是 strict（默认值），MongoDB会对所有插入和更新应用验证规则。 如果 validationLevel是 moderate，MongoDB将验证规则应用于已满足验证条件的现有文档的插入和更新。使用 moderate 级别时，不检查对不符合验证条件的现有文档的更新是否有效。 例如，使用以下文档创建 contacts 集合: db.contacts.insert([ { \"_id\": 1, \"name\": \"Anne\", \"phone\": \"+1 555 123 456\", \"city\": \"London\", \"status\": \"Complete\" }, { \"_id\": 2, \"name\": \"Ivan\", \"city\": \"Vancouver\" } ]) 发出以下命令将验证器添加到 contacts 集合： db.runCommand( { collMod: \"contacts\", validator: { $jsonSchema: { bsonType: \"object\", required: [ \"phone\", \"name\" ], properties: { phone: { bsonType: \"string\", description: \"must be a string and is required\" }, name: { bsonType: \"string\", description: \"must be a string and is required\" } } } }, validationLevel: \"moderate\" } ) 这 contacts 集合现在有一个使用 moderate 验证级别的验证器： 如果试图更新 _id为1, MongoDB将应用验证规则，因为现有文档与条件匹配。 相反，MongoDB不会对_id为2的文档应用验证规则，因为它不符合验证规则。 要完全禁用验证，可以将validationLevel设置为off。 接受或拒绝无效文档 validationAction选项确定MongoDB如何处理违反验证规则的文档： 如果validationAction 为error （默认值），MongoDB将拒绝任何违反验证条件的插入或更新。 如果validationAction 为warn，MongoDB会记录任何冲突，但允许继续插入或更新。 例如，使用以下JSON模式验证器创建一个contacts2集合： db.createCollection( \"contacts2\", { validator: { $jsonSchema: { bsonType: \"object\", required: [ \"phone\" ], properties: { phone: { bsonType: \"string\", description: \"must be a string and is required\" }, email: { bsonType : \"string\", pattern : \"@mongodb\\.com$\", description: \"must be a string and match the regular expression pattern\" }, status: { enum: [ \"Unknown\", \"Incomplete\" ], description: \"can only be one of the enum values\" } } } }, validationAction: \"warn\" } ) 使用warn validationAction，MongoDB会记录任何冲突，但允许继续插入或更新。 例如，以下插入操作违反了验证规则： db.contacts2.insert( { name: \"Amanda\", status: \"Updated\" } ) 不过，由于validationAction 仅为warn ，MongoDB只记录验证冲突消息并允许操作继续： 2017-12-01T12:31:23.738-0500 W STORAGE [conn1] Document would fail validation collection: example.contacts2 doc: { _id: ObjectId('5a2191ebacbbfc2bdc4dcffc'), name: \"Amanda\", status: \"Updated\" } 限制 不能为admin、local和config 数据库中的集合指定验证器。 不能为 system.*集合指定验证器。 绕过文档验证 用户可以使用bypassDocumentValidation 选项绕过文档验证。 以下命令可以使用新选项bypassDocumentValidation跳过每个操作的验证： applyOps 命令 findAndModify 命令和 db.collection.findAndModify() 方法 mapReduce 命令和 db.collection.mapReduce() 方法 insert 命令 update 命令 为聚合 命令和 db.collection.aggregate() 方法提供的过程命令$out 和 $merge 对于已启用访问控制的部署，若要绕过文档验证，经过身份验证的用户必须具有bypassDocumentValidation行动。内置角色dbAdmin 和 restore 提供此操作。 附加信息 另请参见 collMod, db.createCollection(), db.getCollectionInfos()。 ← 数据建模简介 数据建模概念 → 译者：张鹏 原文链接：https://docs.mongodb.com/manual/core/schema-validation/ 参见 原文 - Schema Validation Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/03-data-models.html":{"url":"06-data-modeling/03-data-models.html","title":"Data Modeling Concepts","keywords":"","body":" Data Modeling Concepts ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Modeling Concepts Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/03-data-models/01-data-model-design.html":{"url":"06-data-modeling/03-data-models/01-data-model-design.html","title":"Data Model Design","keywords":"","body":" Data Model Design ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Model Design Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/03-data-models/02-data-model-operations.html":{"url":"06-data-modeling/03-data-models/02-data-model-operations.html","title":"Operational Factors and Data Models","keywords":"","body":" Operational Factors and Data Models ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Operational Factors and Data Models Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models.html":{"url":"06-data-modeling/04-data-models.html","title":"Data Model Examples and Patterns","keywords":"","body":" Data Model Examples and Patterns ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Model Examples and Patterns Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/01-data-models-relationships.html":{"url":"06-data-modeling/04-data-models/01-data-models-relationships.html","title":"Model Relationships Between Documents","keywords":"","body":" Model Relationships Between Documents ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Relationships Between Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/01-data-models-relationships/01-model-embedded-one-to-one-relationships-between-documents.html":{"url":"06-data-modeling/04-data-models/01-data-models-relationships/01-model-embedded-one-to-one-relationships-between-documents.html","title":"Model One-to-One Relationships with Embedded Documents","keywords":"","body":" Model One-to-One Relationships with Embedded Documents ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model One-to-One Relationships with Embedded Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/01-data-models-relationships/02-model-embedded-one-to-many-relationships-between-documents.html":{"url":"06-data-modeling/04-data-models/01-data-models-relationships/02-model-embedded-one-to-many-relationships-between-documents.html","title":"Model One-to-Many Relationships with Embedded Documents","keywords":"","body":" Model One-to-Many Relationships with Embedded Documents ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model One-to-Many Relationships with Embedded Documents Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/01-data-models-relationships/03-model-referenced-one-to-many-relationships-between-documents.html":{"url":"06-data-modeling/04-data-models/01-data-models-relationships/03-model-referenced-one-to-many-relationships-between-documents.html","title":"Model One-to-Many Relationships with Document References","keywords":"","body":" Model One-to-Many Relationships with Document References ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model One-to-Many Relationships with Document References Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures.html","title":"Model Tree Structures","keywords":"","body":" Model Tree Structures ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures/01-model-tree-structures-with-parent-references.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures/01-model-tree-structures-with-parent-references.html","title":"Model Tree Structures with Parent References","keywords":"","body":" Model Tree Structures with Parent References ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures with Parent References Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures/02-model-tree-structures-with-child-references.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures/02-model-tree-structures-with-child-references.html","title":"Model Tree Structures with Child References","keywords":"","body":" Model Tree Structures with Child References ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures with Child References Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures/03-model-tree-structures-with-ancestors-array.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures/03-model-tree-structures-with-ancestors-array.html","title":"Model Tree Structures with an Array of Ancestors","keywords":"","body":" Model Tree Structures with an Array of Ancestors ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures with an Array of Ancestors Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures/04-model-tree-structures-with-materialized-paths.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures/04-model-tree-structures-with-materialized-paths.html","title":"Model Tree Structures with Materialized Paths","keywords":"","body":" Model Tree Structures with Materialized Paths ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures with Materialized Paths Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/02-data-models-tree-structures/05-model-tree-structures-with-nested-sets.html":{"url":"06-data-modeling/04-data-models/02-data-models-tree-structures/05-model-tree-structures-with-nested-sets.html","title":"Model Tree Structures with Nested Sets","keywords":"","body":" Model Tree Structures with Nested Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Tree Structures with Nested Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications.html","title":"Model Specific Application Contexts","keywords":"","body":" Model Specific Application Contexts ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Specific Application Contexts Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/01-model-data-for-atomic-operations.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/01-model-data-for-atomic-operations.html","title":"Model Data for Atomic Operations","keywords":"","body":" Model Data for Atomic Operations ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Data for Atomic Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/02-model-data-for-keyword-search.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/02-model-data-for-keyword-search.html","title":"Model Data to Support Keyword Search","keywords":"","body":" Model Data to Support Keyword Search ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Data to Support Keyword Search Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/03-model-data-for-schema-versioning.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/03-model-data-for-schema-versioning.html","title":"Model Data for Schema Versioning","keywords":"","body":" Model Data for Schema Versioning ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Data for Schema Versioning Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/04-model-monetary-data.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/04-model-monetary-data.html","title":"Model Monetary Data","keywords":"","body":" Model Monetary Data ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Monetary Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/05-model-time-data.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/05-model-time-data.html","title":"Model Time Data","keywords":"","body":" Model Time Data ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Time Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/04-data-models/03-data-models-applications/06-model-computed-data.html":{"url":"06-data-modeling/04-data-models/03-data-models-applications/06-model-computed-data.html","title":"Model Computed Data","keywords":"","body":" Model Computed Data ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Model Computed Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/05-data-models.html":{"url":"06-data-modeling/05-data-models.html","title":"Data Model Reference","keywords":"","body":" Data Model Reference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Model Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"06-data-modeling/05-data-models/01-database-references.html":{"url":"06-data-modeling/05-data-models/01-database-references.html","title":"Database References","keywords":"","body":" Database References ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Database References Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"07-transactions.html":{"url":"07-transactions.html","title":"事务","keywords":"","body":" 事务 在本页 事务API 事务和原子性 事务和操作 事务和会话 读策略/写策略/读偏好 一般信息 其他事务问题 在MongoDB中，对单个文档的操作是原子的。因为您可以使用嵌入式文档和数组来捕获单个文档结构中的数据之间的关系，而不是在多个文档和集合之间进行规范化，所以这种单文档原子性消除了许多实际用例中对多文档事务的需求。 对于需要原子性地读写多个文档（在单个或多个集合中）的情况，MongoDB支持多文档事务。使用分布式事务，可以跨多个操作，集合，数据库，文档和分片使用事务。 事务API 以下示例重点介绍了事务API的关键组成： 译者注，原文可看不同类型的代码 PYTHON JAVA (SYNC) NODE.JS PHP MOTOR C C++11 C 该示例使用新的回调API来处理事务，该API启动事务，执行指定的操作并提交（可能因为错误而中止）。新的回调API还针对 TransientTransactionError 或UnknownTransactionCommitResult 提交错误合并了重试逻辑。 重点 对于MongoDB 4.2（副本集和分片群集）上的事务，客户端必须使用将MongoDB驱动程序更新为MongoDB 4.2。 使用驱动程序时，事务中的每个操作必须与会话相关联（即，将每个操作传递在会话中传递）。 参考 比如，在mongo shell中参考 mongo Shell Example. 事务和原子性 分布式事务和多文档事务 从MongoDB 4.2开始，这两个术语是同义词。 分布式事务是指分片群集和副本集上的多文档事务。 从MongoDB 4.2开始，多文档事务（无论是在分片群集或副本集上）也称为分布式事务。 对于需要原子性地读写多个文档（在单个或多个集合中）的情况，MongoDB支持多文档事务： 在4.0版中，MongoDB支持副本集上的多文档事务。 在版本4.2中，MongoDB引入了分布式事务，它增加了对分片群集上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。 要在MongoDB 4.2部署（副本集和分片群集）上使用事务，客户端必须使用为MongoDB 4.2更新的MongoDB驱动程序。 多文档交易是原子性的（即提供“全有或全无”主张）： 提交事务时，将保存在事务中进行的所有数据更改，并在事务外部可见。 也就是说，一个事务在回滚其他事务时将不会提交其某些更改。在提交事务之前，在事务外部看不到在事务中进行的数据更改。 但是，当事务写入多个分片时，并非所有外部读取操作都需要等待已提交事务的结果在所有分片上可见。 例如，如果提交了一个事务，并且在分片A上可以看到写1，但是在分片B上却看不到写2，则外部读取时设置读关注 \"local\" 结果为可以读取写入1的结果而看不到写入2。 当事务中止时，在事务中进行的所有数据更改都将被丢弃，而不会变得可见。 例如，如果事务中的任何操作失败，则事务中止，并且在事务中进行的所有数据更改都将被丢弃，而不会变得可见。 重点 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。 在许多情况下， 非规范化数据模型（嵌入的文档和数组） 仍将是最佳选择您的数据和用例。 也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和oplog大小限制），另请参阅生产注意事项. 也可参考提交期间的外部读取 事务和操作 分布式事务可用于多个操作，集合，数据库，文档，以及从MongoDB 4.2分片开始的。 对于事务： 您可以在现有集合上指定读/写（CRUD）操作。集合可以在不同的数据库中。有关CRUD操作的列表，请参考 CRUD 操作。 您无法写入 capped 集合。 （从MongoDB 4.2开始） 您无法在config，admin或local数据库中读取/写入集合。 您无法写入system。*集合。 您无法返回支持的操作的查询计划（如 explain）。 对于在事务外部创建的游标，不能在事务内部调用 getMore 。 对于在事务中创建的游标，不能在事务外调用 getMore 。 从MongoDB 4.2开始，您不能将 killCursors 指定为事务的第一个操作。 事务中不允许执行影响数据库目录的操作，例如创建或删除集合或索引。例如，事务不能包含将导致创建新集合的插入操作。请参阅受限操作。 提示 创建或删除集合后立即开始事务，如果在事务内访问了该集合，请在创建或者删除时设置write concern为 \"majority\" ，以确保该事务可以获取所需的锁。 可参考：事务和操作参考 count 操作 要在事务中执行计数操作，请使用 $count 聚合阶段或者 $group （带有 $sum 表达式）聚合阶段。 与4.0功能兼容的MongoDB驱动程序提供了一个集合级API countDocuments(filter, options) 作为使用带有$sum 的 $group 表达式进行计数。4.0驱动程序已弃用 count() API。 从MongoDB 4.0.3开始， mongo shell提供使用$sum 的 $group 表达式进行计数的 db.collection.countDocuments() 方法。 distinct 操作 在事务中执行不同的操作： 对于未分片的集合，可以使用 db.collection.distinct() 方法或者distinct 命令以及具有 $group 阶段的聚合管道。 对于分片集合，不可以使用 db.collection.distinct() 方法或者distinct 命令。 要查找分片集合的不同值，请使用带有 $group 阶段的聚合管道，例如： 代替db.coll.distinct(\"x\")，使用 db.coll.aggregate([ { $group: { _id: null, distinctValues: { $addToSet: \"$x\" } } }, { $project: { _id: 0 } } ]) 代替 db.coll.distinct(\"x\", { status: \"A\" })，使用： db.coll.aggregate([ { $match: { status: \"A\" } }, { $group: { _id: null, distinctValues: { $addToSet: \"$x\" } } }, { $project: { _id: 0 } } ]) 管道将游标返回到文档： { \"distinctValues\" : [ 2, 3, 1 ] } 迭代光标以访问结果文档。 信息类操作 信息命令在事务中是允许的，如 isMaster, buildInfo, connectionStatus （以及辅助方法）；但是他们不能是事务中的第一个操作。 限制的操作 事务中不允许以下的操作： 影响数据库目录的操作，例如创建或删除集合或索引。 例如，事务不能包含将导致创建新集合的插入操作。 listCollections 和 listIndexes 命令及其辅助方法也被排除在外。 非CRUD和非信息性操作，例如 createUser, getParameter, count等等及其辅助命令。 可参考 待处理的DDL操作和事务 事务和操作参考 事务和会话 事务与会话关联； 即您开始一个会话的事务。 在任何给定时间，一个会话最多只能有一个未完成的事务。 使用驱动程序时，事务中的每个操作必须与会话关联。 有关详细信息，请参阅驱动程序专用文档。 如果会话结束并且具有打开的事务，则事务中止。 读关注/写关注/读偏好 事务和读偏好 事务中的操作使用事务级别的读偏好。 使用驱动程序，可以在事务开始时设置事务级别的 读偏好 ： 如果未设置事务级别的读取首选项，则事务将使用会话级别的读取首选项。 如果未设置事务级别和会话级别的读选项，则事务将使用客户端级别的读偏好。 默认情况下，客户端级别的读选项为primary。 包含读取操作的多文档事务必须使用读偏好primary。 给定事务中的所有操作都必须路由到同一成员。 事务和读关注 事务中的操作使用事务级别的读关注。 也就是说，在事务内部忽略在集合和数据库级别设置的任何读取关注。 您可以在事务开始时设置事务级别的读关注。 如果未设置事务级读关注，则事务级读关注默认为会话级读关注。 如果未设置事务级别和会话级别的读关注，则事务级别的读取关注点默认为客户端级别的读关注。 默认情况下，对于主服务器的读取，客户端级别的读关注为“ local”。 另请参见事务和读选项。 事务支持一下读关注级别： \"local\" 读关注点“ local”返回该节点可用的最新数据，但可以回滚。 对于分片群集上的事务，“ local”读关注不能保证数据是从整个分片的同一快照视图获取。 如果需要快照隔离，请使用“snapshot”读关注。 \"majority\" 如果以写关注“majority”提交事务，读关注 \"majority\"返回大多数副本成员已确认的数据（即无法回滚数据）。 如果事务未使用 写关注“majority” 进行提交，则“majority”读关注不保证读操作可以读取多数提交的数据。 对于分片群集上的事务，“majority”读取关注不能保证数据是从整个分片的同一快照视图中获取。 如果需要快照隔离，请使用“snapshot”读关注。 \"snapshot\" 如果事务提交时带有写关注“majority”，读关注\"snapshot\"从大多数已提交数据的快照中返回数据。 如果事务未使用写关注“majority”进行提交，则\"snapshot\"读关注不保证读操作使用了大部分提交的数据的快照。 对于分片群集上的事务，数据的\"snapshot\"视图 跨分片同步。 事务和写关注 事务使用事务级别的写关注进行写操作。 必须在没有显式写关注规范的情况下发出事务内部的写操作，并使用默认写关注。 在提交时，然后使用事务级写关注来提交写操作。 提示： 不要为事务中的各个写操作明确设置写关注。 为事务中的各个写操作设置写关注点将导致错误。 您可以在事务开始时设置事务级别的写关注： 如果未设置事务级写关注，则事务级写关注默认为提交的会话级写关注。 如果未设置事务级写关注和会话级写关注，则事务级写关注默认为客户端级写关注。 默认情况下，客户端级别的写入问题为w：1。 事务支持所有写关注w值，包括： w: 1 在主节点提交写关注w：1后返回确认。 重要 当您使用w：1提交时，您的事务如果存在故障则可以回滚。 当您提交w：1时，会写成事物级别的“majority” 读关注，不保证事务中的读取操作会读取多数提交的数据 。 当您提交w：1时，会写成事务级别的\"snapshot\"，读取关注不保证事务中的读取操作使用多数快照提交的数据。 w: \"majority\" 在提交已应用于多数（ M）有投票权的成员后，写关注w：“majority”返回确认； 即提交已应用于主要和（M-1）个投票辅助。 当您提交w：“ majority”时，事务级别的“ majority “读关注保证了操作已读取多数提交的数据。 对于分片群集上的事务，大多数分批提交的数据的视图不会在分片之间同步。 当您使用w：“majority”提交时，事务级别“快照 “读关注保证操作来自大多数提交的数据的同步快照。 注意 不管事务指定的写关注，分片集群事务的提交操作都包含使用{w：“多数”，j：是}写关注。 一般信息 注意事项 有关使用事务的各种注意事项，请参阅注意事项。 另外，分片群集，另请参见注意事项（分片群集）。 仲裁者 如果任何事务操作读取或写入包含仲裁程序的分片，则其写操作跨越多个分片的事务将出错并中止。 另请参见禁用读关注Majority，以了解已禁用读关注majority的分片的事务限制。 禁用读关注Majority 一个含有3成员PSA（主-次-仲裁器）副本集，或具有3成员PSA分片的分片群集可能已禁用读关注Majority（--enableMajorityReadConcern false 或replication.enableMajorityReadConcern：false) 对于分片集群： 如果事务涉及的分片具有禁用读关注Majority，则事务中不能使用的读关注“快照”。 您只能在事务中使用读关注的“ local”或“majority”。 如果使用读关注“ snapshot”，则事务错误并中止。 当enableMajorityReadConcern = false时，分片群集中不支持读关注级别 'snapshot' 。 如果任何事务的读或写操作涉及禁用了读关注\"majority\"的分片，则其写操作跨越多个分片的事务将出错并中止。 在已禁用读关注“majority”副本集中，您可以指定读关注“ local”或“majority”或“snapshot”。但是，如果您打算过渡到具有禁用读关注majority分片的分片群集，则避免使用读关注的\"snapshot\"。 提示： 检查是否已禁用读关注“majority”，可以在 mongod上运行db.serverStatus（）并检查storageEngine.supportsCommittedReads字段。 如果为“ false”，则禁用读关注“majority” 。 有关更多信息，请参阅3-成员主-从-仲裁者体系结构和三成员主-从-仲裁者 分片。 分片配置限制 您不能在writeConcernMajorityJournalDefault设置为“ false”的分片群集上运行事务（ 如 使用内存存储引擎的具有投票成员的分片）。 注意 不管为事务指定的写关注，分片集群事务的提交操作都包含使用{w：“majority”，j：true}写关注。 诊断 MongoDB提供了各种指标： 方法 db.serverStatus() 方法serverStatus命令 返回 事务 指标。 $currentOp 聚合管道 如果操作是事务的一部分，则返回$currentOp.transaction。 无效会话 的信息作为事务的一部分持有锁。$currentOp.twoPhaseCommitCoordinator 这些指标涉及向多个分片写入的分片事务。 db.currentOp() 方法currentOp 命令 如果操作是事务的一部分，则返回currentOp.transaction 。currentOp.twoPhaseCommitCoordinator 这些指标涉及写入多个分片的分片事务。 mongod 和 mongos日志信息 包括TXN日志组件下慢事务信息（即超过operationProfiling.slowOpThresholdMs阈值的事务信息）。 功能兼容版本 (FCV) 要使用事务，部署的所有成员的featureCompatibilityVersion必须至少为： 部署 Minimum featureCompatibilityVersion//最小FCV 副本 4.0 分片 4.2 要检查成员的FCV，请连接到该成员并运行以下命令： db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } ) 有关更多信息，请参见设置FCV参考页。 存储引擎 从MongoDB 4.2开始，副本集和分片群集支持多文档事务： 主节点使用WiredTiger存储引擎，并且 从成员使用WiredTiger存储引擎或内存存储引擎 在MongoDB 4.0中，仅使用WiredTiger存储引擎的副本集支持事务。 注意： 您无法在具有writeConcernMajorityJournalDefault设置为“ false”的分片的分片集群上运行事务，例如使用内存存储引擎具有投票成员的分片。 其他事务话题 驱动 API 注意事项 注意事项 (分片集群) 事务和操作 译者：王金铷 原文链接：https://docs.mongodb.com/manual/core/transactions/ 参见 原文 - Transactions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"07-transactions/01-transactions-in-applications.html":{"url":"07-transactions/01-transactions-in-applications.html","title":"Drivers API","keywords":"","body":" Drivers API ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Drivers API Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"07-transactions/02-transactions-production-consideration.html":{"url":"07-transactions/02-transactions-production-consideration.html","title":"Production Considerations","keywords":"","body":" Production Considerations ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Production Considerations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"07-transactions/03-transactions-sharded-clusters.html":{"url":"07-transactions/03-transactions-sharded-clusters.html","title":"Production Considerations (Sharded Clusters)","keywords":"","body":" Production Considerations (Sharded Clusters) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Production Considerations (Sharded Clusters) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"07-transactions/04-transactions-operations.html":{"url":"07-transactions/04-transactions-operations.html","title":"事务操作","keywords":"","body":" 事务操作 本页中 支持多文档事务的操作 CRUD 操作 Count 操作 Distinct 操作 信息操作 限制的操作 对于事务来说： 您可以在现有集合上指定读/写（CRUD）操作。其中集合可以在不同的数据库中。有关CRUD操作的列表，请参见 CRUD 操作。 您无法写入 capped 集合。 （从MongoDB 4.2开始） 您无法在config，admin或local数据库中读写集合。 您无法写入system.*集合。 您无法返回支持的操作的查询计划（如：explain）。 对于在事务外部创建的游标，不能在事务内部调用getMore 命令。 对于在事务中创建的游标，不能在事务外调用getMore 。 从MongoDB 4.2开始，您不能在 事务中将 killCursors 作为第一个操作。 多文档事务中不允许执行影响数据库目录的操作，例如创建或删除集合或索引。例如，多文档事务不能包含将导致创建新集合的插入操作。请参阅限制的操作。 多文档事务支持的操作 CRUD 操作 事务中允许以下读/写操作： 方法 命令 备注 db.collection.aggregate() aggregate 不包括以下阶段：$collStats$currentOp$indexStats$listLocalSessions$listSessions$merge$out$planCacheStats db.collection.countDocuments() 不包含以下查询运算符表达式：$where$near$nearSphere 。该方法使用$match聚合阶段进行查询，并使用$group聚合阶段带有$sum表达式来执行计数。 db.collection.distinct() distinct 在未分片集合中可用。对于分片集合，请在 $group阶段使用聚合管道。可查看Distinct Operation。 db.collection.find() find geoSearch db.collection.deleteMany()db.collection.deleteOne()db.collection.remove() delete db.collection.findOneAndDelete()db.collection.findOneAndReplace()db.collection.findOneAndUpdate() findAndModify 仅在针对现有集合运行时使用upsert。 db.collection.insertMany()db.collection.insertOne()db.collection.insert() insert 仅在针对现有集合运行时使用。 db.collection.save() 如果插入，则仅在针对现有集合运行时。 db.collection.updateOne()db.collection.updateMany()db.collection.replaceOne()db.collection.update() update 仅在针对现有集合运行时使用upsert。 db.collection.bulkWrite()Various Bulk Operation Methods 如果插入，则仅在针对现有集合运行时。仅在针对现有集合运行时使用upsert。 分片键值更新 从MongoDB 4.2开始，您可以通过在事务中发出单文档update / findAndModify操作或作为可重试写来更新文档的分片键值（除非分片键字段是不可变的_id字段）。有关详细信息，请参见 更改文档的分片健值. 计数操作 要在事务中执行计数操作，请使用 $count 聚合阶段或 $group （含 $sum 表达式）聚合阶段。 与4.0功能兼容的MongoDB驱动程序提供了一个集合级APIcountDocuments（filter，options）作为辅助方法，该方法使用带有 $group 表达式和$sum 表达式的计数方法。 4.0驱动程序已弃用count（）API。 从MongoDB 4.0.3开始， mongo shell 提供了db.collection.countDocuments() 方法，该方法使用 $group 和 $sum 表达式来执行计数。 Distinct 操作 在事务中执行distinct操作： 对于未分片的集合，可以使用 db.collection.distinct() 方法/distinct 命令以及具有 $group 阶段的聚合管道。 对于分片集合，不能使用 db.collection.distinct() 方法或 distinct 命令。 要查找分片集合的distinct值，请使用带有 $group 阶段的聚合管道。例如： 替代 db.coll.distinct(\"x\")，使用： db.coll.aggregate([ { $group: { _id: null, distinctValues: { $addToSet: \"$x\" } } }, { $project: { _id: 0 } } ]) 替代 db.coll.distinct(\"x\", { status: \"A\" })，使用 db.coll.aggregate([ { $match: { status: \"A\" } }, { $group: { _id: null, distinctValues: { $addToSet: \"$x\" } } }, { $project: { _id: 0 } } ]) 对于一个文档，管道将返回一个游标： { \"distinctValues\" : [ 2, 3, 1 ] } 迭代游标以访问文档结果。 信息操作 信息命令，例如 isMaster, buildInfo, connectionStatus （及其辅助方法）在事务中是被允许的；但是，它们不能是事务中的第一个操作。 受限制的操作 事务中不允许执行以下操作： 影响数据库目录的操作，如创建或删除集合或索引。例如，事务不能包含会导致创建新集合的插入操作。 listCollections 和 listIndexes 命令及其辅助方法也被排除在外。 非CRUD和非信息性操作，例如 createUser, getParameter, count等等及其辅助方法。 另请参见： 待处理的DDL操作和事务 原文链接：https://docs.mongodb.com/manual/core/transactions-operations/ 译者：王金铷 参见 原文 - Transactions and Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes.html":{"url":"08-indexes.html","title":"索引","keywords":"","body":" 索引 在本页面 默认的id索引 创建索引 索引类型 索引属性 索引用途 索引和排序规则 覆盖查询 索引交集 限制条件 其他注意事项 索引支持在MongoDB中有效地执行查询。如果没有索引，MongoDB必须执行集合扫描，即扫描集合中的每个文档，以选择那些与查询语句匹配的文档。如果一个查询存在适当的索引，MongoDB可以使用该索引来限制它必须检查的文档数量。 索引是特殊的数据结构，它以一种易于遍历的形式存储集合数据集的一小部分。索引存储一个或一组特定字段的值，按字段的值排序。索引项的排序支持有效的相等匹配和基于范围的查询操作。此外，MongoDB可以通过使用索引中的排序返回排序后的结果。 下图说明了使用索引选择和排序匹配文档的查询： 基本上，MongoDB中的索引与其他数据库系统中的索引类似。MongoDB在集合级别定义索引，并支持在MongoDB集合中文档的任何字段或子字段上的索引。 默认id索引 在创建集合期间，MongoDB 在_id字段上创建唯一索引。该索引可防止客户端插入两个具有相同值的文档。你不能将_id字段上的index删除。 [success] 注意 在分片群集中，如果您不使用_id字段作为分片键，那么您的应用程序 必须确保_id字段中值的唯一性以防止错误。这通常是通过使用标准的自动生成的ObjectId来完成的。 创建索引 要在Mongo Shell中创建索引 ，请使用 db.collection.createIndex(). db.collection.createIndex( , ) 以下示例在name字段上创建单个键降序索引： db.collection.createIndex( { name: -1 } ) db.collection.createIndex方法只在不存在相同规范的索引时创建索引。 索引名称 索引的默认名称是索引键和索引中每个键的方向(即1或-1)的连接，使用下划线作为分隔符。例如，在{ item : 1, quantity: -1 }上创建的索引名称为item1_quantity-1。 您可以创建具有自定义名称的索引，比如比默认名称更易于阅读的索引。例如，考虑一个经常查询products集合以填充现有库存数据的应用程序。下面的createIndex() 方法在名为查询的商品和数量上创建一个索引: db.products.createIndex( { item: 1, quantity: -1 } , { name: \"query for inventory\" } ) 您可以使用db.collection.getIndexes() 方法查看索引名称。一旦创建索引，您将无法重命名。相反，您必须删除并使用新名称重新创建索引。 索引类型 MongoDB提供了许多不同的索引类型来支持特定类型的数据和查询。 单个字段 除MongoDB定义的_id索引外，MongoDB还支持在文档的单个字段上创建用户定义的升序/降序索引。 对于单字段索引和排序操作，索引键的排序顺序(升序或降序)并不重要，因为MongoDB可以从任何方向遍历索引。 有关单字段索引的更多信息，请参见单字段索引和使用单字段索引排序。 复合索引 MongoDB还支持多个字段上的用户定义索引，即 复合索引。 复合索引中列出的字段的顺序具有重要意义。例如，如果一个复合索引由{userid: 1, score: -1}组成，索引首先按userid排序，然后在每个userid值内按score排序。 对于复合索引和排序操作，索引键的排序顺序(升序或降序)可以决定索引是否支持排序操作。有关索引顺序对复合索引中的结果的影响的更多信息，请参见 排序顺序。 有关复合索引的更多信息，请参见复合索引和在多个字段上排序。 多键索引 MongoDB使用多键索引来索引存储在数组中的内容。如果索引包含数组值的字段，MongoDB为数组的每个元素创建单独的索引项。这些多键索引允许查询通过匹配数组的一个或多个元素来选择包含数组的文档。MongoDB自动决定是否创建一个多键索引，如果索引字段包含数组值;您不需要显式地指定多键类型。 有关多键索引的更多信息，请参见 Multikey Indexes 和 Multikey Index Bounds。 地理空间索引 为了支持对地理空间坐标数据的高效查询，MongoDB提供了两个特殊的索引:在返回结果时使用平面几何的2d索引和使用球面几何返回结果的2dsphere索引。 有关地理空间索引的高级介绍，请参见2d Index Internals。 文本索引 MongoDB提供了一种文本索引类型，它支持搜索集合中的字符串内容。这些文本索引不存储特定于语言的停止词(例如“the”，“a”，“or”)，并且在一个集合中只存储根词的词干。 有关文本索引和搜索的更多信息，请参见文本索引。 Hashed索引 为了支持基于Hashed的分片，MongoDB提供了Hashed索引类型，该索引类型对字段值的Hashed进行索引。这些索引在其范围内具有更随机的值分布，但只支持相等匹配，而不支持基于范围的查询。 索引属性 唯一索引 索引的unique属性使MongoDB拒绝索引字段的重复值。除了唯一性约束，唯一索引和MongoDB其他索引功能上是一致的。 部分索引 3.2版中的新功能。 部分索引仅索引集合中符合指定过滤器表达式的文档。通过对集合中的部分文档建立索引，部分索引可以降低存储需求，并降低创建和维护索引的性能成本。 部分索引提供了稀疏索引功能的超集，因此应优先于稀疏索引。 稀疏索引 索引的稀疏属性可确保索引仅包含具有索引字段的文档的条目。索引会跳过没有索引字段的文档。 可以将稀疏索引与唯一索引结合使用，以防止插入索引字段值重复的文档，并跳过索引缺少索引字段的文档。 TTL索引 TTL索引是MongoDB可以使用的特殊索引，它可以在一定时间后自动从集合中删除文档。对于某些类型的信息（例如计算机生成的事件数据，日志和会话信息），它们仅需要在数据库中保留有限的时间，这是理想的选择。 参见:通过执行指令设置TTL使集合中的数据过期。 索引用途 索引可以提高读操作的效率。分析查询性能教程提供了一个带有和不带有索引的查询的执行统计信息示例。 有关MongoDB如何选择要使用的索引的信息，请参阅查询优化器。 索引和排序 3.4版的新功能。 排序允许用户为字符串比较指定特定的语言的规则，例如字母大小写和重音符号的规则。 Mongo Shell Compass [success] Note 下面的示例演示了Mongo Shell中的索引和排序。 请参阅MongoDB Compass文档，了解如何使用自定义排序法与Compass中的索引。 Python [success] Note 下面的示例演示了Mongo Shell中的索引和排序。 参考驱动程序文档，了解如何在特定驱动程序中使用排序创建索引。 Java [success] Note 下面的示例演示了Mongo Shell中的索引和排序。 参考驱动程序文档，了解如何在特定驱动程序中使用排序创建索引。 Node.js [success] Note 下面的示例演示了Mongo Shell中的索引和排序。 参考驱动程序文档，了解如何在特定驱动程序中使用排序创建索引。 若要使用索引进行字符串比较，操作还必须指定相同的排序。也就是说，如果索引指定了不同的排序，则具有排序的索引不能支持对索引字段执行字符串比较的操作。 例如，该集合myColl在category具有排序规则语言环境的字符串字段上具有索引\"fr\"。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 下面的查询操作指定了与索引相同的排序，可以使用索引: db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作（默认情况下使用“简单”二进制整理程序）无法使用索引： db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是字符串、数组和嵌入式文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 例如，集合myColl有一个关于数值字段score和price以及字符串字段类别的复合索引;索引是用collation locale \"fr\"创建的，用于字符串比较: db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 使用\"simple\"二进制排序规则进行字符串比较的以下操作可以使用索引： db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 以下操作使用\"simple\"二进制排序规则对索引category字段进行字符串比较，该操作可以使用索引来完成查询的一部分：score: 5 db.myColl.find( { score: 5, category: \"cafe\" } ) 有关整理的更多信息，请参见整理参考页。 以下索引仅支持简单的二进制比较，不支持排序规则： 文字索引 2d索引 geoHaystack索引。 覆盖查询 当查询条件和查询的只包含索引字段时，MongoDB直接从索引返回结果，而不扫描任何文档或将文档带入内存。这些覆盖的查询可能非常高效。 有关覆盖查询的更多信息，请参见 覆盖查询。 索引交集 MongoDB可以使用索引的交集来完成查询。对于指定复合查询条件的查询，如果一个索引可以满足查询条件的一部分，而另一个索引可以满足查询条件的另一部分，则MongoDB可以使用两个索引的交集来满足查询。使用复合索引还是使用索引交集是否更有效取决于特定查询和系统。 有关索引交集的详细信息，请参见索引交集。 限制条件 某些限制适用于索引，例如索引键的长度或每个集合的索引数。有关详细信息，请参见索引限制。 其他注意事项 尽管索引可以提高查询性能，但是索引还提出了一些操作上的考虑。有关更多信息，请参见索引的操作注意事项。 应用程序在建立索引期间可能会遇到性能下降的情况，包括对集合的有限读/写访问权限。有关索引构建过程的更多信息，请参见\"现存集合的索引构建\"，包括\"在复制集环境下的索引构建\"章节 一些驱动程序可能指定索引，使用NumberLong(1)而不是1作为规范。这对结果索引没有任何影响。 译者：杨帅 莫薇 参见 原文 - Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/01-index-single.html":{"url":"08-indexes/01-index-single.html","title":"Single Field Indexes","keywords":"","body":" Single Field Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Single Field Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/02-index-compound.html":{"url":"08-indexes/02-index-compound.html","title":"Compound Indexes","keywords":"","body":" Compound Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compound Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/03-index-multikey.html":{"url":"08-indexes/03-index-multikey.html","title":"Multikey Indexes","keywords":"","body":" Multikey Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Multikey Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/03-index-multikey/01-multikey-index-bounds.html":{"url":"08-indexes/03-index-multikey/01-multikey-index-bounds.html","title":"多键索引范围","keywords":"","body":" 多键索引范围 在本页面 多键索引的交集边界 多键索引的复合边界 索引扫描的边界定义查询期间要搜索的索引部分。当索引上存在多个谓词时，MongoDB将尝试通过交集或复合的方式组合这些谓词的边界，以产生具有更小边界的扫描。 多键索引的交集边界 边界交集指的是多个边界的逻辑连接(即:AND)。例如，给定两个边界[[3，∞]]和[[-∞，6]]，边界的交集得到[[3,6]]。 给定一个索引数组字段，请考虑一个查询，该查询在数组上指定多个谓词，并且可以使用 多键索引。如果联接连接谓词，则MongoDB可以与多键索引边界相交 $elemMatch。 给定索引数组字段，考虑一个在数组上指定多个谓词并可以使用多键索引的查询。如果一个$elemMatch连接谓词，MongoDB可以交叉多键索引边界。 例如，一个集合survey包含带有一个字段item和一个数组字段的文档 ratings： { _id: 1, item: \"ABC\", ratings: [ 2, 9 ] } { _id: 2, item: \"XYZ\", ratings: [ 4, 3 ] } 在ratings数组上创建一个多键索引: db.survey.createIndex( { ratings: 1 } ) 下面的查询使用$elemMatch要求数组至少包含一个匹配这两个条件的元素: db.survey.find( { ratings : { $elemMatch: { $gte: 3, $lte: 6 } } } ) 分别取谓词: 大于或等于3的谓词(即$gte: 3)的边界为[[3，∞]]; 小于或等于6谓词(即$lte: 6)的边界为[[-∞，6]]。 因为查询使用$elemMatch来连接这些谓词，MongoDB可以交叉边界到: ratings: [ [ 3, 6 ] ] 如果查询没有将数组字段的条件与$elemMatch连接起来，MongoDB就不能与多键索引边界相交。考虑以下查询: db.survey.find( { ratings : { $gte: 3, $lte: 6 } } ) 查询在ratings数组中搜索至少一个大于或等于3的元素和至少一个小于或等于6的元素。因为单个元素不需要同时满足两个条件，所以MongoDB不相交边界，使用[[3，∞]]或[[-∞，6]]。MongoDB不保证它选择这两个边界中的哪一个。 多键索引的复合边界 复合边界是指对复合索引的多个键使用边界。例如，给定一个复合索引{a: 1, b: 1}，其中a字段的界值为[[3，∞]]，b字段的界值为[[-∞，6]]，复合这些界值可以得到两个界值的使用: { a: [ [ 3, Infinity ] ], b: [ [ -Infinity, 6 ] ] } 如果MongoDB不能复合这两个边界，MongoDB总是按照前场的边界约束索引扫描，在这种情况下，a:[[3，∞]]。 数组字段的复合索引 考虑一个复合的多键索引；即复合索引，其中索引字段之一是数组。例如，一个集合survey包含带有一个字段item和一个数组字段的文档 ratings： { _id: 1, item: \"ABC\", ratings: [ 2, 9 ] } { _id: 2, item: \"XYZ\", ratings: [ 4, 3 ] } 在item字段和ratings字段上创建复合索引: db.survey.createIndex( { item: 1, ratings: 1 } ) 下面的查询在索引的两个键上指定一个条件: db.survey.find( { item: \"XYZ\", ratings: { $gte: 3 } } ) 分别取谓词: 谓词\"XYZ\"的边界是[[\"XYZ\"， \"XYZ\"]]; 评级:{$gte: 3}谓词的边界是[[3，∞]]; MongoDB可以复合这两个边界使用的组合边界: { item: [ [ \"XYZ\", \"XYZ\" ] ], ratings: [ [ 3, Infinity ] ] } 对标量索引字段的范围查询(WiredTiger) 3.4版本的改变:仅针对WiredTiger和内存存储引擎 从MongoDB 3.4开始，对于使用MongoDB 3.4或更高版本创建的多键索引，MongoDB会跟踪哪个索引字段或哪些字段导致一个索引成为多键索引。跟踪这些信息允许MongoDB查询引擎使用更紧密的索引边界 上述复合索引位于标量字段item和数组字段ratings: db.survey.createIndex( { item: 1, ratings: 1 } ) 对于WiredTiger和内存中的存储引擎，如果一个查询操作在MongoDB 3.4或更高版本中创建的复合多键索引的索引标量字段上指定多个谓词，MongoDB将与字段的边界相交。 例如，下面的操作指定了标量字段的范围查询以及数组字段的范围查询: db.survey.find( { item: { $gte: \"L\", $lte: \"Z\"}, ratings : { $elemMatch: { $gte: 3, $lte: 6 } } } ) MongoDB将item到[[“L”，“Z”]]和评级到[[3.0,6.0]]的边界相交，使用以下的组合边界: \"item\" : [ [ \"L\", \"Z\" ] ], \"ratings\" : [ [3.0, 6.0] ] 再举一个例子，考虑标量字段属于嵌套文档的位置。例如，一个集合survey包含以下文档： { _id: 1, item: { name: \"ABC\", manufactured: 2016 }, ratings: [ 2, 9 ] } { _id: 2, item: { name: \"XYZ\", manufactured: 2013 }, ratings: [ 4, 3 ] } 在标量字段“item.name”和“item”上创建复合多键索引。数组字段ratings: db.survey.createIndex( { \"item.name\": 1, \"item.manufactured\": 1, ratings: 1 } ) 考虑以下操作，它在标量字段上指定查询谓词: db.survey.find( { \"item.name\": \"L\" , \"item.manufactured\": 2012 } ) 对于这个查询，MongoDB可以使用以下的组合边界: \"item.name\" : [ [\"L\", \"L\"] ], \"item.manufactured\" : [ [2012.0, 2012.0] ] 早期版本的MongoDB不能合并标量字段的这些边界。 对嵌入文档数组中的字段进行复合索引 如果数组包含嵌入的文档，要对嵌入文档中包含的字段进行索引，请使用索引规范中的虚线字段名。例如，给定以下嵌入文档数组: ratings: [ { score: 2, by: \"mn\" }, { score: 9, by: \"anon\" } ] 分数字段的虚线字段名是“ratings.score”。 非数组字段和数组字段的复合边界 考虑一个包含字段item和数组字段ratings的文档的集合survey2: { _id: 1, item: \"ABC\", ratings: [ { score: 2, by: \"mn\" }, { score: 9, by: \"anon\" } ] } { _id: 2, item: \"XYZ\", ratings: [ { score: 5, by: \"anon\" }, { score: 7, by: \"wv\" } ] } 在非数组字段item和数组ratings中的两个字段上创建复合索引。score和ratings.by: db.survey2.createIndex( { \"item\": 1, \"ratings.score\": 1, \"ratings.by\": 1 } ) 下面的查询为所有三个字段指定了一个条件: db.survey2.find( { item: \"XYZ\", \"ratings.score\": { $lte: 5 }, \"ratings.by\": \"anon\" } ) 分别取谓词: 谓词\"XYZ\"的边界是[[\"XYZ\"， \"XYZ\"]]; {$lte: 5}谓词的边界是[[-∞，5]]; by: \"anon\"谓词的边界是[\"anon\"， \"anon\"]。 MongoDB的可以复合边界为item与键或者为边界\"ratings.score\"或界限为\"ratings.by\"取决于查询谓词和索引关键字的值，。MongoDB不保证与item 领域的界限。例如，MongoDB将选择将item边界与\"ratings.score\"边界复合 ： { \"item\" : [ [ \"XYZ\", \"XYZ\" ] ], \"ratings.score\" : [ [ -Infinity, 5 ] ], \"ratings.by\" : [ [ MinKey, MaxKey ] ] } 或者，MongoDB可以选择将item范围与 \"ratings.by\"范围进行组合： { \"item\" : [ [ \"XYZ\", \"XYZ\" ] ], \"ratings.score\" : [ [ MinKey, MaxKey ] ], \"ratings.by\" : [ [ \"anon\", \"anon\" ] ] } 然而，为了复合“评级”的界限。带有“ratings.by”边界的“score”。查询必须使用$elemMatch。有关更多信息，请参见 数组中索引字段的复合边界。 数组中索引字段的复合边界 将同一个数组的索引键的边界复合在一起: 索引键必须共享相同的字段路径，但不包括字段名称。 查询必须使用该路径上的$elemMatch在字段上指定谓词。 对于嵌入文档中的字段，虚线字段名，例如“a.b.c”.d\"，是d的字段路径。要复合同一个数组的索引键的边界，$elemMatch必须在到但不包括字段名本身的路径上;即.“a.b.c”。 例如，在ratings.score和ratings.by字段创建一个符合索引： db.survey2.createIndex( { \"ratings.score\": 1, \"ratings.by\": 1 } ) 字段\"ratings.score\"和\"ratings.by\"共享字段路径ratings。以下查询使用$elemMatch的字段ratings，以要求所述阵列包含至少有一个元素匹配这两个条件: db.survey2.find( { ratings: { $elemMatch: { score: { $lte: 5 }, by: \"anon\" } } } ) 分别取谓词: { $lte: 5 }谓词的边界是[-∞，5]; by: \"anon\"谓词的边界是[\"anon\"， \"anon\"] MongoDB可以复合这两个边界使用的组合边界: { \"ratings.score\" : [ [ -Infinity, 5 ] ], \"ratings.by\" : [ [ \"anon\", \"anon\" ] ] } 查询没有$elemMatch 如果查询没有将索引数组字段的条件与$elemMatchh连接起来，MongoDB就不能复合它们的边界。考虑以下查询: db.survey2.find( { \"ratings.score\": { $lte: 5 }, \"ratings.by\": \"anon\" } ) 因为数组中嵌入的单个文档不需要同时满足这两个条件，所以MongoDB不复合边界。使用复合索引时，如果MongoDB不能约束索引的所有字段，MongoDB总是约束索引的前导字段，这里是“ratings.score”: { \"ratings.score\": [ [ -Infinity, 5 ] ], \"ratings.by\": [ [ MinKey, MaxKey ] ] } $elemMatch在不完整路径上 如果查询没有在嵌入字段的路径上指定$elemMatch，最多但不包括字段名，MongoDB不能复合来自同一数组的索引键的边界。 例如，集合survey3包含一个字段item和一个数组字段ratings的文档: { _id: 1, item: \"ABC\", ratings: [ { scores: [ { q1: 2, q2: 4 }, { q1: 3, q2: 8 } ], loc: \"A\" }, { scores: [ { q1: 2, q2: 5 } ], loc: \"B\" } ] } { _id: 2, item: \"XYZ\", ratings: [ { scores: [ { q1: 7 }, { q1: 2, q2: 8 } ], loc: \"B\" } ] } 在ratings.scores.q1和ratings.scores.q2字段上创建一个复合索引。 db.survey3.createIndex( { \"ratings.scores.q1\": 1, \"ratings.scores.q2\": 1 } ) 字段\"ratings.scores.q1\"和\"ratings.scores.q2\"共享字段路径\"ratings.scores\"，并且$elemMatch必须在该路径上。 但是，下面的查询使用了$elemMatch，但不是在必需的路径上: db.survey3.find( { ratings: { $elemMatch: { 'scores.q1': 2, 'scores.q2': 8 } } } ) 因此，MongoDB 无法混合边界，并且 \"ratings.scores.q2\"在索引扫描期间该字段将不受限制。要增加界限，查询必须$elemMatch在路径上使用\"ratings.scores\"： db.survey3.find( { 'ratings.scores': { $elemMatch: { 'q1': 2, 'q2': 8 } } } ) 译者：杨帅 参见 原文 - Multikey Index Bounds Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/04-index-text.html":{"url":"08-indexes/04-index-text.html","title":"Text Indexes","keywords":"","body":" Text Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Text Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/04-index-text/01-specify-language-for-text-index.html":{"url":"08-indexes/04-index-text/01-specify-language-for-text-index.html","title":"Specify a Language for Text Index","keywords":"","body":" Specify a Language for Text Index ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Specify a Language for Text Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/04-index-text/02-avoid-text-index-name-limit.html":{"url":"08-indexes/04-index-text/02-avoid-text-index-name-limit.html","title":"Specify Name for text Index","keywords":"","body":" Specify Name for text Index ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Specify Name for text Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/04-index-text/03-control-results-of-text-search.html":{"url":"08-indexes/04-index-text/03-control-results-of-text-search.html","title":"Control Search Results with Weights","keywords":"","body":" Control Search Results with Weights ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Control Search Results with Weights Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/04-index-text/04-limit-number-of-items-scanned-for-text-search.html":{"url":"08-indexes/04-index-text/04-limit-number-of-items-scanned-for-text-search.html","title":"Limit the Number of Entries Scanned","keywords":"","body":" Limit the Number of Entries Scanned ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Limit the Number of Entries Scanned Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/05-index-wildcard.html":{"url":"08-indexes/05-index-wildcard.html","title":"Wildcard Indexes","keywords":"","body":" Wildcard Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Wildcard Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/05-index-wildcard/01-index-wildcard-restrictions.html":{"url":"08-indexes/05-index-wildcard/01-index-wildcard-restrictions.html","title":"通配符索引限制","keywords":"","body":" 通配符索引限制 在本页面 不兼容的索引类型或属性 不支持的查询和聚合模式 分片 不兼容的索引类型或属性 通配符索引不支持以下索引类型或属性： 复合 TTL 文本 2d（地理空间） 2dsphere（地理空间） Hashed Unique 注意 通配符索引与通配符文本索引不同，也不兼容。通配符索引不支持使用$text操作符的查询。 不支持的查询和聚合模式 字段不存在 通配符索引是sparse的，不索引空字段。因此通配符索引不支持查询字段不存在的文档。 例如，考虑一个在product_attributes上具有通配符索引的集合目录。通配符索引不能支持以下查询: db.inventory.find( {\"product_attributes\" : { $exists : false } } ) db.inventory.aggregate([ { $match : { \"product_attributes\" : { $exists : false } } } ]) 字段等于文档或数组 通配符索引为文档或数组的内容生成条目，而不是文档/数组本身。因此通配符索引不能支持精确的文档/数组相等匹配。通配符索引可以支持查询字段等于空文档{}的位置。 例如，考虑一个在 product_attributes 上具有通配符索引的集合目录。通配符索引不能支持以下查询: db.inventory.find({ \"product_attributes\" : { \"price\" : 29.99 } } ) db.inventory.find({ \"product_attributes.tags\" : [ \"waterproof\", \"fireproof\" ] } ) db.inventory.aggregate([{ $match : { \"product_attributes\" : { \"price\" : 29.99 } } }]) db.inventory.aggregate([{ $match : { \"product_attributes.tags\" : [\"waterproof\", \"fireproof\" ] } } }]) 字段不等于文档或数组 通配符索引为文档或数组的内容生成条目，而不是文档/数组本身。因此通配符索引不能支持精确的文档/数组不等匹配。 例如，考虑一个在product_attributes上具有通配符索引的集合目录。通配符索引不能支持以下查询: db.inventory.find( { $ne : [ \"product_attributes\", { \"price\" : 29.99 } ] } ) db.inventory.find( { $ne : [ \"product_attributes.tags\", [ \"waterproof\", \"fireproof\" ] ] } ) db.inventory.aggregate([{ $match : { $ne : [ \"product_attributes\", { \"price\" : 29.99 } ] } }]) db.inventory.aggregate([{ $match : { $ne : [ \"product_attributes.tags\", [ \"waterproof\", \"fireproof\" ] ] } }]) 字段不等于null 如果给定字段是集合中任何文档中的数组，通配符索引不能支持查询该字段不等于null的文档。 例如，考虑一个在product_attributes上具有通配符索引的集合目录。如果product_attributes通配符索引不能支持以下查询。标签是集合中任意文档的数组: db.inventory.find( { $ne : [ \"product_attributes.tags\", null ] } ) db.inventory.aggregate([{ $match : { $ne : [ \"product_attributes.tags\", null ] } }]) 分片 您不能使用通配符索引来分片集合。在要分片的一个或多个字段上创建一个非通配符索引。有关分片键选择的更多信息，请参见分片 键。 参见 原文 - Wildcard Index Restrictions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/06-2dsphere.html":{"url":"08-indexes/06-2dsphere.html","title":"2dsphere Indexes","keywords":"","body":" 2dsphere Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 2dsphere Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/06-2dsphere/01-query-a-2dsphere-index.html":{"url":"08-indexes/06-2dsphere/01-query-a-2dsphere-index.html","title":"查询一个2dsphere索引","keywords":"","body":" 查询一个2dsphere索引 在本页面 多边形绑定的GeoJSON对象 GeoJSON对象的交集 接近GeoJSON点 球体上定义的圆内的点 以下各节描述了2dsphere索引支持的查询。 多边形绑定的GeoJSON对象 该$geoWithin操作符查询在GeoJSON多边形中找到的位置数据。您的位置数据必须以GeoJSON格式存储。使用以下语法: db..find( { : { $geoWithin : { $geometry : { type : \"Polygon\" , coordinates : [ ] } } } } ) 下面的例子选择了全部存在于GeoJSON多边形中的所有点和形状: db.places.find( { loc : { $geoWithin : { $geometry : { type : \"Polygon\" , coordinates : [ [ [ 0 , 0 ] , [ 3 , 6 ] , [ 6 , 1 ] , [ 0 , 0 ] ] ] } } } } ) GeoJSON对象的交集 该$geoIntersects操作符查询与指定GeoJSON对象相交的位置。如果交点非空，则该位置与该对象相交。这包括具有共享优势的文档。 该$geoIntersects操作符使用以下语法: db..find( { : { $geoIntersects : { $geometry : { type : \"\" , coordinates : [ ] } } } } ) 下面的示例使用$geoIntersects选择与coordinates数组定义的多边形相交的所有索引点和形状。 db.places.find( { loc : { $geoIntersects : { $geometry : { type : \"Polygon\" , coordinates: [ [ [ 0 , 0 ] , [ 3 , 6 ] , [ 6 , 1 ] , [ 0 , 0 ] ] ] } } } } ) 接近GeoJSON点 接近查询返回最接近定义点的点，并按距离对结果进行排序。对GeoJSON数据的接近度查询需要一个2dsphere索引。 要查询与GeoJSON点的接近程度，请使用任一 $near运算符。距离以米为单位。 该$near使用的语法如下： db..find( { : { $near : { $geometry : { type : \"Point\" , coordinates : [ , ] } , $maxDistance : } } } ) 有关示例，请参见$near。 参见$nearSphere操作符和:pipeline:$geoNear聚合管道阶段。 球体上定义的圆内的点 要在球体的“球冠”中选择所有网格坐标，请$geoWithin与$centerSphere运算符一起使用 。指定一个包含以下内容的数组： 圆心的网格坐标 圆的半径，以弧度为单位。要计算弧度，请参见 使用球面几何计算距离。 使用以下语法： db..find( { : { $geoWithin : { $centerSphere : [ [ , ] , ] } } } ) 下面的示例查询网格坐标并返回所有半径为经度 88 W 和纬度 30 N 的10英里内的文档。示例将10英里的距离转换为弧度，通过除以地球近似的赤道半径3963.2英里: db.places.find( { loc : { $geoWithin : { $centerSphere : [ [ -88 , 30 ] , 10 / 3963.2 ] } } } ) 译者：杨帅 参见 原文 - Query a 2dsphere Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d.html":{"url":"08-indexes/07-2d.html","title":"2d Indexes","keywords":"","body":" 2d Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 2d Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/01-build-a-2d-index.html":{"url":"08-indexes/07-2d/01-build-a-2d-index.html","title":"Create a 2d Index","keywords":"","body":" Create a 2d Index ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Create a 2d Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/02-query-a-2d-index.html":{"url":"08-indexes/07-2d/02-query-a-2d-index.html","title":"查询一个“2d”索引","keywords":"","body":" 查询一个“2d”索引 在本页面 在平面上定义的形状内的点 球体上定义的圆内的点 接近平面上的一点 在平面上精确匹配 下面的部分描述了 2d 索引支持的查询。 在平面上定义的形状内的点 要选择平面上给定形状中的所有旧坐标对，请使用$geoWithin操作符和一个形状操作符。使用以下语法: db..find( { : { $geoWithin : { $box|$polygon|$center : } } } ) 下面查询由左下角的[0,0]和右上角的[100,100]定义的矩形内的文档。 db.places.find( { loc : { $geoWithin : { $box : [ [ 0 , 0 ] , [ 100 , 100 ] ] } } } ) 下面查询以[-74,40.74]为圆心，半径为10的圆内的文档: db.places.find( { loc: { $geoWithin : { $center : [ [-74, 40.74 ] , 10 ] } } } ) 关于每种形状的语法和示例，请看下面: $box $polygon $center (defines a circle) 球体上定义的圆内的点 由于遗留的原因，MongoDB支持平面“2d”索引上的基本球形查询。通常，球形计算应该使用2dsphere索引，如2dsphere索引中所述。 要在球体的“球冠”中查询传统坐标对，请$geoWithin与$centerSphere运算符一起使用。指定一个包含以下内容的数组： 圆心的网格坐标 圆的半径，以弧度为单位。要计算弧度，请参见 使用球面几何计算距离。 使用以下语法: db..find( { : { $geoWithin : { $centerSphere : [ [ , ] , ] } } } ) 下面的示例查询返回以经度 88 W 和纬度 30 N 为半径的10英里范围内的所有文档。这个例子通过将距离除以地球赤道半径3963.2英里来将距离转换为弧度: db..find( { loc : { $geoWithin : { $centerSphere : [ [ 88 , 30 ] , 10 / 3963.2 ] } } } ) 接近平面上的一点 接近查询返回最接近定义点的遗留坐标对，并按距离对结果排序。使用$near操作符。操作符需要一个 2d 索引。 $near操作符使用以下语法: db..find( { : { $near : [ , ] } } ) 例如，请参见$near。 在平面上的精确匹配 不能使用2d索引返回坐标对的精确匹配。在存储坐标的字段上使用升序或降序标量索引，以返回准确的匹配。 在下面的例子中，find()操作将返回一个精确匹配的位置，如果你有一个{'loc': 1}索引: db..find( { loc: [ , ] } ) 该查询将返回值为[， ]的所有文档。 参见 原文 - Query a 2d Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/03-geospatial-indexes.html":{"url":"08-indexes/07-2d/03-geospatial-indexes.html","title":"2d Index Internals","keywords":"","body":" 2d Index Internals ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 2d Index Internals Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/04-calculate-distances-using-spherical-geometry-with-2d-geospatial-indexes.html":{"url":"08-indexes/07-2d/04-calculate-distances-using-spherical-geometry-with-2d-geospatial-indexes.html","title":"Calculate Distance Using Spherical Geometry","keywords":"","body":" Calculate Distance Using Spherical Geometry ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Calculate Distance Using Spherical Geometry Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/2d-Index-Internals.html":{"url":"08-indexes/07-2d/2d-Index-Internals.html","title":"2d索引内部","keywords":"","body":" 2d索引内部 在本页面 2d索引的Geohash值的计算 2d索引的多位置文档 本文对MongoDB的 2d 地理空间索引的内部原理进行了更深入的解释。本材料不是正常操作或应用程序开发所必需的，但对于故障排除和进一步理解可能很有用。 2d索引的Geohash值的计算 当你创建一个地理空间索引遗留坐标对,MongoDB计算地理散列的坐标对在指定位置范围和geohash值然后索引。 要计算geohash值，可以递归地将二维映射划分为象限。然后为每个象限分配一个两比特的值。例如，四个象限的两位表示为: 01 11 00 10 这些两位值(00，01，10，和11)表示每个象限和每个象限内的所有点。对于具有两位分辨率的geohash，位于左下象限的所有点的geohash值都为 00 。左上角象限的geohash值为 01 。右下角和右上角的geohash值分别为 10 和 11 。 为了提供额外的精度，继续将每个象限划分为子象限。每个子象限都将包含象限的geohash值与子象限的值连接起来。右上象限的geohash为 11 ，子象限的geohash分别为(从左上方向顺时针方向): 1101 、 1111 、 1110 和 1100 。 用于“2d”索引的多位置文档 注意 索引可以覆盖文档中的多个地理空间字段，并且可以使用MultiPoint嵌入式文档表示点列表。 虽然 2d 地理空间索引在文档中不支持多个地理空间字段，但您可以使用多键索引在单个文档中索引多个坐标对。在最简单的例子中，你可能有一个字段。(例如:locs)，它包含一个坐标数组，如下例所示: db.places.save( { locs : [ [ 55.5 , 42.3 ] , [ -74 , 44.74 ] , { lng : 55.5 , lat : 42.3 } ] } ) 数组的值可以是数组(如[55.5,42.3])，也可以是嵌入文档(如{lng: 55.5, lat: 42.3})。 然后可以在 locs 字段上创建地理空间索引，如下所示: db.places.createIndex( { \"locs\": \"2d\" } ) 您还可以将位置数据建模为嵌入文档中的一个字段。在这种情况下，文档将包含一个字段(例如。' address ')，它包含一个文档数组，其中每个文档都有一个字段(例如。' loc: ')保存位置坐标。例如: db.records.save( { name : \"John Smith\", addresses : [ { context : \"home\" , loc : [ 55.5, 42.3 ] } , { context : \"work\", loc : [ -74 , 44.74 ] } ] } ) 然后可以在 addresses 上创建地理空间索引。字段如下例所示: db.records.createIndex( { \"addresses.loc\": \"2d\" } ) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/Calculate-Distance-Using-Spherical-Geometry.html":{"url":"08-indexes/07-2d/Calculate-Distance-Using-Spherical-Geometry.html","title":"使用球面几何计算距离","keywords":"","body":" 使用球面几何计算距离 警告 对于球形查询，使用' 2dsphere '索引结果。 对球形查询使用“2d”索引可能会导致不正确的结果，例如对环绕极点的球形查询使用“2d”索引。 2d索引支持在欧几里得平面(平面)上计算距离的查询。索引还支持以下查询操作符和命令，计算距离使用球面几何: 注意 虽然“2d”索引支持使用球面距离的基本查询，但如果您的数据主要是经度和纬度，请考虑移动到“2dsphere”索引。 $nearSphere $centerSphere $near $geoNear带有选择的流水线级spherical: true 重要 上述操作使用弧度表示距离。其他球形查询操作符则不是这样，比如' $geoWithin '。 要使球形查询运算符正常运行，必须将距离转换为弧度，并将弧度转换为应用程序使用的距离单位。 转换: 到弧度的距离：用与距离测量相同的单位将距离除以球体（例如地球）的半径。 弧度到距离：将弧度乘以要转换距离的单位制中球体（例如地球）的半径。 地球的赤道半径大约为3,963.2英里或6,378.1公里。 以下查询将从places集合中返回半径为“100”英里的圆心“[-74,40.74]”所描述的圆内的文档: db.places.find( { loc: { $geoWithin: { $centerSphere: [ [ -74, 40.74 ] , 100 / 3963.2 ] } } } ) 注意 如果指定纬度和经度坐标，请先列出经度，再列出纬度: 有效经度值在‘-180’和‘180’之间，包括两者。 有效纬度值在' -90 '和' 90 '之间，两者都包括。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/07-2d/Create-a-2d-Index.html":{"url":"08-indexes/07-2d/Create-a-2d-Index.html","title":"创建一个2d索引","keywords":"","body":" 创建一个2d索引 在本页面 定义2d索引的位置范围 定义2d索引的位置精度 要构建一个地理空间的 2d 索引，使用db.collection.createIndex()方法并指定 2d 。使用以下语法: db..createIndex( { : \"2d\" , : } , { } ) 2d 索引使用以下可选的索引规范选项: { min : , max : , bits : } 定义2d索引的位置范围 默认情况下， 2d 索引假定经度和纬度，边界为[-180 , 180)。如果文档包含的坐标数据超出了指定的范围，MongoDB将返回一个错误。 重要 默认边界允许应用程序插入纬度大于90或小于-90的无效文档。对于这些无效点的地理空间查询行为没有定义。 在 2d 索引上，你可以改变位置范围。 您可以创建一个 2d 地理空间索引，其中包含默认位置范围之外的位置范围。在创建索引时使用' min '和' max '选项。使用以下语法: db.collection.createIndex( { : \"2d\" } , { min : , max : } ) 定义“2d”索引的位置精度 默认情况下，传统坐标对的“2d”索引使用26位精度，使用默认的-180到180的范围，相当于2英尺或60厘米的精度。精度由用于存储位置数据的geohash值的位大小来度量。您可以配置精度最高为32位的地理空间索引。 索引精度不影响查询精度。实际的网格坐标总是在最终的查询处理中使用。降低精度的优点是插入操作的处理开销更低，占用的空间更少。更高精度的一个优点是查询扫描索引的较小部分以返回结果。 若要配置默认位置以外的位置精度，请在创建索引时使用 bits 选项。使用下面的语法: db..createIndex( { : \"\"} , { bits : } ) 有关geohash值的内部信息，请参见计算2d索引的geohash值。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/08-geohaystack.html":{"url":"08-indexes/08-geohaystack.html","title":"geoHaystack Indexes","keywords":"","body":" geoHaystack Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - geoHaystack Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/08-geohaystack/01-build-a-geohaystack-index.html":{"url":"08-indexes/08-geohaystack/01-build-a-geohaystack-index.html","title":"Create a Haystack Index","keywords":"","body":" Create a Haystack Index ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Create a Haystack Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/08-geohaystack/02-query-a-geohaystack-index.html":{"url":"08-indexes/08-geohaystack/02-query-a-geohaystack-index.html","title":"查询Haystack索引","keywords":"","body":" 查询Haystack索引 弃用 MongoDB 4.4不支持geoHaystack索引和 geoSearch 命令。使用2d索引或 $geoWithin 代替。 Haystack索引是一种特殊的2d地理空间索引，优化后可以在小区域内返回结果。要创建一个haystack索引，请参见创建一个haystack索引。 要查询一个haystack索引，使用 geoSearch 命令。您必须为geoSearch指定坐标和附加字段。例如，要返回示例点附近的type字段中值为restaurant的所有文档，命令如下: db.runCommand( { geoSearch : \"places\" , search : { type: \"restaurant\" } , near : [-74, 40.74] , maxDistance : 10 } ) 注意 Haystack索引不适合查询最接近特定位置的完整文档列表。与存储桶大小相比，最近的文档可能更远。 请注意 haystack索引目前不支持球形查询操作。 find()方法不能访问haystack索引。 参见 原文 - Query a Haystack Index Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/08-geohaystack/Create-a-Haystack-Index.html":{"url":"08-indexes/08-geohaystack/Create-a-Haystack-Index.html","title":"创建Haystack索引","keywords":"","body":" 创建Haystack索引 弃用 MongoDB 4.4不支持geoHaystack索引和地理搜索命令。使用$geoNear或$geoWithin 的2d索引。 haystack索引必须引用两个字段:位置字段和第二个字段。第二个字段用于精确匹配。Haystack索引基于位置和对单个附加条件的精确匹配返回文档。这些索引不一定适合于将最近的文档返回到特定位置。 要构建一个haystack索引，请使用以下语法: db.coll.createIndex( { : \"geoHaystack\" , : 1 } , { bucketSize : } ) 要构建haystack索引，必须在创建索引时指定' bucketSize '选项。' bucketSize '为' 5 '创建一个索引，该索引将指定经度和纬度的5个单位内的位置值分组。“bucketSize”还决定了索引的粒度。您可以根据数据的分布调整参数，以便通常只搜索很小的区域。bucket定义的区域可以重叠。文档可以存在于多个桶中。 例子 如果您有一个包含类似以下字段的文档集合: { _id : 100, pos: { lng : 126.9, lat : 35.2 } , type : \"restaurant\"} { _id : 200, pos: { lng : 127.5, lat : 36.1 } , type : \"restaurant\"} { _id : 300, pos: { lng : 128.0, lat : 36.7 } , type : \"national park\"} 下面的操作创建了一个带有bucket的haystack索引，该bucket将键存储在一个经度或纬度单位内。 db.places.createIndex( { pos : \"geoHaystack\", type : 1 } , { bucketSize : 1 } ) 这个索引将值为200的“_id”字段存储在两个不同的存储桶中: 在包含“_id”字段值为“100”的文档的bucket中 在包含“_id”字段值为“300”的文档的bucket中 要使用haystack索引进行查询，可以使用 geoSearch 命令。参见查询Haystack索引. 默认情况下，使用haystack索引的查询返回50个文档。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/09-index-hashed.html":{"url":"08-indexes/09-index-hashed.html","title":"Hashed Indexes","keywords":"","body":" Hashed Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Hashed Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties.html":{"url":"08-indexes/10-index-properties.html","title":"索引特性","keywords":"","body":" 索引特性 索引的unique特性 开启unique选项，索引对应字段具有唯一性，对应字段拒绝重复值。除唯一性约束外，在功能上，索引的unique特性可与其他特性交替使用。 索引的Partial特性 3.2版本新特性 特性相关选项设置后，将仅索引集合中满足指定筛选表达式的文档。对集合中的文档子集创建索引，设置了partial特性的索引将占用更低的存储，并降低mongodb创建索引和维护索引的性能开销。 在功能上，索引的Partial特性是sparse特性的超集，当一个索引同时拥有两种特性时，以Partial特性优先。 索引的Sparse特性 索引的 sparse 特性确保只对存在索引字段的文档创建索引。创建索引时将会跳过那些没有对应字段值的文档。 你或许可以将sparse选项和unique选项结合使用，以防止索引字段插入重复值，并对对应索引字段缺失的文档不创建索引，提升数据库效率。 索引的TTL特性 索引的TTL特性，允许MongoDB在一定时间后自动从集合中移除文档。这非常适合某些类型的信息，例如：机器生成的事件数据、日志和会话信息，这些信息只需要在数据库中保留有限的时间。 有关实现说明，请参见：Expire Data from Collections by Setting TTL 译者：程哲欣 参见 原文 - Index Properties Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/01-index-ttl.html":{"url":"08-indexes/10-index-properties/01-index-ttl.html","title":"TTL索引","keywords":"","body":" TTL索引 在本页面 行为 限制 请注意 如果您要删除文档以节省存储成本，考虑MongoDB Atlas中的Online Archive。在线归档自动将不经常访问的数据归档到完全托管的S3 bucket，从而实现经济有效的数据分层。 TTL索引是一种特殊的单字段索引，MongoDB可以使用它在一定的时间或特定的时钟时间后自动从集合中删除文档。数据过期对于某些类型的信息很有用，比如机器生成的事件数据、日志和会话信息，这些信息只需要在数据库中保存有限的时间。 要创建一个TTL索引,使用db.collection.createIndex ()方法expireAfterSeconds选项字段的值是一个日期或一个数组,其中包含日期值. 例如，要在eventlog集合的lastModifiedDate字段上创建一个TTL索引，在mongo shell中使用以下操作: db.eventlog.createIndex( { \"lastModifiedDate\": 1 }, { expireAfterSeconds: 3600 } ) 行为 过期的数据 TTL索引会在指定的秒数之后使文档过期；即:过期阈值是索引字段值加上指定的秒数。 如果字段是一个数组，并且索引中有多个日期值，MongoDB使用数组中的最低(即最早)日期值来计算过期阈值。 如果文档中的索引字段不是date或包含日期值的数组，文档将不会过期。 如果文档不包含索引字段，则文档将不会过期。 删除操作 在后台线程中的mongod读取索引中的值并从集合中删除过期的document。 当TTL线程处于活动状态时，您将db.currentOp()在数据库概要分析器的输出或数据中看到删除操作。 删除操作的时间 一旦索引在主数据库上构建完成，MongoDB就开始删除过期的文档。有关索引构建过程的更多信息，请参见填充集合上的索引构建。 TTL索引不能保证过期数据在过期时立即删除。在文档过期和MongoDB从数据库中删除文档之间可能存在延迟。 删除过期文档的后台任务每60秒运行一次。因此，文档可能在文档到期和后台任务运行之间保持在集合中。 因为移除操作的持续时间取决于你的mongod实例的工作负载，过期的数据可能存在一段时间超过运行后台任务的60秒周期。 复制集 在副本集成员上，仅当成员处于primary状态时，TTL后台线程才会删除文档。当成员处于辅助状态时，TTL背景线程处于空闲状态。次要成员从主要成员复制删除操作。 支持查询 TTL索引支持查询的方式与非TTL索引相同。 限制 TTL索引是单字段索引。复合索引不支持TTL，并且忽略该 expireAfterSeconds选项。 该_id字段不支持TTL索引。 您无法在上限集合上创建TTL索引，因为MongoDB无法从上限集合中删除文档。 您不能用于createIndex()更改expireAfterSeconds现有索引的值。而是将 collModdatabase命令与indexcollection标志一起使用 。否则，要更改现有索引的选项的值，必须首先删除索引并重新创建。 如果某个字段已经存在非TTL单字段索引，则无法在同一字段上创建TTL索引，因为您无法创建具有相同键规范且仅选项不同的索引。要将非TTL单字段索引更改为TTL索引，必须首先删除该索引，然后使用该expireAfterSeconds选项重新创建 。 参见 原文 - TTL Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/01-index-ttl/01-expire-data.html":{"url":"08-indexes/10-index-properties/01-index-ttl/01-expire-data.html","title":"通过设置TTL使集合中的数据过期","keywords":"","body":" 通过设置TTL使集合中的数据过期 在本页面 程序 本文介绍了MongoDB的“生存时间”或TTL集合特性。TTL集合使它可能存储数据在MongoDB和有' mongod '自动删除数据后指定的秒数或在一个特定的时钟时间。 数据过期对于某些类别的信息很有用，包括机器生成的事件数据、日志和会话信息，这些信息只需要持续有限的一段时间。 一个特殊的TTL索引属性支持TTL集合的实现。TTL特性依赖于' mongod '中的一个后台线程，该线程读取索引中的日期类型值并从集合中删除过期的document。 程序 若要创建TTL索引，请在其值为日期或包含日期值的数组 的字段上使用db.collection.createIndex()带有expireAfterSeconds选项 的 方法 。 请注意 TTL索引是单个字段索引。复合索引不支持TTL属性。有关TTL索引的更多信息，请参见TTL索引。 You can modify the expireAfterSeconds of an existing TTL index using the collMod command. 在指定的秒数之后使文档过期 要在索引字段之后的指定秒数过期数据，在保存BSON日期类型值或BSON日期类型对象数组的字段上创建一个TTL索引，并在expireAfterSeconds字段中指定一个正的非零值。当' expireAfterSeconds '字段中的秒数超过索引字段中指定的时间时,文档将过期。 例如，下面的操作在“log_events”集合的“createdAt”字段上创建一个索引，并指定“expireAfterSeconds”的值“3600”，将过期时间设置为“createdAt”指定的时间之后一小时。 db.log_events.createIndex( { \"createdAt\": 1 }, { expireAfterSeconds: 3600 } ) 当向“log_events”集合添加文档时，将“createdAt”字段设置为当前时间: db.log_events.insert( { \"createdAt\": new Date(), \"logEvent\": 2, \"logMessage\": \"Success!\" } ) 当文档的createdAt值大于expireAfterSeconds中指定的秒数时，MongoDB将自动从log_events集合中删除文档。 在特定的时钟时间时过期文档 要使文档在特定的时钟时间过期，首先在一个字段上创建一个TTL索引，该字段包含BSON日期类型的值或BSON日期类型对象的数组和指定expireAfterSeconds值为0。对于集合中的每个文档，将索引日期字段设置为与文档应该过期的时间对应的值。如果索引日期字段包含过去的日期，MongoDB认为文档过期。 例如，以下操作在“log_events”集合的“expireAt”字段上创建一个索引，并指定“expireAfterSeconds”的值为“0”: db.log_events.createIndex( { \"expireAt\": 1 }, { expireAfterSeconds: 0 } ) 对于每个文档，将expireAt的值设置为与文档应该过期的时间对应。例如，下面的 insert() 操作添加了一个应该在July 22, 2013 14:00:00到期的文档。 db.log_events.insert( { \"expireAt\": new Date('July 22, 2013 14:00:00'), \"logEvent\": 2, \"logMessage\": \"Success!\" } ) 当文档' expireAt的值大于expireAfterSeconds中指定的秒数时，MongoDB将自动从log_events集合中删除文档。在本例中是“0”秒。因此，数据在指定的expireAt值过期。 参见 原文 - Expire Data from Collections by Setting TTL Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/02-index-unique.html":{"url":"08-indexes/10-index-properties/02-index-unique.html","title":"Unique Indexes","keywords":"","body":" Unique Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Unique Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/03-index-partial.html":{"url":"08-indexes/10-index-properties/03-index-partial.html","title":"Partial Indexes","keywords":"","body":" Partial Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Partial Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/04-index-case-insensitive.html":{"url":"08-indexes/10-index-properties/04-index-case-insensitive.html","title":"Case Insensitive Indexes","keywords":"","body":" Case Insensitive Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Case Insensitive Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/05-index-hidden.html":{"url":"08-indexes/10-index-properties/05-index-hidden.html","title":"Hidden Indexes","keywords":"","body":" Hidden Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Hidden Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/06-index-sparse.html":{"url":"08-indexes/10-index-properties/06-index-sparse.html","title":"Sparse Indexes","keywords":"","body":" Sparse Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sparse Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/Case-Insensitive-Indexes.html":{"url":"08-indexes/10-index-properties/Case-Insensitive-Indexes.html","title":"不分大小写索引","keywords":"","body":" 不分大小写索引 在本页面 行为 例子 创建不区分大小写的索引 具有默认排序规则的集合中的区分大小写的索引 3.4版本新功能 不区分大小写索引支持执行不考虑大小写的字符串比较的查询。 通过指定“collation”参数作为选项，可以使用' db.collection.createIndex() '创建大小写不敏感索引。例如: db.collection.createIndex( { \"key\" : 1 }, { collation: { locale : , strength : } } ) 要为区分大小写的索引指定排序规则，请包括: locale:指定语言规则。参见Collation locale获取可用locale列表。 strength:确定比较规则。值“1”或“2”表示排序规则不区分大小写。 有关其他排序字段，请参见collation。 行为 使用不区分大小写的索引不会影响查询的结果，但可以提高性能;请参阅Indexes以获得关于索引成本和收益的详细讨论。 若要使用指定排序规则的索引，查询和排序操作必须指定与索引相同的排序规则。如果集合定义了排序规则，所有查询和索引都会继承该排序规则，除非它们显式指定不同的排序规则。 例子 创建不区分大小写的索引 使用一个不分大小写指数在一组没有默认排序,创建一个索引排序和“strength”参数设置为“1”或“2”(见排序的strength参数的详细描述)。必须在查询级别指定相同的排序规则，才能使用索引级别的排序规则。 下面的示例创建一个没有默认排序规则的集合，然后在“type”字段上使用大小写不敏感排序规则添加索引。 db.createCollection(\"fruit\") db.fruit.createIndex( { type: 1}, { collation: { locale: 'en', strength: 2 } } ) 要使用索引，查询必须指定相同的排序规则。 db.fruit.insert( [ { type: \"apple\" }, { type: \"Apple\" }, { type: \"APPLE\" } ] ) db.fruit.find( { type: \"apple\" } ) // does not use index, finds one result db.fruit.find( { type: \"apple\" } ).collation( { locale: 'en', strength: 2 } ) // uses the index, finds three results db.fruit.find( { type: \"apple\" } ).collation( { locale: 'en', strength: 1 } ) // does not use the index, finds three results 具有默认排序规则的集合中的区分大小写的索引 使用默认排序规则创建集合时，除非指定不同的排序规则，否则随后创建的所有索引都会继承该排序规则。所有没有指定不同排序规则的查询也继承默认排序规则。 下面的示例使用默认排序规则创建名为“names”的集合，然后在“first_name”字段上创建索引。 db.createCollection(\"names\", { collation: { locale: 'en_US', strength: 2 } } ) db.names.createIndex( { first_name: 1 } ) // inherits the default collation 插入少量名称: db.names.insert( [ { first_name: \"Betsy\" }, { first_name: \"BETSY\"}, { first_name: \"betsy\"} ] ) 对该集合的查询默认情况下使用指定的排序规则，如果可能还使用索引。 db.names.find( { first_name: \"betsy\" } ) // inherits the default collation: { collation: { locale: 'en_US', strength: 2 } } // finds three results 上述操作使用集合的默认排序规则并查找所有三个文档。它使用' first_name '字段上的索引以获得更好的性能。 通过在查询中指定不同的排序规则，仍然可以对这个集合执行区分大小写的搜索: db.names.find( { first_name: \"betsy\" } ).collation( { locale: 'en_US' } ) // does not use the collection's default collation, finds one result 上面的操作只找到一个文档，因为它使用的排序规则没有指定strength值。它不使用集合的默认排序规则或索引。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/Partial-Indexes.html":{"url":"08-indexes/10-index-properties/Partial-Indexes.html","title":"部分索引","keywords":"","body":" 部分索引 在本页面 创建部分索引 行为 限制 例子 新版本3.2. 部分索引只索引集合中满足指定筛选器表达式的文档。通过索引集合中文档的子集，部分索引可以降低存储需求，并降低创建和维护索引的性能成本。 创建部分索引 使用db.collection.createIndex()方法和'partialFilterExpression'选项。“partialFilterExpression”选项接受指定筛选条件的文档，使用: 等式表达式（即 运算符），field: value$eq $exists: true 表达， $gt，$gte，$lt，$lte表情， $type 表达式， $and 只在顶层操作符 例如，下面的操作创建一个复合索引，该索引只对“rating”字段大于5的文档进行索引。 db.restaurants.createIndex( { cuisine: 1, name: 1 }, { partialFilterExpression: { rating: { $gt: 5 } } } ) 你可以为所有的MongoDB索引类型,指定一个partialFilterExpression选项. 行为 查询范围 如果使用索引导致结果集不完整，则MongoDB不会将部分索引用于查询或排序操作。 若要使用部分索引，查询必须将筛选器表达式(或指定筛选器表达式子集的经过修改的筛选器表达式)作为其查询条件的一部分。 例如，给定以下索引: db.restaurants.createIndex( { cuisine: 1 }, { partialFilterExpression: { rating: { $gt: 5 } } } ) 下面的查询可以使用索引，因为查询谓词包含条件“rating: {$gte: 8}”，它匹配索引筛选器表达式“rating: {$gt: 5}”匹配的文档子集: db.restaurants.find( { cuisine: \"Italian\", rating: { $gte: 8 } } ) 但是，以下查询不能在“cuisine”字段上使用部分索引，因为使用该索引会导致不完整的结果集。具体来说，查询谓词包括条件rating: {$lt: 8}，而索引有过滤器rating: {$gt: 5}。也就是说，查询{cuisine: \"Italian\"， rating: {$lt: 8}}匹配的文档(例如，一家评级为1的意大利餐厅)比编入索引的文档更多。 db.restaurants.find( { cuisine: \"Italian\", rating: { $lt: 8 } } ) 类似地，以下查询不能使用部分索引，因为查询谓词不包括筛选器表达式，并且使用索引将返回不完整的结果集。 db.restaurants.find( { cuisine: \"Italian\" } ) 与“sparse”索引进行比较 提示 部分索引代表sparse索引提供的功能的超集，应优先于sparse索引。 部分索引提供了一种比sparse索引索引更有表现力的机制来指定索引哪些文档。 Sparse索引根据索引字段的存在性选择文档进行索引，对于复合索引则根据索引字段的存在性选择文档。 部分索引根据指定的筛选器确定索引项。过滤器可以包括索引键以外的字段，并可以指定条件，而不仅仅是存在检查。例如，部分索引可以实现与sparse索引相同的行为: db.contacts.createIndex( { name: 1 }, { partialFilterExpression: { name: { $exists: true } } } ) 此部分索引支持与“name”字段上的sparse索引相同的查询。 但是，部分索引还可以在索引键以外的字段上指定筛选器表达式。例如，下面的操作创建了一个部分索引，其中索引在name字段上，但是过滤器表达式在email字段上: db.contacts.createIndex( { name: 1 }, { partialFilterExpression: { email: { $exists: true } } } ) 为了让查询优化器选择此部分索引，查询谓词必须包含“name”字段上的条件，以及“email”字段上的非空匹配。 例如，下面的查询可以使用索引，因为它包括' name '字段上的条件和' email '字段上的非空匹配: db.contacts.find( { name: \"xyz\", email: { $regex: /\\.org$/ } } ) 但是，以下查询不能使用索引，因为它在“email”字段上包含了一个null匹配，这是过滤器表达式{email: {$exists: true}}不允许的: db.contacts.find( { name: \"xyz\", email: { $exists: false } } ) 限制 在MongoDB中，您不能创建仅在选项上有所不同的多个索引版本。因此，您不能创建仅因过滤器表达式而不同的多个部分索引。 您不能同时指定partialFilterExpression选项和sparse选项。 MongoDB 3.0或更早版本不支持部分索引。要使用部分索引，必须使用MongoDB 3.2或更高版本。对于分片集群或复制集，所有节点必须是版本3.2或更高。 _id索引不能是部分索引。 分片键索引不能是部分索引。 例子 在集合上创建部分索引 考虑包含类似于以下文档的集合restaurants { \"_id\" : ObjectId(\"5641f6a7522545bc535b5dc9\"), \"address\" : { \"building\" : \"1007\", \"coord\" : [ -73.856077, 40.848447 ], \"street\" : \"Morris Park Ave\", \"zipcode\" : \"10462\" }, \"borough\" : \"Bronx\", \"cuisine\" : \"Bakery\", \"rating\" : { \"date\" : ISODate(\"2014-03-03T00:00:00Z\"), \"grade\" : \"A\", \"score\" : 2 }, \"name\" : \"Morris Park Bake Shop\", \"restaurant_id\" : \"30075445\" } 您可以在borough和cuisine字段上添加部分索引，仅选择索引rating.grade 字段为的文档A： db.restaurants.createIndex( { borough: 1, cuisine: 1 }, { partialFilterExpression: { 'rating.grade': { $eq: \"A\" } } } ) 然后，对restaurants集合的以下查询使用部分索引返回Bronx中rating.grade等于的餐厅A： db.restaurants.find( { borough: \"Bronx\", 'rating.grade': \"A\" } ) 但是，以下查询不能使用部分索引，因为查询表达式不包含该rating.grade字段： db.restaurants.find( { borough: \"Bronx\", cuisine: \"Bakery\" } ) 具有唯一约束的部分索引 部分索引仅索引集合中符合指定过滤器表达式的文档。如果同时指定 partialFilterExpression和约束，则唯一约束仅适用于满足过滤器表达式的文档。如果文档不符合过滤条件，则具有唯一约束的部分索引不会阻止插入不符合唯一约束的文档。 例如，集合users包含以下文档: { \"_id\" : ObjectId(\"56424f1efa0358a27fa1f99a\"), \"username\" : \"david\", \"age\" : 29 } { \"_id\" : ObjectId(\"56424f37fa0358a27fa1f99b\"), \"username\" : \"amanda\", \"age\" : 35 } { \"_id\" : ObjectId(\"56424fe2fa0358a27fa1f99c\"), \"username\" : \"rajiv\", \"age\" : 57 } 下面的操作创建了一个索引，该索引在“username”字段上指定了一个unique constraint和一个部分过滤表达式age: {$gte: 21}。 db.users.createIndex( { username: 1 }, { unique: true, partialFilterExpression: { age: { $gte: 21 } } } ) 由于指定用户名的文档已经存在，且“age”字段大于21，因此索引防止插入以下文档: db.users.insert( { username: \"david\", age: 27 } ) db.users.insert( { username: \"amanda\", age: 25 } ) db.users.insert( { username: \"rajiv\", age: 32 } ) 但是，允许使用重复用户名的以下文档，因为唯一约束只适用于“age”大于或等于21的文档。 db.users.insert( { username: \"david\", age: 20 } ) db.users.insert( { username: \"amanda\" } ) db.users.insert( { username: \"rajiv\", age: null } ) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/Sparse-Indexes.html":{"url":"08-indexes/10-index-properties/Sparse-Indexes.html","title":"Sparse索引","keywords":"","body":" Sparse索引 在本页面 创建sparse索引 行为 例子 Sparse索引只包含有索引字段的文档的条目，即使索引字段包含空值。索引会跳过任何缺少索引字段的文档。索引是“稀疏的”，因为它不包括一个集合的所有文档。相反，非稀疏索引包含集合中的所有文档，为那些不包含索引字段的文档存储空值。 重要的 从MongoDB 3.2开始，MongoDB提供了创建部分索引的选项。部分索引提供了sparse索引功能的超集。如果你正在使用MongoDB 3.2或更高版本，部分索引应该比稀疏索引更受欢迎。 创建sparse索引 要创建一个“sparse”索引，使用db.collection.createIndex()方法，并将“sparse”选项设置为“true”。例如，下面的操作在mongo shell中创建了一个稀疏的索引在xmpp_id字段的地址集合: db.addresses.createIndex( { \"xmpp_id\": 1 }, { sparse: true } ) 索引不会索引不包含“xmpp_id”字段的文档。 注意 不要将MongoDB中的sparse索引与其他数据库中的块级索引混淆。可以将它们看作具有特定过滤器的密集索引。 行为 “Sparse”索引和不完整结果 如果sparse索引会导致查询和排序操作的结果集不完整，MongoDB将不会使用该索引，除非hint()明确指定该索引。 例如，查询{x: {$exists: false}}不会在x字段上使用sparse索引，除非有明确提示。参见集合上的稀疏索引不能返回完整的结果了解详细的行为示例。 Changed in version 3.4. 如果在执行集合中所有文档的count()(i.e.带有空查询谓词)时包含 sparse索引count()，则即使sparse索引导致计数不正确，也会使用sparse索引。 db.collection.insert({ _id: 1, y: 1 } ); db.collection.createIndex( { x: 1 }, { sparse: true } ); db.collection.find().hint( { x: 1 } ).count(); 要获得正确的计数，在对集合中的所有文档执行计数时，不要使用sparse索引的“hint()”。 db.collection.find().count(); db.collection.createIndex({ y: 1 }); db.collection.find().hint({ y: 1 }).count(); 默认情况下是“sparse”的索引 2dsphere(版本2)， 2d， geoHaystack和文本索引始终为sparse。 Sparse复合索引 Sparse复合索引只包含升序/降序索引键将索引一个文档，只要该文档包含至少一个键。 包含一个地理空间的稀疏的复合索引键(即2 dsphere, 2d,或geoHaystack索引键)连同升序/降序索引键,只有地理空间的存在领域(s)文档中确定索引文档的引用。 对于包含text索引键和升序/降序索引键的sparse复合索引，只有“text”索引字段的存在决定该索引是否引用一个文档。 “Sparse”和“unique”属性 一个“sparse”和unique索引可以防止集合的文档具有一个字段的重复值，但允许多个文档忽略该键。 例子 在集合上创建sparse索引 考虑一个包含以下文档的集合“scores”: { \"_id\" : ObjectId(\"523b6e32fb408eea0eec2647\"), \"userid\" : \"newbie\" } { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } { \"_id\" : ObjectId(\"523b6e6ffb408eea0eec2649\"), \"userid\" : \"nina\", \"score\" : 90 } 集合在“score”字段上有一个sparse索引: db.scores.createIndex( { score: 1 } , { sparse: true } ) 然后，下面对scores集合的查询使用sparse索引返回score字段小于(' $lt ')的文档90: db.scores.find( { score: { $lt: 90 } } ) 由于userid的文档\"newbie\"不包含该 score字段，因此不满足查询条件，因此查询可以使用sparse索引返回结果： { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } 集合上的sparse索引不能返回完整的结果 考虑一个包含以下文档的集合“scores”: { \"_id\" : ObjectId(\"523b6e32fb408eea0eec2647\"), \"userid\" : \"newbie\" } { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } { \"_id\" : ObjectId(\"523b6e6ffb408eea0eec2649\"), \"userid\" : \"nina\", \"score\" : 90 } 集合在“score”字段上有一个sparse索引: db.scores.createIndex( { score: 1 } , { sparse: true } ) 因为userid的文档 \"newbie\"不包含score字段，所以sparse索引不包含该文档的条目。 考虑以下查询返回scores集合中的所有文档，按score字段排序: db.scores.find().sort( { score: -1 } ) 即使是按索引字段排序，MongoDB也不会选择sparse索引来完成查询，以返回完整的结果: { \"_id\" : ObjectId(\"523b6e6ffb408eea0eec2649\"), \"userid\" : \"nina\", \"score\" : 90 } { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } { \"_id\" : ObjectId(\"523b6e32fb408eea0eec2647\"), \"userid\" : \"newbie\" } 要使用sparse索引，显式地用hint()指定索引: db.scores.find().sort( { score: -1 } ).hint( { score: 1 } ) 使用索引只返回那些带有score字段的文档: { \"_id\" : ObjectId(\"523b6e6ffb408eea0eec2649\"), \"userid\" : \"nina\", \"score\" : 90 } { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } 也可以看看： explain() 和 Analyze Query Performance 具有唯一约束的sparse索引 考虑一个包含以下文档的集合scores: { \"_id\" : ObjectId(\"523b6e32fb408eea0eec2647\"), \"userid\" : \"newbie\" } { \"_id\" : ObjectId(\"523b6e61fb408eea0eec2648\"), \"userid\" : \"abby\", \"score\" : 82 } { \"_id\" : ObjectId(\"523b6e6ffb408eea0eec2649\"), \"userid\" : \"nina\", \"score\" : 90 } 您可以使用以下操作在score字段上创建一个unique constraint和sparse过滤器: db.scores.createIndex( { score: 1 } , { sparse: true, unique: true } ) 该索引将允许插入具有该score字段唯一值或不包含该score字段的文档。这样，鉴于scores集合中现有的文档，索引允许进行以下插入操作： db.scores.insert( { \"userid\": \"AAAAAAA\", \"score\": 43 } ) db.scores.insert( { \"userid\": \"BBBBBBB\", \"score\": 34 } ) db.scores.insert( { \"userid\": \"CCCCCCC\" } ) db.scores.insert( { \"userid\": \"DDDDDDD\" } ) 但是，索引不允许添加以下文件，因为文件已经存在，其score值为82和90: db.scores.insert( { \"userid\": \"AAAAAAA\", \"score\": 82 } ) db.scores.insert( { \"userid\": \"BBBBBBB\", \"score\": 90 } ) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/10-index-properties/Unique-Indexes.html":{"url":"08-indexes/10-index-properties/Unique-Indexes.html","title":"唯一索引","keywords":"","body":" 唯一索引 在本页面 创建唯一索引 行为 唯一索引确保索引字段不会存储重复值;例如，强制索引字段的唯一性。默认情况下，MongoDB在创建集合期间在_id字段上创建一个唯一的索引。 新的内部格式 从MongoDB 4.2开始，对于4.2（或更高版本）的featureCompatibilityVersion（fCV），MongoDB使用一种新的内部格式来存储与早期MongoDB版本不兼容的唯一索引。新格式适用于现有的唯一索引以及新创建/重建的唯一索引。 创建唯一索引 要创建一个唯一的索引，使用db.collection.createIndex()方法，并将unique选项设置为true。 db.collection.createIndex( , { unique: true } ) 单个字段上的唯一索引 例如，要在members集合的user_id字段上创建一个唯一的索引，在mongo shell中使用以下操作: db.members.createIndex( { \"user_id\": 1 }, { unique: true } ) 独特的复合索引 您还可以在复合索引上强制执行唯一约束。如果您在复合索引上使用唯一约束，那么MongoDB将对索引键值的组合执行惟一性。 例如，要在members集合的groupNumber， lastname和firstname字段上创建一个唯一的索引，在mongo shell中使用以下操作: db.members.createIndex( { groupNumber: 1, lastname: 1, firstname: 1 }, { unique: true } ) 创建的索引强制groupNumber、lastname和firstname值的组合的唯一性。 再举一个例子，考虑一个包含以下文档的集合: { _id: 1, a: [ { loc: \"A\", qty: 5 }, { qty: 10 } ] } 创建一个独特的复合multikey索引在a.loc和a.qty: db.collection.createIndex( { \"a.loc\": 1, \"a.qty\": 1 }, { unique: true } ) 唯一索引允许将以下文档插入到集合中，因为索引强制a.loc和a.qty值组合的唯一性： db.collection.insert( { _id: 2, a: [ { loc: \"A\" }, { qty: 5 } ] } ) db.collection.insert( { _id: 3, a: [ { loc: \"A\", qty: 10 } ] } ) 也可以看看： 跨不同文档的唯一约束和唯一索引和丢失字段 行为 限制 如果集合已经包含了违反索引的唯一约束的数据，MongoDB不能在指定的索引字段上创建一个唯一索引。 不能在hashed索引上指定唯一的约束。 在复制集和分片集群上建立唯一索引 对于复制集和分片集群，使用滚动过程创建唯一索引需要在过程中停止对集合的所有写操作。如果不能在过程中停止对集合的所有写操作，则不要使用滚动过程。相反，在集合上建立你的唯一索引: db.collection.createIndex()在主数据库上发布副本集， db.collection.createIndex()在分片mongos群集上发出。 跨不同文档的唯一约束 唯一约束适用于集合中的不同文档。也就是说，唯一索引防止单独的文档对索引键具有相同的值。 因为约束适用于单独的文档,一个独特的多键索引,一个文档可能数组元素,导致重复索引键值,只要文档不重复的索引键值的另一个文档。在本例中，重复索引条目只插入索引一次。 例如，考虑一个包含以下文档的集合: { _id: 1, a: [ { loc: \"A\", qty: 5 }, { qty: 10 } ] } { _id: 2, a: [ { loc: \"A\" }, { qty: 5 } ] } { _id: 3, a: [ { loc: \"A\", qty: 10 } ] } 在a.loc和a.qty上创建唯一的复合多键索引： db.collection.createIndex( { \"a.loc\": 1, \"a.qty\": 1 }, { unique: true } ) 如果集合中的其他文档的索引 key value 为{ \"a.loc\": \"B\", \"a.qty\": null }，则唯一索引允许将以下文档插入到集合中。 db.collection.insert( { _id: 4, a: [ { loc: \"B\" }, { loc: \"B\" } ] } ) 唯一索引和丢失字段 如果文档在唯一索引中没有索引字段的值，索引将为该文档存储空值。由于唯一的约束，MongoDB将只允许一个没有索引字段的文档。如果有多个文档没有索引字段的值或缺少索引字段，索引构建将失败，并出现重复键错误。 例如，一个集合在x上有一个唯一的索引: db.collection.createIndex( { \"x\": 1 }, { unique: true } ) 如果集合中没有包含缺少x字段的文档，唯一索引允许插入没有x字段的文档: db.collection.insert( { y: 1 } ) 但是，如果集合中已经包含了一个没有字段x的文档，则在插入一个没有字段x的文档时出现唯一的索引错误: db.collection.insert( { z: 1 } ) 由于违反了字段x值的唯一约束，操作无法插入文档: WriteResult({ \"nInserted\" : 0, \"writeError\" : { \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error index: test.collection.$a.b_1 dup key: { : null }\" } }) 也可以看看： Unique Partial Indexes 独特的部分索引 3.2版本新增. 部分索引只索引集合中满足指定筛选器表达式的文档。如果您同时指定了partialFilterExpression和一个unique约束，唯一约束只适用于满足筛选器表达式的文档。 如果文档不满足筛选条件，则具有唯一约束的部分索引不会阻止插入不满足唯一约束的文档。例如，请参阅带有唯一约束的部分索引。 分片集群和唯一索引 您不能在hashed索引上指定唯一的约束。 对于一个范围分片集合，只有以下索引可以是唯一的: 分片键上的索引 一个复合索引，其中片键是一个前缀 默认_id索引；不过，该_id指数仅实施每碎片的唯一性约束，如果该_id字段是不是分片键或片键的前缀。 唯一性和_ID索引 如果_id字段不是分片键或分片键的前缀，_id索引只对每个分片强制唯一性约束，而对各个分片强制而不是。 唯一的索引约束意味着: 对于要分片的集合，如果该集合有其他唯一索引，则不能对该集合进行分片。 对于已经分片的集合，不能在其他字段上创建唯一索引。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/11-index-creation.html":{"url":"08-indexes/11-index-creation.html","title":"Index Builds on Populated Collections","keywords":"","body":" Index Builds on Populated Collections ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Index Builds on Populated Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/11-index-creation/01-build-indexes-on-replica-sets.html":{"url":"08-indexes/11-index-creation/01-build-indexes-on-replica-sets.html","title":"在复制集上建立索引","keywords":"","body":" 在复制集上建立索引 在本页面 注意事项 前提条件 程序 索引构建会影响复制集的性能。默认情况下，MongoDB 4.4及以后版本在所有承载数据的复制集成员上同时构建索引。对于不能容忍由于索引构建而导致性能下降的工作负载，可以考虑使用以下过程以滚动方式构建索引。 滚动索引构建一次最多抽取一个复制集成员(从辅助成员开始)，并在该成员上作为独立的索引构建。构建滚动索引至少需要一次复制集的选择。 注意事项 唯一索引 要使用以下过程创建唯一索引，必须在此过程中停止对集合的所有写操作。 如果在此过程中不能停止对集合的所有写操作，请不要使用此页面上的过程。相反，通过在主节点上为一个副本集发出' db.collection.createIndex() '来在该集合上构建你的唯一索引。 Oplog大小 确保您的oplog足够大，以允许索引或重新索引操作完成，而不会落后太多而无法跟上。参见oplog sizing文档了解更多信息。 前提条件 用于构建唯一索引 要使用以下过程创建唯一索引，必须在索引构建期间停止对集合的所有写操作。否则，复制集成员之间的数据可能会不一致。如果不能停止对集合的所有写操作，请不要使用以下过程创建唯一索引。 程序 重要 以下以滚动方式构建索引的过程适用于复制集部署，而不适用分片集群。有关分片集群的过程，请参阅在分片集群上构建滚动索引。 A. 停止一个辅助节点并作为独立节点重新启动 停止与辅助节点关联的mongod进程。进行以下配置更新后重新启动： 配置文件 如果您正在使用配置文件，请进行以下配置更新: 注释掉replication.replSetName选项。 更改net.port到一个不同的端口。[1]记录原始的端口设置作为注释。 在setParameter部分设置参数' disablelogicalicalsessioncacherefresh '为' true '。 例如，更新后的副本集成员配置文件将包括如下示例所示的内容: net: bindIp: localhost, port: 27217 port: 27017 replication: replSetName: myRepl setParameter: disableLogicalSessionCacheRefresh: true 其他设置（例如storage.dbPath等）保持不变。 并重新启动: mongod --config 命令行选项 如果使用命令行选项，请进行以下配置更新: 删除---复制集。 修改---端口到另一个端口。 在---setParameter选项中设置参数disableLogicalSessionCacheRefresh为true 例如，如果你的复制集成员通常运行在默认端口27017和----replSet选项，你应该指定一个不同的端口，省略----replSet选项，并设置disableLogicalSessionCacheRefresh参数为true: mongod --port 27217 --setParameter disableLogicalSessionCacheRefresh=true 其他设置（例如--dbpath等）保持不变。 B. 建立索引 直接连接到mongod实例作为一个独立的运行在新的端口上，并为这个实例创建新的索引。 例如，将mongo连接到实例，然后使用createIndex()来username在records集合的字段上创建升序索引： db.records.createIndex( { username: 1 } ) C. 重新启动程序mongod作为复制集成员 索引构建完成后，关闭mongod 实例。撤消以独立版本启动时所做的配置更改，以返回其原始配置并以复制集的成员身份重新启动。 重要 一定要删除' disableLogicalSessionCacheRefresh '参数。 例如，重新启动复制集成员: 配置文件 如果您正在使用配置文件: 恢复到原始端口号。 取消replication.replSetName的注释。 删除setParameter中的参数' disableLogicalSessionCacheRefresh '。 例如： copycopied net: bindIp: localhost, port: 27017 replication: replSetName: myRepl Other settings (e.g. storage.dbPath, etc.) remain the same. 并重新启动 mongod --config 命令行选项 如果您正在使用配置文件: 恢复到原始端口号 包括----replSet选项。 删除参数disableLogicalSessionCacheRefresh。 例如： mongod --port 27017 --replSet myRepl 其他设置（例如--dbpath等）保持不变。 D.重复其余的步骤 一旦该成员赶上集合中的其他成员，请对其余的次要成员一次重复一个成员的过程： A.停止一个辅助节点并以独立方式重新启动 B.建立索引 C.重新启动程序mongod作为副本集成员 E. 在主服务器上构建索引 当所有的辅助服务器都有了新的索引时，从主服务器下走一步，使用上面描述的过程作为一个独立的程序重新启动它，并在前主服务器上构建索引: 使用mongo shell中的rs.stepDown()方法mongo降低主数据库的性能。成功降级后，当前的主节点将成为辅助节点，复制集成员将选择新的主节点。 A.停止一个辅助节点并以独立方式重新启动 B.建立索引 C.重新启动程序mongod作为副本集成员 参见 原文 - Rolling Index Builds on Replica Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/11-index-creation/02-build-indexes-on-sharded-clusters.html":{"url":"08-indexes/11-index-creation/02-build-indexes-on-sharded-clusters.html","title":"在分片群集上建立滚动索引","keywords":"","body":" 在分片群集上建立滚动索引 在本页面 注意事项 前提条件 程序 附加信息 索引构建会影响分片集群的性能。默认情况下，MongoDB 4.4及以后版本在所有承载数据的复制集成员上同时构建索引。基于分片集群的索引仅发生在那些包含被索引的集合数据的分片上。对于不能容忍由于索引构建而导致性能下降的工作负载，可以考虑使用以下过程以滚动方式构建索引。 滚动索引构建一次最多取出一个碎片复制集成员(从辅助成员开始)，并在该成员上作为一个独立的成员构建索引。构建滚动索引需要每个碎片至少进行一次复制集选择。 注意事项 唯一索引 要使用以下过程创建唯一索引，必须在此过程中停止对集合的所有写操作。 如果在此过程中无法停止对集合的所有写操作，请不要使用此页面上的过程。相反，可以通过db.collection.createIndex()在分片mongos群集上发出来在集合上构建唯一索引。 Oplog大小 确保您的oplog足够大，以允许索引或重新索引操作完成，而不会落后太多而无法跟上。参见oplog sizing文档了解更多信息。 前提条件 用于构建唯一索引 1.要使用以下过程创建唯一索引，必须在索引生成期间停止对集合的所有写操作。否则，复制集成员之间的数据可能会不一致。如果 不能停止对集合的所有写操作，请不要使用以下过程创建唯一索引。 警告 如果不能停止对集合的所有写操作，请不要使用以下过程创建唯一索引。 2.在创建索引之前，验证集合中没有文档违反索引约束。如果一个集合分布在多个切片上，而一个切片中包含有重复文档的块，那么 创建索引操作可能在没有重复的切片上成功，但在有重复的切片上失败。为了避免在多个碎片之间留下不一致的索引，可以从 mongos中发出db.collection.dropIndex()来从集合中删除索引。 程序 重要 以下以滚动方式构建索引的过程适用于分片集群部署，而不适用于复制集部署。关于复制集的过程，请参见复制集上的滚动索引构建。 A. 停止平衡器 将mongoshell连接到分片mongos 群集中的实例，然后运行sh.stopBalancer()以禁用平衡器: sh.stopBalancer() 注意 如果迁移正在进行中，系统将在停止平衡器之前完成迁移。 要验证均衡器被禁用，运行sh.getBalancerState()，如果均衡器被禁用，将返回false: sh.getBalancerState() B. 确定集合的分布 在mongoshell连接程序 mongos，刷新缓存的路由表， mongos以免返回该集合的陈旧分发信息。刷新后，运行 db.collection.getShardDistribution()要构建索引的集合。 例如，如果您想在test 数据库的records集合上使用升序索引: db.adminCommand( { flushRouterConfig: \"test.records\" } ); db.records.getShardDistribution(); 该方法输出切分分布。例如，考虑一个分片集群，有3个分片' shardA '、' shardB '和' shardC '， ' db.collection.getShardDistribution() '返回以下结果: Shard shardA at shardA/s1-mongo1.example.net:27018,s1-mongo2.example.net:27018,s1-mongo3.example.net:27018 data : 1KiB docs : 50 chunks : 1 estimated data per chunk : 1KiB estimated docs per chunk : 50 Shard shardC at shardC/s3-mongo1.example.net:27018,s3-mongo2.example.net:27018,s3-mongo3.example.net:27018 data : 1KiB docs : 50 chunks : 1 estimated data per chunk : 1KiB estimated docs per chunk : 50 Totals data : 3KiB docs : 100 chunks : 2 Shard shardA contains 50% data, 50% docs in cluster, avg obj size on shard : 40B Shard shardC contains 50% data, 50% docs in cluster, avg obj size on shard : 40B 从输出中，您只为test构建索引。记录在shardA和shardC。 C. 在包含集合块的碎片上构建索引 对于包含集合块的每个分片，遵循以下过程在分片上构建索引。 C1. 停止一个辅助设备并独立重启 对于受影响的分片，停止mongod与其辅助节点之一相关联的过程。在进行以下配置更新后重新启动: 配置文件 如果您正在使用配置文件，请进行以下配置更新: 将net.port更改为其他端口。记下原始端口设置作为注释。 注释掉该replication.replSetName选项。 注释掉该sharding.clusterRole选项。 在部分skipShardingConfigurationChecks 中将参数设置（也适用于MongoDB 3.6.3 +，3.4.11 +，3.2.19 +） truesetParameter 在设置参数部分将参数disableLogicalSessionCacheRefresh设置为true。 例如，对于一个分片复制集成员，更新后的配置文件将包括如下示例所示的内容: net: bindIp: localhost, port: 27218 port: 27018 replication: replSetName: shardA sharding: clusterRole: shardsvr setParameter: skipShardingConfigurationChecks: true disableLogicalSessionCacheRefresh: true 并重新启动: mongod --config 其他设置(例如' storage.dbPath '等)保持不变。 命令行选项 如果使用命令行选项，请进行以下配置更新: 修改--port为其他端口。 删除--replSet。 --shardsvr如果分片成员和--configsvr配置服务器成员则删除。 在--setParameter选项中将参数skipShardingConfigurationChecks (也可用于MongoDB 3.6.3+、3.4.11+、3.2.19+)设置为true。 在 --setParameter选项中设置参数disableLogicalSessionCacheRefresh为true。 例如，重新启动不带--replSet和 --shardsvr选项的分片副本集成员。指定新的端口号，并将skipShardingConfigurationChecks和 disableLogicalSessionCacheRefresh参数都设置 为true： mongod --port 27218 --setParameter skipShardingConfigurationChecks=true --setParameter disableLogicalSessionCacheRefresh=true 其他设置（例如--dbpath等）保持不变。 C2. 建立索引 直接连接到' mongod '实例作为一个独立的运行在新的端口上，并为这个实例创建新的索引。 例如，将mongoshell连接到实例，并使用db.collection.createIndex()方法username在records 集合的字段上创建升序索引： db.records.createIndex( { username: 1 } ) C3. 重新启动程序 mongod 作为复制集成员 当索引构建完成时，关闭' mongod '实例。撤销作为独立启动时所做的配置更改，以返回原始配置并重新启动。 重要 一定要删除' skipShardingConfigurationChecks '参数和' disableLogicalSessionCacheRefresh '参数。 例如，重新启动你的复制集分片成员: 配置文件 如果您正在使用配置文件，请进行以下配置更新: 恢复为原始端口号。 取消注释replication.replSetName。 取消注释sharding.clusterRole。 skipShardingConfigurationChecks 在该setParameter部分中删除参数。 disableLogicalSessionCacheRefresh 在该setParameter部分中删除参数。 net: bindIp: localhost, port: 27018 replication: replSetName: shardA sharding: clusterRole: shardsvr 其他设置(例如' storage.dbPath '等)保持不变。 并重新启动： mongod --config 命令行选项 如果使用命令行选项，请进行以下配置更新: 恢复为原始端口号。 包括--replSet。 包括分片--shardsvr成员或--configsvr配置服务器成员。 删除参数 skipShardingConfigurationChecks。 删除参数disableLogicalSessionCacheRefresh。 例如： mongod --port 27018 --replSet shardA --shardsvr 其他设置（例如--dbpath等）保持不变。 C4. 对分片的其他次要数据重复此过程 一旦该成员赶上了集合中的其他成员，就对分片中剩余的次要成员一次重复这个过程: C1.停止一台备用服务器并独立启动 C2.建立索引 C3.重新启动程序mongod作为副本集成员 C5. 在主服务器上构建索引 当分片的所有辅助数据库都具有新索引时，请降低分片的主数据库，使用上述步骤以独立方式重新启动它，然后在前一个主数据库上建立索引: 使用外壳程序中的rs.stepDown()方法mongo降低主数据库的性能。成功降级后，当前的主节点将成为辅助节点，复制集成员将选择新的主节点。 C1.停止一台备用服务器并独立启动 C2.建立索引 C3.重新启动程序mongod作为副本集成员 D. 对其他受影响的分片重复此操作 在为切分构建完索引之后，重复C]。在包含集合块的切分上为其他受影响的切分构建索引。 一旦完成了为分片建立索引，请重复步骤 C .在包含集合块的碎片上构建索引为其他受影响的分片建立索引。 E.重新启动平衡器 为受影响的分片完成滚动索引构建后，重新启动平衡器。 将mongoshell连接到分片mongos 群集中的实例，然后运行sh.startBalancer()： sh.startBalancer() 附加信息 如果在包含集合块的每个分片上没有完全相同的索引(包括索引选项)，则分片集合具有不一致的索引。虽然在正常操作中不应该出现索引不一致的情况，但也会出现索引不一致的情况，例如: 当用户正在创建一个索引，一个“唯一”的关键约束和一个分片包含块与重复的文档。在这种情况下，创建索引操作可能在没有重复的分片上成功，但在有重复的切分上失败。 当用户以滚动方式在多个切片之间创建索引，但要么未能为关联的切片建立索引，要么不正确地建立了不同规格的索引。 从MongoDB 4.4（和4.2.6）开始，配置服务器主服务器会定期检查分片集合中各分片之间的索引不一致。要配置这些定期检查，请参阅 enableShardedIndexConsistencyCheck和 shardedIndexConsistencyCheckIntervalMS。 当在配置服务器主服务器上运行时，该命令serverStatus返回该字段 shardedIndexConsistency以报告索引不一致情况。 要检查分片集合是否具有不一致的索引，请参阅 查找分片中的不一致索引。 参见 原文 - Rolling Index Builds on Sharded Clusters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/12-index-intersection.html":{"url":"08-indexes/12-index-intersection.html","title":"索引交集","keywords":"","body":" 索引交集 在本页面 索引前缀交集 索引交集和复合索引 索引交集和排序 MongoDB可以使用多个索引的交集来完成查询。通常，每个索引交集涉及两个索引。但是，MongoDB可以使用多个/嵌套索引交集来解析查询。 为了说明索引交集，请考虑orders具有以下索引的集合： { qty: 1 } { item: 1 } MongoDB可以使用两个索引的交集来支持以下查询： db.orders.find( { item: \"abc123\", qty: { $gt: 15 } } ) 要确定MongoDB是否使用了索引交集，运行 explain();explain()的结果将包括AND_SORTED阶段或AND_HASH阶段。 索引前缀交集 使用索引交集，MongoDB可以使用整个索引或索引前缀的交集。索引前缀是复合索引的子集，由一个或多个从索引开头开始的键组成。 考虑orders具有以下索引的集合： { qty: 1 } { status: 1, ord_date: -1 } 为了完成以下查询，它在qty字段和status字段上都指定了一个条件，MongoDB可以使用两个索引的交集: db.orders.find( { qty: { $gt: 10 } , status: \"A\" } ) 索引交集和复合索引 索引交集并不能消除创建复合索引的需要 。但是，由于复合索引中的列表顺序（即，键在索引中的列出顺序）和排序顺序（即，升序或降序）都很重要 ，因此复合索引可能不支持不包含以下内容的查询条件：该指数的前缀键，或者指定一个不同的排序顺序。 例如，如果一个集合orders具有以下复合索引，且该status字段在字段之前列出ord_date： { status: 1, ord_date: -1 } 复合索引可以支持以下查询： db.orders.find( { status: { $in: [\"A\", \"P\" ] } } ) db.orders.find( { ord_date: { $gt: new Date(\"2014-02-01\") }, status: {$in:[ \"P\", \"A\" ] } } ) 但不是以下两个查询： db.orders.find( { ord_date: { $gt: new Date(\"2014-02-01\") } } ) db.orders.find( { } ).sort( { ord_date: 1 } ) 但是，如果集合具有两个单独的索引： { status: 1 } { ord_date: -1 } 这两个索引可以单独或通过索引交集来支持所有上述四个查询。 创建支持查询的复合索引还是依赖索引交集之间的选择取决于系统的具体情况。 也可以看看 复合索引， 创建复合索引以支持多个不同的查询 索引交集和排序 当sort() 操作要求索引与查询谓词完全分开时，索引交集不适用。 例如，该orders集合具有以下索引： { qty: 1 } { status: 1, ord_date: -1 } { status: 1 } { ord_date: -1 } MongoDB不能对以下带有排序的查询使用索引交集： db.orders.find( { qty: { $gt: 10 } } ).sort( { status: 1 } ) 也就是说，MongoDB不会将索引用于查询，而将单独索引或索引用于排序。{ qty: 1 }``{ status: 1 }``{ status: 1, ord_date: -1 } 也就是说，MongoDB不使用{ qty: 1 }索引进行查询，使用单独的{ status: 1 }或{ status: 1, ord_date: -1 }索引进行排序。 然而，MongoDB可以使用索引交集来进行以下排序查询，因为索引{ status: 1, ord_date: -1 }可以完成部分查询谓词。 db.orders.find( { qty: { $gt: 10 } , status: \"A\" } ).sort( { ord_date: -1 } ) 参见 原文 - Index Intersection Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/13-manage-indexes.html":{"url":"08-indexes/13-manage-indexes.html","title":"Manage Indexes","keywords":"","body":" Manage Indexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/14-measure-index-use.html":{"url":"08-indexes/14-measure-index-use.html","title":"衡量索引使用","keywords":"","body":" 衡量索引使用 在本页面 使用$indexStats度量索引使用 使用 explain()返回查询计划 使用hint()控制索引使用 索引指标 使用$indexStats度量索引使用 使用$indexStats 聚合阶段获取关于集合中每个索引的使用情况的统计信息。例如，以下聚合操作返回关于orders集合中索引使用情况的统计信息: db.orders.aggregate( [ { $indexStats: { } } ] ) 也可参考： $indexStats 使用 explain()返回查询计划 在executionStats 模式中使用db.collection.explain() 或cursor.explain()方法返回关于查询过程的统计信息，包括使用的索引、扫描的文档数量以及查询处理所用的时间(以毫秒为单位)。 在allPlansExecution 模式下使用 db.collection.explain() 或cursor.explain()方法查看计划选择期间收集的部分执行统计信息。 也可参考： planCacheKey 使用hint()控制索引使用 要强制MongoDB为db.collection.find()操作使用特定的索引，请使用hint()方法指定该索引。将hint()方法附加到find()方法。考虑下面的例子: 代码示例如下： db.people.find( { name: \"John Doe\", zipcode: { $gt: \"63000\" } } ).hint( { zipcode: 1 } ) 查看使用特定索引的执行统计信息，在db.collection.find()语句追加的hint()方法后跟随cursor.explain()方法，代码示例如下： db.people.find( { name: \"John Doe\", zipcode: { $gt: \"63000\" } } ).hint( { zipcode: 1 } ).explain(\"executionStats\") 或者在db.collection.explain().find()方法后追加hint()方法。 db.people.explain(\"executionStats\").find( { name: \"John Doe\", zipcode: { $gt: \"63000\" } } ).hint( { zipcode: 1 } ) 在hint()方法中声明$natural参数，避免MongoDB在查询过程中使用任何索引。 db.people.find( { name: \"John Doe\", zipcode: { $gt: \"63000\" } } ).hint( { $natural: 1 } ) 索引指标 除了$indexStats聚合阶段，MongoDB提供了各种索引统计数据，您可能想要考虑分析索引使用您的数据库: 在serverStatus方法的输出结果中： metrics.queryExecutor.scanned和metrics.operation.scanAndOrder 在collStats输出结果中 totalIndexSize和indexSizes 在dbStats输出结果中 dbStats.indexes和dbStats.indexSize 译者：程哲欣 参见 原文 - Measure Index Use Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/15-indexes.html":{"url":"08-indexes/15-indexes.html","title":"Indexing Strategies","keywords":"","body":" Indexing Strategies ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Indexing Strategies Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/15-indexes/01-create-indexes-to-support-queries.html":{"url":"08-indexes/15-indexes/01-create-indexes-to-support-queries.html","title":"创建索引来支持查询","keywords":"","body":" 创建索引来支持查询 在本页面 如果所有查询都使用相同的单键，则创建单键索引 创建复合索引以支持几种不同的查询 索引使用和排序 当索引包含查询扫描的所有字段时，索引就支持查询。查询扫描的是索引而不是集合。创建支持查询的索引可以极大地提高查询性能。 本文档描述创建支持查询的索引的策略。 如果所有查询使用相同的单键，则创建单键索引 如果只查询给定集合中的单个键，则只需为该集合创建一个单键索引。例如，您可以在product集合中创建category索引: db.products.createIndex( { \"category\": 1 } ) 创建复合索引来支持几个不同的查询 如果有时只查询一个键，而有时又查询该键和第二个键的组合，那么创建复合索引比创建单键索引更有效。MongoDB将对两个查询使用复合索引。例如，您可以在category和两者上创建索引item。 db.products.createIndex( { \"category\": 1, \"item\": 1 } ) 这允许您两个选择。您可以只查询category，也可以与category组合查询item。多个字段上的单个复合索引可以支持所有搜索这些字段的“前缀”子集的查询。 例子 以下是一个集合的索引: { x: 1, y: 1, z: 1 } 以下索引可以支持查询: { x: 1 } { x: 1, y: 1 } 在某些情况下，前缀索引可能提供更好的查询性能:例如，如果' z '是一个大数组。 {x: 1, y: 1, z: 1}索引也可以支持与以下索引相同的许多查询: { x: 1, z: 1 } 此外，{x: 1, z: 1}还有其他用途。给定以下查询: db.collection.find( { x: 5 } ).sort( { z: 1} ) {x: 1, z: 1}索引同时支持查询和排序操作，而{x: 1, y: 1, z: 1}索引只支持查询。有关排序的更多信息，请参见使用索引对查询结果排序。 从2.6版本开始，MongoDB可以使用索引交集来完成查询。是创建支持查询的复合索引，还是依赖索引交集，这取决于系统的具体情况。更多细节请参见索引交集和复合索引。 索引的使用和排序 若要使用索引进行字符串比较，操作还必须指定相同的排序规则。也就是说，如果索引指定了不同的排序规则，则具有排序规则的索引不能支持对索引字段执行字符串比较的操作。 例如，集合' myColl '在字符串字段' category '上有一个索引，其排序区域设置为' fr'。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 下面的查询操作指定了与索引相同的排序规则，可以使用索引: db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作，默认使用“simple”二进制排序器，不能使用索引: db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是字符串、数组和嵌入文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 例如，集合' myColl '在数值字段score和price以及字符串字段category上有一个复合索引;索引是用collation locale \"fr\" 创建的，用于字符串比较: db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 以下使用 \"simple\" 二进制排序来进行字符串比较的操作可以使用索引: db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 下面的操作使用 \"simple\"二进制排序对索引的category字段进行字符串比较，可以使用索引来完成查询的score: 5部分: db.myColl.find( { score: 5, category: \"cafe\" } ) 参见 原文 - Create Indexes to Support Your Queries Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/15-indexes/02-sort-results-with-indexes.html":{"url":"08-indexes/15-indexes/02-sort-results-with-indexes.html","title":"Use Indexes to Sort Query Results","keywords":"","body":" Use Indexes to Sort Query Results ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Use Indexes to Sort Query Results Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/15-indexes/03-ensure-indexes-fit-ram.html":{"url":"08-indexes/15-indexes/03-ensure-indexes-fit-ram.html","title":"确保索引适合RAM","keywords":"","body":" 确保索引适合RAM 在本页面 仅在RAM中保存最近值的索引 为了实现最快的处理，请确保索引完全适合RAM，以便系统可以避免从磁盘读取索引。 要检查索引的大小，使用 db.collection.totalIndexSize() 帮助器，该帮助程序以字节为单位返回数据： > db.collection.totalIndexSize() 4294976499 上面的示例显示了一个接近4.3GB的索引大小。为了确保该索引适合RAM，您不仅必须拥有多于该数量的可用RAM，而且还必须为其余工作集提供RAM 。还请记住： 如果您拥有并使用多个集合，则必须考虑所有集合上所有索引的大小。索引和工作集必须能够同时装入内存。 在一些有限的情况下，索引不需要装入内存。参见只在RAM中保存最近值的索引。 也可以看看： collStats 和 db.collection.stats() 仅在RAM中保存最近值的索引 索引不必在所有情况下都完全适合RAM。如果索引字段的值随每次插入而增加，并且大多数查询选择最近添加的文档；那么MongoDB只需要将索引中保留最新或“最右边”值的部分保留在RAM中。这样可以有效地将索引用于读取和写入操作，并最大程度地减少支持索引所需的RAM数量。 参见 原文 - Ensure Indexes Fit in RAM Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/15-indexes/04-create-queries-that-ensure-selectivity.html":{"url":"08-indexes/15-indexes/04-create-queries-that-ensure-selectivity.html","title":"创建以确保选择性的查询","keywords":"","body":" 创建以确保选择性的查询 选择性是指查询使用索引缩小结果的能力。有效的索引更具选择性，允许MongoDB使用索引来完成与完成查询相关的大部分工作。 为了确保选择性，编写限制索引字段可能的文档数量的查询。编写相对于索引数据具有适当选择性的查询。 例子 假设您有一个名为“status”的字段，其中可能的值是new和processing。如果你在“status”上添加索引，你就创建了一个低选择性的索引。索引在查找记录方面帮助不大。 根据您的查询，一种更好的策略是创建一个包含低选择性字段和另一个字段的 复合索引。例如，您可以在status和上创建复合索引created_at. 另一个选择，同样取决于您的用例，可能是使用单独的集合，每个状态一个集合。 例子 考虑一个集合上的索引{a: 1}(即键“a”按升序排序的索引)，其中“a”有三个值均匀分布在集合中: { _id: ObjectId(), a: 1, b: \"ab\" } { _id: ObjectId(), a: 1, b: \"cd\" } { _id: ObjectId(), a: 1, b: \"ef\" } { _id: ObjectId(), a: 2, b: \"jk\" } { _id: ObjectId(), a: 2, b: \"lm\" } { _id: ObjectId(), a: 2, b: \"no\" } { _id: ObjectId(), a: 3, b: \"pq\" } { _id: ObjectId(), a: 3, b: \"rs\" } { _id: ObjectId(), a: 3, b: \"tv\" } 如果你查询{a: 2, b: \"no\"}， MongoDB必须扫描3个文档在集合中返回一个匹配的结果。类似地，{a: {$gt: 1}， b: \"tv\"}的查询必须扫描6个文档，也要返回一个结果。 考虑一个集合上的相同索引，其中“a”有9 个值均匀分布在整个集合中: { _id: ObjectId(), a: 1, b: \"ab\" } { _id: ObjectId(), a: 2, b: \"cd\" } { _id: ObjectId(), a: 3, b: \"ef\" } { _id: ObjectId(), a: 4, b: \"jk\" } { _id: ObjectId(), a: 5, b: \"lm\" } { _id: ObjectId(), a: 6, b: \"no\" } { _id: ObjectId(), a: 7, b: \"pq\" } { _id: ObjectId(), a: 8, b: \"rs\" } { _id: ObjectId(), a: 9, b: \"tv\" } 如果您查询{a: 2, b: \"cd\"}， MongoDB必须只扫描一个文档来完成查询。索引和查询更具选择性，因为' a '的值是均匀分布的，和查询可以使用索引选择特定的文档。 然而，尽管 a 上的索引更具有选择性，但是像{a: {$gt: 5}， b: \"tv\"}这样的查询仍然需要扫描4个文档。 如果整体选择性很低，并且MongoDB必须读取大量文档才能返回结果，那么有些查询在没有索引的情况下可能执行得更快。要确定性能，请参阅度量索引使用。 参见 原文 - Create Queries that Ensure Selectivity Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/16-indexes.html":{"url":"08-indexes/16-indexes.html","title":"Indexing Reference","keywords":"","body":" Indexing Reference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Indexing Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/2d-Indexes.html":{"url":"08-indexes/2d-Indexes.html","title":"2d索引","keywords":"","body":" 2d索引 在本页面 注意事项 行为 sparse 属性 排序选项 对存储为二维平面上的点的数据使用2d索引。2d索引用于MongoDB 2.2和更早版本中使用的旧式坐标对。 在以下情况下使用2d索引： 您的数据库具有来自MongoDB 2.2或更早版本的旧版旧版坐标对, 您不打算将任何位置数据存储为GeoJSON对象。 有关地理空间查询的更多信息，请参见地理空间查询。 注意事项 从MongoDB 4.0开始，您可以在$geoNear管道阶段指定一个关键选项，以指示要使用的索引字段路径。这允许$geoNear阶段被用于包含多个2d索引和/或多个 2dsphere索引的集合: 如果您的集合具有多个2d索引和/或多个 2dsphere索引，则必须使用该key选项来指定要使用的索引字段路径。 如果不指定key，则不能有多个 2d索引和/或多个2dsphere索引，因为如果没有使用key，则多个2d索引或 2dsphere索引之间的索引选择是不明确的。 [success] 注意 如果未指定key，并且最多只有一个 2d索引索引和/或只有一个2d索引索引，则MongoDB首先会寻找2d要使用的索引。如果2d索引不存在，则MongoDB查找2dsphere要使用的索引。 如果位置数据包含GeoJSON对象，则不要使用2d索引。要同时在旧式坐标对 和 GeoJSON对象上建立索引，请使用2dsphere索引。 在对集合进行切分时，不能使用2d索引作为分片键。但是，您可以通过使用不同的字段作为分片键在切分集合上创建地理空间索引。 行为 该2d索引支持在平坦的欧几里德平面上进行的计算。2d索引还支持在球体上只计算距离(即 $nearSphere)，但是对于球体上的几何计算(例如$geoWithin)，将数据存储为GeoJSON objects并使用2dsphere索引。 2d索引可以引用两个字段。第一个必须是位置字段。2d复合索引构造首先在location字段上选择的查询，然后根据附加条件过滤这些结果。复合2d索引可以覆盖查询。 sparse属性 2d索引总是稀疏的并且忽略稀疏选项。如果文档缺少2d索引字段（或者该字段是null或为空数组），则MongoDB不会将文档条目添加到 2d索引中。对于插入，MongoDB会插入文档，但不会添加到2d索引中。 对于包含2d索引键和其他类型的键的复合索引，只有2d索引字段才能确定索引是否引用文档。 排序选项 2d索引仅支持简单的二进制比较，不支持排序选项。 要在具有非简单排序规则的集合上创建2d索引，必须在创建索引时显式指定{collation: {locale: \"simple\"}}。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/2dsphere-Indexes.html":{"url":"08-indexes/2dsphere-Indexes.html","title":"2dsphere索引","keywords":"","body":" 2dsphere索引 在本页面 概述 版本号 注意事项 创建2dsphere索引 概述 2dsphere索引支持计算类似地球的球体上的几何形状的查询。2dsphere索引支持所有MongoDB地理空间查询：包含、相交和邻近度查询。 有关地理空间查询的更多信息，请参见地理空间查询。 2dsphere索引支持存储为GeoJSON对象和旧版坐标对的数据(另请参阅2dsphere索引字段限制)。对于遗留坐标对，索引将数据转换为GeoJSONPoint。 版本号 | 2dsphere索引版本 | 描述 | | ---------------- | ------------------------------------------------------------ | | 版本3 | MongoDB 3.2引入了一个版本3的2dsphere索引。版本3是在MongoDB 3.2和更高版本中创建的2dsphere索引的默认版本。 | | 版本2 | MongoDB 2.6引入了2dsphere索引的版本2。版本2是在MongoDB 2.6和3.0系列中创建的2dsphere索引的默认版本。 | 要覆盖默认版本并指定其他版本，请在创建索引时包含选项{“ 2dsphereIndexVersion”：}。 sparse属性 版本2和更高版本的2dsphere索引始终为sparse且忽略sparse选项。如果文档缺少2dsphere索引所在字段（或者该字段为null或空数组），则MongoDB不会将文档条目添加到索引中。对于插入，MongoDB会插入文档，但不添加到2dsphere索引。对于包含2dsphere索引键以及其他类型键的复合索引，该索引是否引用文档只取决于2dsphere索引字段。 对于包含2dsphere索引键和其他类型的键的复合索引，只有2dsphere索引字段确定索引是否引用文档。 MongoDB的早期版本仅支持2dsphere (Version 1)索引。 默认情况下，2dsphere (Version 1)索引不是sparse索引，并且拒绝该字段为空的文档。 其他GeoJSON对象 版本2和更高版本的2dsphere索引包含对其他GeoJSON对象的支持：MultiPoint，MultiLineString，MultiPolygon和GeometryCollection。有关所有受支持的GeoJSON对象的详细信息，请参见GeoJSON对象。 注意事项 geoNear和$geoNear的限制 从MongoDB 4.0开始，您可以为$geoNear管道指定一个key选项以明确指示要使用的索引字段路径。这使得$geoNear在具有多个2dsphere索引或多个2d索引的文档中也能被使用： 如果您的集合具有多个2dsphere索引或多个2d索引，则必须使用key选项来指定使用哪个索引字段路径。 如果未指定key，您将无法使用多个2dsphere索引或多个2d索引。 因为没有指定key时，在多个2d索引或2dsphere索引中选择索引将变得无法明确。 [success] 注意 如果您不指定key，您将最多只能拥有一个2dsphere索引或一个2dsphere索引，MongoDB首先寻找2d索引。 如果不存在2d索引，则MongoDB会寻找2dsphere索引。 分片键限制 对集合做分片时，不能将2dsphere索引用作分片键。 但是，您可以通过使用一个不同的字段作为分片键来在分片集合上创建地理空间索引。 2dsphere索引字段限制 具有2dsphere索引的字段必须包含坐标对或GeoJSON形式的数据。如果您尝试插入一个在2dsphere索引字段中包含非几何数据的文档，或者在一个索引字段中包含非几何数据的集合上构建2dsphere索引，该操作将失败。 创建2dsphere索引 要创建2dsphere索引，请使用db.collection.createIndex() 方法并指定字符串\"2dsphere\"作为索引类型： db.collection.createIndex( { : \"2dsphere\" } ) 其中的是其值为GeoJSON对象或旧式坐标对的字段。 与只能引用一个位置字段和另一个字段的复合2d索引不同的是，复合2dsphere索引可以引用多个位置字段及非位置字段。 以下示例，基于一个places集合，该集合的文档将位置数据以GeoJSON Point形式存储在loc字段中： db.places.insert( { loc : { type: \"Point\", coordinates: [ -73.97, 40.77 ] }, name: \"Central Park\", category : \"Parks\" } ) db.places.insert( { loc : { type: \"Point\", coordinates: [ -73.88, 40.78 ] }, name: \"La Guardia Airport\", category : \"Airport\" } ) 创建2dsphere索引 以下操作在位置字段loc上创建一个2dsphere索引： db.places.createIndex( { loc : \"2dsphere\" } ) 使用2dsphere索引键创建复合索引 复合索引可以包含2dsphere索引键和非地理空间索引键。例如，以下操作将创建一个复合索引，其中第一个键loc是2dsphere索引键，其余键category和names是非地理空间索引键，并分别指定降序（-1）和升序（1）。 db.places.createIndex( { loc : \"2dsphere\" , category : -1, name: 1 } ) 与2d索引不同，复合2dsphere索引不需要将位置字段作为第一个索引字段。 例如： db.places.createIndex( { category : 1 , loc : \"2dsphere\" } ) 译者：杨帅 周正 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Compound-Indexes.html":{"url":"08-indexes/Compound-Indexes.html","title":"复合索引","keywords":"","body":" 复合索引 在本页面 创建复合索引 排序顺序 前缀 索引交集 其他注意事项 MongoDB支持复合索引，其中单个索引结构持有对集合文档中多个字段 [1]的引用。下图展示了两个字段上的复合索引示例: [1] mongodb对任何复合索引施加32个字段的限制。 复合索引可以支持在多个字段上匹配的查询。 创建复合索引 要创建一个复合索引，使用类似如下原型的操作: db.collection.createIndex( { : , : , ... } ) 索引规范中的字段值描述该字段的索引类型。例如，值1指定按升序对项排序的索引。值-1指定按降序对项排序的索引。有关其他索引类型，请参见索引类型。 [warning] 重要 不能创建具有hashed索引类型的复合索引。如果试图创建包含hashed索引字段的复合索引，将收到一个错误。 考虑一个名为products的集合，它包含类似于以下文档的文档: { \"_id\": ObjectId(...), \"item\": \"Banana\", \"category\": [\"food\", \"produce\", \"grocery\"], \"location\": \"4th Street Store\", \"stock\": 4, \"type\": \"cases\" } 以下操作在item和 stock字段上创建一个升序索引： db.products.createIndex( { \"item\": 1, \"stock\": 1 } ) 复合索引中列出的字段的顺序很重要。索引将包含对文档的引用，这些文档首先按item字段的值排序，然后在该字段的每个值内item，按stock字段的值排序。有关更多信息，请参见排序顺序。 除了支持在所有索引字段上都匹配的查询之外，复合索引还可以支持在索引字段的前缀上匹配的查询。也就是说，索引支持对item字段以及item和stock字段的查询： db.products.find( { item: \"Banana\" } ) db.products.find( { item: \"Banana\", stock: { $gt: 5 } } ) 有关详细信息，请参见前缀。 排序顺序 索引以升序（1）或降序（-1）排序顺序存储对字段的引用。对于单字段索引，键的排序顺序无关紧要，因为MongoDB可以在任一方向上遍历索引。但是，对于复合索引，属性的顺序决定了索引是否支持结果集的排序。 假设一个包含字段username和date的文档的集合事件。应用程序可以发出查询，返回的结果首先按升序username值排序，然后按降序(即从最近到最后)date排序，例如: db.events.find().sort( { username: 1, date: -1 } ) 或先按username 降序再按date升序返回结果的查询，例如: db.events.find().sort( { username: -1, date: 1 } ) 以下索引可以支持这两种排序操作： db.events.createIndex( { \"username\" : 1, \"date\" : -1 } ) 但是，上面的索引不支持先升序username值再升序 date值排序，例如: db.events.find().sort( { username: 1, date: 1 } ) 有关排序顺序和复合索引的更多信息，请参见 使用索引对查询结果进行排序。 前缀 索引前缀是索引字段的开始子集。例如，假设以下复合索引: { \"item\": 1, \"location\": 1, \"stock\": 1 } 索引具有以下索引前缀： { item: 1 } { item: 1, location: 1 } 对于复合索引，MongoDB可以使用索引来支持对索引前缀的查询。这样，MongoDB可以将索引用于以下字段的查询： the item 字段, the item 字段 and the location 字段, the item 字段 and the location 字段 和 the stock 字段. MongoDB还可以使用索引来支持对item和 stock字段的查询，因为item字段对应于一个前缀。但是，在支持查询方面，索引的效率不如只支持item和stock的索引。 然而，MongoDB不能使用索引来支持查询，包括以下字段，因为没有item字段，列出的字段都不对应前缀索引: the location 字段, the stock 字段, the location stock 字段. 如果你有一个集合,复合索引和索引的前缀(例如:{a:1,b: 1}和{a:1}),如果两个索引都没有稀疏约束或唯一约束，那么您可以删除前缀上的索引(例如{a: 1})。MongoDB将在所有使用前缀索引的情况下使用复合索引。 索引交集 从2.6版本开始，MongoDB可以使用索引交集来完成查询。是创建支持查询的复合索引，还是依赖索引交集，这取决于系统的具体情况。有关更多细节，请参见 索引交集和复合索引。 其他注意事项 在索引构建期间，应用程序可能会遇到性能下降，包括对集合的读/写访问受限。有关索引构建过程的更多信息，，请参见 “填充集合上的索引构建”，包括“ 复制环境中的索引构建”部分。 一些驱动程序可能使用NumberLong(1)而不是 1将规范指定为索引。这对结果索引没有任何影响。 译者：莫薇 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/geoHaystack-Indexes.html":{"url":"08-indexes/geoHaystack-Indexes.html","title":"geoHaystack索引","keywords":"","body":" geoHaystack索引 在本页面 行为 sparse 属性 创建geoHaystack索引 “geoHaystack”索引是一种特殊的索引，优化后可以在小范围内返回结果。“geoHaystack”索引提高了使用平面几何图形查询的性能。 对于使用球形几何的查询，2dsphere索引比haystack索引更好。2dsphere索引允许字段重新排序；geoHaystack索引要求第一个字段为位置字段。另外，geoHaystack 索引只能通过命令使用，因此总是一次返回所有结果。 行为 geoHaystack索引从同一地理区域创建文档的“存储桶”，以提高限于该区域的查询的性能。geoHaystack索引中的每个存储段都包含在给定经度和纬度指定邻近范围内的所有文档。 sparse属性 geoHaystack索引默认为sparse，忽略sparse: true选项。如果一个文档缺少一个geoHaystack索引字段(或者该字段是“null”或空数组)，MongoDB不会为该文档添加一个条目到geoHaystack索引中。对于插入，MongoDB插入文档，但不添加到geoHaystack索引。 geoHaystack索引包括一个geoHaystack索引键和一个非地理空间索引键;但是，只有geoHaystack索引字段决定索引是否引用文档。 排序选项 geoHaystack索引只支持简单的二进制比较，不支持collation。 要在具有非简单排序规则的集合上创建geoHaystack索引，必须在创建索引时显式指定{collation: {locale: \"simple\"}}。 创建geoHaystack索引 要创建geoHaystack索引，请参见创建Haystack索引。有关查询haystack索引的信息和示例，请参见查询haystack索引。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Hashed-Indexes.html":{"url":"08-indexes/Hashed-Indexes.html","title":"Hashed 索引","keywords":"","body":" Hashed 索引 在本页面 Hashing 函数 创建Hashed索引 注意事项 Hashed索引使用索引字段值的hashes来维护条目。 Hashed索引支持使用hashes的分片键进行分片。基于Hashed的分片使用字段的散列索引作为分片键，以便跨分片集群对数据进行分区。 使用hashed的分片键对集合进行分片会导致数据分布更加随机。有关更多详细信息，请参见Hashed分片。 Hashing 函数 Hashed索引使用hashing函数来计算索引字段值的哈希。hashing函数折叠嵌入式文档并计算整个值的hash，但不支持多键（即数组）索引。 提示： MongoDB在解析使用已排序索引的查询时自动计算hashed值。应用程序不需要计算hashes。 创建Hashed索引 要创建hashed索引，请指定 hashed 作为索引键的值，如下例所示: db.collection.createIndex( { _id: \"hashed\" } ) 注意事项 MongoDB支持任何单个字段的 hashed 索引。hashing函数折叠嵌入的文档并计算整个值的hash值，但不支持多键(即.数组)索引。 您不能创建具有hashed索引字段的复合索引，也不能在索引上指定唯一约束hashed；但是，您可以hashed在同一字段上创建索引和升序/降序（即非哈希）索引：MongoDB将对范围查询使用标量索引。 253 限制 注意 MongoDB hashed索引在散列之前将浮点数截断为64位整数。例如，hashed指数将存储用于持有的值的字段的值相同2.3，2.2和2.9。为避免冲突，请不要hashed对无法可靠转换为64位整数（然后再返回到浮点数）的浮点数使用索引。MongoDB hashed索引不支持大于253的浮点值。 要查看键的hashed值是多少，请参阅convertShardKeyToHashed()。 查看键对应的hashed请查看convertShardKeyToHashed()。 PowerPC 和263 对于hashed索引，MongoDB 4.2确保PowerPC上浮点值263的hashed值与其他平台一致。 尽管不支持字段上可能包含大于253的浮点值的hashed索引，但客户端仍然可以在索引字段值为263的地方插入文档。 db.adminCommand(\"listDatabases\").databases.forEach(function(d){ let mdb = db.getSiblingDB(d.name); mdb.getCollectionInfos({ type: \"collection\" }).forEach(function(c){ let currentCollection = mdb.getCollection(c.name); currentCollection.getIndexes().forEach(function(idx){ let idxValues = Object.values(Object.assign({}, idx.key)); if (idxValues.includes(\"hashed\")) { print(\"Hashed index: \" + idx.name + \" on \" + idx.ns); printjson(idx); }; }); }); }); 要检查索引字段是否包含值263，对集合和索引字段执行以下操作: 如果一个collection中的索引字段数据内容仅是数值，不存在任何文档： ```powershell // substitute the actual collection name for // substitute the actual indexed field name for db..find( { : Math.pow(2,63) } ); - 如果一个collection中的索引字段是文档(或者数值)，可以执行： ```powershell // substitute the actual collection name for // substitute the actual indexed field name for db..find({ $where: function() { function findVal(obj, val) { if (obj === val) return true; for (const child in obj) { if (findVal(obj[child], val)) { return true; } } return false; } return findVal(this., Math.pow(2, 63)); } }) 译者：程哲欣 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Index-Builds-on-Populated-Collections.html":{"url":"08-indexes/Index-Builds-on-Populated-Collections.html","title":"在填充的集合上建立索引","keywords":"","body":" 在填充的集合上建立索引 在本页面 行为 索引构建对数据库性能的影响 复制集中的索引构建 构建失败和恢复 监视进行中的索引构建 终止进行中的索引构建 索引建立过程 MongoDB 4.2版本新变化 针对已填充的集合的MongoDB索引构建需要对该集合的排他性读写锁定。需要对集合进行读取或写入锁定的操作必须等待，直到mongod释放锁定为止 。MongoDB 4.2使用了优化的构建过程，该过程仅在索引构建的开始和结束时持有排他锁。其余的构建过程将产生交错的读写操作。 索引构建过程总结如下: 初始化 mongod 进程对正在编制索引的集合使用独占锁。所有对该集合的读写操作将阻塞直到mongod 进程释放锁。在此期间，应用程序无法访问集合。 数据摄取和加工 mongod进程释放上一过程中获取的所有锁，然后针对被索引的集合获取一系列意向锁。在此期间，应用程序可以对集合发出读写操作。 清理 mongod进程释放上一过程中获取的所有锁，然后针对被索引集合获取独占锁。这时将阻塞对该集合所有读写操作直到mongod进程释放锁。应用程序此时无法访问该集合。 完成 mongod进程标记索引状态为已可用，然后释放索引构建过程中的所有锁。 索引构建过程中的加锁描述细节参见Index Build Process章节。更深入了解MongoDB的加锁行为参见FAQ: Concurrency。 行为 MongoDB 4.2索引构建完全替代了以前MongoDB版本中支持的索引构建过程。如果指定为createIndexes 或它的shell助手createIndexes()和createIndexes()， MongoDB会忽略后台索引构建选项。 与前景和背景构建进行比较 MongoDB的早期版本支持在前台或后台构建索引。前台索引构建速度很快，能够生成更高效的索引数据结构，但是需要在构建期间阻塞对被索引的集合的父数据库的所有读写访问。后台索引构建速度较慢，效率较低，但允许在构建过程中对数据库及其集合进行读写访问。 MongoDB 4.2版本变化 MongoDB 4.2索引构建只在构建过程的开始和结束时对被索引的集合获得独占锁，以保护元数据的更改。构建过程的其余部分使用后台索引构建的生成行为来最大化构建期间对集合的读写访问。4.2索引构建仍然产生高效的索引数据结构，尽管有更宽松的锁定行为。 MongoDB 4.2的索引构建性能至少与后台索引构建相当。对于在构建过程中很少或没有收到更新的工作负载，4.2索引构建构建的速度可以与基于相同数据的前台索引构建的速度一样快。 使用db.currentOp() 命令监视正在进行的索引构建的进度。 索引构建期间的冲突约束 对集合具有强制约束作用的索引，例如：unique 索引， mongod进程会在索引构建完成后对所有预先存在的和并发写入的文档进行约束性检查。如果任何文档违反了索引约束条件，mongod进程将终止构建并抛出错误。 举例：对inventory集合的product_sku属性构建unique特性索引。如果任意文档的product_sku属性有重复值，索引构建过程仍可成功开始，如果在构建结束时仍然存在任何冲突，mongod进程会终止构建并抛出错误。 类似的，在索引构建的过程中，应用程序可成功对inventory集合写入product_sku属性值重复的文档。如果在构建结束时存在任何索引约束冲突，mongod进程会终止构建并抛出错误。 降低因违反约束而导致索引生成失败的风险： 校验集合中没有违反索引约束的文档。 停止所有可能违反该集合索引约束条件的应用程序写入操作。 索引构建对数据库性能的影响 高负载写入时的索引构建 在目标集合处于高负载写入状态时执行索引构建操作，会造成写入性能下降和更长的索引构建时间。 考虑指定一个维护窗口用于构建索引，在此期间停止或减少对目标集合的写入操作。以减少索引生成过程对性能的潜在负面影响。 可用系统内存不足时的索引构建 命令支持在集合上构建多个索引。createIndexes命令同时使用内存和磁盘上的临时文件空间完成索引构建。createIndexes命令默认的内存使用限制是500MB，该空间在所有使用createIndexes命令生成的索引之间共享。一旦在构建索引时到达该空间限制，createIndexes命令将使用--dbpath目录下_tmp文件夹下的临时磁盘文件空间，用于完成索引构建。 你可以自定义maxIndexBuildMemoryUsageMegabytes参数，更改该空间大小限制。设置更高的内存空间可以在索引大小超500MB时更快完成索引构建。当然，该参数设置过高也会导致占用太多无用内存造成系统内存错误。 如果主机内存有限，你可能需要安排一个维护期，增加整个系统内存，再更改mongod进程中的内存参数设置。 复制集中的索引构建 尽量减少建立索引对以下方面的影响: 复制集中，使用滚动索引生成策略，如Build Indexes on Replica Sets章节所述。 拥有分片复制集的分片集群中，使用滚动索引生成策略，如Build Indexes on Sharded Clusters章节所述。 你可以在primary节点执行索引构建。索引生成完成后，secondaries节点进行复制并开始索引构建。复制集中在开始构建索引之前请注意如下风险： Secondaries节点可能不进行同步 Secondary节点的索引构建将阻塞应用正在执行的对构建索引集合的事务操作。 mongod进程在构建索引完成前将无法使用任何oplog。 如果索引生成在执行操作或命令时持有独占锁，则对被索引集合的复制写操作也可能被延迟到索引构建完成之后。mongod 进程无法使用任何oplog直到锁释放。如果复制延迟时间超过secondary节点的oplog window，secondary将不进行同步，需要通过resynchronization来恢复。 在构建索引之前，使用rs.printReplicationInfo()命令鉴别每个副本集成员配置的时间区间中可处理的oplog大小。你可以增大oplog大小increase the oplog size，降低不同步的概率。例如，设置oplog的窗口可以覆盖72个小时的操作记录，只要确保secondary节点可以容忍这么久的复制延迟。 或者在维护时间窗口中执行索引构建，应用程序停止对该索引集合的所有事物操作、写操作和元数据操作。 Secondary节点的索引构建可能造成读写操作延迟 MongoDB 4.2索引生成过程的开始和结束时获取正在索引的集合的独占锁。当secondary节点索引生成持有独占锁时，该secondary节点将暂停任何读写操作，直到索引生成释放该锁为止。 索引生成完成后，辅助进程索引将删除 在secondary节点完成索引构建的复制之前，在primary节点删除索引，将不会中断secondary节点的构建。当secondary节点执行索引删除的复制操作时，其须等待之前的索引生成操作执行复制完毕。此外，由于索引删除是集合上的元数据操作，因此索引删除会暂停该secondary节点上的复制。 构建失败和恢复 单个mongod进程的索引构建中断 如果mongod进程在索引构建时终止了，索引构建任务和所有进程将丢失。重启mongod进程不会重新执行索引构建，你必须重新运行createIndex() 操作来重启索引构建。 Primary节点mongod进程的索引构建中断 如果primary节点在索引构建时停止了，索引构建任务和所有进程将丢失。你必须重新运行createIndex() 操作来重启索引构建。 Secondary节点mongod进程的索引构建中断 如果secondary节点在索引构建时停止了，索引构建任务将保留。重启 mongod进程将恢复索引构建并从头重新开始。 启动进程会在任意已恢复的索引生成之后暂停。所有操作，包括复制将进入等待直到索引构建完成。如果secondary节点的oplog未在时间窗口区间完成缩影索引构建的复制，secondary不再进行这部分oplog的复制集的同步，需要resynchronization恢复。 如果你重启了mongod进程作为独立的复制集节点实例或删除--replSetName)。mongod进程仍将从头恢复索引构建。你可以使用storage.indexBuildRetry配置文件设置或写入命令行参数--noIndexBuildRetry。 MONGODB 4.0以上版本 你不能对副本集中的一个mongod进程实例，设置storage.indexBuildRetry选项 或 --noIndexBuildRetry选项。 构建过程中的回滚 从4.0版本开始，MongoDB在任意正在执行索引构建的进程完成后进行rollback。 监视进行中的索引构建 你可以在mongo shell中执行db.currentOp()命令，查看索引构建操作的状态。筛选当前操作中的索引创建操作，参见Active Indexing Operations操作。 msg包含了索引构建当前阶段的完成百分比。 终止进行中的索引构建 终止primary节点或单个 mongod 进程中正在执行的索引构建命令，请在mongo进程中使用db.killOp()命令。当终止索引生成时，db.killOp()命令可能不会立即执行，并可能在大部分索引生成操作完成后执行。 你无法终止一个已经在复制集secondary节点进行复制的索引构建操作。你必须首先在primary节点drop删除索引。secondary节点将复制删除操作并在索引构建完成后删除索引。所用复制操作将阻塞直到索引构建完成并执行完删除操作。 尽量降低复制集和拥有复制集的分片集群的构建索引影响，参见： 在复制集上建立索引 在分片群集上建立索引 索引建立过程 如下表格描述索引构建过程中的每个阶段： 阶段 描述 Lock mongod 进程获得索引集合的独占X锁。该集合的所有读写操作被阻塞，包括应用程序对该集合所有复制写操作或者元数据指令。mongod进程不会释放独占锁。 初始化 mongod进程在该初始状态创建三个数据结构：初始索引元数据项。一张临时表（\"side writes table\"），用来存储构建过程中对索引集合进行写入时生成的key。一张临时表(“constraint violation table”)，用于存储可能导致重复键约束冲突的所有文档。 Lock mongod 进程将之前获取的独占锁X降级为意图独占锁IX，[mongod]进程周期性的释放该锁，允许进行交错读写操作。 扫描集合 mongod进程对集合中每个文档生成一个key，并将该key存储到外部分类器中，如果 mongod进程在集合扫描期间发现重复key，它会将该key存储在constraint violation表中以备后续处理。如果mongod进程在生成key时遇到任何其他错误，构建将失败并出现错误。一旦mongod进程完成集合扫描，它将分类的key转储到索引中。 进程端写入表 mongod 使用先进先出方式处理Side Writes Table表中数据，如果遇到重复key，将该key写入constraint violation table表以备后续处理。如果mongod进程在处理键时出现任何异常错误，构建将失败。对于每个在索引构建过程中写入集合的文档，mongod进程都会给该文档生成一个key，并将其存储到side write table表中。mongod使用快照系统设置要处理的key的数量限制。 Lock mongod进程将索引集合上的意图独占锁IX升级为共享S锁。这会阻塞该集合的所有写操作，包括应用程序对该集合的任何复制写操作或元数据操作。 处理完临时端写表 mongod进程继续处理Side Writes Table表中的存量数据。mongod进程在该阶段可能会暂停复制。如果遇到重复key，将该key写入constraint violation table表以备后续处理。如果mongod进程在处理键时出现任何异常错误，构建将失败。 Lock mongod进程将索引集合的共享S锁升级成独占X锁。该集合的所有读写操作被阻塞，包括应用程序对该集合所有复制写操作或者元数据指令操作。mongod进程不会释放独占锁。 下侧写表 mongod在处理完Side Write Table表中所有数据后将其删除。如果遇到重复key，将该key写入constraint violation table表以备后续处理。如果mongod进程在处理键时出现任何异常错误，构建将失败。 流程约束违规表 mongod进程使用先入先出的方式处理Constraint Violation Table表中数据，之后删除该表。如果其中任何键仍然出现重复键错误，mongod将终止构建并抛出错误。mongod进程在处理完Constraint Violation Table表后或出现重复键约束时将删除该表。 将索引标记为就绪 mongod将索引元数据更新为可使用状态。 Lock mongod进程释放该索引集合的独占X锁。 译者：程哲欣 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Indexing-Reference.html":{"url":"08-indexes/Indexing-Reference.html","title":"索引参考","keywords":"","body":" 索引参考 在本页面 mongoShell中的索引方法 索引数据库命令 地理空间查询选择器 索引查询修饰符 mongoShell中的索引方法 名称 描述 db.collection.createIndex() 在集合上建立索引。 db.collection.dropIndex() 删除集合上的指定索引。 db.collection.dropIndexes() 删除集合上的所有索引。 db.collection.getIndexes() 返回描述集合中现有索引的文档数组。 db.collection.reIndex() 重建集合上的所有现有索引。 db.collection.totalIndexSize() 报告集合上的索引使用的总大小。提供围绕输出totalIndexSize字段的包装器collStats。 cursor.explain() 报告有关游标的查询执行计划。 cursor.hint() 强制MongoDB对查询使用特定的索引。 cursor.max() 指定游标的排他上限。用于cursor.hint() cursor.min() 指定一个游标的下限值。用于cursor.hint() 索引数据库命令 名称 描述 createIndexes 为一个集合构建一个或多个索引。 dropIndexes 从集合中删除索引。 compact 对集合进行碎片整理并重建索引。 reIndex 重建集合上的所有索引。 validate 内部命令，用于扫描集合的数据并为正确性编制索引。 geoSearch 执行使用MongoDB的干草堆索引功能的地理空间查询。 checkShardingIndex 验证分片键索引的内部命令。 地理空间查询选择器 名称 描述 $geoWithin 选择边界GeoJSON几何内的几何。该2dsphere和2D指标支持 $geoWithin。 $geoIntersects 选择与GeoJSON几何形状相交的几何形状。该2dsphere索引支持 $geoIntersects。 $near 返回点附近的地理空间对象。需要地理空间索引。该2dsphere和2D指标支持 $near。 $nearSphere 返回球体上某个点附近的地理空间对象。需要地理空间索引。该2dsphere和2D指标支持 $nearSphere。 索引查询修饰符 名称 描述 $explain 强制MongoDB报告查询执行计划。请参阅explain()。 $hint 强制MongoDB使用特定索引。看到hint() $max 指定要在查询中使用的索引的排他上限。请参阅max()。 $min 指定一个包容性的下限为索引在查询中使用。请参阅min()。 $returnKey 强制光标只返回索引中包含的字段。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Indexing-Strategies.html":{"url":"08-indexes/Indexing-Strategies.html","title":"索引策略","keywords":"","body":" 索引策略 应用程序的最佳索引必须考虑许多因素，包括预期的查询类型、读写比率和系统上的空闲内存量。 在开发索引策略时，您应该对应用程序的查询有深刻的理解。在构建索引之前，要映射出将要运行的查询类型，以便构建引用这些字段的索引。索引会带来性能成本，但与频繁查询大型数据集的成本相比，它更值得。考虑应用程序中每个查询的相对频率，以及该查询是否适合使用索引。 设计索引的最佳总体策略是使用与您将在生产环境中运行的数据集相似的数据集来分析各种索引配置，以查看哪种配置性能最佳。检查为您的集合创建的当前索引，以确保它们支持您当前和计划中的查询。如果不再使用索引，请删除该索引。 通常，MongoDB只使用一个索引来完成大多数查询。然而，一个$or查询的每个子句可能使用一个不同的索引，此外，MongoDB可以使用多个索引的交集。 下面的文档介绍了索引策略: 创建索引支持查询 当索引包含查询扫描的所有字段时，索引就支持查询。创建支持查询的索引可以极大地提高查询性能。 使用索引对查询结果进行排序 为了支持高效查询，在指定索引字段的顺序和排序顺序时，请使用这里的策略。 确保索引适合RAM 当索引适合RAM时，系统可以避免从磁盘读取索引，从而获得最快的处理速度。 创建以确保选择性的查询 选择性是指查询使用索引缩小结果的能力。选择性允许MongoDB在与完成查询相关的大部分工作中使用索引。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Indexing-Strategies/Use-Indexes-to-Sort-Query-Results.html":{"url":"08-indexes/Indexing-Strategies/Use-Indexes-to-Sort-Query-Results.html","title":"使用索引对查询结果进行排序","keywords":"","body":" 使用索引对查询结果进行排序 在本页面 使用单个字段索引排序 对多个字段上排序 索引使用和排序 由于索引包含有序的记录，MongoDB可以从包含排序字段的索引中获得排序结果。MongoDB 可能使用多个索引来支持排序操作如果排序使用相同的索引作为查询谓词。 如果MongoDB不能使用一个或多个索引来获取排序顺序，MongoDB必须对数据执行阻塞排序操作。阻塞排序表示MongoDB在返回结果之前必须使用和处理所有输入文档。阻塞排序不会阻塞对集合或数据库的并发操作。 如果MongoDB要求对阻塞排序操作使用超过100 MB的系统内存，则除非查询指定cursor.allowDiskUse()（MongoDB 4.4中的New），否则MongoDB返回错误。 allowDiskUse()允许MongoDB在处理阻塞排序操作时使用磁盘上的临时文件存储超过100兆字节系统内存限制的数据。 使用索引的排序操作通常比阻塞排序具有更好的性能。有关创建索引以支持排序操作的更多信息，请参见使用索引对查询结果排序。 注意 由于在MongoDB 3.6中对数组字段排序行为的改变，当排序一个数组索引多键索引查询计划包括一个阻塞排序阶段。新的排序行为可能会对性能产生负面影响。 在阻塞排序中，在生成输出之前，排序步骤必须使用所有输入。在非阻塞排序或索引排序中，排序步骤扫描索引以按请求的顺序生成结果。 使用单个字段索引排序 如果在单个字段上有升序或降序索引，则字段上的排序操作可以是任意方向的。 例如，为一个集合records在字段“a”上创建一个升序索引: db.records.createIndex( { a: 1 } ) 这个索引可以支持对“a”的升序排序: db.records.find().sort( { a: 1 } ) 索引也可以支持以下对“a”的降序排序，以逆序遍历索引: db.records.find().sort( { a: -1 } ) 对多个字段进行排序 创建一个复合索引来支持在多个字段上排序。 可以对索引的所有键或子集指定排序;但是，排序键必须按照它们在索引中出现的相同顺序列出。例如，一个索引键模式{a: 1, b: 1}可以支持{a: 1, b: 1}上的排序，但不支持{b: 1, a: 1}上的排序。 为一个查询使用复合索引排序,指定的排序方向所有键cursor.sort ()文件必须匹配索引键模式或匹配索引键的反模式。例如，索引键模式{a: 1, b: -1}可以支持对{a: 1, b: -1}和{a: -1, b: 1}的排序，但对{a: -1, b: -1}或{a: 1, b: 1}的排序不支持。 排序和索引前缀 如果排序键对应于索引键或索引前缀，MongoDB可以使用索引对查询结果排序。复合索引的prefix是由索引键模式开头的一个或多个键组成的子集。 例如，在data集合上创建一个复合索引: db.data.createIndex( { a:1, b: 1, c: 1, d: 1 } ) 那么，以下是该索引的前缀: { a: 1 } { a: 1, b: 1 } { a: 1, b: 1, c: 1 } 下面的查询和排序操作使用索引前缀对结果进行排序。这些操作不需要在内存中对结果集排序。 例子 索引的前缀 db.data.find().sort( { a: 1 } ) { a: 1 } db.data.find().sort( { a: -1 } ) { a: 1 } db.data.find().sort( { a: 1, b: 1 } ) { a: 1, b: 1 } db.data.find().sort( { a: -1, b: -1 } ) { a: 1, b: 1 } db.data.find().sort( { a: 1, b: 1, c: 1 } ) { a: 1, b: 1, c: 1 } db.data.find( { a: { $gt: 4 } } ).sort( { a: 1, b: 1 } ) { a: 1, b: 1 } 考虑下面的例子，索引的前缀键同时出现在查询谓词和排序中: db.data.find( { a: { $gt: 4 } } ).sort( { a: 1, b: 1 } ) 在这种情况下，MongoDB可以使用索引来按照排序指定的顺序检索文档。如示例所示，查询谓词中的索引前缀可以与排序中的前缀不同。 索引的排序和非前缀子集 索引可以支持对索引键模式的非前缀子集进行排序操作。为此，查询必须在排序键之前的所有前缀键上包含相等条件。 例如，集合data有以下索引: { a: 1, b: 1, c: 1, d: 1 } 下面的操作可以使用索引来获取排序顺序: 例子 Index Prefix db.data.find( { a: 5 } ).sort( { b: 1, c: 1 } ) { a: 1 , b: 1, c: 1 } db.data.find( { b: 3, a: 4 } ).sort( { c: 1 } ) { a: 1, b: 1, c: 1 } db.data.find( { a: 5, b: { $lt: 3} } ).sort( { b: 1 } ) { a: 1, b: 1 } 如最后一个操作所示，只有排序子集之前的索引字段在查询文档中必须具有相等条件；其他索引字段可以指定其他条件。 如果查询没有在排序规范之前或重叠的索引前缀上指定相等条件，则操作将无法有效地使用索引。例如，下面的操作指定一个排序文档为{c: 1}，但是查询文档不包含前面索引字段“a”和“b”的相等匹配: db.data.find( { a: { $gt: 2 } } ).sort( { c: 1 } ) db.data.find( { c: 5 } ).sort( { c: 1 } ) 这些操作不能有效地使用索引{a: 1, b: 1, c: 1, d: 1}，甚至不能使用索引来检索文档。 索引的使用和排序 若要使用索引进行字符串比较，操作还必须指定相同的排序规则。也就是说，如果索引指定了不同的排序规则，则具有排序规则的索引不能支持对索引字段执行字符串比较的操作。 例如，集合myColl在字符串字段category上有一个索引，其排序区域设置为fr 。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 下面的查询操作指定了与索引相同的排序规则，可以使用索引: db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作，默认使用simple二进制排序器，不能使用索引: db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是字符串、数组和嵌入文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 例如，集合myColl在数值字段score和price以及字符串字段category上有一个复合索引;索引是用collation locale ' fr '创建的，用于字符串比较: db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 以下使用' simple '二进制排序来进行字符串比较的操作可以使用索引: db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 下面的操作使用\"simple\"二进制排序对索引的category字段进行字符串比较，可以使用索引来完成查询的score: 5部分: db.myColl.find( { score: 5, category: \"cafe\" } ) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Manage-Indexes.html":{"url":"08-indexes/Manage-Indexes.html","title":"管理索引","keywords":"","body":" 管理索引 Mongo Shell 在本页面 查看现有索引 删除索引 修改索引 在分片中查找不一致的索引 此页显示如何管理现有索引。有关创建索引的说明，请参阅特定索引类型页。 查看现有索引 以下部分提供了查看集合或整个数据库上现有索引的方法。 列出集合上的所有索引 要返回一个集合上所有索引的列表，使用db. collections . getindexes ()方法或类似的驱动程序的方法。 例如，要查看people集合上的所有索引，运行以下命令: db.people.getIndexes() 列出数据库的所有索引 在mongo shell中,可以使用以下操作列出数据库中所有的集合索引: db.getCollectionNames().forEach(function(collection) { indexes = db[collection].getIndexes(); print(\"Indexes for \" + collection + \":\"); printjson(indexes); }); 从3.0版本开始，MongoDB不再支持对系统的直接访问。索引集合，以前用于列出数据库中的所有索引。 列出特定类型的索引 列出所有索引的类型(例如散列,文本)集合在所有数据库,您可以使用以下操作在mongoshell: // The following finds all hashed indexes db.adminCommand(\"listDatabases\").databases.forEach(function(d){ let mdb = db.getSiblingDB(d.name); mdb.getCollectionInfos({ type: \"collection\" }).forEach(function(c){ let currentCollection = mdb.getCollection(c.name); currentCollection.getIndexes().forEach(function(idx){ let idxValues = Object.values(Object.assign({}, idx.key)); if (idxValues.includes(\"hashed\")) { print(\"Hashed index: \" + idx.name + \" on \" + idx.ns); printjson(idx); }; }); }); }); 删除索引 MongoDB提供了两种方法从集合中删除索引: db.collection.dropIndex() db.collection.dropIndexes() 删除特定的指数 要删除一个索引，使用db.collection.dropIndex()方法。 例如，下面的操作删除了 accounts 集合中的 tax-id 字段的升序索引: db.accounts.dropIndex( { \"tax-id\": 1 } ) 该操作返回一个文档，其中显示了该操作的状态: { \"nIndexesWas\" : 3, \"ok\" : 1 } 其中nIndexesWas的值反映了在删除这个索引之前的索引数量。 对于文本索引，将索引名称传递给 db.collection.dropIndex()方法。有关详细信息，请参见使用索引名称删除文本索引。 注意 从MongoDB 4.2开始，' db.collection.dropIndexes() '可以接受一个索引名称数组。 删除所有索引 你也可以使用db. collections . dropindexes ()从一个集合中删除_id索引之外的所有索引。 例如，下面的命令从 accounts 集合中删除所有索引: db.accounts.dropIndexes() 这些shell助手提供了dropIndexes 数据库命令的包装器。您的客户端库可能有一个不同的或额外的接口用于这些操作。 修改索引 要修改现有索引，您需要删除并重新创建索引。TTL索引是该规则的例外 ，可以通过collMod命令与index收集标志一起 对其进行修改。 在分片中查找不一致的索引 如果分片集合在每个包含该分片块的分片上没有完全相同的索引（包括索引选项），则该集合具有不一致的索引。虽然在正常操作中不应该出现索引不一致的情况，但也会出现索引不一致的情况，例如: 当用户创建具有unique键约束的索引并且一个分片包含具有重复文档的块时。在这种情况下，创建索引操作可能会在没有重复的分片上成功，但在没有重复的分片上不会成功。 当用户创建一个索引碎片在对面(滚动的方式(即手动构建跨多个碎片索引一个接一个地)但是无论未能构建相关碎片或是不正确的索引构建索引与不同的规范。 从MongoDB 4.2.6,配置服务器主,默认情况下,检查索引不一致在分片的碎片集合,和命令(\"serverStatus\"),主要配置服务器上运行时,返回字段shardedIndexConsistency来报告索引不一致的分片集合的数量。 如果shardedIndexConsistency报告任何索引不一致，则可以对分片集合运行以下管道，直到找到不一致为止。 注意 下面的管道用于MongoDB 4.2.4及以上版本。 定义以下聚合管道: const pipeline = [ // Get indexes and the shards that they belong to. {$indexStats: {}}, // Attach a list of all shards which reported indexes to each document from $indexStats. {$group: {_id: null, indexDoc: {$push: \"$$ROOT\"}, allShards: {$addToSet: \"$shard\"}}}, // Unwind the generated array back into an array of index documents. {$unwind: \"$indexDoc\"}, // Group by index name. { $group: { \"_id\": \"$indexDoc.name\", \"shards\": {$push: \"$indexDoc.shard\"}, // Convert each index specification into an array of its properties // that can be compared using set operators. \"specs\": {$push: {$objectToArray: {$ifNull: [\"$indexDoc.spec\", {}]}}}, \"allShards\": {$first: \"$allShards\"} } }, // Compute which indexes are not present on all targeted shards and // which index specification properties aren't the same across all shards. { $project: { missingFromShards: {$setDifference: [\"$allShards\", \"$shards\"]}, inconsistentProperties: { $setDifference: [ {$reduce: { input: \"$specs\", initialValue: {$arrayElemAt: [\"$specs\", 0]}, in: {$setUnion: [\"$$value\", \"$$this\"]}}}, {$reduce: { input: \"$specs\", initialValue: {$arrayElemAt: [\"$specs\", 0]}, in: {$setIntersection: [\"$$value\", \"$$this\"]}}} ] } } }, // Only return output that indicates an index was inconsistent, i.e. either a shard was missing // an index or a property on at least one shard was not the same on all others. { $match: { $expr: {$or: [ {$gt: [{$size: \"$missingFromShards\"}, 0]}, {$gt: [{$size: \"$inconsistentProperties\"}, 0]}, ] } } }, // Output relevant fields. {$project: {_id: 0, indexName: \"$$ROOT._id\", inconsistentProperties: 1, missingFromShards: 1}} ]; 运行要测试的分片集合的聚合管道。例如，要测试分片集合是否测试。在相关的碎片上有不一致的索引: db.getSiblingDB(\"test\").reviews.aggregate(pipeline) 如果集合的索引不一致，则该集合的聚合将返回关于不一致索引的详细信息: { \"missingFromShards\" : [ \"shardB\" ], \"inconsistentProperties\" : [ ], \"indexName\" : \"page_1_score_1\" } { \"missingFromShards\" : [ ], \"inconsistentProperties\" : [ { \"k\" : \"expireAfterSeconds\", \"v\" : 60 }, { \"k\" : \"expireAfterSeconds\", \"v\" : 600 } ], \"indexName\" : \"reviewDt_1\" } 返回的文档指出了分片集合 test.reviews 的两个不一致之处: shardB上的集合中缺少一个名为page_1_score_1的索引。 一个名为reviewDt_1的索引在集合的各个分片上具有不一致的属性，特别是expireAfterSeconds属性不同。 要解决特定分片集合中缺少索引的不一致问题 ​ 从受影响的分片上的集合中删除不正确的索引，然后重建索引。要重建索引，您可以： 在受影响的分片上为集合执行滚动索引构建。 或者 从一个mongos 实例发出一个索引构建 db.collection.createIndex()。该操作仅在没有索引的分片上构建集合的索引。 要解决索引属性在各个分片之间的差异 ​ 从受影响的分片上的集合中删除不正确的索引，并重新构建索引。重建索引，你可以: 在受影响的碎片上为集合执行滚动索引构建。 或者 从一个mongos 实例发出一个索引构建 db.collection.createIndex()。该操作仅在没有索引的碎片上构建集合的索引。 或者，如果不一致是该expireAfterSeconds属性，则可以运行collMod命令以更新秒数，而不是删除并重建索引。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Multikey-Indexes.html":{"url":"08-indexes/Multikey-Indexes.html","title":"多键索引","keywords":"","body":" 多键索引 在本页面 创建多键索引 索引界限 唯一多键索引 局限性 例子 为了索引包含数组值的字段，MongoDB为数组中的每个元素创建一个索引键。这些多键索引支持对数组字段的高效查询。多键索引可以在包含标量值(例如字符串、数字)和嵌套文档的数组上构造。 标量值指的是既不是嵌入式文档也不是数组的值。 创建多键索引 使用 db.collection.createIndex()方法创建一个多键索引: db.coll.createIndex( { : } ) MongoDB自动创建一个多键索引，如果任何索引字段是一个数组;您不需要显式地指定多键类型。 3.4版本的改变:仅针对WiredTiger和内存存储引擎， 从MongoDB 3.4开始，对于使用MongoDB 3.4或更高版本创建的多键索引，MongoDB会跟踪哪个索引字段或哪些字段导致一个索引成为多键索引。跟踪这些信息允许MongoDB查询引擎使用更紧密的索引边界。 索引界限 如果索引是多键的，那么索引边界的计算遵循特殊规则。有关多键索引边界的详细信息，请参见多键索引边界。 唯一多键索引 对于唯一索引，唯一约束适用于集合中的各个单独文档，而不是在单个文档中。 由于unique约束适用于单独的文档，对于 唯一多键索引，只要文档的索引键值不复制另一个文档的索引键值，文档可能具有导致重复索引键值的数组元素。 有关更多信息，请参见跨单独文档的唯一约束。 局限性 复合多键索引 对于复合多键索引，每个索引文档最多只能有一个索引字段，其值是一个数组。那就是: 如果文档的多个待索引字段是数组，则无法创建复合多键索引。例如，考虑一个包含以下文档的集合: { _id: 1, a: [ 1, 2 ], b: [ 1, 2 ], category: \"AB - both arrays\" } 因为a和b字段都是数组，所以不能在集合上创建复合多键索引{a: 1, b: 1}。 或者，如果复合多键索引已经存在，则不能插入违反此限制的文档。 假设一个包含以下文档的集合： { _id: 1, a: [1, 2], b: 1, category: \"A array\" } { _id: 2, a: 1, b: [1, 2], category: \"B array\" } 允许使用复合多键索引{A: 1, b: 1}，因为对于每个文档，只有一个复合多键索引的字段是一个数组;也就是说，没有文档同时包含a和b字段的数组值。 但是，在创建复合多键索引之后，如果您试图插入一个a和b字段都是数组的文档，MongoDB将导致插入失败。 如果字段是文档数组，则可以索引嵌入的字段以创建复合索引。例如，考虑一个包含以下文档的集合: { _id: 1, a: [ { x: 5, z: [ 1, 2 ] }, { z: [ 1, 2 ] } ] } { _id: 2, a: [ { x: 5 }, { z: 4 } ] } 你可以在{\"a.x\": 1, \"a.z\": 1 }上创建一个复合索引。数组最多只能有一个索引字段的限制也适用。 有关示例，请参见带有嵌入式文档的索引数组。 也可以看看 跨单独文档的唯一约束 单个字段上的唯一索引 排序 由于MongoDB 3.6中数组字段排序行为的改变，当对多键索引的数组排序时，查询计划包括一个阻塞排序阶段。新的排序行为可能会对性能产生负面影响。 在阻塞排序中，在生成输出之前，排序步骤必须使用所有输入。在非阻塞排序或索引排序中，排序步骤扫描索引以按请求的顺序生成结果。 分片键 不能指定多键索引为分片键。 但是，如果分片键索引是复合索引的前缀，那么如果其他键中的一个(即不属于切分键的键)索引了数组，那么复合索引就可以变成复合多键索引。复合多键索引会对性能产生影响。 Hashed索引 Hashed索引不能为多键。 覆盖查询 多键索引不能覆盖对数组字段的查询。 然而，从3.6开始，如果索引跟踪哪个或哪个字段导致索引为多键，那么多键索引可以覆盖对非数组字段的查询。在MongoDB 3.4或更高版本的存储引擎上创建的多键索引，而不是MMAPv1[]_跟踪该数据。 从4.2版本开始，MongoDB删除了已弃用的MMAPv1存储引擎。 整体查询数组字段 当一个查询过滤器为一个数组指定了一个精确的匹配，MongoDB可以使用multikey索引来查找查询数组的第一个元素，但是不能使用multikey索引扫描来查找整个数组。相反，在使用multikey索引查找查询数组的第一个元素之后，MongoDB检索相关的文档，并筛选其数组与查询中的数组匹配的文档。 例如，假设一个包含以下文档的inventory集合: { _id: 5, type: \"food\", item: \"aaa\", ratings: [ 5, 8, 9 ] } { _id: 6, type: \"food\", item: \"bbb\", ratings: [ 5, 9 ] } { _id: 7, type: \"food\", item: \"ccc\", ratings: [ 9, 5, 8 ] } { _id: 8, type: \"food\", item: \"ddd\", ratings: [ 9, 5 ] } { _id: 9, type: \"food\", item: \"eee\", ratings: [ 5, 9, 5 ] } 该集合在ratings字段上有一个多键索引: db.inventory.createIndex( { ratings: 1 } ) 下面的查询查找ratings字段为数组[5,9]的文档: db.inventory.find( { ratings: [ 5, 9 ] } ) MongoDB可以使用多键索引来查找ratings数组中任何位置有5的文档。然后，MongoDB检索这些文档，筛选ratings数组等于查询数组的文档[5,9]。 $expr $expr 不支持多键索引。 例子 索引基本数组 假设一个包含以下文档的survey集合: { _id: 1, item: \"ABC\", ratings: [ 2, 5, 9 ] } 在ratings上创建索引: db.survey.createIndex( { ratings: 1 } ) 由于ratings字段包含一个数组，ratings的索引是多键的。多键索引包含以下三个索引键，每个都指向同一个文档: 2， 5， 9。 数组索引与嵌入式文件 可以在包含嵌套对象的数组字段上创建多键索引。 假设使用以下形式的文档进行inventory收集: { _id: 1, item: \"abc\", stock: [ { size: \"S\", color: \"red\", quantity: 25 }, { size: \"S\", color: \"blue\", quantity: 10 }, { size: \"M\", color: \"blue\", quantity: 50 } ] } { _id: 2, item: \"def\", stock: [ { size: \"S\", color: \"blue\", quantity: 20 }, { size: \"M\", color: \"blue\", quantity: 5 }, { size: \"M\", color: \"black\", quantity: 10 }, { size: \"L\", color: \"red\", quantity: 2 } ] } { _id: 3, item: \"ijk\", stock: [ { size: \"M\", color: \"blue\", quantity: 15 }, { size: \"L\", color: \"blue\", quantity: 100 }, { size: \"L\", color: \"red\", quantity: 25 } ] } ... 以下操作在stock.size 和stock.quantity字段上创建一个多键索引： db.inventory.createIndex( { \"stock.size\": 1, \"stock.quantity\": 1 } ) 复合多键索引可以支持具有谓词的查询，这些谓词既包括索引字段，也包括仅包括索引前缀“stock.size”的谓词。，如以下例子所示: db.inventory.find( { \"stock.size\": \"M\" } ) db.inventory.find( { \"stock.size\": \"S\", \"stock.quantity\": { $gt: 20 } } ) 有关MongoDB如何组合多键索引边界的详细信息，请参见多键索引边界。有关复合索引和前缀的行为的更多信息，请参见复合索引和前缀。 复合多键索引也可以支持排序操作，例如下面的例子: db.inventory.find( ).sort( { \"stock.size\": 1, \"stock.quantity\": 1 } ) db.inventory.find( { \"stock.size\": \"M\" } ).sort( { \"stock.quantity\": 1 } ) 有关复合索引和排序操作的行为的更多信息，请参见使用索引对查询结果进行排序。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Single-Field-Indexes.html":{"url":"08-indexes/Single-Field-Indexes.html","title":"单字段索引","keywords":"","body":" 单字段索引 在本页面 在单个字段上创建升序索引 在嵌入式字段上创建索引 在内嵌文档上创建索引 其他注意事项 MongoDB为文档集合中任何字段上的索引提供了完整的支持 。默认情况下，所有集合在_id字段上都有一个索引，应用程序和用户可以添加其他索引来支持重要的查询和操作。 本文档描述单个字段上的升序/降序索引。 在单个字段上创建升序索引 假设一个 records的集合，包含类似于如下所示的文档: { \"_id\": ObjectId(\"570c04a4ad233577f97dc459\"), \"score\": 1034, \"location\": { state: \"NY\", city: \"New York\" } } 下面的操作在records集合的score字段上创建一个升序索引: db.records.createIndex( { score: 1 } ) 索引规范中的字段值描述该字段的索引类型。例如，值' 1 '指定一个索引，该索引按升序对项目排序。值' -1 '指定按降序排列项目的索引。有关其他索引类型，请参见索引类型 创建的索引将支持在字段score上选择查询，例如: db.records.find( { score: 2 } ) db.records.find( { score: { $gt: 10 } } ) 在嵌入式字段上创建索引 可以在嵌入文档中的字段上创建索引，就像索引文档中的顶级字段一样。嵌入字段上的索引不同于嵌入文档上的索引，它包含了完整的内容，直到索引中嵌入文档的最大“索引大小”为止。相反，嵌入字段上的索引允许您使用“点表示法”来内省嵌入的文档。 考虑一个名为“records”的集合，它包含类似于以下示例文档的文档: { \"_id\": ObjectId(\"570c04a4ad233577f97dc459\"), \"score\": 1034, \"location\": { state: \"NY\", city: \"New York\" } } 以下操作在\"location.state\" 字段上创建索引： db.records.createIndex( { \"location.state\": 1 } ) 创建的索引将支持选择字段\"location.state\"的查询。，例如: db.records.find( { \"location.state\": \"CA\" } ) db.records.find( { \"location.city\": \"Albany\", \"location.state\": \"NY\" } ) 在内嵌文档上创建索引 您还可以在整个内嵌文档上创建索引。 考虑一个名为“records”的集合，它包含类似于以下示例文档的文档: { \"_id\": ObjectId(\"570c04a4ad233577f97dc459\"), \"score\": 1034, \"location\": { state: \"NY\", city: \"New York\" } } “location”字段是一个内嵌文档，包含嵌入式字段city和state。下面的命令创建一个索引的\"location\"字段作为一个整体: db.records.createIndex( { location: 1 } ) 以下查询可以使用\"location\"字段的索引: db.records.find( { location: { city: \"New York\", state: \"NY\" } } ) [success] Note 尽管查询可以使用索引，但结果集不包括上面的示例文档。在嵌入文档上执行相等匹配时，字段顺序很重要，内嵌文档必须精确匹配。有关查询内嵌文档的更多信息，请参见查询内嵌文档。 其他注意事项 在索引构建期间，应用程序可能会遇到性能下降，包括对集合的读/写访问受限。有关索引构建过程的更多信息，请参见 填充集合上索引构建”，包括复制环境中的索引构建部分。 一些驱动程序可能指定索引，使用NumberLong(1)而不是1作为规范。这对结果索引没有任何影响。 译者：杨帅 莫薇 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Text-Indexes.html":{"url":"08-indexes/Text-Indexes.html","title":"文本索引","keywords":"","body":" 文本索引 在本页面 概述 版本 创建文本索引 不区分大小写 变音符号不敏感 标记化分隔符 索引条目 支持的语言和停用词 sparse 属性 限制条件 存储要求和性能成本 文字搜索支持 MONGODB地图搜索 Atlas Search可以很容易地在MongoDB数据上构建快速、基于相关性的搜索功能。在MongoDB Atlas上试试吧，这是我们的完全托管数据库服务。 概述 MongoDB提供文本索引以支持对字符串内容的文本搜索查询。text索引可以包含任何值为字符串或字符串元素数组的字段。 版本 文本索引版本 描述 版本3 MongoDB引入了text索引的第3版。版本3是text在MongoDB 3.2和更高版本中创建的索引的默认版本。 版本2 MongoDB 2.6引入了text索引的版本2 。版本2是text在MongoDB 2.6和3.0系列中创建的索引的默认版本。 版本1 MongoDB 2.4引入了text索引的版本1 。MongoDB 2.4仅支持版本1。 要覆盖默认版本并指定不同的版本，在创建索引时包括选项{\"textIndexVersion\":}。 创建文本索引 [success] 重要 一个集合最多可以有一个 text索引。 若要创建text索引，请使用 db.collection.createIndex()方法。若要索引包含字符串或字符串元素数组的字段，请包含该字段并在索引文档中指定字符串字面量“text”，如下例所示: db.reviews.createIndex( { comments: \"text\" } ) 您可以为索引建立多个字段的text索引。以下示例text在字段subject和 comments上创建索引： db.reviews.createIndex( { subject: \"text\", comments: \"text\" } ) 复合索引可以包含文本索引键和升序/降序索引键。有关更多信息，请参见复合索引。 为了删除text索引，请使用索引名称。有关更多信息，请参见使用索引名称删除文本索引。 指定权重 对于文本索引，索引字段的权重表示该字段相对于其他索引字段在文本搜索分数方面的重要性。 对于文档中的每个索引字段，MongoDB将匹配的数量乘以权重并对结果进行求和。然后，MongoDB使用这个总和计算文档的分数。有关按文本分数返回和排序的详细信息，请参阅$meta操作符。 索引字段的默认权重为1。要调整索引字段的权重，请在db.collection.createIndex()方法中包含权重选项。 有关使用权重控制文本搜索结果的更多信息，请参见使用权重控制搜索结果。 通配符文本索引 [succress] 注意 通配符文本索引不同于通配符索引。通配符索引不支持使用$text操作符的查询。 尽管通配符文本索引和通配符索引共享通配符$**字段模式，但它们是不同的索引类型。仅通配符文本索引支持$text运算符。 在多个字段上创建文本索引时，还可以使用通配符说明符($**)。通过通配符文本索引，MongoDB为集合中每个文档包含字符串数据的每个字段建立索引。下面的示例使用通配符创建一个文本索引: db.collection.createIndex( { \"$**\": \"text\" } ) 该索引允许对所有具有字符串内容的字段进行文本搜索。如果不清楚在文本索引中包含哪些字段或用于特殊查询，那么这种索引对于高度非结构化数据非常有用。 通配符文本索引是多个字段上的文本索引。因此，您可以在创建索引期间为特定字段分配权重，以控制结果的排序。有关使用权重控制文本搜索结果的详细信息，请参见 使用权重控制搜索结果。 通配符文本索引(与所有文本索引一样)可以是复合索引的一部分。例如，下面在字段a以及通配符上创建一个复合索引: db.collection.createIndex( { a: 1, \"$**\": \"text\" } ) 与所有复合文本索引一样，由于a位于文本索引键之前，为了使用该索引执行$text搜索，查询谓词必须包含一个相等匹配条件a。有关复合文本索引的信息，请参见复合文本索引。 不区分大小写 在版本3.2中更改 版本3文本索引支持常用的C语言、简单的S语言，对于土耳其语言，支持Unicode 8.0字符数据库大小写折叠中指定的特殊T大小写折叠。 此案的大小写扩展文本索引包括字符不区分大小写的区分标志,如 é和É,从非拉丁字母和字符,如“И”和“и”西里尔字母。 文本索引的版本3也不支持变音符号。因此，索引也不区分 é, É, e, and E. 以前版本的文本索引只对[A-z]不区分大小写;例如，只对非变音符拉丁字符不区分大小写。对于所有其他字符，早期版本的文本索引将它们视为不同的字符。 变音符号不敏感 在版本3.2中更改 在版本3中，text索引不区分音素。即，索引不包含变音符号和它们的未标记的对应，如字符区分é，ê和 e。更具体地说，文本索引去除Unicode 8.0字符数据库道具列表中分类为变音符号的字符。 text索引的第3版对带有变音符号的字符也不区分大小写。这样，索引也没有区分之间é，É，e，和E。 text索引的早期版本将带变音符号的字符视为不同的字符。 标记化分隔符 在版本3.2中更改 对于符号化，第3版text索引使用下分类的分隔符Dash，Hyphen，Pattern_Syntax， Quotation_Mark，Terminal_Punctuation，和White_Space中 的Unicode 8.0字符数据库道具列表。 在Unicode 8.0字符数据库Prop列表中，版本3文本索引使用分界符分类在破折号、连字符、Pattern_Syntax、Quotation_Mark、Terminal_Punctuation和White_Space中。 例如，如果给定的一个字符串，该索引对待，和空格作为分隔符。\"Il a dit qu'il «était le meilleur joueur du monde»\"``text``«``» 例如，如果给定一个字符串“Il a dit qu'il«etait le meilleur joueur du monde»”，文本索引将«,»和空格作为分隔符。 该指数治疗的早期版本«作为术语的一部分 \"«était\"，and»作为长期的一部分\"monde»\"。 索引条目 文本索引对索引项的索引字段中的术语进行标记和词根处理。文本索引在集合中每个文档的每个索引字段中为每个唯一的词根项存储一个索引项。索引使用简单的特定语言的后缀词干。 支持的语言和停用词 MongoDB支持多种语言的文本搜索。text指数下降特定语言的停用词（如英语，the，an， a，and，等）和使用简单的语言特定的后缀而产生。有关支持的语言的列表，请参见文本搜索语言。 如果您将语言值指定为\"none\"，则text索引将使用简单的标记化，不包含停止词列表和词干分析。 要为文本索引指定一种语言，请参见 为文本索引指定语言。 sparse属性 text索引总是sparse并且忽略 sparse选项。如果文档缺少text索引字段（或者该字段是null或为空数组），则MongoDB不会将文档条目添加到text索引中。对于插入，MongoDB会插入文档，但不会添加到text索引中。 对于包含text索引键和其他类型的键的复合索引，只有text索引字段才能确定索引是否引用文档。其他键不能确定索引是否引用文档。 限制条件 每个集合有一个文本索引 一个集合最多可以有一个 text索引。 文字搜索和提示 如果查询包含$text查询表达式，则不能使用hint()。 文本索引和排序 排序操作无法从text索引获得排序顺序，即使从复合文本索引也无法获得排序顺序；即排序操作不能使用文本索引中的顺序。 复合索引 复合索引可以包含文本索引键和升序/降序索引键。但是，这些复合索引有以下限制: 复合文本索引不能包含任何其他特殊索引类型，例如多键或地理空间索引字段。 如果复合文本索引在文本索引键之前包含键，那么要执行$text搜索，查询谓词必须包含前面键的相等匹配条件。 在创建复合文本索引时，必须在索引规范文档中邻接列出所有文本索引键。 另请参见文本索引和排序。 有关复合文本索引的示例，请参见限制扫描的条目数。 删除文本索引 要删除text索引，请将索引名称传递给 db.collection.dropIndex()方法。要获取索引的名称，请运行该db.collection.getIndexes()方法。 有关text索引的默认命名方案以及覆盖默认名称的信息，请参见指定文本索引的名称。 排序选项 text索引仅支持简单的二进制比较，不支持排序。 要在具有非简单排序规则的集合上创建文本索引，必须在创建索引时显式指定{collation: {locale: \"simple\"}}。 存储要求和性能成本 文本索引有以下存储要求和性能成本: text索引可以很大。对于每个插入的文档，每个索引字段中的每个唯一后词形词都包含一个索引条目。 构建text索引与构建大型多键索引非常相似，并且比在相同数据上构建简单的有序(标量)索引要花更长的时间。 在text现有集合上建立较大索引时，请确保对打开文件描述符的限制足够高。请参阅建议的设置。 text 索引会影响插入吞吐量，因为MongoDB必须在每个新源文档的每个索引字段中为每个唯一的词干词添加一个索引条目。 此外，text索引不存储短语或有关文档中单词接近度的信息。结果，当整个集合放入RAM中时，短语查询将更有效地运行。 文本搜索支持 文本索引支持$text查询操作。有关文本搜索的示例，请参见$text引用页面。有关聚合管道中的$text 操作示例，请参见聚合管道中的文本搜索。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Text-Indexes/Control-Search-Results-with-Weights.html":{"url":"08-indexes/Text-Indexes/Control-Search-Results-with-Weights.html","title":"用权重控制搜索结果","keywords":"","body":" 用权重控制搜索结果 文本搜索为索引字段中包含搜索词的每个文档分配一个分数。分数决定了文档与给定搜索查询的相关性。 对于文本索引，索引字段的权重表示该字段相对于其他索引字段在文本搜索分数方面的重要性。 对于文档中的每个索引字段，MongoDB将匹配的数量乘以权重并对结果进行求和。然后，MongoDB使用这个总和计算文档的分数。有关按文本分数返回和排序的详细信息，请参阅 $meta操作符。 索引字段的默认权重为1。要调整索引字段的权重，请在db.collection.createIndex()方法中包含权重选项。 [warning] warning 仔细选择权重，以防止需要重新索引。 集合blog包含以下文档： { _id: 1, content: \"This morning I had a cup of coffee.\", about: \"beverage\", keywords: [ \"coffee\" ] } { _id: 2, content: \"Who doesn't like cake?\", about: \"food\", keywords: [ \"cake\", \"food\", \"dessert\" ] } 要为内容字段和关键字字段创建具有不同字段权重的文本索引，请包含createIndex()方法的权重选项。例如，下面的命令在三个字段上创建一个索引，并为其中两个字段分配权重: db.blog.createIndex( { content: \"text\", keywords: \"text\", about: \"text\" }, { weights: { content: 10, keywords: 5 }, name: \"TextIndex\" } ) 文本索引有以下字段和权重: content的权重是10， keywords的权重为5， about的默认权重为1。 这些权重表示索引字段之间的相对重要性。例如，content字段中的term匹配有: 2倍(即10:5)的影响，作为一个词匹配的关键字字段 10倍(即10:1)的影响，作为一场关于领域的学期比赛的影响。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Text-Indexes/Limit-the-Number-of-Entries-Scanned.html":{"url":"08-indexes/Text-Indexes/Limit-the-Number-of-Entries-Scanned.html","title":"限制扫描条目的数量","keywords":"","body":" 限制扫描条目的数量 本教程描述了如何创建索引来限制对包含$text表达式和相等条件的查询扫描的索引条目的数量。 集合inventory包含以下文档： { _id: 1, dept: \"tech\", description: \"lime green computer\" } { _id: 2, dept: \"tech\", description: \"wireless red mouse\" } { _id: 3, dept: \"kitchen\", description: \"green placemat\" } { _id: 4, dept: \"kitchen\", description: \"red peeler\" } { _id: 5, dept: \"food\", description: \"green apple\" } { _id: 6, dept: \"food\", description: \"red potato\" } 考虑由各个部门执行文本搜索的通用用例，例如: db.inventory.find( { dept: \"kitchen\", $text: { $search: \"green\" } } ) 为了限制文本搜索只扫描特定部门内的那些文档，创建一个复合索引，首先在字段dept上指定一个升序/降序索引键，然后在字段描述上指定一个文本索引键: db.inventory.createIndex( { dept: 1, description: \"text\" } ) 然后，特定部门内的文本搜索将限制索引文档的扫描。例如，下面的查询只扫描那些dept = kitchen的文档: db.inventory.find( { dept: \"kitchen\", $text: { $search: \"green\" } } ) [success] 注意 复合text索引不能包含任何其他特殊索引类型，例如多键或 地理空间索引字段。 如果复合text索引在 索引键之前包含键，则要text执行$text搜索，查询谓词必须在前面的键上包含相等匹配条件。 创建复合text索引时，所有text索引键必须在索引规范文档中相邻列出。 也可以看看 文字索引 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Text-Indexes/Specify-a-Language-for-Text-Index.html":{"url":"08-indexes/Text-Indexes/Specify-a-Language-for-Text-Index.html","title":"为文本索引指定语言","keywords":"","body":" 为文本索引指定语言 在本页面 指定text索引的默认语言 用多种语言为集合创建文本索引 本教程描述了如何指定与文本索引关联的默认语言，以及如何为包含不同语言文档的集合创建文本索引。 指定text索引的默认语言 与索引数据相关联的默认语言决定了解析词根(即：词干分析)和忽略停止词的规则。索引数据的默认语言是英语。 要指定不同的语言，请在创建文本索引时使用default_language选项。有关default_language可用的语言，请参阅文本搜索语言。 下面的示例为quotes集合在内容字段上创建了一个文本索引，并将default_language设置为西班牙语: db.quotes.createIndex( { content : \"text\" }, { default_language: \"spanish\" } ) 用多种语言为集合创建文本索引 指定文档内的索引语言 如果集合包含使用不同语言的文档或嵌入文档，则在文档或嵌入文档中包含名为language的字段，并将该文档或嵌入文档的语言指定为其值。 构建text索引时，MongoDB将为该文档或嵌入式文档使用指定的语言： 文档中指定的语言将覆盖text索引的默认语言。 嵌入式文档中的指定语言将覆盖附件文档中指定的语言或索引的默认语言。 有关支持的语言列表，请参见文本搜索语言。 例如，一个集合quotes包含多语言文档，根据需要包括language文档和/或嵌入文档中的字段： { _id: 1, language: \"portuguese\", original: \"A sorte protege os audazes.\", translation: [ { language: \"english\", quote: \"Fortune favors the bold.\" }, { language: \"spanish\", quote: \"La suerte protege a los audaces.\" } ] } { _id: 2, language: \"spanish\", original: \"Nada hay más surrealista que la realidad.\", translation: [ { language: \"english\", quote: \"There is nothing more surreal than reality.\" }, { language: \"french\", quote: \"Il n'y a rien de plus surréaliste que la réalité.\" } ] } { _id: 3, original: \"is this a dagger which I see before me.\", translation: { language: \"spanish\", quote: \"Es este un puñal que veo delante de mí.\" } } 如果您使用默认的英语语言在quote字段上创建了一个文本索引。 db.quotes.createIndex( { original: \"text\", \"translation.quote\": \"text\" } ) 然后，对于包含该language 字段的文档和嵌入文档，text索引使用该语言来解析词干和其他语言特征。 对于不包含该language字段的嵌入式文档， 如果封闭的文档包含该language字段，则索引将文档的语言用于嵌入式文档。 否则，索引将为嵌入文档使用默认语言。 对于不包含该language字段的文档，索引使用默认语言，即英语。 使用任何字段来指定文档的语言 要使用非语言名称的字段，请在创建索引时包含language_override选项。 例如，下面的命令使用idioma作为字段名而不是language: db.quotes.createIndex( { quote : \"text\" }, { language_override: \"idioma\" } ) quotes集合的文档可以在idioma字段中指定一种语言： { _id: 1, idioma: \"portuguese\", quote: \"A sorte protege os audazes\" } { _id: 2, idioma: \"spanish\", quote: \"Nada hay más surrealista que la realidad.\" } { _id: 3, idioma: \"english\", quote: \"is this a dagger which I see before me\" } 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Text-Indexes/Specify-Name-for-text-Index.html":{"url":"08-indexes/Text-Indexes/Specify-Name-for-text-Index.html","title":"指定文本索引的名称","keywords":"","body":" 指定文本索引的名称 在本页面 指定text索引名称 使用索引名称删除text索引 在MONGODB 4.2中的改变 从4.2版本开始，由于特性兼容性版本设置为“4.2”或更大，MongoDB删除了最大127字节的索引名长度限制。在以前的版本或特性兼容性版本(fCV)设置为“4.0”的MongoDB版本中，索引名必须在这个限制之内。 索引的默认名称由与串联的每个索引字段名称组成_text。例如，下面的命令创建一个text上的字段索引content，users.comments和 users.profiles： 索引的默认名称由每个索引字段名和_text连接起来组成。例如，下面的命令在字段content、users.comments和users.profiles上创建一个文本索引: db.collection.createIndex( { content: \"text\", \"users.comments\": \"text\", \"users.profiles\": \"text\" } ) 索引的默认名称是： \"content_text_users.comments_text_users.profiles_text\" 指定text索引名称 您可以将name选项传递给 db.collection.createIndex()方法： db.collection.createIndex( { content: \"text\", \"users.comments\": \"text\", \"users.profiles\": \"text\" }, { name: \"MyTextIndex\" } ) 使用索引名称删除text索引 无论是文本索引具有默认名称或指定一个名称为文本索引，删除该文本索引，通过索引名称的db.collection.dropIndex()方法。 例如，考虑以下操作创建的索引: db.collection.createIndex( { content: \"text\", \"users.comments\": \"text\", \"users.profiles\": \"text\" }, { name: \"MyTextIndex\" } ) 然后，要删除此文本索引，请将名称传递\"MyTextIndex\"给 db.collection.dropIndex()方法，如下所示： db.collection.dropIndex(\"MyTextIndex\") 若要获取索引的名称，请使用 db.collection.getIndexes()方法。 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"08-indexes/Wildcard-Indexes.html":{"url":"08-indexes/Wildcard-Indexes.html","title":"通配符索引","keywords":"","body":" 通配符索引 在本页面 创建通配符索引 注意事项 行为 限制条件 通配符索引查询/排序支持 MongoDB支持在一个或一组字段上创建索引，以支持查询。由于MongoDB支持动态模式，应用程序可以查询不能提前知道名称或任意名称的字段。 MongoDB版本中的新功能： 4.2 MongoDB 4.2引入了通配符索引，以支持针对未知或任意字段的查询。 考虑一个应用程序，该应用程序在该userMetadata字段下捕获用户定义的数据 并支持查询该数据： { \"userMetadata\" : { \"likes\" : [ \"dogs\", \"cats\" ] } } { \"userMetadata\" : { \"dislikes\" : \"pickles\" } } { \"userMetadata\" : { \"age\" : 45 } } { \"userMetadata\" : \"inactive\" } 管理员希望创建索引来支持对userMetadata的任何子字段的查询。 在通配符索引userMetadata 可以支持单场查询userMetadata， userMetadata.likes，userMetadata.dislikes，和 userMetadata.age： db.userData.createIndex( { \"userMetadata.$**\" : 1 } ) 该索引可以支持以下查询： db.userData.find({ \"userMetadata.likes\" : \"dogs\" }) db.userData.find({ \"userMetadata.dislikes\" : \"pickles\" }) db.userData.find({ \"userMetadata.age\" : { $gt : 30 } }) db.userData.find({ \"userMetadata\" : \"inactive\" }) userMetadata上的非通配符索引只能支持对userMetadata的查询。 [warning] 重要 通配符索引并非旨在替代基于工作负载的索引计划。有关创建索引以支持查询的更多信息，请参见创建索引以支持查询。有关通配符索引限制的完整文档，请参阅通配符索引限制。 创建通配符索引 [warning] 重要 该featureCompatibilityVersion必须创建通配符索引。有关设置fCV的说明，请参阅MongoDB 4.4部署的特性兼容性版本。 可以使用createIndexes数据库命令或其shell助手createIndex()或createIndexes()创建通配符索引。 在字段上创建通配符索引 索引特定字段的值: db.collection.createIndex( { \"fieldA.$**\" : 1 } ) 使用这个通配符索引，MongoDB将索引fieldA的所有值。如果字段是嵌套的文档或数组，通配符索引将递归到文档/数组中，并存储文档/数组中所有字段的值。 例如，product_catalog集合中的文档可能包含product_attributes字段。product_attributes字段可以包含任意嵌套的字段，包括嵌入的文档和数组: { \"product_name\" : \"Spy Coat\", \"product_attributes\" : { \"material\" : [ \"Tweed\", \"Wool\", \"Leather\" ] \"size\" : { \"length\" : 72, \"units\" : \"inches\" } } } { \"product_name\" : \"Spy Pen\", \"product_attributes\" : { \"colors\" : [ \"Blue\", \"Black\" ], \"secret_feature\" : { \"name\" : \"laser\", \"power\" : \"1000\", \"units\" : \"watts\", } } } 下面的操作在product_attributes字段上创建一个通配符索引: db.products_catalog.createIndex( { \"product_attributes.$**\" : 1 } ) 通配符索引可以支持对product_attributes或其内嵌字段的任意单字段查询: db.products_catalog.find( { \"product_attributes.size.length\" : { $gt : 60 } } ) db.products_catalog.find( { \"product_attributes.material\" : \"Leather\" } ) db.products_catalog.find( { \"product_attributes.secret_feature.name\" : \"laser\" } ) [success] 注意 特定于路径的通配符索引语法与该wildcardProjection选项不兼容 。有关更多信息，请参见通配符索引的选项。 有关示例，请参见在单字段路径上创建通配符索引。 在所有字段上创建通配符索引 要索引文档中所有字段的值(不包括_id)，指定“$**”作为索引键: db.collection.createIndex( { \"$**\" : 1 } ) 使用这个通配符索引，MongoDB为集合中每个文档的所有字段建立索引。如果给定字段是嵌套的文档或数组，通配符索引将递归到文档/数组中，并存储文档/数组中所有字段的值。 有关示例，请参见在所有字段路径上创建通配符索引。 [success] 注意 通配符索引默认情况下省略_id字段。要在通配符索引中包含_id字段，必须显式地将其包含在wildcardProjection文档中。有关更多信息，请参见通配符索引选项。 在多个特定字段上创建通配符索引 索引一个文档中多个特定字段的值: db.collection.createIndex( { \"$**\" : 1 }, { \"wildcardProjection\" : { \"fieldA\" : 1, \"fieldB.fieldC\" : 1 } } ) 使用这个通配符索引，MongoDB为集合中每个文档的指定字段的所有值建立索引。如果给定字段是嵌套的文档或数组，通配符索引将递归到文档/数组中，并存储文档/数组中所有字段的值。 [success] 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关详细信息 wildcardProjection，请参阅通配符索引选项。 有关示例，请参阅在通配符索引覆盖范围中包括特定字段。 创建排除多个特定字段的通配符索引 要为文档中除特定字段路径之外的所有字段的字段建立索引，请执行以下操作 ： db.collection.createIndex( { \"$**\" : 1 }, { \"wildcardProjection\" : { \"fieldA\" : 0, \"fieldB.fieldC\" : 0 } } ) 使用这个通配符索引，MongoDB为集合中每个文档的所有字段建立索引，不包括指定的字段路径。如果给定字段是嵌套的文档或数组，通配符索引将递归到文档/数组中，并存储文档/数组中所有字段的值。 有关示例，请参见从通配符索引覆盖率中忽略特定字段。 [success] 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关详细信息 wildcardProjection，请参阅通配符索引选项。 注意事项 通配符索引可以在任何给定查询谓词中最多支持一个字段。有关通配符索引查询支持的更多信息，请参见通配符索引查询/排序支持。 该featureCompatibilityVersion必须创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.4部署上设置功能兼容版本。mongod 4.2 通配符索引默认情况下省略_id字段。要在通配符索引中包含_id字段，必须显式地将其包含在wildcardProjection文档中(即{“_id”:1})。 您可以在一个集合中创建多个通配符索引。 通配符索引可能与集合中的其他索引覆盖相同的字段。 通配符索引是sparse索引，即使索引字段包含空值，也仅包含具有索引字段的文档的条目。 行为 通配符索引在索引对象(例如嵌入的文档)或数组字段时有特定的行为: 如果该字段是对象，则通配符索引会下降到该对象中并为其内容建立索引。通配符索引继续下降到它遇到的任何其他嵌入式文档中。 如果该字段是一个数组，则通配符索引将遍历该数组并索引每个元素： 如果数组中的元素是对象，则通配符索引会下降到该对象中以如上所述索引其内容。 如果该元素是一个数组--也就是说，其被直接嵌入父阵列内的阵列-然后通配符指数并不能遍历嵌入式阵列，但索引的整个阵列作为一个单一的值。 对于所有其他字段，将原始(非对象/数组)值记录到索引中。 通配符索引将继续遍历任何其他嵌套对象或数组，直到达到原始值(即不是对象或数组的字段)为止。然后，它将索引此原始值以及该字段的完整路径。 例如，考虑以下文档： { \"parentField\" : { \"nestedField\" : \"nestedValue\", \"nestedObject\" : { \"deeplyNestedField\" : \"deeplyNestedValue\" }, \"nestedArray\" : [ \"nestedArrayElementOne\", [ \"nestedArrayElementTwo\" ] ] } } 包含parentField的通配符索引记录了以下条目: \"parentField.nestedField\" : \"nestedValue\" \"parentField.nestedObject.deeplyNestedField\" : \"deeplyNestedValue\" \"parentField.nestedArray\" : \"nestedArrayElementOne\" \"parentField.nestedArray\" : [\"nestedArrayElementTwo\"] 注意，记录parentField.nestedArray不包含每个元素的数组位置。当将元素记录到索引中时，通配符索引会忽略数组元素的位置。通配符索引仍然可以支持包含显式数组索引的查询。有关更多信息，请参见具有显式数组索引的查询。 有关嵌套对象的通配符索引行为的更多信息，请参见嵌套对象。 有关嵌套数组的通配符索引行为的更多信息，请参见嵌套数组。 嵌套对象 当通配符索引遇到嵌套对象时，它下降到该对象并对其内容进行索引。例如: { \"parentField\" : { \"nestedField\" : \"nestedValue\", \"nestedArray\" : [\"nestedElement\"] \"nestedObject\" : { \"deeplyNestedField\" : \"deeplyNestedValue\" } } } 包含parentField的通配符索引向下遍历对象并索引其内容: 对于本身就是对象（即嵌入式文档）的每个字段，请进入该对象以为其内容编制索引。 对于每个是数组的字段，遍历该数组并为其内容建立索引。 对于所有其他字段，将原始（非对象/数组）值记录到索引中。 通配符索引继续遍历任何附加的嵌套对象或数组，直到它到达一个基本值(即一个不是对象或数组的字段)。然后，它为这个原始值以及该字段的完整路径建立索引。 给定样本文档，通配符索引将以下记录添加到索引中： \"parentField.nestedField\" : \"nestedValue\" \"parentField.nestedObject.deeplyNestedField\" : \"deeplyNestedValue\" \"parentField.nestedArray\" : \"nestedElement\" 有关嵌套数组的通配符索引行为的更多信息，请参见嵌套数组。 嵌套数组 当通配符索引遇到嵌套数组时，它尝试遍历该数组以索引其元素。如果数组本身是父数组(即嵌入式数组)中的一个元素，通配符索引会将整个数组记录为一个值，而不是遍历其内容。例如: { \"parentArray\" : [ \"arrayElementOne\", [ \"embeddedArrayElement\" ], \"nestedObject\" : { \"nestedArray\" : [ \"nestedArrayElementOne\", \"nestedArrayElementTwo\" ] } ] } 包含parentArray的通配符索引向下到数组中遍历和索引它的内容: 对于作为数组（即嵌入式数组）的每个元素，将整个数组索引为一个值。 对于作为对象的每个元素，请进入该对象以遍历并为其内容编制索引。 对于所有其他字段，将原始（非对象/数组）值记录到索引中。 通配符索引继续遍历任何附加的嵌套对象或数组，直到它到达一个基本值(即一个不是对象或数组的字段)。然后，它为这个原始值以及该字段的完整路径建立索引。 给定样本文档，通配符索引将以下记录添加到索引中： \"parentArray\" : \"arrayElementOne\" \"parentArray\" : [\"embeddedArrayElement\"] \"parentArray.nestedObject.nestedArray\" : \"nestedArrayElementOne\" \"parentArray.nestedObject.nestedArray\" : \"nestedArrayElementTwo\" 注意，记录parentField.nestedArray不包含每个元素的数组位置。当将元素记录到索引中时，通配符索引会忽略数组元素的位置。通配符索引仍然可以支持包含显式数组索引的查询。有关更多信息，请参见 具有显式数组索引的查询。 也可以看看：Nested Depth for BSON Documents. 限制条件 您不能使用通配符索引来分片集合。在要分片的一个或多个字段上创建一个非通配符索引。有关分片键选择的更多信息，请参见分片 键。 您不能创建复合索引。 您不能为通配符索引指定以下属性： TTL Unique 您不能使用通配符语法创建以下索引类型： 2d（地理空间） 2dsphere（地理空间） Hashed [warning] 重要 通配符索引与通配符文本索引不同并且不兼容 。通配符索引不能支持使用$text运算符的查询。 有关通配符索引创建限制的完整文档，请参阅 不兼容的索引类型或属性。 通配符索引查询/排序支持 覆盖查询 仅当满足以下所有条件时，通配符索引才能支持覆盖的查询 ： 查询计划者选择通配符索引来满足查询谓词。 查询谓词恰好指定了通配符索引覆盖的一个字段。 该投影显式排除_id并仅包括查询字段。 指定的查询字段永远不会是数组。 考虑employees集合上的以下通配符索引： db.products.createIndex( { \"$**\" : 1 } ) 下面的操作查询单个字段的姓，并从结果文档中抽取所有其他字段: db.products.find( { \"lastName\" : \"Doe\" }, { \"_id\" : 0, \"lastName\" : 1 } ) 假设指定的lastName对象永远不是数组，MongoDB可以使用$**通配符索引来支持覆盖查询。 包含多个字段的查询谓词 通配符索引最多可以支持一个查询谓词字段。那是： MongoDB无法使用非通配符索引来满足查询谓词的一部分，而不能使用通配符索引来满足另一部分。 MongoDB无法使用一个通配符索引来满足查询谓词的一部分，而使用另一个通配符索引来满足另一部分。 即使单个通配符索引可以支持多个查询字段，MongoDB也可以使用通配符索引来仅支持其中一个查询字段。解析所有其余字段而没有索引。 但是，MongoDB可以使用相同的通配符索引来满足查询$or或聚合 $or运算符的每个独立参数。 查询和排序 MongoDB可以使用通配符索引来满足sort()，只有当所有这些都是真的: 查询计划者选择通配符索引来满足查询谓词。 该sort()指定唯一的查询谓词场。 指定的字段永远不会是数组。 如果不满足上述条件，则MongoDB无法使用通配符索引进行排序。MongoDB不支持sort 需要与查询谓词不同的索引的操作。有关更多信息，请参见索引交集和排序。 考虑以下products集合上的通配符索引: db.products.createIndex( { \"product_attributes.$**\" : 1 } ) 下面的操作查询单个字段product_attributes.price和种类在同一领域: db.products.find( { \"product_attributes.price\" : { $gt : 10.00 } }, ).sort( { \"product_attributes.price\" : 1 } ) 假设指定的price对象永远不是数组，MongoDB可以使用product_attributes.$**通配符索引来满足find()和sort()。 不支持的查询模式 通配符索引不支持查询条件，该条件检查字段是否不存在。 通配符索引不支持查询条件，该条件检查字段是否等于文档或数组 通配符索引不能支持检查字段是否不等于null的查询条件。 有关详细信息，请参阅不支持的查询和聚合模式。 用明确的数组索引查询 MongoDB通配符索引不会在索引期间记录数组中任何给定元素的数组位置。但是，MongoDB仍然可以选择通配符索引来回答包含具有一个或多个显式数组索引（例如，parentArray.0.nestedArray.0）的字段路径的查询 。由于为每个连续的嵌套数组定义索引范围的复杂性越来越高，因此，如果该路径包含的8显式数组索引不多，MongoDB不会考虑使用通配符索引来回答查询中的给定字段路径。MongoDB仍然可以考虑使用通配符索引来回答查询中的其他字段路径。 例如： { \"parentObject\" : { \"nestedArray\" : [ \"elementOne\", { \"deeplyNestedArray\" : [ \"elementTwo\" ] } ] } } MongoDB可以选择一个通配符索引，其中包括parentObject，以满足以下查询: \"parentObject.nestedArray.0\" : \"elementOne\" \"parentObject.nestedArray.1.deeplyNestedArray.0\" : \"elementTwo\" 如果查询谓词中的给定字段路径指定了8个以上的显式数组索引，则MongoDB不会考虑使用通配符索引来回答该字段路径。相反，MongoDB要么选择另一个符合条件的索引来回答查询，要么执行集合扫描。 请注意，通配符索引本身对索引时遍历文档的深度没有任何限制；该限制仅适用于明确指定确切数组索引的查询。通过发出没有显式数组索引的相同查询，MongoDB可以选择通配符索引来回答该查询： \"parentObject.nestedArray\" : \"elementOne\" \"parentObject.nestedArray.deeplyNestedArray\" : \"elementTwo\" 也可以看看 Nested Depth for BSON Documents 译者：杨帅 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security.html":{"url":"09-security.html","title":"安全","keywords":"","body":" 安全 MongoD提供了各种各样的功能让你安全地部署MongoDB，诸如：身份认证、访问控制、加密。一些关键的安全功能包括： Authentication Authorization TLS/SSL 身份认证 SCRAM x.509 基于角色的访问控制 启动访问控制 用户与角色管理 TLS/SSL (传输加密) 使用TLS/SSL配置mongod和mongos 为客户端配置TLS/SSL Enterprise Only Encryption Kerberos 验证 LDAP 代理验证 静态加密 审计 客户端字段级加密 译者：傅立 参见 原文 - Security Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/01-security-checklist.html":{"url":"09-security/01-security-checklist.html","title":"安全检查列表","keywords":"","body":" 安全检查列表 MongoDB还为如何保护MongoDB部署提供了一个建议的操作列表即安全检查列表) 最后更新于：2019-12-05 这个文档提供了一个保护MongoDB应该实施的安全措施列表。这个列表并不是完整无遗的。 生产环境前的检查列表/注意事项 ➤启动访问控制和强制身份认证 启动访问控制和指定身份认证的机制。你可以使用MongoDB的SCRMA或者x.509身份认证机制或者集成你已经使用的Kerberos/LDAP基础设施。身份认证要求所有的客户端和服务端在连接到系统之前提供有效的凭证。 请参阅身份认证和开启访问控制。 ➤ 配置基于角色的访问控制 首先创建一个管理员用户，然后再创建其他的用户。为每一人/应用程序创建唯一的用户以访问系统。 遵循最小权限原则。为一组用户创建他们所需的确切访问权限的角色。然后创建用户并且仅为他们分配执行操作所需的角色。一个用户可以是个人或者一个客户端程序。 提示： 一个用户在不同数据库可以拥有不同的权限。如果一个用户要求在多个数据库的权限，使用有多个可授予适当数据库权限的角色来创建一个单一用户，而不是给不同的数据库创建多个用户。 请参阅基于角色的访问控制和用户与角色管理。 ➤ 加密通信（TLS/SSL） 配置MongoDB为所有传入和传出连接使用TLS/SSL。使用TLS/SSL加密MongoDB部署的mongod和mongos组件以及所有应用程序和MongoDB之间的通信。 从4.0版本开始，MongoDB使用操作系统原生的TLS/SSL库： 操作系统 使用的系统库 Linux/BSD OpenSSL macOS Secure Transport 注意 从4.0版本开始，在支持TLS1.1+的系统上，MongoDB会禁用TLS1.0加密。更多详细信息，请参阅 禁用TLS1.0. 请参阅使用TLS/SSL配置mongod和mongos ➤加密和保护数据 从MongoDB 3.2企业版开始，你可以使用WiredTiger存储引擎的本地静态加密来加密存储层的数据。 如果你没有使用WiredTiger的静态加密，MongoDB的数据应该在每台主机上使用文件系统、设备或物理加密（例如dm-crypt）。使用文件系统权限保护MongoDB数据。MongoDB数据包括数据文件、配置文件、审计日志以及秘钥文件。 将日志收集到一个中央日志存储区。这些日志包含了DB身份认证尝试及其源IP地址. ➤ 限制网络暴露 确保MongoDB运行在受信任的网络环境中并且配置防火墙或者安全组来控制MongoDB实例的入站和出站流量。 只允许受信任的客户端访问MongoDB实例所在的网络接口和端口。例如，使用白名单机制允许受信任的IP地址访问。 注意 从MongoDB 3.6开始，MongoDB的二进制文件：mongod和mongos会默认绑定在localhost上。MongoDB 2.6到3.4版本，只有官方MongoDB RPM（Red Hat、CentOS、Fedora Linux和衍生品）和DEB（Debian、Ubuntu和衍生品）包中的二进制文件默认绑定在localhost。了解更多关于这个改变的信息，请参阅localhost绑定兼容变更 请参阅： 网络和配置加固 net.bindIp配置设定 security.clusterIpSourceWhitelist配置设定 authenticationRestrictions为每个用户指定IP白名单 禁用直接SSH root访问。 ➤系统活动审计 跟踪对数据库配置和数据的访问和更改。MongoDB企业版包含了一个系统审计工具，可以记录MongoDB实例上的系统事件（例如用户操作、连接事件）。这些审计记录使审查分析得以进行并且允许管理员去验证适当的控制。可以设置过滤器来记录特定的事件，例如身份认证事件。 请参阅Auditing 和Configure Auditing ➤使用专用用户运行MongoDB 使用一个专用的操作系统账户运行MongoDB进程。确保这个账户除了访问数据，没有不必要的权限。 关于运行MongoDB的更多信息，请参阅MongoDB安装 ➤ 使用安全的配置选项运行MongoDB MongoDB支持使用JavaScript代码对服务器端执行特定的操作，包括：mapReduce和$where。如果你不使用这些操作，在命令行使用--noscripting选项来禁用服务器端脚本。 确保启用了输入验证。MongoDB默认通过net.wireObjectCheck设置启用输入验证。这确保了mongod实例存储的所有文档都是有效的BSON。 请参阅：网络和配置加固 ➤索取安全技术实施指南（如适用） 安全技术实施指南（STIG）包含美国国防部内部部署的安全指南。MongoDB公司为需要的情况提供了它的STIG。请索取一个副本以获取更多信息。 ➤考虑安全标准的合规性 对于需要遵循HIPAA或者PCI-DSS的应用程序，请参看MongoDB安全参考架构以了解更多关于如何使用关键安全功能来构建合规的应用程序基础设施。 定期/持续的产品检查 定期检查MongoDB产品通用漏洞披露并且更新你的产品。 查询MongoDB的生命周期终止日期并升级你的MongoDB。一般来说，尽量使用最新的版本。 确保你的信息安全管理的系统策略和程序在你安装的MongoDB上生效，包括执行以下操作： 定期对你的设备打补丁并且检查操作指南 检查策略及流程变更，尤其是网络规则的更改，以防无意中将MongoDB暴露在互联网。 检查MongoDB数据库用户并定期进行轮换。 原文链接：https://docs.mongodb.com/manual/security/ https://docs.mongodb.com/manual/administration/security-checklist/ 译者：傅立 参见 原文 - Security Checklist Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/02-enable-authentication.html":{"url":"09-security/02-enable-authentication.html","title":"Enable Access Control","keywords":"","body":" Enable Access Control ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Enable Access Control Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication.html":{"url":"09-security/03-authentication.html","title":"身份验证","keywords":"","body":" 身份验证 在本页面 身份验证方法 身份验证机制 内部身份验证 分片集群中的身份验证 身份验证是验证客户端身份的过程。当访问控制（即授权）开启的时候，MongoDB要求所有客户端进行身份认证，以确定他们的访问权限。 尽管身份认证和授权紧密相连，但是身份认证和授权是不同的。身份认证是验证用户的身份，授权决定已通过验证的用户对资源和操作的访问权限。 身份验证的方法 作为一个用户要进行身份验证，你必须提供一个用户名、密码和关联这个用户的认证数据库。 使用mongo shell 进行身份验证，可以： 当连接mongod或者mongos实例时，使用mongo命令行认证选项（--username、--password和--authenticationDatabase），也可以 先连接mongod或者mongos实例，然后在认证数据库上运行authenticate命令或者db.auth()方法。 重要： 当使用不同的用户进行多次身份验证时，不会删除已经通过身份认证的用户的凭证。这可能导致这个进行过多个用户身份认证的连接具有比用户预期更多的权限，并导致在一个逻辑会话中的操作引发错误。 关于使用MongoDB驱动程序进行身份验证的示例，请参阅驱动程序文档。 身份验证机制 MongoDB支持许多身份认证机制，客户端可以使用这些身份认证机制来验证自己的身份。MongoDB允许集成这些机制到已经存在的身份认证系统。 MongoDB支持多种身份验证机制： SCRAM (默认的) x.509证书身份验证. 内部身份验证 除了验证客户端的身份之外，MongoDB能要求副本集和分片集群的成员对其各自的副本集或者分片集群的成员资格进行身份验证。更多的信息请参阅：内部/成员身份认证。 分片集群的身份验证 在分片集群中，客户端通常直接向mongos实例进行身份认证。然而，一些维护操作可能要求对特定的分片进行认证。更多关于身份认证和分片集群的信息，请参阅分片集群用户。 原文链接：https://docs.mongodb.com/manual/core/authentication/ 译者：傅立 参见 原文 - Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/01-security-users.html":{"url":"09-security/03-authentication/01-security-users.html","title":"Users","keywords":"","body":" Users ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Users Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/01-security-users/01-create-users.html":{"url":"09-security/03-authentication/01-security-users/01-create-users.html","title":"Add Users","keywords":"","body":" Add Users ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Add Users Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/02-authentication-mechanisms.html":{"url":"09-security/03-authentication/02-authentication-mechanisms.html","title":"Authentication Mechanisms","keywords":"","body":" Authentication Mechanisms ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Authentication Mechanisms Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/02-authentication-mechanisms/01-security-scram.html":{"url":"09-security/03-authentication/02-authentication-mechanisms/01-security-scram.html","title":"SCRAM","keywords":"","body":" SCRAM ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - SCRAM Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/02-authentication-mechanisms/02-security-x.509.html":{"url":"09-security/03-authentication/02-authentication-mechanisms/02-security-x.509.html","title":"x.509","keywords":"","body":" x.509 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - x.509 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/02-authentication-mechanisms/02-security-x.509/01-configure-x509-client-authentication.html":{"url":"09-security/03-authentication/02-authentication-mechanisms/02-security-x.509/01-configure-x509-client-authentication.html","title":"Use x.509 Certificates to Authenticate Clients","keywords":"","body":" Use x.509 Certificates to Authenticate Clients ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Use x.509 Certificates to Authenticate Clients Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise.html","title":"Enterprise Authentication Mechanisms","keywords":"","body":" Enterprise Authentication Mechanisms ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Enterprise Authentication Mechanisms Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos.html","title":"Kerberos Authentication","keywords":"","body":" Kerberos Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Kerberos Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/01-control-access-to-mongodb-with-kerberos-authentication.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/01-control-access-to-mongodb-with-kerberos-authentication.html","title":"Configure MongoDB with Kerberos Authentication on Linux","keywords":"","body":" Configure MongoDB with Kerberos Authentication on Linux ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure MongoDB with Kerberos Authentication on Linux Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/02-control-access-to-mongodb-windows-with-kerberos-authentication.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/02-control-access-to-mongodb-windows-with-kerberos-authentication.html","title":"Configure MongoDB with Kerberos Authentication on Windows","keywords":"","body":" Configure MongoDB with Kerberos Authentication on Windows ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure MongoDB with Kerberos Authentication on Windows Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/03-troubleshoot-kerberos.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/03-troubleshoot-kerberos.html","title":"Troubleshoot Kerberos Authentication","keywords":"","body":" Troubleshoot Kerberos Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Troubleshoot Kerberos Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/04-kerberos-auth-activedirectory-authz.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/01-kerberos/04-kerberos-auth-activedirectory-authz.html","title":"Configure MongoDB with Kerberos Authentication and Active Directory Authorization","keywords":"","body":" Configure MongoDB with Kerberos Authentication and Active Directory Authorization ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure MongoDB with Kerberos Authentication and Active Directory Authorization Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap.html","title":"LDAP Proxy Authentication","keywords":"","body":" LDAP Proxy Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - LDAP Proxy Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/01-configure-ldap-sasl-activedirectory.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/01-configure-ldap-sasl-activedirectory.html","title":"Authenticate Using SASL and LDAP with ActiveDirectory","keywords":"","body":" Authenticate Using SASL and LDAP with ActiveDirectory ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Authenticate Using SASL and LDAP with ActiveDirectory Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/02-configure-ldap-sasl-openldap.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/02-configure-ldap-sasl-openldap.html","title":"Authenticate Using SASL and LDAP with OpenLDAP","keywords":"","body":" Authenticate Using SASL and LDAP with OpenLDAP ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Authenticate Using SASL and LDAP with OpenLDAP Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/03-authenticate-nativeldap-activedirectory.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/02-security-ldap/03-authenticate-nativeldap-activedirectory.html","title":"Authenticate and Authorize Users Using Active Directory via Native LDAP","keywords":"","body":" Authenticate and Authorize Users Using Active Directory via Native LDAP ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Authenticate and Authorize Users Using Active Directory via Native LDAP Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/03-authentication-mechanisms-enterprise/03-security-ldap-external.html":{"url":"09-security/03-authentication/03-authentication-mechanisms-enterprise/03-security-ldap-external.html","title":"LDAP Authorization","keywords":"","body":" LDAP Authorization ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - LDAP Authorization Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication.html":{"url":"09-security/03-authentication/04-security-internal-authentication.html","title":"Internal/Membership Authentication","keywords":"","body":" Internal/Membership Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Internal/Membership Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/01-deploy-replica-set-with-keyfile-access-control.html":{"url":"09-security/03-authentication/04-security-internal-authentication/01-deploy-replica-set-with-keyfile-access-control.html","title":"Deploy Replica Set With Keyfile Authentication","keywords":"","body":" Deploy Replica Set With Keyfile Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy Replica Set With Keyfile Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/02-enforce-keyfile-access-control-in-existing-replica-set.html":{"url":"09-security/03-authentication/04-security-internal-authentication/02-enforce-keyfile-access-control-in-existing-replica-set.html","title":"Update Replica Set to Keyfile Authentication","keywords":"","body":" Update Replica Set to Keyfile Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Update Replica Set to Keyfile Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/03-enforce-keyfile-access-control-in-existing-replica-set-without-downtime.html":{"url":"09-security/03-authentication/04-security-internal-authentication/03-enforce-keyfile-access-control-in-existing-replica-set-without-downtime.html","title":"Update Replica Set to Keyfile Authentication (No Downtime)","keywords":"","body":" Update Replica Set to Keyfile Authentication (No Downtime) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Update Replica Set to Keyfile Authentication (No Downtime) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/04-rotate-key-replica-set.html":{"url":"09-security/03-authentication/04-security-internal-authentication/04-rotate-key-replica-set.html","title":"Rotate Keys for Replica Sets","keywords":"","body":" Rotate Keys for Replica Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rotate Keys for Replica Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/05-deploy-sharded-cluster-with-keyfile-access-control.html":{"url":"09-security/03-authentication/04-security-internal-authentication/05-deploy-sharded-cluster-with-keyfile-access-control.html","title":"Deploy Sharded Cluster with Keyfile Authentication","keywords":"","body":" Deploy Sharded Cluster with Keyfile Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy Sharded Cluster with Keyfile Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/06-enforce-keyfile-access-control-in-existing-sharded-cluster.html":{"url":"09-security/03-authentication/04-security-internal-authentication/06-enforce-keyfile-access-control-in-existing-sharded-cluster.html","title":"Update Sharded Cluster to Keyfile Authentication","keywords":"","body":" Update Sharded Cluster to Keyfile Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Update Sharded Cluster to Keyfile Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/07-enforce-keyfile-access-control-in-existing-sharded-cluster-no-downtime.html":{"url":"09-security/03-authentication/04-security-internal-authentication/07-enforce-keyfile-access-control-in-existing-sharded-cluster-no-downtime.html","title":"Update Sharded Cluster to Keyfile Authentication (No Downtime)","keywords":"","body":" Update Sharded Cluster to Keyfile Authentication (No Downtime) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Update Sharded Cluster to Keyfile Authentication (No Downtime) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/08-rotate-key-sharded-cluster.html":{"url":"09-security/03-authentication/04-security-internal-authentication/08-rotate-key-sharded-cluster.html","title":"Rotate Keys for Sharded Clusters","keywords":"","body":" Rotate Keys for Sharded Clusters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rotate Keys for Sharded Clusters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/09-configure-x509-member-authentication.html":{"url":"09-security/03-authentication/04-security-internal-authentication/09-configure-x509-member-authentication.html","title":"Use x.509 Certificate for Membership Authentication","keywords":"","body":" Use x.509 Certificate for Membership Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Use x.509 Certificate for Membership Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/10-upgrade-keyfile-to-x509.html":{"url":"09-security/03-authentication/04-security-internal-authentication/10-upgrade-keyfile-to-x509.html","title":"Upgrade from Keyfile Authentication to x.509 Authentication","keywords":"","body":" Upgrade from Keyfile Authentication to x.509 Authentication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade from Keyfile Authentication to x.509 Authentication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/03-authentication/04-security-internal-authentication/11-rotate-x509-membership-certificates.html":{"url":"09-security/03-authentication/04-security-internal-authentication/11-rotate-x509-membership-certificates.html","title":"Rolling Update of x.509 Cluster Certificates that Contain New DN","keywords":"","body":" Rolling Update of x.509 Cluster Certificates that Contain New DN ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rolling Update of x.509 Cluster Certificates that Contain New DN Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization.html":{"url":"09-security/04-authorization.html","title":"Role-Based Access Control","keywords":"","body":" Role-Based Access Control ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Role-Based Access Control Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization/01-built-in-roles.html":{"url":"09-security/04-authorization/01-built-in-roles.html","title":"Built-In Roles","keywords":"","body":" Built-In Roles ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Built-In Roles Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization/02-security-user-defined-roles.html":{"url":"09-security/04-authorization/02-security-user-defined-roles.html","title":"User-Defined Roles","keywords":"","body":" User-Defined Roles ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - User-Defined Roles Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization/03-manage-users-and-roles.html":{"url":"09-security/04-authorization/03-manage-users-and-roles.html","title":"Manage Users and Roles","keywords":"","body":" Manage Users and Roles ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Users and Roles Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization/04-change-own-password-and-custom-data.html":{"url":"09-security/04-authorization/04-change-own-password-and-custom-data.html","title":"Change Your Password and Custom Data","keywords":"","body":" Change Your Password and Custom Data ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change Your Password and Custom Data Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/04-authorization/05-collection-level-access-control.html":{"url":"09-security/04-authorization/05-collection-level-access-control.html","title":"Collection-Level Access Control","keywords":"","body":" Collection-Level Access Control ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Collection-Level Access Control Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/05-security-transport-encryption.html":{"url":"09-security/05-security-transport-encryption.html","title":"TLS/SSL (Transport Encryption)","keywords":"","body":" TLS/SSL (Transport Encryption) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - TLS/SSL (Transport Encryption) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/05-security-transport-encryption/01-configure-ssl.html":{"url":"09-security/05-security-transport-encryption/01-configure-ssl.html","title":"Configure mongod and mongos for TLS/SSL","keywords":"","body":" Configure mongod and mongos for TLS/SSL ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure mongod and mongos for TLS/SSL Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/05-security-transport-encryption/02-configure-ssl-clients.html":{"url":"09-security/05-security-transport-encryption/02-configure-ssl-clients.html","title":"TLS/SSL Configuration for Clients","keywords":"","body":" TLS/SSL Configuration for Clients ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - TLS/SSL Configuration for Clients Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/05-security-transport-encryption/03-upgrade-cluster-to-ssl.html":{"url":"09-security/05-security-transport-encryption/03-upgrade-cluster-to-ssl.html","title":"Upgrade a Cluster to Use TLS/SSL","keywords":"","body":" Upgrade a Cluster to Use TLS/SSL ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Cluster to Use TLS/SSL Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/05-security-transport-encryption/04-configure-fips.html":{"url":"09-security/05-security-transport-encryption/04-configure-fips.html","title":"Configure MongoDB for FIPS","keywords":"","body":" Configure MongoDB for FIPS ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure MongoDB for FIPS Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/06-security-encryption-at-rest.html":{"url":"09-security/06-security-encryption-at-rest.html","title":"Encryption at Rest","keywords":"","body":" Encryption at Rest ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Encryption at Rest Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/06-security-encryption-at-rest/01-configure-encryption.html":{"url":"09-security/06-security-encryption-at-rest/01-configure-encryption.html","title":"Configure Encryption","keywords":"","body":" Configure Encryption ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure Encryption Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/06-security-encryption-at-rest/02-rotate-encryption-key.html":{"url":"09-security/06-security-encryption-at-rest/02-rotate-encryption-key.html","title":"Rotate Encryption Keys","keywords":"","body":" Rotate Encryption Keys ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rotate Encryption Keys Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption.html":{"url":"09-security/07-security-client-side-encryption.html","title":"Client-Side Field Level Encryption","keywords":"","body":" Client-Side Field Level Encryption ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Client-Side Field Level Encryption Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption.html":{"url":"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption.html","title":"Automatic Client-Side Field Level Encryption","keywords":"","body":" Automatic Client-Side Field Level Encryption ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Automatic Client-Side Field Level Encryption Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/01-security-client-side-automatic-json-schema.html":{"url":"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/01-security-client-side-automatic-json-schema.html","title":"Automatic Encryption Rules","keywords":"","body":" Automatic Encryption Rules ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Automatic Encryption Rules Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/02-security-client-side-query-aggregation-support.html":{"url":"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/02-security-client-side-query-aggregation-support.html","title":"Read/Write Support with Automatic Field Level Encryption","keywords":"","body":" Read/Write Support with Automatic Field Level Encryption ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Read/Write Support with Automatic Field Level Encryption Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/03-security-client-side-encryption-appendix.html":{"url":"09-security/07-security-client-side-encryption/01-security-automatic-client-side-encryption/03-security-client-side-encryption-appendix.html","title":"Appendix","keywords":"","body":" Appendix ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Appendix Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/02-security-explicit-client-side-encryption.html":{"url":"09-security/07-security-client-side-encryption/02-security-explicit-client-side-encryption.html","title":"Explicit (Manual) Client-Side Field Level Encryption","keywords":"","body":" Explicit (Manual) Client-Side Field Level Encryption ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Explicit (Manual) Client-Side Field Level Encryption Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/03-security-client-side-encryption-key-management.html":{"url":"09-security/07-security-client-side-encryption/03-security-client-side-encryption-key-management.html","title":"Master Key and Data Encryption Key Management","keywords":"","body":" Master Key and Data Encryption Key Management ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Master Key and Data Encryption Key Management Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/03-security-client-side-encryption-key-management/01-manage-client-side-encryption-data-keys.html":{"url":"09-security/07-security-client-side-encryption/03-security-client-side-encryption-key-management/01-manage-client-side-encryption-data-keys.html","title":"Manage Data Encryption Keys","keywords":"","body":" Manage Data Encryption Keys ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Data Encryption Keys Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/07-security-client-side-encryption/04-security-client-side-encryption-limitations.html":{"url":"09-security/07-security-client-side-encryption/04-security-client-side-encryption-limitations.html","title":"Limitations","keywords":"","body":" Limitations ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Limitations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/08-auditing.html":{"url":"09-security/08-auditing.html","title":"审计","keywords":"","body":" 审计 在本页 启用和配置审计输出 审计事件和过滤器 审计保证 MongoDB 企业版包含针对 mongod 和 mongos 实例的审计功能 。审核功能使管理员和用户可以跟踪具有多个用户和多个客户端应用的 mongodb 的运行情况。 启用和配置审计输出 审计功能可以将审计事件写入控制台console，syslog，JSON 文件或 BSON 文件。要为 MongoDB 企业版启用审计，请参阅配置审计。 有关审计日志消息的信息，请参阅系统事件审计消息。 审计事件和过滤器 启用后，审计系统可以记录以下操作[1]: 模式（DDL）, 副本集集群和分片集群， 认证和授权，以及 CRUD操作（要求auditAuthorizationSuccess设置为true）。 有关审计的操作的详细信息，请参阅审计事件操作，详细信息和结果。 使用审计系统，您可以设置过滤器以限制捕获的事件。要设置过滤器，请参阅“配置审计过滤器”。 在一个被中止的事务中[1]中的操作任然会生成一个审计事件，但是没有一个审计事件指示事务被中止了。 审计保证 审计系统将每个审计事件2写入审计事件的内存缓冲区中。MongoDB定期将此缓冲区写入磁盘。对于从任何单个连接收集的事件，这些事件具有总顺序：如果MongoDB将一个事件写入磁盘，系统将保证已将该连接的所有先前事件写入磁盘。 如果审计事件条目对应的操作影响数据库的持久状态，如修改数据的操作，则MongoDB始终会在将审计事件写入磁盘之前将事件条目写入日志 也就是说，在将操作添加到日志之前，MongoDB会在触发该操作的连接上写入所有审计事件，直到并包括该操作的条目。 这些审计保证要求MongoDB在journaling启用的情况下运行 。 警告 如果服务器在将事件提交到审计日志之前终止，则MongoDB可能会丢失事件。在MongoDB提交审计日志之前，客户端可能会收到事件确认。 例如，在审计聚合操作时，服务器可能在返回结果之后但在刷新审计日志之前崩溃。 2审计配置可以包括一个筛选器，以限制要审计的事件。 附录： Configure Auditing 配置审计：https://docs.mongodb.com/manual/tutorial/configure-auditing/ Configure Audit Filters 配置审计过滤器：https://docs.mongodb.com/manual/tutorial/configure-audit-filters/ System Event Audit Messages 系统事件审计消息： https://docs.mongodb.com/manual/reference/audit-message/ 原文链接：https://docs.mongodb.com/manual/core/auditing/ 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/08-auditing/01-configure-auditing.html":{"url":"09-security/08-auditing/01-configure-auditing.html","title":"配置审计","keywords":"","body":" 配置审计 在本页 启用和配置审计输出 启用和配置审计输出 MONGODB ATLAS中的审计: MongoDB Atlas支持对所有M10更大的集群进行审计。 Atlas支持指定“配置审计过滤器”中所述的JSON格式的审计过滤器， 并使用Atlas审计过滤器构建器来简化审计配置。 要了解更多信息，请参阅Atlas文档中的“设置数据库审计和配置自定义审计过滤器”。 MongoDB 企业版支持审计各种操作。 完整的审计解决方案必须涉及所有 mongod服务器 和 mongos 路由器过程。 审计工具可以将审计事件写入到控制台、syslog（Windows上不提供该 选项）、JSON文件或BSON文件。有关审计的操作和审计日志消息的详细信息，请参阅系统事件审计消息系统事件审计消息。 启用和配置审计输出 使用该--auditDestination选项可以启用审计并指定在何处输出审计事件。 警告 对于分片群集，如果对mongos实例启用审计，则必须对群集中的所有mongod实例（即分片和配置服务器）启用审计。 输出到Syslog 要启用审计并将审计事件以JSON格式打印到syslog（在Windows上该选项不可用），请为--auditDestination设置为syslog。例如： mongod --dbpath data/db --auditDestination syslog 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定 --bind_ip。有关更多信息，请参见 Localhost绑定兼容性更改。 重要 绑定到其他IP地址之前，请考虑启用范围控制和其他 绑定到其他IP地址之前，请考虑启用“安全性检查表” 中列出的访问控制和其他安全措施，以防止未经授权的访问。 警告 syslog消息限制可能导致审计消息被截断。审计系统不会在发生截断时检测到截断或错误。 您也可以在配置文件中指定以下选项： storage: dbPath: data/db auditLog: destination: syslog 输出到控制台 要启用审计并将审计事件打印到标准输出（即stdout），请为--auditDestination指定参数为'console'。例如： mongod --dbpath data/db --auditDestination console 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定 --bind_ip。有关更多信息，请参见 Localhost绑定兼容性更改。 重要 绑定到其他IP地址之前，请考虑启用“安全性检查表”中列出的访问控制和其他安全措施，以防止未经授权的访问。 您也可以在配置文件中指定以下选项： storage: dbPath: data/db auditLog: destination: console 输出到JSON文件¶ 要启用审计并将审计事件打印为BSON二进制格式的文件，请指定以下选项： 选项            值 --auditDestination   file --auditFormat     JSON --auditPath       输出文件名，接受完整路径名或相对路径名。 例如，以下选项启用审计并将审计事件记录到相对路径'data/db/auditLog.json'的文件中： mongod --dbpath data/db --auditDestination file --auditFormat JSON --auditPath data/db/auditLog.json 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定--bind_ip参数。有关更多信息，请参见Localhost绑定兼容性更改。 重要： 绑定到其他IP地址之前，请考虑启用“安全性检查表”中列出的访问控制和其他安全措施，以防止未经授权的访问。 审计文件与服务器日志文件同时旋转。 您也可以在配置文件中指定以下选项： storage: dbPath: data/db auditLog: destination: file format: JSON path: data/db/auditLog.json 注意 与以BSON格式打印到文件相比，以JSON格式打印审计事件到文件的性能降低服务器性能。 输出到BSON文件 ¶ 要启用审计并将审计事件打印为BSON二进制格式的文件，请指定以下选项： 选项            值 --auditDestination   file --auditFormat     BSON --auditPath        输出文件名，接受完整路径名或相对路径名。 例如，以下选项启用审计并将审计事件记录到相对路径'data/db/auditLog.bson'的文件中： mongod --dbpath data/db --auditDestination file --auditFormat BSON --auditPath data/db/auditLog.bson 例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定--bind_ip。更多信息请查看Localhost绑定兼容性更改。 重要 绑定到其他IP地址之前，请考虑启用“安全性检查表”中列出的访问控制和其他安全措施，以防止未经授权的访问。 审计文件与服务器日志文件同时旋转。 您也可以在配置文件中指定以下选项： storage: dbPath: data/db auditLog: destination: file format: BSON path: data/db/auditLog.bson 要查看文件的内容，请将文件传递给MongoDB实用程序 bsondump。例如，以下内容将审计日志转换为可读格式并输出到终端： bsondump data/db/auditLog.bson 也可以看 配置审计过滤器，审计，系统事件审计消息 原文链接：https://docs.mongodb.com/manual/tutorial/configure-auditing/ 译者：谢伟成 参见 原文 - Configure Auditing Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/08-auditing/02-configure-audit-filters.html":{"url":"09-security/08-auditing/02-configure-audit-filters.html","title":"配置审计过滤器","keywords":"","body":" 配置审计过滤器¶ 在本页 --auditFilter 选项 示例 MongoDB Atlas 中的审计 MongoDB Atlas支持对所有M10和更大的集群进行审计。 Atlas支持在配置审计过滤器中指定JSON格式的审计过滤器，并使用Atlas审计过滤器构建器来简化审计配置。 要了解更多信息，请参阅Atlas文档中的设置数据库审计和配置自定义审计过滤器。 MongoDB 企业版支持审计各种操作。 启用审计功能会默认的记录所有可审计的操作，如审计事件操作，详细信息和结果。 为了能指定那些事件需要被记录，审计功能包含--auditFilter选项。 注意 从mongoDB 3.6开始，mongod and mongos默认绑定localhost。 如果你部署的实例运行在不同的主机上或者如果你希望远程客户端连接到部署实例，你必须指定--bind_ip or net.bindIp. 更多信息，请查看Localhost 绑定兼容性更改。 绑定到其他IP地址之前，请考虑启用访问控制和“安全性检查表”中的列出的其他安全措施，以防止未经授权的访问。 --auditFilter 选项¶ --auditFilter`选项采用以下查询文档的字符串的表示形式： 复制 { : , ... } 可以是审计消息中的任何字段，包括param文档中返回的字段。 是一个查询条件表达式。 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 例子¶ 多种操作类型的过滤器¶ 以下示例通过使用过滤器仅审计 createCollection 和 dropCollection操作： 复制 { atype: { $in: [\"createCollection\", \"dropCollection\"] } } 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 复制 mongod --dbpath data/db --auditDestination file --auditFilter '{ atype: { $in: [ \"createCollection\", \"dropCollection\" ] } }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，​​请指定--bind_ip参数。更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ atype: { $in: [ \"createCollection\", \"dropCollection\" ] } }' 筛选单个数据库上的身份验证操作¶ 可以包含审计消息中的任何字段。对于身份认证操作(即，atype: \"authenticate\")，审计消息中的 param 文档中包含 db 字段。 以下示例使用过滤器仅审计针对test数据库的身份验证操作。 复制 { atype: \"authenticate\", \"param.db\": \"test\" } 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 复制 mongod --dbpath data/db --auth --auditDestination file --auditFilter '{ atype: \"authenticate\", \"param.db\": \"test\" }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定--bind_ip参数。更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db security: authorization: enabled auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ atype: \"authenticate\", \"param.db\": \"test\" }' 要过滤数据库中的所有身份验证操作，请使用过滤器{ atype: \"authenticate\" }。 筛选单个数据库的集合创建和删除操作¶ 可以包含审计消息中的任何字段。对于集合创建和删除操作(即，atype: \"createCollection\"和atype: \"dropCollection\")，审计消息中的 param 文档中包含ns 字段。 以下示例使用过滤器仅审计针对test数据库的创建集合和删除集合操作。 注意 正则表达式需要两个反斜杠(\\\\)才能转义(.) 复制 { atype: { $in: [ \"createCollection\", \"dropCollection\" ] }, \"param.ns\": /^test\\\\./ } } 将过滤器文档括在单引号中使其转成字符串来指定一个审计过滤器。 复制 mongod --dbpath data/db --auth --auditDestination file --auditFilter '{ atype: { $in: [ \"createCollection\", \"dropCollection\" ] }, \"param.ns\": /^test\\\\./ } }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定 --bind_ip参数。更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db security: authorization: enabled auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ atype: { $in: [ \"createCollection\", \"dropCollection\" ] }, \"param.ns\": /^test\\\\./ } }' 通过授权角色进行筛选¶ 以下示例通过使用过滤器来审计test数据库上具有 readWrite角色的用户的操作，包括具有从[readWrite]继承的角色的用户： 复制 { roles: { role: \"readWrite\", db: \"test\" } } 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 复制 mongod --dbpath data/db --auth --auditDestination file --auditFilter '{ roles: { role: \"readWrite\", db: \"test\" } }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定 --bind_ip参数。更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db security: authorization: enabled auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ roles: { role: \"readWrite\", db: \"test\" } }' 读写操作中的过滤器¶ 要在审计中进行捕获读和写操作，必须设置审计参数使审计系统记录身份验证成功。1 注意 启用审计授权成功与仅记录授权失败相比会使性能下降更多。 下面的例子用来审计find(), insert(), remove(), update(), save()和 findAndModify()这些操作，过滤器如下： 复制 { atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] } } 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 复制 mongod --dbpath data/db --auth --setParameter auditAuthorizationSuccess=true --auditDestination file --auditFilter '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\"] } }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定--bind_ip参数。更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db security: authorization: enabled auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ atype: \"authCheck\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] } }' setParameter: { auditAuthorizationSuccess: true } 过滤集合的读写操作¶ 要在审计中进行捕获读和写操作，还必须使用 auditAuthorizationSuccess 参数使审计系统能够记录授权成功。 1 注意 启用审计授权成功与仅记录授权失败相比，启用会使性能下降更多。 下面的例子用来审计在test数据库的orders集合上的find(), insert(), remove(), update(), save(), and findAndModify()操作，过滤器如下： 复制 { atype: \"authCheck\", \"param.ns\": \"test.orders\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] } } 指定一个审计过滤器，可以将过滤器文档括在单引号中使其转成字符串。 复制 mongod --dbpath data/db --auth --setParameter auditAuthorizationSuccess=true --auditDestination file --auditFilter '{ atype: \"authCheck\", \"param.ns\": \"test.orders\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] } }' --auditFormat BSON --auditPath data/db/auditLog.bson 包括配置所需的其他选项。例如，如果您希望远程客户端连接到您的部署，或者您的部署成员在不同的主机上运行，请指定 --bind_ip参数。有关更多信息，请参见Localhost绑定兼容性更改。 在配置文件中指定审计过滤器，必须使用配置文件的YAML格式。 复制 storage: dbPath: data/db security: authorization: enabled auditLog: destination: file format: BSON path: data/db/auditLog.bson filter: '{ atype: \"authCheck\", \"param.ns\": \"test.orders\", \"param.command\": { $in: [ \"find\", \"insert\", \"delete\", \"update\", \"findandmodify\" ] } }' setParameter: { auditAuthorizationSuccess: true } 也可以看看 配置审计, 审计, 系统事件审计消息 [1]（1，2）可以启用审计授权成功参数不启用 --auth; 但是所有操作将返回成功以进行授权检查。 原文链接：https://docs.mongodb.com/manual/tutorial/configure-audit-filters/ 译者：谢伟成 参见 原文 - Configure Audit Filters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/08-auditing/03-audit-message.html":{"url":"09-security/08-auditing/03-audit-message.html","title":"系统事件审计消息","keywords":"","body":" 系统事件审计消息¶ 在本页 审计消息 审计事件操作，详情和结果 注意 仅在MongoDB 企业版和MongoDB Atlas可用。 审计消息¶ 事件审计功能可以用JSON格式记录事件。配置审计输出，请参阅配置审计。 记录的JSON消息格式如下： 复制 { atype: , ts : { \"$date\": }, local: { ip: , port: }, remote: { ip: , port: }, users : [ { user: , db: }, ... ], roles: [ { role: , db: }, ... ], param: , result: } 字段 类型 描述 atype string 操作类型. 详情请看审计事件操作，详情和结果. ts document 文档包含日期和UTC时间格式为ISO 8601 local document 文档包含运行实例本地IP和端口 remote document 文档包含与事件相关的传入连接的远程ip和端口号 users array 数组包含一组用户识别文档。由于MongoDB允许会话以每个数据库的不同用户身份登录，因此该数组可以包含多个用户。每个文档都包含user字段记录用户名和db字段记录验证该用户的数据库名 roles array 数组包含文档，用于指定授予用户的角色。每个文档包含一个role字段记录角色名和一个db字段记录与该角色相关的数据库名 param document 事件的详细信息。请看审计事件操作，详情和结果. result integer 错误码。请看审计事件操作，详情和结果. 审计事件操作，详情和结果¶ 下表列出了每种atype或操作类型，相关的param详细信息和result值(如果有)。 atype param result authenticate { user: , db: , mechanism: } 0 - Success 18 - Authentication Failed authCheck { command:, ns:., args:} ns字段是可选的。args字段可能已经被修改了。 0 - Success13 - Unauthorized to perform the operation.默认情况下，审计系统仅记录授权失败。要使系统记录授权成功，请使用auditAuthorizationSuccess参数。[1] createCollection { ns:.} 0 - Success createDatabase { ns:} 0 - Success createIndex { ns:., indexName:, indexSpec:} 0 - Success renameCollection { old:., new:.} 0 - Success dropCollection { ns:.} 0 - Success dropDatabase { ns:} 0 - Success dropIndex { ns:., indexName:} 0 - Success createUser { user:, db:, customData:, roles: [ { role: , db: }, ... ] }customData字段是可选的。 0 - Success dropUser { user:, db:} 0 - Success dropAllUsersFromDatabase { db:} 0 - Success updateUser { user:, db:, passwordChanged:, customData:, roles: [ { role:, db: }, ... ] } customData 字段是可选的。 0 - Success grantRolesToUser { user: , db: , roles: [ { role: , db: }, ... ] } 0 - Success revokeRolesFromUser { user: , db: , roles: [ { role: , db: }, ... ] } 0 - Success createRole { role:, db:, roles: [ { role:, db: }, ... ], privileges: [ { resource:, actions: [, ... ] }, ... ] }roles和privileges字段是可选的，关于resource文档详情，请查看Resource Document.关于操作列表，请查看Privilege Actions. 0 - Success updateRole { role:, db:, roles: [ { role:, db: }, ... ], privileges: [ { resource:, actions: [, ... ] }, ... ] }roles和privileges字段是可选的。关于resource文档详情，请查看Resource Document.关于操作列表，请查看Privilege Actions. 0 - Success dropRole { role:, db: } 0 - Success dropAllRolesFromDatabase { db: } 0 - Success grantRolesToRole { role:, db:, roles: [ { role:, db: }, ... ] } 0 - Success revokeRolesFromRole { role:, db:, roles: [ { role:, db: }, ... ] } 0 - Success grantPrivilegesToRole { role:, db:, privileges: [ { resource:, actions: [, ... ] }, ... ] }关于resource这个字段对应的文档，请查看Resource Document.关于操作列表，请查看Privilege Actions. 0 - Success revokePrivilegesFromRole { role:, db:, privileges: [ { resource:, actions: [, ... ] }, ... ] }关于resource这个字段对应的文档，请查看Resource Document.关于操作列表，请查看Privilege Actions. 0 - Success replSetReconfig `{ old: { _id:, version:, ... members: [ ... ], settings: { ... } }, new: { _id:, version:, ... members: [ ... ], settings: { ... } } }关于副本集配置对应的文档, 请查看 Replica Set Configuration. 0 - Success enableSharding { ns:} 0 - Success shardCollection { ns:., key:, options: { unique:} } 0 - Success addShard { shard:, connectionString::, maxSize:}当分片是副本集时，connectionString包含副本集集群名字和可以包含其他副本集成员。 0 - Success removeShard { shard:} 0 - Success shutdown { }Indicates commencement of database shutdown. 指明数据库开始关闭 0 - Success applicationMessage { msg:}请查看logApplicationMessage. 0 - Success [1]启用审计授权成功与仅记录授权失败相比，启用会使性能下降更多。 原文链接：https://docs.mongodb.com/manual/reference/audit-message/ 译者：谢伟成 参见 原文 - System Event Audit Messages Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/09-security-hardening.html":{"url":"09-security/09-security-hardening.html","title":"Network and Configuration Hardening","keywords":"","body":" Network and Configuration Hardening ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Network and Configuration Hardening Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/09-security-hardening/01-security-mongodb-configuration.html":{"url":"09-security/09-security-hardening/01-security-mongodb-configuration.html","title":"IP Binding","keywords":"","body":" IP Binding ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - IP Binding Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/09-security-hardening/02-configure-linux-iptables-firewall.html":{"url":"09-security/09-security-hardening/02-configure-linux-iptables-firewall.html","title":"Configure Linux iptables Firewall for MongoDB","keywords":"","body":" Configure Linux iptables Firewall for MongoDB ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure Linux iptables Firewall for MongoDB Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/09-security-hardening/03-configure-windows-netsh-firewall.html":{"url":"09-security/09-security-hardening/03-configure-windows-netsh-firewall.html","title":"Configure Windows netsh Firewall for MongoDB","keywords":"","body":" Configure Windows netsh Firewall for MongoDB ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure Windows netsh Firewall for MongoDB Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/10-implement-field-level-redaction.html":{"url":"09-security/10-implement-field-level-redaction.html","title":"Implement Field Level Redaction","keywords":"","body":" Implement Field Level Redaction ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Implement Field Level Redaction Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/11-security.html":{"url":"09-security/11-security.html","title":"Security Reference","keywords":"","body":" Security Reference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Security Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/11-security/01-system-roles-collection.html":{"url":"09-security/11-security/01-system-roles-collection.html","title":"system.roles 集合","keywords":"","body":" system.roles 集合 在本页 system.roles 集合的Schema 例子 admin数据库中的system.roles集合存储用户定义的角色。为了创建和管理这些用户自定义角色，MongoDB提供了角色管理命令。 system.roles 集合的Schema system.roles集合中的文档具有以下的schema： 复制 { _id: , role: \"\", db: \"\", privileges: [ { resource: { }, actions: [ \"\", ... ] }, ... ], roles: [ { role: \"\", db: \"\" }, ... ] } 一个system.roles文档具有以下字段： admin.system.roles.``role 该role字段是一个字符串，用于指定角色的名称。 admin.system.roles.``db 该db字段是一个字符串，用于指定角色所属的数据库。MongoDB通过名称（即role）及其数据库的配对来唯一标识每个角色 。 admin.system.roles.``privileges 该privileges数组包含权限文件，这些文件定义了角色的权限。 权限文档具有以下语法： 复制 { resource: { }, actions: [ \"\", ... ] } 每个权限文档具有以下字段： admin.system.roles.privileges[n].resource 一个文档，该文档指定权限操作所应用的资源。 该文档具有以下格式之一： 复制 { db: , collection: } 或者 { cluster : true } 有关更多详细信息，请阅读资源文档。 admin.system.roles.privileges[n].actions 资源上允许的一系列操作， 有关操作列表，请参阅权限操作 admin.system.roles.roles 该roles数组包含角色文档，这些角色文档指定了该角色从中继承权限的角色。 角色文档具有以下语法： 复制 { role: \"\", db: \"\" } 角色文档具有以下字段： admin.system.roles.roles[n].role 角色名称。角色可以是 MongoDB 提供的内置角色，也可以是用户定义的角色。 admin.system.roles.roles[n].db` 定义角色的数据库的名称。 案例 考虑以下在admin 数据库的 system.roles 中发现的示例文档 用户自定义的角色指定权限 以下是为 myApp 数据库定义的自定义用户 appUser 的示例文档 复制 { _id: \"myApp.appUser\", role: \"appUser\", db: \"myApp\", privileges: [ { resource: { db: \"myApp\" , collection: \"\" }, actions: [ \"find\", \"createCollection\", \"dbStats\", \"collStats\" ] }, { resource: { db: \"myApp\", collection: \"logs\" }, actions: [ \"insert\" ] }, { resource: { db: \"myApp\", collection: \"data\" }, actions: [ \"insert\", \"update\", \"remove\", \"compact\" ] }, { resource: { db: \"myApp\", collection: \"system.js\" }, actions: [ \"find\" ] }, ], roles: [] } privileges数组列出了appUser角色指定的五个权限 第一个权限允许对 myApp 数据库中除 system 集合以外所有集合执行(\"find\",\"createCollection\",\"dbStats\",\"collStats\"`) 操作， 详见 将数据库指定为操作资源. 后面的两个权限允许对 myApp 数据库中指定的集合 logs 和 data 上执行额外的操作，详见 指定数据库中的集合作为操作资源. 最后一个权限允许在 myApp 数据库的 system 集合 上操作。虽然第一个权限为查找操作授予了数据库范围，但是不能在 myApp 数据库的 system 集合上操作。为了授予访问 system 集合的权限，权限必须显示指定需要操作的集合。详见操作资源文档. 空的roles数组指定 appUser 没有从其他角色继承权限。 用户自定义的角色继承其他角色权限 以下示例文档为 myApp 数据库定义了用户自定义角色 appAdmin ：文档显示 appAdmin 角色指定了权限，也从其他角色继承了权限。 复制 { _id: \"myApp.appAdmin\", role: \"appAdmin\", db: \"myApp\", privileges: [ { resource: { db: \"myApp\", collection: \"\" }, actions: [ \"insert\", \"dbStats\", \"collStats\", \"compact\" ] } ], roles: [ { role: \"appUser\", db: \"myApp\" } ] } privileges 数组列举了 appAdmin 角色指定的权限，这个角色有一个权限，允许在除 system 集合外的所有集合上执行 ( \"insert\", \"dbStats\", \"collStats\", \"compact\")操作。详见执行数据库作为操作资源. roles数组列出了由角色名称和数据库标识的角色，角色 appAdmin 从中继承权限。 原文链接：https://docs.mongodb.com/manual/reference/system-roles-collection/ 译者：谢伟成 参见 原文 - system.roles Collection Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/11-security/02-system-users-collection.html":{"url":"09-security/11-security/02-system-users-collection.html","title":"system.users 集合","keywords":"","body":" system.users 集合 在本页 system.users 集合的Schema 例子 system.users 集合在 admin 数据库中，保存了用户身份验证和授权的信息。为了管理这个集合的数据，MongoDB 提供了用户管理指令。 system.users 集合的Schema system.users 集合中的文档具有以下的 schema： 复制 { _id: , userId : , // Starting in MongoDB 4.0.9 user: \"\", db: \"\", credentials: { }, roles: [ { role: \"\", db: \"\" }, ... ], customData: , authenticationRestrictions : [ ] // Starting in MongoDB 4.0 } 每个 system.users 文档都有以下字段： admin.system.users.``userId 创建时分配给用户的唯一标识符。userId 适用于在MongoDB 4.0.9 及更高的版本创建的用户 admin.system.users.``user 用户名。用户位于单个逻辑数据库的上下文中(请参考资料admin.system.users.db)，但可以通过roles组中指定的角色访问其他数据库。 admin.system.users.``db 与用户关联的身份验证数据库。用户的权限不一定限于此数据库。用户可以通过该roles组在其他数据库中拥有特权。 admin.system.users.``credentials 用户的身份验证信息。对于具有外部存储的身份验证凭据的用户，例如使用 Kerberos 或x.509证书进行身份验证的system.users 用户，该用户的文档不包含该 credentials字段。对于 SCRAM用户凭据，该信息包括机制，迭代计数和身份验证参数。 也可以看看 scramSHA256IterationCount scramIterationCount admin.system.users.``roles 授予用户的一系列角色。该组包含 内置角色和用户定义角色。 角色文档具有以下语法： 复制 { role: \"\", db: \"\" } 角色文档有以下字段 `admin.system.users.roles[n].``role ​ 角色名称。角色可以是 MongoDB 提供的内置角色，也可以是用户自定义角色。 admin.system.users.roles[n].``db ​ 定义角色的数据库的名称。 使用角色管理或用户管理命令指定\"readWrite\"角色时，如果运行命令的数据库中存在该角色，则可以单独指定角色名称（例如“ readWrite”）。 admin.system.users.``customData 有关用户的可选自定义信息。 admin.system.users.``authenticationRestrictions 服务器为用户强制执行的一系列身份验证限制。该数组包含 IP 地址和 CIDR 范围的列表，允许用户从中连接到服务器或服务器可以从中接受用户。 版本4.0中的新功能。 Example 考虑system.users集合中的以下文档： 复制 { \"_id\" : \"home.Kari\", \"userId\" : UUID(\"ec1eced7-055a-4ca8-8737-60dd02c52793\"), // Available starting in MongoDB 4.0.9 \"user\" : \"Kari\", \"db\" : \"home\", \"credentials\" : { \"SCRAM-SHA-1\" : { \"iterationCount\" : 10000, \"salt\" : \"S/xM2yXFosynbCu4GzFDgQ==\", \"storedKey\" : \"Ist4cgpEd1vTbnRnQLdobgmOsBA=\", \"serverKey\" : \"e/0DyzS6GPboAA2YNBkGYm87+cg=\" }, \"SCRAM-SHA-256\" : { \"iterationCount\" : 15000, \"salt\" : \"p1G+fZadAeYAbECN8F/6TMzXGYWBaZ3DtWM0ig==\", \"storedKey\" : \"LEgLOqZQmkGhd0owm/+6V7VdJUYJcXBhPUvi9z+GBfk=\", \"serverKey\" : \"JKfnkVv9iXwxyc8JaapKVwLPy6SfnmB8gMb1Pr15T+s=\" } }, \"authenticationRestrictions\" : [ // Available starting in MongoDB 4.0 { \"clientSource\" : [ \"69.89.31.226\" ], \"serverAddress\" : [ \"172.16.254.1\" ] } ], \"customData\" : { \"zipCode\" : \"64157\" }, \"roles\" : [ { \"role\" : \"read\", \"db\" : \"home\" }, { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } 该文档显示用户Kari的身份验证数据库是 home数据库。在数据库中Kari 具有 read 角色，在 test 数据库中具有readWrite角色 。 原文链接：https://docs.mongodb.com/manual/reference/system-users-collection/ 译者：谢伟成 参见 原文 - system.users Collection Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/11-security/03-resource-document.html":{"url":"09-security/11-security/03-resource-document.html","title":"资源文档","keywords":"","body":" 资源文档 在本页 数据库和/或集合资源 集群资源 anyResource 资源文档指定了权限所允许操作的资源。 数据库和/或集合资源 使用以下语法指定数据库和/或者集合： 复制 { db: , collection: } 指定一个数据库中的集合作为操作资源 如果资源文档同时指定了db和collection字段为非空字符串，操作资源就是该指定数据库中的指定集合。例如，下面的文档指定了products数据库中的inventory集合。 复制 { db: \"products\", collection: \"inventory\" } 非admin数据库范围内的用户自定义角色，为其权限指定操作资源时必须指定与该角色相同的数据库。admin数据库范围内定义的角色可以指定其他其他数据库为操作资源。 指定一个数据库为资源 如果仅collection字段为空字符串（\"\"），操作资源就是该指定的数据库，但system集合除外。例如，下面的资源文档指定了操作资源为test数据库，但system集合除外。 复制 { db: \"test\", collection: \"\" } 非admin数据库范围内的用户自定义角色，为其权限指定操作资源时必须指定与该角色相同的数据库。admin数据库范围内定义的角色可以指定其他数据库为操作资源。 说明 当你指定一个数据库作为操作资源时，system集合是不包括在内的，除非像下面这样明确指定： 复制 { db: \"test\", collection: \"system.js\" } system集合包括但是不限于以下几项： .system.profile .system.js admin数据库中的system.users集合 admin数据库中的system.roles集合 通过数据库指定集合作为操作资源 如果db字段是空字符串（\"\"），那么操作资源则是所有数据库中具有指定名称的集合。例如，以下文档指定了所有数据库中accounts集合的资源： 复制 { db: \"\", collection: \"accounts\" } 对于用户自定义角色，只有作用于admin数据库的角色才能拥有此资源指定的权限。 指定所有数据库中的非 system 集合 如果db和collection两个字段都为空字符串（\"\"），那么可操作的资源将是所有数据库中除system外的所有集合。 复制 { db: \"\", collection: \"\" } 对于用户自定义角色，只有作用于admin数据库的角色才能拥有此资源指定的权限。 集群资源 要将群集指定为资源，请使用以下语法： 复制 { cluster : true } 使用集群作为 actions 的操作资源，而不是对特定的数据库或集合进行操作，这样的操作会影响系统状态。 此类操作的示例包括“关机”，“ 副本集重新配置”和“添加分片”。 例如，以下文档授予“集群”上的“关机”动作。 cluster资源是用来执行那些影响系统状态的操作，而不是用来对特定的数据库或集合执行操作。此类操作的示例包括shutdown、replSetReconfig和addShard。例如，以下文档会将shutdown操作赋予cluster。 复制 { resource: { cluster : true }, actions: [ \"shutdown\" ] } 对于用户自定义角色，只有作用于admin数据库的角色才能拥有此资源指定的权限。 anyResource 内部资源anyResource使我们能访问系统中任何资源，它只供内部使用。除特殊情况外，不要使用这个资源。使用这个资源的语法为{ anyResource: true }。 原文链接：https://docs.mongodb.com/manual/reference/resource-document/ 译者：谢伟成 参见 原文 - Resource Document Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/11-security/04-privilege-actions.html":{"url":"09-security/11-security/04-privilege-actions.html","title":"权限操作","keywords":"","body":" 权限操作 在本页面 查询和写入操作 数据库管理操作 部署管理操作 变更流操作 复制操作 分片操作 服务器管理操作 会话操作 免费监控操作 诊断操作 内部操作 权限操作定义了用户可以对资源执行的操作。MongoDB 权限包括 资源和允许的操作。此页面列出了按通用目的分组的可用操作。 MongoDB为内置角色提供了预定义的资源对和允许的操作对。有关授予的操作的列表，请参见 内置角色。要定义自定义角色，请参阅 创建用户定义的角色。 查询和写操作¶ find 用户可以执行以下命令及其等效的帮助方法： aggregate对于所有管道操作 （$collStats，$out和 $indexStats除外） 。 checkShardingIndex count dataSize distinct filemd5 find geoSearch getLastError getMore killCursors，前提是光标与当前经过身份验证的用户相关联。 listCollections listIndexes mapReduce与{out: inline}选项 resetError 输出到集合时，mapReduce命令和 db.collection.mapReduce辅助方法的查询部分是必需的。 findAndModify命令行和db.collection.findAndModify辅助方法的查询部分是必需的。 cloneCollectionAsCapped和renameCollection命令行以及db.collection.renameCollection()辅助方法要求有源集合。 对于MongoDB 4.0.6+： 如果用户没有listDatabases 操作权限，用户运行listDatabases 命令行时authorizedDatabases未指定或设置选项为true，则用户可以运行该命令以返回该用户具有权限的数据库的列表（包括该用户对特定集合具有权限的数据库）。 对于MongoDB 4.0.5： 如果用户没有listDatabases 操作权限，在authorizedDatabases未指定选项或设置为true的情况下运行listDatabases 命令时，用户可以运行该命令以返回该用户对其具有find操作权限的数据库的列表 。 对于MongoDB 4.0.0-4.0.4： 如果用户没有listDatabases 操作权限，则用户可以运行listDatabases 命令以返回该用户对其具有find操作权限的数据库列表 。 将此操作应用于数据库或集合资源。 insert 用户可以执行以下命令及其等效方法： insert create 输出到集合时，mapReduce 命令和 db.collection.mapReduce()方法的输出部分是必需的。 使用管道$out运算符时，aggregate命令和 db.collection.aggregate()帮助程序方法是必需的。 当使用update和findAndModify 命令以及等效的帮助程序方法时，upsert是必需的 。 以下命令及其辅助方法在目标集合上是必需的： cloneCollection cloneCollectionAsCapped renameCollection 将此操作应用于数据库或集合资源。 remove 用户可以执行delete命令和等效的辅助方法。 findAndModify 命令和db.collection.findAndModify()方法的write 部分是必需的。 当您指定replace输出到集合时，该mapReduce命令和 db.collection.mapReduce()辅助方法是必需的。 使用$out管道运算符时，aggregate命令和 db.collection.aggregate()辅助方法是必需的。 将此操作应用于数据库或集合资源。 update 用户可以执行update命令和等效的帮助方法。 在不指定replace操作的情况下输出到集合时，mapReduce命令和 db.collection.mapReduce()辅助方法是必需的 。 findAndModify命令和 db.collection.findAndModify()辅助方法是必需的。 将此操作应用于数据库或集合资源。 bypassDocumentValidation 3.2版中的新功能。 用户可以绕过支持bypassDocumentValidation选项的命令和方法的文档验证。以下命令及其等效方法支持绕过文档验证： aggregate applyOps 在目标集合上的cloneCollection findAndModify insert mapReduce update 将此操作应用于数据库或集合资源。 useUUID 3.6版的新功能。 用户可以使用UUID来执行以下命令 ，就像它是名称空间一样： find listIndexes 例如，此权限授权用户运行以下命令，该find命令对具有给定UUID的集合执行命令。为了获得成功，此操作还需要授权用户find在与给定UUID对应的集合名称空间上执行命令。 复制 db.runCommand({find: UUID(\"123e4567-e89b-12d3-a456-426655440000\")}) 有关集合UUID的更多信息，请参见 集合。 将此操作应用于cluster资源。 数据库管理操作¶ changeCustomData 用户可以更改给定数据库中任何用户的自定义信息。将此操作应用于数据库资源。 changeOwnCustomData 用户可以更改自己的自定义信息。将此操作应用于数据库资源。另请参阅 更改密码和自定义数据。 changeOwnPassword 用户可以更改自己的密码。将此操作应用于数据库资源。另请参阅 更改密码和自定义数据。 changePassword 用户可以更改给定数据库中任何用户的密码。将此操作应用于数据库资源。 createCollection 用户可以执行db.createCollection()方法。将此操作应用于数据库或集合资源。 createIndex 提供对db.collection.createIndex()方法和createIndexes命令的访问。将此操作应用于数据库或集合资源。 createRole 用户可以在给定的数据库中创建新角色。将此操作应用于数据库资源。 createUser 用户可以在给定的数据库中创建新用户。将此操作应用于数据库资源。 dropCollection 用户可以执行该db.collection.drop()方法。将此操作应用于数据库或集合资源。 dropRole 用户可以从给定的数据库中删除任何角色。将此操作应用于数据库资源。 dropUser 用户可以从给定的数据库中删除任何用户。将此操作应用于数据库资源。 enableProfiler 用户可以执行db.setProfilingLevel()方法。将此操作应用于数据库资源。 grantRole 用户可以将数据库中的任何角色从系统中的任何数据库授予任何用户。将此操作应用于数据库资源。 killCursors 从MongoDB 4.2开始，用户始终可以关闭自己的游标，而不管用户是否具有 killCursors的权限。因此，该killCursors 权限在MongoDB 4.2+中无效。 在MongoDB 3.6.3到MongoDB 4.0.x中，killCursors启用访问控制后，用户需要权限来关闭自己的游标。游标创建时，游标与用户相关联。将此操作应用于收集资源。 killAnyCursor 版本3.6.3中的新功能。 用户可以关闭任何游标，甚至可以关闭其他用户创建的游标。将此操作应用于收集资源。 revokeRole 用户可以从系统中任何数据库的任何用户中删除任何角色。将此操作应用于数据库资源。 setAuthenticationRestriction 3.6版的新功能。 运行以下命令时，用户可以在user文档中指定 authenticationRestrictions字段： createUser updateUser 运行以下命令时，用户可以authenticationRestrictions在role文档中指定字段 ： createRole updateRole 注意 以下内置角色授予此权限： 该userAdmin角色提供对数据库的这一权限的角色分配。 该 userAdminAnyDatabase角色在所有数据库上提供此权限。 在传递上，restore和root角色也提供此特权。 将此操作应用于数据库资源。 unlock 用户可以执行db.fsyncUnlock()方法。将此操作应用于cluster资源。 viewRole 用户可以查看有关给定数据库中任何角色的信息。将此操作应用于数据库资源。 viewUser 用户可以在给定的数据库中查看任何用户的信息。将此操作应用于数据库资源。 部署管理操作¶ authSchemaUpgrade 用户可以执行authSchemaUpgrade命令。将此操作应用于cluster资源。 cleanupOrphaned 用户可以执行cleanupOrphaned命令。将此操作应用于cluster资源。 cpuProfiler 用户可以启用和使用CPU分析器。将此操作应用于 cluster资源。 inprog 用户可以使用db.currentOp()方法返回有关挂起和活动操作的信息。将此操作应用于cluster资源。 在版本3.2.9中进行了更改：即使没有inprog权限，用户也可以在mongod实例上通过运行db.currentOp( { \"$ownOps\": true } )来查看自己的操作。 invalidateUserCache 提供对invalidateUserCache命令的访问。将此操作应用于cluster资源。 killop 用户可以执行db.killOp()方法。将此操作应用于cluster资源。 在版本3.2.9中进行了更改：即使没有killop权限，在 mongod实例上，用户也可以关闭自己的操作。 planCacheRead 用户可以执行以下操作： $planCacheStats 聚集阶段。 planCacheListPlans命令和 PlanCache.getPlansByQuery()方法。 planCacheListQueryShapes命令和 PlanCache.listQueryShapes()方法。 将此操作应用于数据库或集合资源。 planCacheWrite 用户可以执行planCacheClear命令以及 PlanCache.clear()和PlanCache.clearPlansByQuery() 方法。将此操作应用于数据库或集合资源。 storageDetails 用户可以执行storageDetails命令。将此操作应用于数据库或集合资源。 变更流操作¶ changeStream 用户在指定集合上使用changeStream和find上，在指定数据库中的所有非system集合或所有数据库中的所有非system集合都可以为这些资源打开变更流游标。 复制操作¶ appendOplogNote 用户可以在操作日志中添加注释。将此操作应用于 cluster资源。 replSetConfigure 用户可以配置副本集。将此操作应用于cluster 资源。 replSetGetConfig 用户可以查看副本集的配置。提供对replSetGetConfig命令和rs.conf()辅助方法的访问 。 将此操作应用于cluster资源。 replSetGetStatus 用户可以执行replSetGetStatus命令。将此操作应用于cluster资源。 replSetHeartbeat 用户可以执行replSetHeartbeat命令。将此操作应用于cluster资源。 replSetStateChange 用户可以通过 replSetFreeze，replSetMaintenance， replSetStepDown，和replSetSyncFrom 命令改变一个副本集的状态。将此操作应用于cluster资源。 resync 用户可以执行resync命令。将此操作应用于cluster资源。 分片操作¶ addShard 用户可以执行addShard命令。将此操作应用于cluster资源。 clearJumboFlag 从4.2.3和4.0.15开始可用 使用clearJumboFlag命令清除块的巨型标志所必需 。将此操作应用于数据库或集合资源。 包含在clusterManager内置角色中。 enableSharding 适用资源 该操作可以应用于以下任一情况： 数据库或集合资源，用于为数据库启用分片或对集合进行分片。 群集资源以执行各种分片区操作（从版本4.2.2、4.0.14、3.6.16开始）。 资源 描述 数据库或集合 授予用户执行以下操作的权限：使用以下enableSharding命令在数据库上启用分片 ，然后使用shardCollection 命令对集合进行分片。 群集从版本4.2.2、4.0.14、3.6.16开始 授予用户执行以下分区域操作的权限：- addShardToZone - updateZoneKeyRange - removeShardFromZone 如果对数据库中的相应集合执行find/ update操作，则还可以执行这些分片区 config操作。有关详细信息，请参见具体操作。 flushRouterConfig 用户可以执行flushRouterConfig命令。将此操作应用于cluster资源。 getShardMap 用户可以执行getShardMap命令。将此操作应用于cluster资源。 getShardVersion 用户可以执行getShardVersion命令。将此操作应用于数据库资源。 listShards 用户可以执行listShards命令。将此操作应用于cluster资源。 moveChunk 用户可以执行moveChunk命令。此外，如果将权限应用于适当的数据库资源，则用户可以执行movePrimary命令。将此操作应用于数据库或集合资源。 removeShard 用户可以执行removeShard命令。将此操作应用于cluster资源。 shardingState 用户可以执行shardingState命令。将此操作应用于cluster资源。 splitChunk 用户可以执行splitChunk命令和 mergeChunks命令。将此操作应用于数据库或集合资源。 splitVector 用户可以执行splitVector命令。将此操作应用于数据库或集合资源。 服务器管理操作¶ applicationMessage 用户可以执行logApplicationMessage命令。将此操作应用于cluster资源。 closeAllDatabases 用户可以执行closeAllDatabases命令。将此操作应用于cluster资源。 collMod 用户可以执行collMod命令。将此操作应用于数据库或集合资源。 compact 用户可以执行compact命令。将此操作应用于数据库或集合资源。 connPoolSync 用户可以执行connPoolSync命令。将此操作应用于cluster资源。 convertToCapped 用户可以执行convertToCapped命令。将此操作应用于数据库或集合资源。 dropConnections 用户可以执行dropConnections命令。将此操作应用于cluster资源。 dropDatabase 用户可以执行dropDatabase命令。将此操作应用于数据库资源。 dropIndex 用户可以执行dropIndexes命令。将此操作应用于数据库或集合资源。 forceUUID 3.6版的新功能。 用户可以使用 applyOps命令使用用户定义的集合UUID创建集合。 将此操作应用于cluster资源。 fsync 用户可以执行fsync命令。将此操作应用于cluster资源。 getParameter 用户可以执行getParameter命令。将此操作应用于cluster资源。 hostInfo 提供有关运行MongoDB实例的服务器的信息。将此操作应用于cluster资源。 logRotate 用户可以执行logRotate命令。将此操作应用于cluster资源。 reIndex 用户可以执行reIndex命令。将此操作应用于数据库或集合资源。 renameCollectionSameDB 允许用户使用renameCollection命令在当前数据库上重命名集合 。将此操作应用于数据库资源。 此外，用户必须拥有 find源集合或者没有 find目标集合。 如果已经存在使用新名称的集合，则用户还必须使用dropCollection对目标集合执行操作。 setParameter 用户可以执行setParameter命令。将此操作应用于cluster资源。 shutdown 用户可以执行shutdown命令。将此操作应用于cluster资源。 touch 用户可以执行touch命令。将此操作应用于cluster资源。 会话的操作¶ impersonate 3.6版的新功能。 用户可以使用users和roles模式执行killAllSessionsByPattern命令。将此操作应用于 cluster资源。 要运行killAllSessionsByPattern命令，用户还必须对群集资源具有killAnySession权限。 listSessions 3.6版的新功能。 用户可以为所有用户或指定用户执行$listSessions一项或 $listLocalSessions多项操作。将此操作应用于cluster资源。 killAnySession SEE ALSOimpersonate 3.6版的新功能。 用户可以执行killAllSessions和 killAllSessionsByPattern命令。将此操作应用于cluster资源。 也可以看看impersonate 免费的监控操作¶ checkFreeMonitoringStatus 对cluster资源执行此操作的用户可以检查“ 免费监控”的状态。 4.0版本中的新功能。 setFreeMonitoring 对cluster资源执行此操作的用户可以启用或禁用“ 免费监控”。 4.0版本中的新功能。 诊断操作¶ collStats 用户可以执行collStats命令。将此操作应用于数据库或集合资源。 connPoolStats 用户可以执行connPoolStats和shardConnPoolStats 命令。将此操作应用于cluster资源。 cursorInfo 用户可以执行cursorInfo命令。将此操作应用于cluster资源。 dbHash 用户可以执行dbHash命令。将此操作应用于数据库或集合资源。 dbStats 用户可以执行dbStats命令。将此操作应用于数据库资源。 getCmdLineOpts 用户可以执行getCmdLineOpts命令。将此操作应用于cluster资源。 getLog 用户可以执行getLog命令。将此操作应用于cluster资源。 indexStats 用户可以执行indexStats命令。将此操作应用于数据库或集合资源。 在版本3.0中进行了更改： MongoDB 3.0删除了该indexStats命令。 listDatabases 用户可以执行listDatabases命令。将此操作应用于cluster资源。 对于MongoDB 4.0.6+： 如果用户没有listDatabases 操作权限，则如果运行listDatabases 命令时authorizedDatabases未指定或设置选项为true，则用户可以运行该命令以返回该用户具有权限的数据库的列表（包括该用户对特定集合具有权限的数据库）。 对于MongoDB 4.0.5： 如果用户没有listDatabases 操作权限，则在authorizedDatabases命令未指定选项或设置为true的情况下运行listDatabases 命令时，用户可以运行该命令以返回该用户对其具有find操作权限的数据库的列表 。 对于MongoDB 4.0.0-4.0.4： 如果用户没有listDatabases 操作权限，则用户可以运行listDatabases 命令以返回该用户对其具有find操作权限的数据库列表 。 listCollections 用户可以执行listCollections命令。将此操作应用于数据库资源。 注意 从4.0版本开始，没有所需权限的用户可以在 authorizedCollections和nameOnly选项都设置为true的情况下运行listCollections命令。在这种情况下，该命令仅返回用户具有特权的集合的名称和类型。 listIndexes 用户可以执行listIndexes命令。将此操作应用于数据库或集合资源。 netstat 用户可以执行netstat命令。将此操作应用于cluster资源。 serverStatus 用户可以执行serverStatus命令。将此操作应用于cluster资源。 validate 用户可以执行validate命令。将此操作应用于数据库或集合资源。 top 用户可以执行top命令。将此操作应用于 cluster资源。 内部操作¶ anyAction 允许对资源执行任何操作。除非绝对必要，否则不要分配此操作。 internal 允许内部动作。除非绝对必要，否则不要分配此操作。 原文链接：https://docs.mongodb.com/manual/reference/privilege-actions/ 译者：谢伟成 参见 原文 - Privilege Actions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/12-create-a-vulnerability-report.html":{"url":"09-security/12-create-a-vulnerability-report.html","title":"Create a Vulnerability Report","keywords":"","body":" Create a Vulnerability Report ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Create a Vulnerability Report Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/13-security.html":{"url":"09-security/13-security.html","title":"Appendix","keywords":"","body":" Appendix ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Appendix Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/13-security/01-appendixA-openssl-ca.html":{"url":"09-security/13-security/01-appendixA-openssl-ca.html","title":"Appendix A - OpenSSL CA Certificate for Testing","keywords":"","body":" Appendix A - OpenSSL CA Certificate for Testing ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Appendix A - OpenSSL CA Certificate for Testing Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/13-security/02-appendixB-openssl-server.html":{"url":"09-security/13-security/02-appendixB-openssl-server.html","title":"Appendix B - OpenSSL Server Certificates for Testing","keywords":"","body":" Appendix B - OpenSSL Server Certificates for Testing ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Appendix B - OpenSSL Server Certificates for Testing Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/13-security/03-appendixC-openssl-client.html":{"url":"09-security/13-security/03-appendixC-openssl-client.html","title":"Appendix C - OpenSSL Client Certificates for Testing","keywords":"","body":" Appendix C - OpenSSL Client Certificates for Testing ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Appendix C - OpenSSL Client Certificates for Testing Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Appendix.html":{"url":"09-security/Appendix.html","title":"附录","keywords":"","body":" 附录 附录A-用于测试的 OpenSSL CA 证书 附录B-用于测试的 OpenSSL 服务器证书 附录C-用于测试的 OpenSSL 客户端证书 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Appendix/Appendix-A-OpenSSL-CA-Certificate-for-Testing.html":{"url":"09-security/Appendix/Appendix-A-OpenSSL-CA-Certificate-for-Testing.html","title":"附录 A - 用于测试的 OpenSSl CA 证书","keywords":"","body":" 附录 A - 用于测试的 OpenSSl CA 证书 免责声明 提供此页面仅用于测试目的，证书仅用于测试目的。 以下教程提供了一些有关创建测试 x.509证书的准则 ： 请勿将这些证书用于生产。相反，请遵循您的安全策略。 有关 OpenSSL 的信息，请参考官方的 OpenSSL 文档。尽管本教程使用的是 OpenSSL，但不应将本材料当作 OpenSSL 的权威参考。 程序 以下过程概述了创建测试 CA PEM 文件的步骤。该过程同时创建 CA PEM 文件和中间授权证书以及用于签署服务器/客户端测试证书的密钥文件。 A.创建OpenSSL配置文件 创建具有以下内容的配置文件 openssl-test-ca.cnf： NOT FOR PRODUCTION USE. OpenSSL configuration file for testing. 不用于生产用途。用于测试的OpenSSL配置文件。 For the CA policy 对于CA策略 [ policy_match ] countryName = match stateOrProvinceName = match organizationName = match organizationalUnitName = optional commonName = supplied emailAddress = optional [ req ] default_bits = 4096 default_keyfile = myTestCertificateKey.pem The default private key file name. 默认私钥文件名 default_md = sha256 Use SHA-256 for Signatures 使用SHA-256签名 distinguished_name = req_dn req_extensions = v3_req x509_extensions = v3_ca The extentions to add to the self signed cert [ v3_req ] subjectKeyIdentifier = hash basicConstraints = CA:FALSE keyUsage = critical, digitalSignature, keyEncipherment nsComment = \"OpenSSL Generated Certificate for TESTING only. NOT FOR PRODUCTION USE.\" extendedKeyUsage = serverAuth, clientAuth [ req_dn ] countryName = Country Name (2 letter code) countryName_default = countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = TestCertificateStateName stateOrProvinceName_max = 64 localityName = Locality Name (eg, city) localityName_default = TestCertificateLocalityName localityName_max = 64 organizationName = Organization Name (eg, company) organizationName_default = TestCertificateOrgName organizationName_max = 64 organizationalUnitName = Organizational Unit Name (eg, section) organizationalUnitName_default = TestCertificateOrgUnitName organizationalUnitName_max = 64 commonName = Common Name (eg, YOUR name) commonName_max = 64 [ v3_ca ] Extensions for a typical CA 典型CA的扩展 subjectKeyIdentifier=hash basicConstraints = critical,CA:true authorityKeyIdentifier=keyid:always,issuer:always 可选。您可以更新默认专有名称(DN)值。 B. 生成测试 CA PEM 文件 创建测试 CA 密钥文件 mongodb-test-ca.key。 复制 openssl genrsa -out mongodb-test-ia.key 4096 提示: 此私钥用于为CA生成有效证书。尽管此私钥与本附录中的所有文件一样，仅用于测试目的，但您应遵循良好的安全惯例并保护此密钥文件。 mongod-test-ca.crt使用生成的密钥文件创建CA证书。当要求提供专有名称值时，为您的测试CA证书输入适当的值。 复制 openssl req -new -x509 -days 1826 -key mongodb-test-ca.key -out mongodb-test-ca.crt -config openssl-test-ca.cnf 创建中间证书的私钥 openssl genrsa -out mongodb-test-ia.key 4096 提示: 此私钥用于为中间机构生成有效的证书。尽管此私钥与本附录中的所有文件一样，仅用于测试目的，但您应遵循良好的安全惯例并保护此密钥文件。 为中间证书创建证书签名请求。当要求提供专有名称值时，请为您的测试中间机构证书输入适当的值。 openssl req -new -key mongodb-test-ia.key -out mongodb-test-ia.csr -config openssl-test-ca.cnf 创建中间证书mongodb-test-ia.crt。 复制openssl x509 -sha256 -req -days 730 -in mongodb-test-ia.csr -CA mongodb-test-ca.crt -CAkey mongodb-test-ca.key -set_serial 01 -out mongodb-test-ia.crt -extfile openssl-test-ca.cnf -extensions v3_ca 从测试的 CA 证书 mongod-test-ca.crt 和测试的中间证书 mongodb-test-ia.crt 创建测试的 CA PEM 文件。 你可以使用测试的 PEM 文件为 TLS/SSL 测试配置mongod， mongos或者mongo。 您可以使用测试中间权限来为服务器和客户端签署测试证书。单个机构必须为客户端和服务器都颁发证书。 也可以看看 附录B-用于测试的OpenSSL服务器证书 附录C-用于测试的OpenSSL客户端证书 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Appendix/Appendix-B-OpenSSL-Server-Certificates-for-Testing.html":{"url":"09-security/Appendix/Appendix-B-OpenSSL-Server-Certificates-for-Testing.html","title":"附录 B-用于测试的OpenSSL服务器证书","keywords":"","body":" 附录 B-用于测试的OpenSSL服务器证书 免责声明 此页面仅用于测试目的；证书仅用于测试目的。 以下教程提供了创建测试x.509证书的一些基本步骤： 请勿将这些证书用于生产环境。相反，请遵循您的安全策略。 有关OpenSSL的信息，请参考官方的OpenSSL文档。尽管本教程使用的是OpenSSL，但不应将本材料当作OpenSSL的权威参考。 前提条件 本页所描述的过程会使用测试的中间权限证书以及在附录A - 用于测试的OpenSSL CA证书中创建的秘钥 mongodb-test-ia.crt 和 mongodb-test-ia.key 。 过程¶ 以下过程概述了为MongoDB服务器创建测试证书的步骤。有关为MongoDB客户端创建测试证书的步骤，请参阅附录C - 用于测试的OpenSSL客户端证书。 A. 创建OpenSSL配置文件 使用以下内容为您的服务器创建一个测试配置文件openssl-test-server.cnf： NOT FOR PRODUCTION USE. OpenSSL configuration file for testing. [ req ] default_bits = 4096 default_keyfile = myTestServerCertificateKey.pem The default private key file name. default_md = sha256 distinguished_name = req_dn req_extensions = v3_req [ v3_req ] subjectKeyIdentifier = hash basicConstraints = CA:FALSE keyUsage = critical, digitalSignature, keyEncipherment nsComment = \"OpenSSL Generated Certificate for TESTING only. NOT FOR PRODUCTION USE.\" extendedKeyUsage = serverAuth, clientAuth subjectAltName = @alt_names [ alt_names ] DNS.1 = TODO: Enter the DNS names. The DNS names should match the server names. DNS.2 = TODO: Enter the DNS names. The DNS names should match the server names. IP.1 = TODO: Enter the IP address. SAN matching by IP address is available starting in MongoDB 4.2 IP.2 = TODO: Enter the IP address. SAN matching by IP address is available starting in MongoDB 4.2 [ req_dn ] countryName = Country Name (2 letter code) countryName_default = TestServerCertificateCountry countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = TestServerCertificateState stateOrProvinceName_max = 64 localityName = Locality Name (eg, city) localityName_default = TestServerCertificateLocality localityName_max = 64 organizationName = Organization Name (eg, company) organizationName_default = TestServerCertificateOrg organizationName_max = 64 organizationalUnitName = Organizational Unit Name (eg, section) organizationalUnitName_default = TestServerCertificateOrgUnit organizationalUnitName_max = 64 commonName = Common Name (eg, YOUR name) commonName_max = 64 在该[alt_names]部分中，输入适合MongoDB服务器的DNS名称和/或IP地址。您可以为MongoDB服务器指定多个DNS名称。 对于OpenSSL SAN标识符，MongoDB支持： DNS名称和/或 IP地址字段（从MongoDB 4.2开始) 可选。你可以更新默认的专有名称(DN)值 提示 为至少一个下列属性指定一个非空值：组织 (O)、组织单元 (OU)或者域组件 (DC) 为内部成员身份验证创建测试服务器证书，如果指定了下面的属性，则在成员证书之间必须完全匹配：组织 (O)、组织单元 (OU)、域组件 (DC)。 有关内部成员身份验证要求的更多信息，请查阅成员身份验证。 B. 为服务器生成测试PEM文件¶ 重要 在继续之前，请确保在配置文件openssl-test-server.cnf中的[alt_names]部分输入了适当的DNS名称。 创建测试密钥文件mongodb-test-server1.key。openssl genrsa -out mongodb-test-server1.key 4096 创建测试的证书签名请求mongodb-test-server1.csr。 当要求提供专有名称值时，为您的测试证书输入适当的值： 为以下属性中的至少一个指定一个非空值：组织(O)、组织单位(OU)或域组件(DC)。 为内部成员身份验证创建测试服务器证书时，如果指定了以下属性，则这些属性必须在成员证书之间完全匹配：组织(O)、组织单位(OU)、域组件(DC)。 复制 openssl req -new -key mongodb-test-server1.key -out mongodb-test-server1.csr -config openssl-test-server.cnf 创建测试服务器证书mongodb-test-server1.crt。 openssl x509 -sha256 -req -days 365 -in mongodb-test-server1.csr -CA mongodb-test-ia.crt -CAkey mongodb-test-ia.key -CAcreateserial -out mongodb-test-server1.crt -extfile openssl-test-server.cnf -extensions v3_req 为服务器创建测试PEM文件。 cat mongodb-test-server1.crt mongodb-test-server1.key > test-server1.pem 你可以使用testPEM文件为TLS/SSL测试配置一个mongod或一个mongos。例如： 对于MongDB 4.2或更高版本 mongod --tlsMode requireTLS --tlsCertificateKeyFile test-server1.pem --tlsCAFile test-ca.pem 虽然仍然可以使用，但--sslMode、--sslPEMKeyFile和--sslCAFile在MongoDB 4.2中已废弃。 对于MongoDB 4.0及更早的版本 mongod --sslMode requireSSL --sslPEMKeyFile test-server1.pem --sslCAFile test-ca.pem 在macOS系统中 如果你使用Keychain Access管理证书，创建一个pkcs-12而不是PEM文件添加到Keychain Access中。 openssl pkcs12 -export -out test-client.pfx -inkey mongodb-test-client.key -in mongodb-test-client.crt -certfile mongodb-test-ia.crt 将其添加到Keychain Access后，您无需指定证书密钥文件，就可以使用--tlsCertificateSelector来指定要使用的证书。如果CA文件也在Keychain Access中，也可省略--tlsCAFile。 对于MongoDB 4.2或者更高版本 mongo --tls --tlsCertificateSelector subject=\"\" 虽然仍然可以使用，--sslMode和--sslCertificateSelector在MongoDB 4.2中已废弃。 对于MongoDB 4.0及更早版本 mongo --ssl --sslCertificateSelector subject=\"\" 要向Keychain Access添加证书，请参阅Keychain Access的官方文档。 另请参阅 附录A - 用于测试的OpenSSL CA证书 附录C - 用于测试的OpenSSL客户端证书 成员的x.509证书 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Appendix/Appendix-C-OpenSSL-Client-Certificates-for-Testing.html":{"url":"09-security/Appendix/Appendix-C-OpenSSL-Client-Certificates-for-Testing.html","title":"附录C - 用于测试的OpenSSL客户端证书","keywords":"","body":" 附录C - 用于测试的OpenSSL客户端证书 声明 此页仅用于测试目的；证书仅用于测试目的。 以下教程提供了创建测试x.509证书的一些基本步骤。 请勿将这些证书用于生产环境。相反，请遵循您的安全策略。 有关OpenSSL的信息，请参考官方的OpenSSL文档。尽管本教程使用了OpenSSL，但不应将其视为OpenSSL的权威参考。 前提条件 此页面上描述的过程使用了测试中间权限证书及在附录A-用于测试的OpenSSL CA证书中创建的密钥mongodb-test-ia.crt和mongodb-test-ia.key。 过程 以下过程概述了为MongoDB客户端创建测试证书的步骤。有关为MongoDB服务器创建测试证书的步骤，请参阅附录B - 用于测试的OpenSSL服务器证书 A. 创建OpenSSL配置文件 用下面的内容为你的客户端创建一个测试配置文件openssl-test-client.cnf： NOT FOR PRODUCTION USE. OpenSSL configuration file for testing. [ req ] default_bits = 4096 default_keyfile = myTestClientCertificateKey.pem The default private key file name. default_md = sha256 distinguished_name = req_dn req_extensions = v3_req [ v3_req ] subjectKeyIdentifier = hash basicConstraints = CA:FALSE keyUsage = critical, digitalSignature, keyEncipherment nsComment = \"OpenSSL Generated Certificate for TESTING only. NOT FOR PRODUCTION USE.\" extendedKeyUsage = serverAuth, clientAuth [ req_dn ] countryName = Country Name (2 letter code) countryName_default = countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = TestClientCertificateState stateOrProvinceName_max = 64 localityName = Locality Name (eg, city) localityName_default = TestClientCertificateLocality localityName_max = 64 organizationName = Organization Name (eg, company) organizationName_default = TestClientCertificateOrg organizationName_max = 64 organizationalUnitName = Organizational Unit Name (eg, section) organizationalUnitName_default = TestClientCertificateOrgUnit organizationalUnitName_max = 64 commonName = Common Name (eg, YOUR name) commonName_max = 64 可选。您可以更新默认专有名称（DN）值。确保客户端证书与服务器证书在以下至少一项属性上有所不同：组织（O），组织单位（OU）或域组件（DC）。 B. 为客户端创建测试的PEM文件 创建测试密钥文件mongodb-test-client.key。 openssl genrsa -out mongodb-test-client.key 4096 创建测试的认证签名文件mongodb-test-client.csr。当要求提供专有名称值时，为你的测试证书输入合适的值。 重要 客户端证书主题必须与服务器证书主题在以下属性中至少有一项要不同：组织（O），组织单位（OU）或域组件（DC）。 openssl req -new -key mongodb-test-client.key -out mongodb-test-client.csr -config openssl-test-client.cnf 创建测试客户端证书mongodb-test-client.crt。openssl x509 -sha256 -req -days 365 -in mongodb-test-client.csr -CA mongodb-test-ia.crt -CAkey mongodb-test-ia.key -CAcreateserial -out mongodb-test-client.crt -extfile openssl-test-client.cnf -extensions v3_req 为客户端创建测试的PEM文件。 cat mongodb-test-client.crt mongodb-test-client.key > test-client.pem 你可以使用测试的PEM文件为TLS/SSL测试配置mongo shell。例如，连接一个mongod或者mongos： 对于MongoDB 4.2或更高版本，在客户端中包含以下选项： mongo --tls --host --tlsCertificateKeyFile test-client.pem --tlsCAFile test-ca.pem 对于MongoDB 4.0或更早版本，在客户端中包含以下选项： mongo --ssl --host --sslPEMKeyFile test-client.pem --sslCAFile test-ca.pem 在macOS系统中 如果您使用Keychain Access管理证书，创建一个pkcs-12而不是PEM文件添加到Keychain Access中： openssl pkcs12 -export -out test-client.pfx -inkey mongodb-test-client.key -in mongodb-test-client.crt -certfile mongodb-test-ia.crt 将其添加到Keychain Access后，您无需指定证书密钥文件，就可以使用--tlsCertificateSelector来指定要使用的证书。如果CA文件也在Keychain Access中，也可以省略--tlsCAFile。 对于MongoDB 4.2或更高版本 mongo --tls --tlsCertificateSelector subject=\"\" 虽然仍然可以使用，--sslMode和--sslCertificateSelector在MongoDB 4.2中已废弃。 对于MongoDB 4.0及更早版本 mongo --ssl --sslCertificateSelector subject=\"\" 要向Keychain Access添加证书，请参阅Keychain Access的官方文档。 mongod --tlsMode requireTLS --tlsCertificateSelector subject=\"\" 另请查阅 附录A - 用于测试的OpenSSL CA证书 附录C - 用于测试的OpenSSL客户端证书 成员的x.509证书 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Enable-Access-Control.html":{"url":"09-security/Enable-Access-Control.html","title":"启用访问控制","keywords":"","body":" 启用访问控制 在页面上 概述 用户管理员 使用过程 其他注意事项 概述 在MongoDB部署时启用访问控制可以加强身份验证，要求用户表明自己的身份。当访问一个在部署时开启了访问控制的MongoDB时，用户只能执行由其角色决定的操作。 下面的教程在一个独立的mongod实例上启用了访问控制并且使用默认的身份验证机制。对于所有支持的身份验证机制，请参阅身份验证机制。 用户管理员 启用访问控制时，确认你已经有一个具有userAdmin或者userAdminAnyDatabase角色的用户在admin数据库中。这个用户能管理用户和角色，例如：创建用户、授予或者撤销用户的角色、创建或者修改角色。 配置过程 下面的过程首先将一个管理员用户添加到一个运行时没有开启访问控制的MongoDB实例中，然后启用访问控制。 说明： 这个示例的MongoDB实例，使用27017端口和/var/lib/mongodb目录作为数据目录。这个示例中假设存在/var/lib/mongodb这个数据目录。可以根据需要指定不同的数据目录。 1 没开启访问控制时启动MongoDB 没开启访问控制时启动独立的mongod实例。 例如，打开终端并发出以下命令： mongod --port 27017 --dbpath /var/lib/mongodb 2 连接这个实例 例如，打开一个新的终端并且使用mongo shell连接到mongod实例： mongo --port 适当地指定其他的命令行选项，将mongo shell 连接到你部署的mongod 实例，诸如 --host。 3 创建一个用户管理员 通过mongo shell 在admin数据库中增加一个有userAdminAnyDatabase 角色的用户。包括此用户需要的其他角色。例如，下面在admin数据库中创建用户myUserAdmin，此用户有userAdminAnyDatabase和readWriteAnyDatabase角色。 提示： mongo shell 从4.2版本开始，你可以结合使用passwordPrompt()方法和各种用户身份认证/管理方法/命令来提示输入密码，而不是直接在方法/命令调用中指定密码。然而，你仍然可以像早期版本的mongo shell一样直接指定密码。 use admin db.creatUser( { user: \"myUserAdmin\", pwd: passwordPrompt, // 或者输入明文密码 roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" }, \"readWriteAnyDatabase\" ] } ) 注解： 你在其中创建用户的数据库（在这个示例中是 admin）就是这个用户的身份认证数据库。尽管用户将向此数据库进行身份认证，但用户可以在其他数据库中具有角色；即用户的身份认证数据库不会限制用户的权限。 4 开启访问控制后重启MongoDB实例 a. 关闭mongod 实例。例如，通过mongo shell 输入下面的命令： db.adminCommand({shutdown: 1}) b.退出mongo shell。 c.开启访问控制后启动mongod 如果你从命令行启动mongod，则在命令行选项中增加 --auth： mongod --auth --port 27017 --dbpath /var/lib/mongodb 如果你使用配置文件启动mongod，则在配置文件中增加security.authorization设置： security: authorization: enabled 连接到此实例的客户端现在必须使用MongoDB的用户来认证自己。客户端只能执行其使用的MongoDB 用户所具有的角色指定的操作。 5 连接并作为用户管理员进行身份认证 使用mongo shell，你可以： 连接时直接使用用户凭证来通过身份认证，或者 连接时先不进行身份认证，连接后使用db.auth()方法进行身份认证 在连接时进行身份认证 开启mongo shell时，使用选项：-u 、-p 和 --authenticationDatabase 命令行选项。 mongo --port 27017 -u \"myUserAdmin\" --authenticationDatabase \"admin\" -p 当提示时输入你的密码，在本示例中是：adb123。 在连接后进行身份认证 连接mongo shell到mongod： mongo --port 27017 在这个mongo shell 中，切换到认证数据库（在这个例子中是：admin），然后使用 db.auth(, )方法进行身份认证。 use admin db.auth(\"myUserAdmin\", \"abc123\") 6 根据你的部署需要创建其他用户 一旦身份验证为用户管理员，就能使用db.createUser()来创建其他用户。你可以将任务内置角色或用户自定义的角色分配给用户。 下面的操作将用户myTester添加到test数据库，该用户在test数据库具有readWrite角色，在reporting 数据库具有read角色。 use test db.createUser( { user: \"myTester\", pwd: \"xyz123\", roles: [ { role: \"readWrite\", db: \"test\" }, { role: \"read\", db: \"reporting\" } ] } ) 说明： 你在其中创建用户的数据库（在这个示例中是test）就是这个用户的身份认证数据库。虽然用户将在此数据库进行身份认证，但用户可以具有其他数据库的角色；即用户的身份认证数据库不限制用户的权限。 执行完上面操作即创建完其他用户之后，断开和mongo shell 的连接。 7 连接到实例并且使用myTester用户进行身份验证。 将用户myUserAdmin从mongo shell断开连接后，使用myTester用户重连时，你可以： 连接时直接使用用户凭证来通过身份验证，或者 连接时先不进行身份认证，连接后使用db.auth()方法进行身份认证 在连接期进行身份验证 开启mongo shell时，使用选项：-u 、-p 和 --authenticationDatabase 命令行选项。 mongo --port 27017 -u \"myTester\" --authenticationDatabase \"test\" -p 当提示时输入你的密码，在本示例中是：xyz123。 连接后进行身份验证 连接mongo shell到mongod： mongo --port 27017 在这个mongo shell 中，切换到认证数据库（在这个例子中是：admin），然后使用 db.auth(, )方法进行身份认证。 use test db.auth(\"myTester\", \"xyz123\") 8 使用用户myTester插入一个文档 作为用户myTester，你有在test数据库读写的权限和在reporting数据库读的权限。一旦使用myTester用户进行身份认证通过后，就可以在test数据库中插入一个文档到集合里面。例如，你可以在test数据库中做如下的插入操作： db.foo.insert( { x: 1, y: 1 } ) 也可以参阅：管理用户和角色. 其他的注意事项 副本集和分片集群 副本集和分片集群开启访问控制后，要求成员之间进行内部身份认证。更多详情，请参阅 内部身份认证.。 本地主机Localhost异常 你可以在启动访问控制之前或之后创建用户。如果你在创建用户之前开启了访问控制，MongoDB提供了一个localhost 异常，它允许你在admin数据库创建一个用户管理员。创建之后，你必须使用这个用户管理员进行身份认证后，才能根据需要创建其他用户。 原文链接：https://docs.mongodb.com/manual/tutorial/enable-authentication/ 译者：傅立 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Network-and-Configuration-Hardening.html":{"url":"09-security/Network-and-Configuration-Hardening.html","title":"网络和配置强化","keywords":"","body":" 网络和配置强化 MongoDB 配置强化 网络强化 要降低整个 MongoDB 系统的风险暴露，请确保只有可信主机才能访问 MongoDB。 MongoDB 配置强化 IP绑定 从MongoDB 3.6开始，MongoDB 二进制文件, mongod 和 mongos 默认绑定本地主机(localhost)。从MongoDB 版本 2.6 到 3.4，只有官方 MongoDB RPM安装包(Red Hat，CentOS，Fedora Linux 和衍生产品)和 DEB安装包(Debian，Ubuntu 及衍生产品)中的二进制文件默认绑定到本地主机(localhost)。要了解有关此更改的更多信息，请参阅 本地主机绑定兼容性更改。 警告： 在绑定到非本地主机(例如可公开访问的) IP 地址之前，请确保已保护数据库集群防止未经授权的访问。有关安全建议的完整列表，请参阅安全检查表。至少需要要考虑 启用身份验证 和施强化网络基础架构。 重要提示： 确保只能在受信任的网络上访问 mongod 和mongos实例。如果您的系统具有多个网络接口，请将 MongoDB 程序绑定到专用或内部网络接口。 更多的信息，参照 IP 绑定。 HTTP状态接口和REST API 3.6版本的变化： MongoDB 3.6 移除了 MongoDB数据库的HTTP Interface 和REST API。 网络强化 防火墙 防火墙允许管理员通过提供网络通信的细粒度控制来过滤和控制对系统的访问。对于 MongoDB 的管理员，以下功能非常重要：将特定端口上的传入流量限制到特定系统，并限制来自不受信任主机的传入流量。 在 Linux 系统上，iptables 接口提供对底层 netfilter 防火墙的访问。在 Windows 系统上，netsh 命令 line 接口提供对底层 Windows 防火墙的访问。有关防火墙配置的其他信息，请参阅： 为 MongoDB 配置 Linux iptables 防火墙 为 MongoDB 配置 Windows netsh 防火墙 为了获得最佳结果并最大限度地减少总体风险，请确保只有来自可靠来源的流量才能到达mongod和mongos实例，并且mongod和mongos实例只能连接到受信任的输出。 虚拟专用网 虚拟专用网络或VPN使得通过加密和有限访问的可信网络连接两个网络成为可能。通常，使用 VPN 的 MongoDB 用户使用 TLS/SSL 而不是 IPSEC VPN 来解决性能问题。 根据配置和实现，VPN 提供证书验证和加密协议选择，这需要对所有客户端进行严格的身份验证和识别。此外，由于 VPN 提供了一个安全通道，通过使用 VPN 连接来控制对 MongoDB 实例的访问，您可以防止篡改和“中间人”攻击。 附录 IP绑定：https://docs.mongodb.com/manual/core/security-mongodb-configuration/ iptables为MongoDB 配置Linux 防火墙：https://docs.mongodb.com/manual/tutorial/configure-linux-iptables-firewall/ netsh为MongoDB 配置Windows 防火墙：https://docs.mongodb.com/manual/tutorial/configure-windows-netsh-firewall/ 实施字段级别修订：https://docs.mongodb.com/manual/tutorial/implement-field-level-redaction/ 原文链接：https://docs.mongodb.com/manual/core/security-hardening/ 译者：孔令升 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"09-security/Security-Reference.html":{"url":"09-security/Security-Reference.html","title":"安全参考","keywords":"","body":" 安全参考 在本页 mongo shell中的安全相关方法) 安全参考文档 下面列举了mongo shell 中可用的与安全相关的方法，以及其他安全相关材料。 mongo shell中的安全相关方法 用户管理和认证方法 Name Description db.auth() 向数据库验证用户 db.changeUserPassword() 改变用户的密码 db.createUser() 创建一个新用户 db.dropUser() 删除一个用户 db.dropAllUsers() 删除与数据库相关的用户 db.getUser() 返回指定用户信息 db.getUsers() 返回所有与数据库相关的用户信息 db.grantRolesToUser() 授予用户角色和角色包含的权限 db.removeUser() 弃用，从数据库删除用户 db.revokeRolesFromUser() 删除用户的角色 db.updateUser() 更新用户数据 passwordPrompt() 提示输入密码，作为在各种mongo shell用户管理方法中直接指定密码的替代方法 角色管理方法 Name Description db.createRole() 创建一个角色和指定其权限 db.dropRole() 删除一个用户自定义角色 db.dropAllRoles() 删除与数据库关联的所有用户自定义的角色 db.getRole() 返回指定角色的信息 db.getRoles() 返回数据库中所有用户自定义角色的信息 db.grantPrivilegesToRole() 给指定用户分配权限 db.revokePrivilegesFromRole() 从用户自定义角色中删除指定权限 db.grantRolesToRole() 指定用户定义的角色从哪些角色继承特权。 db.revokeRolesFromRole() 从角色中删除继承的角色 db.updateRole() 更新用户自定义的角色。 安全相关文档 system.roles Collection 描述存储用户自定义角色的集合的内容。 system.users Collection 描述存储用户凭据和角色分配的集合的内容。 Resource Document 描述角色的资源文档。 Privilege Actions 可用于权限的操作列表。 原文链接：https://docs.mongodb.com/manual/reference/security/ 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"10-changeStreams.html":{"url":"10-changeStreams.html","title":"改变流","keywords":"","body":" 改变流 在本页面 可用性 监视集合/数据库/部署 打开变更流 修改变更流输出 查找完整文档以进行更新操作 恢复变更流 用例 访问控制 活动通知 比较 3.6版的新功能。 变更流允许应用程序访问实时数据更改，而不会带来复杂性和拖延oplog的风险。应用程序可以使用变更流来订阅单个集合，数据库或整个部署中的所有数据变更，并立即对其做出反应。因为变更流使用聚合框架，所以应用程序还可以过滤特定的变更或随意转换通知。 可用性 变更流可用于副本集和分片群集。 存储引擎。 副本集和分片群集必须使用WiredTiger存储引擎。变更流还可用于采用MongoDB静态加密功能的部署 。 副本集协议版本。 副本集和分片群集必须使用副本集协议版本1（pv1）。 阅读关注“多数”启用。 从MongoDB 4.2开始，无论是否支持读关注，更改流都可用\"majority\"。也就是说，majority可以启用（默认）读取关注支持或禁用以使用更改流。 在MongoDB 4.0和更早版本中，更改流仅在\"majority\"启用了阅读关注支持后才可用（默认）。 监视集合/数据库/部署 您可以针对以下情况打开变更流： 目标 描述 集合 你可以打开一个变换流光标单个集合（除system收藏，或任何集合在 admin，local和config数据库）。 本页上的示例使用MongoDB驱动程序打开并使用单个集合的变更流游标。另请参见mongoshell方法 db.collection.watch()。 | 数据库 |在MongoDB中4.0开始，你可以打开一个变换流光标单个数据库（不包括admin，local和 config数据库）来监视更改其所有非系统集合。 有关MongoDB驱动程序方法，请参阅驱动程序文档。另请参见mongoshell方法 db.watch()。| |部署 | 在MongoDB中4.0开始，你可以打开一个变换流光标部署（无论是副本集中或分片集群）来监视除了所有数据库中更改所有非系统集合admin，local和config。 有关MongoDB驱动程序方法，请参阅驱动程序文档。另请参见mongoshell方法 Mongo.watch()。| 变更流示例 此页面上的示例使用MongoDB驱动程序来说明如何打开集合的更改流游标以及如何使用变更流游标。 打开变更流 要打开变更流： 对于副本集，您可以从任何数据承载成员发出开放变更流操作。 对于分片群集，必须从中发出开放更改流操作mongos。 以下示例打开一个集合的变更流，并在光标上进行迭代以检索变更流文档。 [1] 下面的Python示例假定您已连接到MongoDB副本集并访问了包含inventory集合的数据库。 cursor = db.inventory.watch() document = next(cursor) 要从游标检索数据更改事件，请迭代更改流游标。有关变更流事件的信息，请参见变更事件。 与MongoDB部署的连接保持打开状态时，游标保持打开状态，直到发生以下情况之一： 游标已显式关闭。 发生无效事件。 如果部署是分片群集，则分片删除可能会导致打开的更改流游标关闭，并且关闭的更改流游标可能无法完全恢复。 注意 未封闭游标的生命周期取决于语言。 [1] 从MongoDB 4.0开始，您可以指定a startAtOperationTime 在特定时间点打开游标。如果指定的起点是过去的时间，则必须在操作日志的时间范围内。 修改变更流输出； 在配置变更流时，可以通过提供以下一个或多个以下管道阶段的数组来控制变更流的输出： $addFields$match$project$replaceRoot$replaceWith （从MongoDB 4.2开始可用）$redact$set （从MongoDB 4.2开始可用）$unset （从MongoDB 4.2开始可用） pipeline = [ {'$match': {'fullDocument.username': 'alice'}}, {'$addFields': {'newField': 'this is an added field!'}} ] cursor = db.inventory.watch(pipeline=pipeline) document = next(cursor) 提示: 变更流事件文档的_id字段用作恢复令牌。不要使用管道来修改或删除更改流事件的_id字段。 从MongoDB 4.2开始，如果更改流聚合管道修改了事件的_id字段，则更改流将引发异常。 有关更改流响应文档格式的更多信息，请参见更改事件。 查找完整文档以进行更新操作 默认情况下，更改流仅在更新操作期间返回字段增量。但是，您可以配置变更流以返回更新文档的最新的多数提交版本。 要返回更新文档的最新多数批准版本，请传递full_document='updateLookup'到 db.collection.watch()方法。 在下面的示例中，所有更新操作通知都包含一个full_document字段，该字段表示 受更新操作影响的文档的当前版本。 cursor = db.inventory.watch(full_document='updateLookup') document = next(cursor) 注意 如果有一个或多个修改更新的文件多数提交的操作之后更新操作，但之前的查找，返回完整的文档可以显著从文档的更新操作的时间有所不同。 但是，变更流文档中包含的增量始终正确描述了应用于该更改流事件的监视集合更改。 有关变更流响应文档格式的更多信息，请参见更改事件。 恢复变更流 通过在打开游标时将resume令牌指定为resumeAfter或 startAfter，可以恢复变更流 。 resumeAfter用于变更流 通过resumeAfter在打开游标时将恢复令牌传递给特定事件，您可以在特定事件之后恢复更改流。对于恢复令牌，请使用更改流事件文档的 _id值。有关恢复令牌的更多信息，请参见恢复令牌。 重要 如果时间戳记是过去的，则oplog必须具有足够的历史记录来定位与令牌或时间戳记关联的操作。 resumeAfter在无效事件（例如，集合删除或重命名）关闭流之后，您不能用来恢复变更流。从MongoDB 4.2开始，您可以使用 startAfter在invalidate事件之后启动新的变更流。 您可以使用resume_after修饰符在恢复令牌中指定的操作之后恢复通知。该resume_after调节器将是必须解决的简历令牌的值，例如resume_token在下面的例子。 resume_token = cursor.resume_token cursor = db.inventory.watch(resume_after=resume_token) document = next(cursor) startAfter用于变更流 4.2版中的新功能。 您可以通过startAfter在打开游标时将恢复令牌传递到特定事件之后，开始新的变更流。与resumeAfter不同 ，startAfter可以 通过创建新的更改流在无效事件之后恢复通知。对于恢复令牌，请使用更改流事件文档的_id值。有关恢复令牌的更多信息，请参见恢复令牌。 重要 如果时间戳记是过去的，则oplog必须具有足够的历史记录来定位与令牌或时间戳记关联的操作。 恢复令牌 变更流事件文档的_id值用作恢复令牌： { \"_data\" : } 恢复令牌_data类型取决于MongoDB版本，在某些情况下，取决于更改流打开/恢复时的功能兼容性版本（fcv）（即，fcv值的更改不会影响已打开的更改流的恢复令牌。 ）： MongoDB版本 功能兼容版本 恢复令牌_data类型 MongoDB 4.2及更高版本 “ 4.2”或“ 4.0” 十六进制编码的字符串（v1） MongoDB 4.0.7及更高版本 “ 4.0”或“ 3.6” 十六进制编码的字符串（v1） MongoDB 4.0.6及更早版本 “ 4.0” 十六进制编码的字符串（v0） MongoDB 4.0.6及更早版本 “ 3.6” BinData MongoDB 3.6 “ 3.6” BinData 使用十六进制编码的字符串恢复令牌，您可以对恢复令牌进行比较和排序。 无论fcv值如何，4.0部署都可以使用BinData恢复令牌或十六进制字符串恢复令牌来恢复变更流。这样，4.0部署可以使用在3.6部署的集合中打开的变更流中的恢复令牌。 MongoDB版本中引入的新的恢复令牌格式不能被早期MongoDB版本使用。 提示 从MongoDB 4.2开始，如果变更流聚合管道修改了事件的_id字段，则变更流将引发异常。 用例 变更流可以使具有相关业务系统的体系结构受益，一旦数据变更能够持久，就可以通知下游系统。例如，更改流可以在实现提取，转换和加载（ETL）服务，跨平台同步，协作功能和通知服务时为开发人员节省时间。 访问控制 对于执行身份验证和授权的部署： 要针对特定集合打开变更流，应用程序必须具有对相应集合进行授予changeStream和 find操作的特权。 { resource ： { db ： ， collection ： }， actions ： [ “ find” ， “ changeStream” ] } 要在单个数据库上打开变更流，应用程序必须具有对数据库中所有非集合进行授予changeStream和 find操作的特权system。 { resource ： { db ： ， collection ： “” }， actions ： [ “ find” ， “ changeStream” ] } 要在整个部署上打开变更流，应用程序必须具有为部署中所有数据库的所有非集合授予权限changeStream并对其 find执行操作的特权system。 { resource ： { db ： “” ， collection ： “” }， actions ： [ “ find” ， “ changeStream” ] } 事件通知 变更流仅通知已保留到副本集中大多数数据承载成员的数据更改。这样可以确保仅由多数情况下提交的更改触发通知，这些更改在故障情况下是持久的。 例如，考虑一个3成员副本集，该副本集具有针对primary打开的变更流游标。如果客户端发出插入操作，则该更改流仅在该插入一直存在于大多数承载数据的成员之后，才将数据更改通知应用程序。 如果操作与事务相关联，则更改事件文档包括 txnNumber和lsid。 比较 从MongoDB 4.2开始，更改流将使用simple二进制比较，除非提供了明确的排序规则。在早期版本中，在单个集合（db.collection.watch()）上打开的变更流将继承该集合的默认排序规则。 译者： wh 参见 原文 - Change Streams Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"10-changeStreams/01-change-streams-production-recommendations.html":{"url":"10-changeStreams/01-change-streams-production-recommendations.html","title":"变更流生产建议","keywords":"","body":" 变更流生产建议 在本页面中 副本集 分片集群 如果您删除或重命名集合或数据库，并为其打开了变更流，则变更流游标在操作日志中前进到该点时将关闭。使用带fullDocument：updateLookup选项的变更流游标可能会为查找文档返回null。 尝试对一个已删除的集合恢复变更流将导致错误。在上一次捕获变更流和集合删除事件之间的该集合上发生的任何数据变更都将丢失。 变更流响应文档必须遵守16MB的BSON文档大小限制。根据打开变更流的集合中文档的大小，如果生成的通知文档超过16MB限制，则通知可能会失败。例如，对配置为返回完整更新的文档的变更流的更新操作，或对文档大小等于或略低于限制的文档进行插入/替换操作。 副本集 对于具有仲裁成员的副本集，如果没有足够的数据承载成员导致操作不能满足大多数的条件，则更改流可能会一直保持空闲状态。 例如，考虑一个具有两个数据承载节点和一个仲裁成员的3-成员副本集。如果从节点发生故障（例如由于故障或升级的原因），则写入操作不能满足大多数的条件。变更流将保持打开的状态，但不发送任何通知。 在这种情况下，只要应用程序收到的最后一个操作仍在副本集的操作日志中，则该应用程序可以赶上停机期间发生的所有操作。 如果可以提前预估到停机时间较长，例如升级或重大灾难，请考虑增加oplog的大小，以使操作保留的时间长于预估停机时间。使用rs.printReplicationInfo()可以看到关于oplog状态的信息，包括oplog的大小和可保存的操作时间范围。 分片集群 变更流通过利用全局逻辑时钟提供了整个分片上变更的总体排序。 MongoDB确保更改的顺序得以保留，并且更改流通知可以按接收到的顺序安全地解释。例如，针对3个分片集群打开的更改流游标会返回更改通知，该通知遵循所有三个分片中这些更改的总顺序。 为了保证变更的总体有序，mongos会针对每个变更通知去检查每个分片，查看该分片是否存在最近的变更。如果一个分片集群具有一个或多个分片且其上的集合几乎没有任何活动，或者是“冷”的，可能会对变更流的响应时间产生负面影响，因为mongos仍必须检查这些冷分片以确保变更的总体有序。对于分布不均匀的分片，或者工作负载中大多数操作都只发生在集群部分分片中，这种影响可能会更加明显。 如果分片集合具有较高的活动水平，则mongos可能无法跟上所有分片上的更改。考虑将通知过滤器用于这些类型的集合。例如，传递配置为仅过滤insert操作的$match管道。 对于分片集合，使用multi:true的更新操作可能会导致针对该集合打开的任何更改流都发送孤儿文档的通知。 从未分片的集合被分片的那一刻起，直到变更流追上第一次块迁移的时间，变更流通知文档中的documentKey仅包括文档的_id，而不包括完整的分片键。 原文链接：https://docs.mongodb.com/v4.2/administration/change-streams-production-recommendations/ 译者：刘翔 参见 原文 - Change Streams Production Recommendations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"10-changeStreams/02-change-events.html":{"url":"10-changeStreams/02-change-events.html","title":"Change Events","keywords":"","body":" Change Events 在本页面 Change Eventsinsert Eventupdate Eventreplace Eventdelete Eventdrop Eventrename EventdropDatabase Eventinvalidate Event Change Events以下文档表示变更流响应文档可以具有的所有可能的字段。 { _id : { }, \"operationType\" : \"\", \"fullDocument\" : { }, \"ns\" : { \"db\" : \"\", \"coll\" : \"\" }, \"to\" : { \"db\" : \"\", \"coll\" : \"\" }, \"documentKey\" : { \"_id\" : }, \"updateDescription\" : { \"updatedFields\" : { }, \"removedFields\" : [ \"\", ... ] } \"clusterTime\" : , \"txnNumber\" : , \"lsid\" : { \"id\" : , \"uid\" : } } 有些字段仅适用于某些操作，例如更新。下表描述了变更流响应文档中的每个字段： Field Type Description _id document Metadata related to the operation. Acts as the resumeToken for the resumeAfter parameter when resuming a change stream.copycopied`{ \"_data\" : hex string> } The_data` type depends on the MongoDB versions and, in some cases, the feature compatibility version (fcv) at the time of the change stream’s opening/resumption. For details, see Resume Tokens. operationType string The type of operation that occurred. Can be any of the following values:insert``delete``replace``update``drop``rename``dropDatabase``invalidate fullDocument document The document created or modified by the insert, replace, delete, update operations (i.e. CRUD operations).For insert and replace operations, this represents the new document created by the operation.For delete operations, this field is omitted as the document no longer exists.For update operations, this field only appears if you configured the change stream with fullDocument set to updateLookup. This field then represents the most current majority-committed version of the document modified by the update operation. This document may differ from the changes described in updateDescription if other majority-committed operations modified the document between the original update operation and the full document lookup. ns document The namespace (database and or collection) affected by the event. ns.db string The name of the database. ns.coll string The name of the collection.For dropDatabase operations, this field is omitted. to document When operationType : rename, this document displays the new name for the ns collection. This document is omitted for all other values of operationType. to.db string The new name of the database. to.coll string The new name of the collection. documentKey document A document that contains the _id of the document created or modified by the insert, replace, delete, update operations (i.e. CRUD operations). For sharded collections, also displays the full shard key for the document. The _id field is not repeated if it is already a part of the shard key. updateDescription document A document describing the fields that were updated or removed by the update operation.This document and its fields only appears if the operationType is update. updateDescription.updatedFields document A document whose keys correspond to the fields that were modified by the update operation. The value of each field corresponds to the new value of those fields, rather than the operation that resulted in the new value. updateDescription.removedFields array An array of fields that were removed by the update operation. clusterTime Timestamp The timestamp from the oplog entry associated with the event.For events that happened as part of a multi-document transaction, the associated change stream notifications will have the same clusterTime value, namely the time when the transaction was committed.On a sharded cluster, events that occur on different shards can have the same clusterTime but be associated with different transactions or even not be associcated with any transaction. To identify events for a single transaction, you can use the combination of lsid and txnNumber in the change stream event document.New in version 4.0. txnNumber NumberLong The transaction number.Only present if the operation is part of a multi-document transaction.New in version 4.0. lsid Document The identifier for the session associated with the transaction.Only present if the operation is part of a multi-document transaction.New in version 4.0. insert事件 以下示例说明了一个insert事件： { _id: { }, operationType: 'insert', clusterTime: , ns: { db: 'engineering', coll: 'users' }, documentKey: { userName: 'alice123', _id: ObjectId(\"599af247bb69cd89961c986d\") }, fullDocument: { _id: ObjectId(\"599af247bb69cd89961c986d\"), userName: 'alice123', name: 'Alice' } } 该documentKey字段包括_id和userName 字段。这表示engineering.users集合已分片，并且在userName和上都有分片键_id。 该fullDocument文档表示插入时文档的版本。 update事件 以下示例说明了一个update事件： { _id: { }, operationType: 'update', clusterTime: , ns: { db: 'engineering', coll: 'users' }, documentKey: { _id: ObjectId(\"58a4eb4a30c75625e00d2820\") }, updateDescription: { updatedFields: { email: 'alice@10gen.com' }, removedFields: ['phoneNumber'] } } 以下示例说明了update使用选项打开的变更流的事件：fullDocument : updateLookup { _id: { }, operationType: 'update', clusterTime: , ns: { db: 'engineering', coll: 'users' }, documentKey: { _id: ObjectId(\"58a4eb4a30c75625e00d2820\") }, updateDescription: { updatedFields: { email: 'alice@10gen.com' }, removedFields: ['phoneNumber'] }, fullDocument: { _id: ObjectId(\"58a4eb4a30c75625e00d2820\"), name: 'Alice', userName: 'alice123', email: 'alice@10gen.com', team: 'replication' } } 该fullDocument文档代表了更新文档的最新多数批准版本。该fullDocument文档可能与更新操作时的文档有所不同，具体取决于在更新操作和文档查找之间发生的交错多数授权操作的数量。 replace事件 以下示例说明了一个replace事件： { _id: { }, operationType: 'replace', clusterTime: , ns: { db: 'engineering', coll: 'users' }, documentKey: { _id: ObjectId(\"599af247bb69cd89961c986d\") }, fullDocument: { _id: ObjectId(\"599af247bb69cd89961c986d\"), userName: 'alice123', name: 'Alice' } } 一个replace操作使用update命令，并且包括两个阶段： 使用documentKey和删除原始文档 使用相同的插入新文档 documentkey 在fullDocument一个的replace事件表示替换文件的插入后的文件。 delete事件 以下示例说明了一个delete事件： { _id: { }, operationType: 'delete', clusterTime: , ns: { db: 'engineering', coll: 'users' }, documentKey: { _id: ObjectId(\"599af247bb69cd89961c986d\") } } 该fullDocument文档被省略，因为在更改流游标将delete事件发送到客户端时，该文档不再存在。 drop事件 版本4.0.1中的新功能。 一个drop在集合从数据库中删除发生的事件。以下示例说明了一个drop事件： { _id: { }, operationType: 'drop', clusterTime: , ns: { db: 'engineering', coll: 'users' } } 一个drop事件导致一个无效事件 变革流张开攻击它的ns集合。 rename事件 版本4.0.1中的新功能。 一个rename在集合重命名发生的事件。以下示例说明了一个rename事件： { _id: { }, operationType: 'rename', clusterTime: , ns: { db: 'engineering', coll: 'users' }, to: { db: 'engineering', coll: 'people' } } 一个rename事件导致一个 无效事件的流变化对打开的ns集合或to集合。 dropDatabase事件 版本4.0.1中的新功能。 一个dropDatabase当数据库被丢弃发生的事件。以下示例说明了一个dropDatabase事件： { _id: { }, operationType: 'dropDatabase', clusterTime: , ns: { db: 'engineering' } } 一个dropDatabase事件导致一个 无效事件的流变化对打开的ns.db数据库。 invalidate事件 以下示例说明了一个invalidate事件： { _id: { }, operationType: 'invalidate', clusterTime: } 对于针对集合打开的变更流，影响监视的集合的 放置事件， 重命名事件或 dropDatabase事件导致 无效事件。 对于针对数据库打开的变更流，影响受监视数据库的 dropDatabase事件将导致 invalidate事件。 invalidate 事件关闭更改流游标。 resumeAfter在无效事件（例如，集合删除或重命名）关闭流之后，您不能用来恢复更改 流。从MongoDB 4.2开始，您可以使用 startAfter在invalidate事件之后启动新的更改流。 译者：wh 参见 原文 - Change Events Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication.html":{"url":"11-replication.html","title":"复制集","keywords":"","body":"复制 在本页 冗余和数据可用性 MongoDB中的复制 异步复制 自动故障转移 读操作 事务 变更流 附加功能 MongoDB中的副本集是一组维护相同数据集合的 mongod进程。副本集提供了冗余和高可用性，并且这是所有生产部署的基础。本节介绍MongoDB中的复制以及副本集的组件和体系结构。本节还提供了副本集常见任务的教程。 冗余和数据可用性¶ 复制提供了冗余并增加了 数据可用性。对于不同数据库服务器上的多个数据副本，复制为防止单台数据库服务器故障提供了一定程度的容错能力。 在某些情况下，复制可以提高读取性能，因为客户端可以将读操作发送到不同的服务器上。在不同的数据中心维护数据副本可以提高分布式应用程序的数据本地化和可用性。您还可以维护额外的副本以实现特殊用途，比如灾难恢复、报告或备份。 MongoDB的复制¶ 副本集是一组维护相同数据集合的 mongod实例。副本集包含多个数据承载节点和一个可选的仲裁节点。在数据承载节点中，有且仅有一个成员为主节点，其他节点为从节点。 主节点 接收所有的写操作。一个副本集仅有一个主节点能够用{ w: \"majority\" } 写关注点级别来确认写操作；虽然在某些情况下，另一个mongod的实例也可以暂时认为自己是主节点。[1] 主节点会将其数据集合所有的变化记录到操作日志中，即oplog.。有关主节点操作的更多信息，请参见 副本集主节点。 从节点复制主节点的oplog，并将这些操作应用于它们的数据集，这样以便从节点的数据集能反映出主节点的数据集。如果主节点不可用，一个候选的从节点将会发起选举并使之成为新的主节点。有关副本成员的更多信息，请参见副本成员。 在某些情况下(比如您有一个主节点和一个从节点，但由于成本约束无法添加另一个从节点)，您可以选择将一个 mongod 实例作为 仲裁节点添加到一个副本集中。仲裁节点参与选举但不持有数据(即不提供数据冗余)。有关仲裁节点的更多信息，请参见副本集仲裁节点。 仲裁节点 永远只能是仲裁节点，但在选举过程中主节点也许会降级成为 从节点， 从节点也可能会升级成为主节点。 异步复制¶ 从节点复制主节点的oplog并异步地应用操作到它们的数据集。通过让从节点的数据集反映主服务器的数据集，副本集可以在一个或多个成员失败的情况下继续运行。 有关复制机制的更多信息，请参见 副本集Oplog 和 副本集数据同步。 慢操作¶ 从4.2版本开始（从4.0.6开始也是可行的），副本集的副本成员会记录oplog中应用时间超过慢操作阈值的慢操作条目。这些慢oplog信息被记录在从节点的诊断日志 中，其路径位于REPL 组件的文本applied op: took ms中。这些慢日志条目仅仅依赖于慢操作阈值。它们不依赖于日志级别（无论是系统还是组件级别）、过滤级别，或者慢操作采样比例。过滤器不会捕获慢日志条目。 复制延迟和流控制¶ 复制延迟 指的是将主节点的写操作拷贝(即复制)到 从节点所花费的时间。一些小的延迟期可能是可以接受的，但是随着复制延迟的增长，会出现严重的问题，包括引起主节点的缓存压力。 从MongoDB 4.2开始，管理员可以限制主节点应用写操作的速度，目的是将majority committed 延迟保持在可配置参数flowControlTargetLagSeconds的最大值之下。 默认情况下，流控制是启用的。 注意 为了进行流控制，复制集/分片集群必须满足：参数featureCompatibilityVersion (FCV) 设置为4.2并启用majority读关注点。也就是说，如果FCV不是 4.2 ，或者读关注点majority被禁用，那么启用流控制将不起作用。 启用流控制后，当延迟快接近 flowControlTargetLagSeconds 参数指定的秒数时，主节点上的写操作必须首先获得许可单才可以获取写锁。通过限制每秒发出的许可单的数量，流控制机制可以将延迟保持在目标数值之下。 为获取更多信息，请参见检查复制延迟和流控制。 自动故障转移¶ 当主节点无法和集群中其他节点通信的时间超过参数electionTimeoutMillis配置的期限时（默认10s），一个候选的从节点会发起选举来推荐自己成为新主节点。集群会尝试完成一次新主节点的选举并恢复正常的操作。 副本集在选举成功前是无法处理写操作的。如果读请求被配置运行在从节点 上，则当主节点下线时，副本集可以继续处理这些请求。 假设采用默认的副本配置选项，集群选择新主节点的中间过渡时间通常不应超过12秒。这包括了将主节点标记为unavailable、发起以及完成一次 选举的时间。您可以通过修改settings.electionTimeoutMillis 复制配置选项来调整这个时间期限。网络延迟等因素可能会延长完成副本集选举所需的时间，从而影响您的集群在没有主节点的情况下运行的时间。这些因素取决于您实际的集群架构情况。 将electionTimeoutMillis复制配置选项从默认的10000(10秒)降低可以更快地检测主节点故障。然而，由于诸如临时性的网络延迟等因素，集群可能会更频繁地发起选举，即使主节点在其他方面是健康的。这也许会增加w : 1 级别写操作发生回滚的可能性。 您的应用程序连接逻辑应该包括对自动故障转移和后续选举的容错处理能力。从MongoDB 3.6开始，MongoDB驱动程序可以探测到主节点的丢失，并自动重试某些写操作 一次，提供额外的自动故障转移和选举的内置处理: MongoDB 4.2兼容的驱动程序默认启用可重试写 MongoDB 4.0和3.6兼容的驱动程序必须通过在 连接字符串中包含retryWrites=true来显式地启用可重试写。 请参见 副本集选举来获取副本集选举的完整信息。 为了解更多关于MongoDB失败处理的信息，请参见： 副本集选举 可重试写 副本集故障期间的回滚 读操作¶ 读偏好¶ 默认情况下，客户端从主节点读取[1]；然而，客户端可以定义一个读偏好 将读操作发送给从节点。 异步复制至从节点，意味着从节点读取返回的数据不能反映主节点上数据的状态。 包含读操作的多文档事务必须使用读偏好primary。在给定的事务中所有操作都必须路由至相同的成员节点。 为了解更多关于副本集读的信息，请参见读偏好。 数据可见性¶ 根据读关注，客户端可以在写持久化前看到写结果： 不管写的 write concern级别是什么，其他使用了读关注级别为 \"local\" 或 \"available\" 的客户端，可以在发起写操作的客户端确认其写成功之前查看该客户端写的结果。 使用了读关注级别为 \"local\" 或 \"available\" 的客户端，能读取在副本集故障转移期间可能随后被回滚 掉的数据。 对于多文档事务中的操作，当事务提交时，在事务中所做的所有数据更改都会被保存并在事务外部可见。也就是说，事务在回滚其他更改时不会提交某些更改。 在事务提交之前，事务中所做的数据更改在事务外部是不可见的。 然而，当一个事务写入多个分片时，并不是所有外部的读操作都需要等待提交的事务的结果在分片中可见。例如，如果提交了一个事务，并且在分片a上可以看到写1，但是在分片B上还不能看到写2，那么外部读关注为 \"local\" 的读可以在不看到写2的情况下读取写1的结果。 有关MongoDB读隔离、一致性和近因性的更多信息，请参见Read Isolation, Consistency, and Recency。 事务¶ 从MongoDB 4.0开始，副本集支持多文档事务。 包含读操作的多文档事务必须使用读偏好 primary。给定事务中所有的操作都必须路由至相同的成员节点。 在事务提交之前，事务中所做的数据更改在事务外部是不可见的。 然而，当一个事务写入多个分片时，并不是所有外部的读操作都需要等待提交的事务的结果在分片中可见。例如，如果提交了一个事务，并且在分片a上可以看到写1，但是在分片B上还不能看到写2，那么外部读关注点为 \"local\" 的读可以在不看到写2的情况下读取写1的结果。 变更流¶ 从MongoDB 3.6开始，副本集和分片集群支持变更流。变更流允许应用程序访问实时数据更改，而不需要跟踪oplog的复杂性和风险。应用程序可以使用变更流来订阅一个或多个集合上的所有数据更改。 附加功能¶ 副本集提供了许多选项来支持应用程序的需求。例如，你可以使用多数据中心中的成员来部署一个副本集，或者通过调整一些成员的members[n].priority 来控制选举结果。副本集还支持用于报告、灾难恢复或备份功能的专用成员。 更多有关信息请参见优先级0的副本集成员，隐藏副本集成员和延迟副本集成员 。 [1] (1, 2) 在 某些场景下, 一个复制集中的两个节点可能会认为它们是主节点，但最多，他们中的一个将能够完成写关注点为{ w: \"majority\" }写操作。 可以完成 { w: \"majority\" } 写的节点是当前主节点，而另一个节点是原先的主节点，通常是由于网络分区导致它还没有意识到自己的降级。当这种情况发生时，连接到原先主节点的客户端尽管已经请求了读偏好primary，但可能还 会观察到过时的数据，并且对原先主节点新写的操作最终将回滚掉。 原文链接：https://docs.mongodb.com/manual/replication/ 译者：李正洋 参见 原文 - Replication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members.html":{"url":"11-replication/01-replica-set-members.html","title":"复制集成员","keywords":"","body":" 副本集成员¶ MongoDB 的副本集是一组提供冗余和高可用性的mongod 进程。一个副本集的成员有： 主节点 主节点接受所有的写操作。 从节点 从节点通过复制主节点的操作来维护一个相同的数据集。从节点为特殊用途的配置文件提供了额外的配置项。例如，从节点可配置成无投票权 或0优先级。 副本集的最小推荐配置是一个包含三个数据承载成员的三成员副本集：一个主节点 和两个从节点。在某些情况下（例如你有一个主节点和一个从节点，但由于成本约束无法添加另一个从节点），你可以选择使用一个仲裁节点。仲裁节点参与选举但不持有数据（即不提供数据冗余）。 一个副本集最多可以有50个成员，但仅能有7个可投票成员。 主节点¶ 副本集的主节点是唯一一个可以接受写操作的成员。MongoDB在主节点 上应用写操作，然后将这些操作记录到主节点的oplog中。从节点成员复制这个日志然后应用到它们的数据集中。 在下图的三成员副本集中，主节点接受所有写操作。然后从节点复制oplog应用至它们的数据集中。 副本集所有的成员都可以接受读操作。但是，默认情况下，应用程序会将其读操作定向至主节点。有关更改默认读行为的详细信息，请参阅读偏好 。 副本集最多有一个主节点。 [2] 如果当前主节点不可用，一个选举会抉择出新的主节点。更多详细信息请参见副本集选举。 从节点¶ 一个从节点维护了主节点数据集的一个副本。为了复制数据，从节点通过异步的方式将主节点oplog 应用至自己的数据集中。一个副本集可以有一个或多个从节点。 下图的三成员副本集有两个副本成员。从节点复制主节点的oplog并应用到它们的数据集上。 虽然客户端不能将数据写入到从节点，但客户端可以由从节点读取数据。有关客户端如何将读操作直接读入副本集的详细信息，请参阅读偏好 。 从节点可以成为主节点。如果当前主节点不可用，副本集会发起选举来选择哪个从节点成为新的主节点。 更多详细信息请参见副本集选举。 您可以出于特殊目的来配置从节点成员。您可以配置一个从节点用于: 阻止它在选举中成为主节点，适用于将该节点部署在备用数据中心或者充当一个冷备节点。请查考0优先级副本集成员。 防止应用程序从它读取数据，适用于在该节点上运行需要与正常流量分离的应用程序。请参考隐藏副本集成员。 保持一个运行的“历史”快照，以便在从某些错误(如无意中删除的数据库)恢复时使用。请参考延迟副本集成员。 [1] | 从4.2版本开始（从4.0.6也支持），副本集的副本成员会记录oplog中应用时间超过慢操作阈值的慢操作条目。这些慢oplog信息被记录在从节点的诊断日志 中，其路径位于REPL 组件的文本applied op: took ms中。这些慢日志条目仅仅依赖于慢操作阈值。它们不依赖于日志级别（无论是系统还是组件级别）、过滤级别，或者慢操作采样比例。过滤器不会捕获慢日志条目。 仲裁节点¶ 在某些情况下（例如有一个主节点和一个从节点，但由于成本约束无法添加另一个从节点），你可以在副本集中添加一个仲裁节点。仲裁节点没有数据集的副本，并且不能成为主节点。然而，仲裁节点可以参与主节点选举。一个仲裁节点只有 1 票选举权。 3.6版本的变化：从MongoDB 3.6版本开始，仲裁节点优先级为0。当您升级一个副本集至3.6版本时，如果当前配置中有一个优先级为1的仲裁节点，则MongoDB 3.6会将仲裁节点的优先级重新配置为0。 重要 不要在同时承载副本集的主节点或副本成员的系统上运行仲裁节点。 需要添加一个仲裁节点，请参考添加一个仲裁节点至副本集。 使用仲裁节点时的注意事项，请参考副本集仲裁节点。 [2] | 在 某些场景下, 一个副本集中的两个节点可能会认为它们是主节点，但至多，他们中的一个将能够完成写关心级别为{ w: \"majority\" }的写操作。 可以完成 { w: \"majority\" } 写的节点是当前主节点，而另一个节点是原先的主节点，通常是由于网络分区导致它还没有意识到自己的降级。当这种情况发生时，连接到原先主节点的客户端尽管已经请求了读偏好primary，但可能还会观察到过时的数据，并且对原先主节点新写的操作最终将回滚掉。 随附副本集主节点、从节点和仲裁节点的参看链接： https://docs.mongodb.com/manual/core/replica-set-primary/ https://docs.mongodb.com/manual/core/replica-set-secondary/ https://docs.mongodb.com/manual/core/replica-set-arbiter/ 原文链接：https://docs.mongodb.com/manual/core/replica-set-members/ 译者：李正洋 参见 原文 - Replica Set Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/01-replica-set-primary.html":{"url":"11-replication/01-replica-set-members/01-replica-set-primary.html","title":"Replica Set Primary","keywords":"","body":" Replica Set Primary ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Primary Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/02-replica-set-secondary.html":{"url":"11-replication/01-replica-set-members/02-replica-set-secondary.html","title":"Replica Set Secondary Members","keywords":"","body":" Replica Set Secondary Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Secondary Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/02-replica-set-secondary/01-replica-set-priority-0-member.html":{"url":"11-replication/01-replica-set-members/02-replica-set-secondary/01-replica-set-priority-0-member.html","title":"Priority 0 Replica Set Members","keywords":"","body":" Priority 0 Replica Set Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Priority 0 Replica Set Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/02-replica-set-secondary/02-replica-set-hidden-member.html":{"url":"11-replication/01-replica-set-members/02-replica-set-secondary/02-replica-set-hidden-member.html","title":"Hidden Replica Set Members","keywords":"","body":" Hidden Replica Set Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Hidden Replica Set Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/02-replica-set-secondary/03-replica-set-delayed-member.html":{"url":"11-replication/01-replica-set-members/02-replica-set-secondary/03-replica-set-delayed-member.html","title":"Delayed Replica Set Members","keywords":"","body":" Delayed Replica Set Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Delayed Replica Set Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/01-replica-set-members/03-replica-set-arbiter.html":{"url":"11-replication/01-replica-set-members/03-replica-set-arbiter.html","title":"Replica Set Arbiter","keywords":"","body":" Replica Set Arbiter ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Arbiter Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/02-replica-set-oplog.html":{"url":"11-replication/02-replica-set-oplog.html","title":"副本集日志","keywords":"","body":" 副本集日志 在本页 日志大小 可能需要更大日志的工作负载 日志状态 慢日志应用程序 日志集合的特性 oplog(操作日志)是一个特殊的有限集合，它对数据库中所存储数据的所有修改操作进行滚动记录。 说明 从MongoDB 4.0开始，与其他有限集合不同，oplog集合可以超过其配置的大小限制，以避免大多数提交点被删除。 MongoDB在主节点上应用数据库操作，然后将这些操作记录到主节点的oplog上。然后从节点成员会以异步的方式复制并应用这些操作。所有副本集成员都包含一个oplog的副本，其位于local.oplog.rs 集合中，该集合可以让副本集成员维护数据库的当前状态。 为了便于复制，所有副本集成员将心跳(ping)发送给所有其他成员。任何从节点成员都可以从任何其他成员导入oplog条目。 oplog中的每个操作都是幂等的。也就是说，对目标数据集应用一次或多次oplog操作都会产生相同的结果。 日志大小 当您第一次启动一个副本集成员时，如果您没有指定oplog大小，MongoDB将创建一个默认大小的oplog。[1] 对于Unix和Windows系统 oplog大小依赖于存储引擎： | 存储引擎 | 默认oplog大小 | 下限 | 上限 | | ------------------ | ---------------- | ----- | ---- | | In-Memory存储引擎 | 物理内存的5% | 50MB | 50GB | | WiredTiger存储引擎 | 空闲磁盘空间的5% | 990MB | 50GB | 对于64-bit macOS系统 默认的oplog大小是192MB物理内存或空闲磁盘空间，具体取决于存储引擎: | 存储引擎 | 默认oplog大小 | | ------------------ | ----------------- | | In-Memory存储引擎 | 192MB物理内存 | | WiredTiger存储引擎 | 192MB空闲磁盘空间 | 在大多数情况下，默认的oplog大小就足够了。例如，如果一个oplog是空闲磁盘空间的5%，并且可容纳24小时的操作记录，那么从节点从oplog停止复制条目的时间可以长达24小时，并且不会因oplog条目变得太陈旧而无法继续复制。但是，大多数副本集的操作容量要小得多，它们的oplog可以容纳更多的操作。 在 mongod 创建一个oplog前，您可以使用 oplogSizeMB 选项来定义oplog的大小。一旦您第一次启动副本集成员后，可使用 replSetResizeOplog 管理命令去改变oplog的大小。 replSetResizeOplog 命令允许您动态调整oplog大小而无需重新启动 mongod 进程。 [1] | 从MongoDB 4.0开始，oplog可以超过其配置的大小限制，来避免删除大多数提交点。 可能需要更大日志大小的工作负载 如果您可以预测您的副本集的工作负载与以下模式之一相似，那么您可能希望创建一个比默认值更大的oplog。相反，如果您的应用程序主要执行读操作，而写操作很少，那么更小的oplog可能就足够了。 以下工作负载可能需要大容量的oplog。 一次更新多个文档 为了保持幂等性，oplog必须将多次更新转换为单个操作。这会使用大量的oplog空间，而不会相应增加数据大小或磁盘使用。 删除与插入的数据量相等 如果删除的数据量与插入的数据量大致相同，则数据库在磁盘使用方面不会显著增长，但操作日志的大小可能相当大。 大量的就地更新 如果工作负载中很大一部分是不增加文档大小的更新，那么数据库会记录大量操作，但不会更改磁盘上的数据量。 Oplog状态 为了查看oplog的状态，包括oplog的大小和操作的时间范围，可使用rs.printReplicationInfo() 方法。有关oplog状态的更多内容，请参见检查Oplog大小。 复制延迟和流控制 在各种异常情况下，对从节点oplog的更新可能会滞后于预期的性能时间。在从节点上使用 db.getReplicationInfo()命令，以及根据复制状态输出结果来评估复制的当前状态，并确定是否存在任何意外的复制延迟。 从MongoDB 4.2开始，管理员可以限制主节点应用其写操作的速度，目的是将大多数提交延迟保持在可配置参数flowControlTargetLagSeconds最大值之下。 默认情况下，流控制是启用的。 说明 为了进行流控制，副本集/分片集群必须满足：参数featureCompatibilityVersion (FCV) 设置为4.2，并启用majority读关注。也就是说，如果FCV不是4.2，或者读关注majority被禁用，那么启用流控制将不起作用。 更多信息请参见流控制。 慢Oplog应用程序 从4.2版本开始（从4.0.6开始也是可行的），副本集的副本成员会记录oplog中应用时间超过慢操作阈值的慢操作条目。这些慢oplog信息被记录在从节点REPL 组件的文本applied op: took ms中。 2018-11-16T12:31:35.886-0500 I REPL [repl writer worker 13] applied op: command { ... }, took 112ms 记录在从节点上的慢操作应用程序有： 不受 slowOpSampleRate的影响；例如，所有的慢oplog条目被记录在从节点上。 不受 logLevel/systemLog.verbosity 级别的影响（或者systemLog.component.replication.verbosity 的级别）；例如，对于oplog条目，从节点仅记录慢oplog条目。增加日志的冗余级别不会导致记录所有的oplog条目。 不会被捕获器抓取到，并且不受捕获级别的影响。 更多有关慢操作阈值设置的信息，请参见： mongod --slowms slowOpThresholdMs profile 命令或者 db.setProfilingLevel() shell帮助命令 Oplog集合的特性 如果你的MongoDB部署使用的是WiredTiger存储引擎，你无法从副本集任何成员中删除 local.oplog.rs 集合。这个限制适用于单成员和多成员的副本集。如果一个节点临时宕机并试图在重启过程中重新应用oplog，那么删除oplog可能会导致副本集中的数据不一致。 原文链接：https://docs.mongodb.com/manual/core/replica-set-oplog/ 译者：李正洋 参见 原文 - Replica Set Oplog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/03-replica-set-sync.html":{"url":"11-replication/03-replica-set-sync.html","title":"Replica Set Data Synchronization","keywords":"","body":" Replica Set Data Synchronization ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Data Synchronization Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/04-replica-set-architectures.html":{"url":"11-replication/04-replica-set-architectures.html","title":"副本集部署架构","keywords":"","body":" 副本集部署架构 在本页 策略 副本集命名 部署方式 副本集的架构影响副本集的容量和性能。本文档提供了副本集部署的策略，并描述了常见的体系结构。 生产系统的标准副本集部署是一个三成员的副本集。这些副本集提供了冗余和容错能力。应尽可能避免复杂性，但是要让您的应用程序需求来决定架构体系。 策略 确定成员的数量 依据下面这些策略在副本集中添加成员 最大的投票成员数量 一个副本集至多可以有50个成员，但可投票成员最多只能有7个。如果副本集已经有7个有投票权的成员了，那其他的成员只能作为无投票权成员。 部署奇数个成员 确保副本集有奇数个投票成员。一个副本集最多可以有7个投票成员。如果您有偶数个有投票权的成员，则部署另一个有投票权的数据成员，或者如果有约束禁止部署另一个有投票权的数据成员，则可以部署一个仲裁节点。 仲裁节点不存储数据的副本，并且需要的资源更少。因此，您可以在应用程序服务器或其他共享进程上运行仲裁节点。在没有数据副本的情况下，可能会在不放置副本集其他成员的环境中放置仲裁节点。请参考安全策略。 在下列的MongoDB版本，对于带有仲裁节点的副本集，协议版本 pv1相较于pv0 （在MongoDB4.0+中不再支持）增加了 w:1 级别写操作回滚的可能性。 MongoDB 3.4.1 MongoDB 3.4.0 MongoDB 3.2.11或更早期版本 请参考副本集协议版本。 警告 通常来说，应避免在单个副本集上部署多个仲裁节点。 考虑容错性 副本集的容错性是指在有些节点变为不可用之后仍能保留足够数量的成员来完成主节点选举的成员个数。换句话说，它是副本集的成员个数与完成主节点选举所需要的大多数投票成员个数之间的差值。如果没有主节点，副本集就不能接受写操作。容错性受到副本集大小的影响，但两者之间的关系并不直接。见下表: Number of Members Majority Required to Elect a New Primary Fault Tolerance 3 2 1 4 3 1 5 3 2 6 4 2 向副本集添加一个成员并不总是能提高容错性。但是，在这些情况下，添加的新成员可用作特殊的用途，例如备份或报告。 从4.2.1版本开始，rs.status() 命令可以为副本集返回majorityVoteCount 值。 用隐藏和延迟成员实现特殊用途 添加隐藏或延迟成员来支持特殊的用途，比如备份或者生成报告。 在读压力大的部署上实现负载均衡 在读流量非常大的部署中，可以通过将读流量分发给副本成员来提高读吞吐量。随着部署规模的增长，可以将成员添加或移动到备用数据中心，以提高冗余和可用性。 说明 将副本集的成员分布在双数据中心中会比分布在单数据中心更有利。在双数据中心分布中， 如果其中一个数据中心发生故障，数据仍然可以读取，这与单个数据中心分布不同。 如果只有少数成员的数据中心发生故障，副本集仍然可以提供写操作和读操作。 但是，如果具有大多数成员的数据中心宕机，则副本集会变为只读。 如果可能，将成员分布到至少三个数据中心中。对于配置服务器副本集(CSRS)，最佳实践是在三个(或更多，取决于成员数量)数据中心之间分布成员。如果第三个数据中心的成本过高，一种可能的分布是将数据成员均匀地分布到两个数据中心，并在公司政策允许的情况下将剩余的成员部署在云上。 始终确保主数据中心能够选举出主节点。 在有需求前进行扩容 副本集现有成员必须具有空闲容量来支持添加新成员。总是在当前副本集容量需求饱和之前添加新的成员。 按地理位置分布成员 若要在数据中心发生故障时保护数据，请在备用数据中心中至少保留一个成员。如果可能，使用奇数个数据中心，并选择一个成员分布，这样即使在数据中心故障的情况下，也能最大限度地提高剩余副本集成员构成大多数或至少提供数据副本的可能性。 说明 将副本集的成员分布在双数据中心中会比分布在单数据中心更有利。在双数据中心分布中， 如果其中一个数据中心发生故障，数据仍然可以读取，这与单个数据中心分布不同。 如果只有少数成员的数据中心发生故障，副本集仍然可以提供写操作和读操作。 但是，如果具有大多数成员的数据中心宕机，则副本集会变为只读。 如果可能，将成员分布到至少三个数据中心中。对于配置服务器副本集(CSRS)，最佳实践是在三个(或更多，取决于成员数量)数据中心之间分布成员。如果第三个数据中心的成本过高，一种分布的可能性是将数据成员均匀地分布到两个数据中心，并在公司政策允许的情况下将剩余的成员部署在云上。 为了确保主数据中心中的成员先于备用数据中心中的成员当选为主节点，可以将备数据中心成员的参数 members[n].priority 值设置低于主数据中心的成员。 更多有关信息，请参考分布在两个或多个数据中心的副本集 使用标签集进行目标操作 使用副本集标签集将读操作定向到特定成员，或者自定义写关注来确认特定成员的请求。 也可参考数据中心意识 和MongoDB部署的工作负载隔离。 使用journaling来防止停电 MongoDB默认是启用 journaling。日志可以防止在服务中断（如电源故障和意外重启）时发生数据丢失。 主机名 提示 如果可能，使用一个逻辑DNS主机名来替代IP地址，尤其是在配置副本集成员或者分片集群成员时。使用逻辑DNS主机名可以避免因IP地址变化引起配置变更。 副本集命名 如果您的应用程序连接了多个副本集，每个副本集应该设置一个唯一的名字。一些驱动程序根据副本集名称对副本集连接进行分组。 部署的方式 以下文档描述了常见的副本集部署模式。根据应用程序的需求，其它的模式是可能和有效的。如果需要，在您自己的部署中结合每个架构的特点: 三成员副本集 三成员副本集提供了一个副本集的最小推荐架构。 分布在两个或多个数据中心的副本集 地理分布的集合包括位于多个位置的成员，以防止特定设备的故障，例如停电。 原文链接：https://docs.mongodb.com/manual/core/replica-set-architectures/ 译者：李正洋 参见 原文 - Replica Set Deployment Architectures Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/04-replica-set-architectures/01-replica-set-architecture-three-members.html":{"url":"11-replication/04-replica-set-architectures/01-replica-set-architecture-three-members.html","title":"Three Member Replica Sets","keywords":"","body":" Three Member Replica Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Three Member Replica Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/04-replica-set-architectures/02-replica-set-architecture-geographically-distributed.html":{"url":"11-replication/04-replica-set-architectures/02-replica-set-architecture-geographically-distributed.html","title":"Replica Sets Distributed Across Two or More Data Centers","keywords":"","body":" Replica Sets Distributed Across Two or More Data Centers ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Sets Distributed Across Two or More Data Centers Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/05-replica-set-high-availability.html":{"url":"11-replication/05-replica-set-high-availability.html","title":"Replica Set High Availability","keywords":"","body":" Replica Set High Availability ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set High Availability Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/05-replica-set-high-availability/01-replica-set-elections.html":{"url":"11-replication/05-replica-set-high-availability/01-replica-set-elections.html","title":"Replica Set Elections","keywords":"","body":" Replica Set Elections ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Elections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/05-replica-set-high-availability/02-replica-set-rollbacks.html":{"url":"11-replication/05-replica-set-high-availability/02-replica-set-rollbacks.html","title":"Rollbacks During Replica Set Failover","keywords":"","body":" Rollbacks During Replica Set Failover ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rollbacks During Replica Set Failover Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication.html":{"url":"11-replication/06-replication.html","title":"Replica Set Read and Write Semantics","keywords":"","body":" Replica Set Read and Write Semantics ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Read and Write Semantics Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/01-replica-set-write-concern.html":{"url":"11-replication/06-replication/01-replica-set-write-concern.html","title":"Write Concern for Replica Sets","keywords":"","body":" Write Concern for Replica Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Write Concern for Replica Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/02-read-preference.html":{"url":"11-replication/06-replication/02-read-preference.html","title":"Read Preference","keywords":"","body":" Read Preference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Read Preference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/02-read-preference/01-read-preference-tags.html":{"url":"11-replication/06-replication/02-read-preference/01-read-preference-tags.html","title":"Tag Sets","keywords":"","body":" Tag Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Tag Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/02-read-preference/02-read-preference-staleness.html":{"url":"11-replication/06-replication/02-read-preference/02-read-preference-staleness.html","title":"maxStalenessSeconds","keywords":"","body":" maxStalenessSeconds ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - maxStalenessSeconds Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/02-read-preference/03-read-preference-hedge-option.html":{"url":"11-replication/06-replication/02-read-preference/03-read-preference-hedge-option.html","title":"Hedged Read Option","keywords":"","body":" Hedged Read Option ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Hedged Read Option Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/02-read-preference/04-read-preference-use-cases.html":{"url":"11-replication/06-replication/02-read-preference/04-read-preference-use-cases.html","title":"Read Preference Use Cases","keywords":"","body":" Read Preference Use Cases ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Read Preference Use Cases Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/06-replication/03-read-preference-mechanics.html":{"url":"11-replication/06-replication/03-read-preference-mechanics.html","title":"Server Selection Algorithm","keywords":"","body":" Server Selection Algorithm ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Server Selection Algorithm Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment.html":{"url":"11-replication/07-replica-set-deployment.html","title":"Replica Set Deployment Tutorials","keywords":"","body":" Replica Set Deployment Tutorials ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Deployment Tutorials Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/01-deploy-replica-set.html":{"url":"11-replication/07-replica-set-deployment/01-deploy-replica-set.html","title":"Deploy a Replica Set","keywords":"","body":" Deploy a Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy a Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/02-deploy-replica-set-for-testing.html":{"url":"11-replication/07-replica-set-deployment/02-deploy-replica-set-for-testing.html","title":"Deploy a Replica Set for Testing and Development","keywords":"","body":" Deploy a Replica Set for Testing and Development ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy a Replica Set for Testing and Development Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/03-deploy-geographically-distributed-replica-set.html":{"url":"11-replication/07-replica-set-deployment/03-deploy-geographically-distributed-replica-set.html","title":"Deploy a Geographically Redundant Replica Set","keywords":"","body":" Deploy a Geographically Redundant Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy a Geographically Redundant Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/04-add-replica-set-arbiter.html":{"url":"11-replication/07-replica-set-deployment/04-add-replica-set-arbiter.html","title":"Add an Arbiter to Replica Set","keywords":"","body":" Add an Arbiter to Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Add an Arbiter to Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/05-convert-standalone-to-replica-set.html":{"url":"11-replication/07-replica-set-deployment/05-convert-standalone-to-replica-set.html","title":"Convert a Standalone to a Replica Set","keywords":"","body":" Convert a Standalone to a Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Convert a Standalone to a Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/06-expand-replica-set.html":{"url":"11-replication/07-replica-set-deployment/06-expand-replica-set.html","title":"Add Members to a Replica Set","keywords":"","body":" Add Members to a Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Add Members to a Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/07-remove-replica-set-member.html":{"url":"11-replication/07-replica-set-deployment/07-remove-replica-set-member.html","title":"Remove Members from Replica Set","keywords":"","body":" Remove Members from Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Remove Members from Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/07-replica-set-deployment/08-replace-replica-set-member.html":{"url":"11-replication/07-replica-set-deployment/08-replace-replica-set-member.html","title":"Replace a Replica Set Member","keywords":"","body":" Replace a Replica Set Member ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replace a Replica Set Member Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration.html":{"url":"11-replication/08-replica-set-member-configuration.html","title":"Member Configuration Tutorials","keywords":"","body":" Member Configuration Tutorials ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Member Configuration Tutorials Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/01-adjust-replica-set-member-priority.html":{"url":"11-replication/08-replica-set-member-configuration/01-adjust-replica-set-member-priority.html","title":"Adjust Priority for Replica Set Member","keywords":"","body":" Adjust Priority for Replica Set Member ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Adjust Priority for Replica Set Member Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/02-configure-secondary-only-replica-set-member.html":{"url":"11-replication/08-replica-set-member-configuration/02-configure-secondary-only-replica-set-member.html","title":"Prevent Secondary from Becoming Primary","keywords":"","body":" Prevent Secondary from Becoming Primary ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Prevent Secondary from Becoming Primary Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/03-configure-a-hidden-replica-set-member.html":{"url":"11-replication/08-replica-set-member-configuration/03-configure-a-hidden-replica-set-member.html","title":"Configure a Hidden Replica Set Member","keywords":"","body":" Configure a Hidden Replica Set Member ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure a Hidden Replica Set Member Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/04-configure-a-delayed-replica-set-member.html":{"url":"11-replication/08-replica-set-member-configuration/04-configure-a-delayed-replica-set-member.html","title":"Configure a Delayed Replica Set Member","keywords":"","body":" Configure a Delayed Replica Set Member ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure a Delayed Replica Set Member Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/05-configure-a-non-voting-replica-set-member.html":{"url":"11-replication/08-replica-set-member-configuration/05-configure-a-non-voting-replica-set-member.html","title":"Configure Non-Voting Replica Set Member","keywords":"","body":" Configure Non-Voting Replica Set Member ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure Non-Voting Replica Set Member Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/08-replica-set-member-configuration/06-convert-secondary-into-arbiter.html":{"url":"11-replication/08-replica-set-member-configuration/06-convert-secondary-into-arbiter.html","title":"Convert a Secondary to an Arbiter","keywords":"","body":" Convert a Secondary to an Arbiter ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Convert a Secondary to an Arbiter Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance.html":{"url":"11-replication/09-replica-set-maintenance.html","title":"Replica Set Maintenance Tutorials","keywords":"","body":" Replica Set Maintenance Tutorials ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Maintenance Tutorials Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/01-change-oplog-size.html":{"url":"11-replication/09-replica-set-maintenance/01-change-oplog-size.html","title":"Change the Size of the Oplog","keywords":"","body":" Change the Size of the Oplog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change the Size of the Oplog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/02-perform-maintence-on-replica-set-members.html":{"url":"11-replication/09-replica-set-maintenance/02-perform-maintence-on-replica-set-members.html","title":"Perform Maintenance on Replica Set Members","keywords":"","body":" Perform Maintenance on Replica Set Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Perform Maintenance on Replica Set Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/03-force-member-to-be-primary.html":{"url":"11-replication/09-replica-set-maintenance/03-force-member-to-be-primary.html","title":"Force a Member to Become Primary","keywords":"","body":" Force a Member to Become Primary ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Force a Member to Become Primary Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/04-resync-replica-set-member.html":{"url":"11-replication/09-replica-set-maintenance/04-resync-replica-set-member.html","title":"Resync a Member of a Replica Set","keywords":"","body":" Resync a Member of a Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Resync a Member of a Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/05-configure-replica-set-tag-sets.html":{"url":"11-replication/09-replica-set-maintenance/05-configure-replica-set-tag-sets.html","title":"Configure Replica Set Tag Sets","keywords":"","body":" Configure Replica Set Tag Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure Replica Set Tag Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/06-reconfigure-replica-set-with-unavailable-members.html":{"url":"11-replication/09-replica-set-maintenance/06-reconfigure-replica-set-with-unavailable-members.html","title":"Reconfigure a Replica Set with Unavailable Members","keywords":"","body":" Reconfigure a Replica Set with Unavailable Members ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Reconfigure a Replica Set with Unavailable Members Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/07-manage-chained-replication.html":{"url":"11-replication/09-replica-set-maintenance/07-manage-chained-replication.html","title":"Manage Chained Replication","keywords":"","body":" Manage Chained Replication ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Chained Replication Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/08-change-hostnames-in-a-replica-set.html":{"url":"11-replication/09-replica-set-maintenance/08-change-hostnames-in-a-replica-set.html","title":"Change Hostnames in a Replica Set","keywords":"","body":" Change Hostnames in a Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change Hostnames in a Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/09-replica-set-maintenance/09-configure-replica-set-secondary-sync-target.html":{"url":"11-replication/09-replica-set-maintenance/09-configure-replica-set-secondary-sync-target.html","title":"Configure a Secondary’s Sync Target","keywords":"","body":" Configure a Secondary’s Sync Target ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Configure a Secondary’s Sync Target Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication.html":{"url":"11-replication/10-replication.html","title":"Replication Reference","keywords":"","body":" Replication Reference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replication Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication/01-replica-configuration.html":{"url":"11-replication/10-replication/01-replica-configuration.html","title":"Replica Set Configuration","keywords":"","body":" Replica Set Configuration ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Configuration Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication/02-replica-set-protocol-versions.html":{"url":"11-replication/10-replication/02-replica-set-protocol-versions.html","title":"Replica Set Protocol Version","keywords":"","body":" Replica Set Protocol Version ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Protocol Version Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication/03-troubleshoot-replica-sets.html":{"url":"11-replication/10-replication/03-troubleshoot-replica-sets.html","title":"Troubleshoot Replica Sets","keywords":"","body":" Troubleshoot Replica Sets ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Troubleshoot Replica Sets Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication/04-local-database.html":{"url":"11-replication/10-replication/04-local-database.html","title":"The local Database","keywords":"","body":" The local Database ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - The local Database Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/10-replication/05-replica-states.html":{"url":"11-replication/10-replication/05-replica-states.html","title":"Replica Set Member States","keywords":"","body":" Replica Set Member States ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replica Set Member States Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"11-replication/Replica-Set-Data-Synchronization.html":{"url":"11-replication/Replica-Set-Data-Synchronization.html","title":"副本集数据同步","keywords":"","body":" 副本集数据同步 在本页 初始化同步 复制 为了维护共享数据集的最新副本，副本集中的从节点成员可以从其他成员同步或复制数据。MongoDB中有两种形式的数据同步：初始化同步将完整的数据集填充至新成员；而复制会持续将变更应用到整个数据集上。 初始化同步 初始化同步会从副本集成员中的一个节点复制所有的数据到另外一个成员。有关初始化同步源选择条件的更多信息请参见初始化同步源选择。 从MongoDB 4.2.7开始，你可以使用参数initialSyncSourceReadPreference 指定优先的初始化同步源。这只能在启动mongod时配置。 过程 当执行一个初始化同步时，MongoDB会： 克隆除local数据库之外的所有数据库。为了进行克隆，mongod 扫描每个源数据库中的各个集合，并将所有数据插入到这些集合各自的副本中。 3.4版本的变化：初始化同步在为每个集合复制文档时会建立集合的所有索引。在MongoDB的早期版本中，在这个阶段只建立_id索引。 3.4版本的变化：初始化同步会获取在数据复制期间新增的oplog记录。请确保目标成员的local 数据库中有足够的磁盘空间，以便可以在数据复制阶段期间内临时存储这些oplog记录。 对数据集应用所有的更改。使用来自源库的oplog，mongod 更新其数据集以反映副本集的当前状态。当初始化同步完成后，目标成员会从 STARTUP2状态转为SECONDARY状态。 若要执行初始化同步，请参见重新同步副本集成员。 容错 为了从短暂网络或操作故障中恢复，初始化同步具有内置的重试逻辑。 版本3.4的变化：MongoDB 3.4改进了初始化同步的重试逻辑，对网络上的间歇性故障更有弹性。 初始化同步源的选择 初始化同步源的选择取决于mongod 的启动参数initialSyncSourceReadPreference （版本4.2.7中的新参数）： 若参数initialSyncSourceReadPreference 设置为 primary （禁用级联后的默认值），则选择主节点作为同步源。如果主服务器不可用或无法访问，则记录错误并定期检查主服务器的可用性。 若参数initialSyncSourceReadPreference 设置为primaryPreferred，则优先尝试选择主节点作为同步源。如果主节点不可用或者无法访问，则将从剩余可用的副本集成员中选择同步源。 若参数initialSyncSourceReadPreference 设置为nearest （启用级联后的默认值），则从副本集成员中选择网络时延最小的节点最为同步源。 对于所有其他受支持的读偏好类型，则将从这些副本集成员中选择同步源。 执行初始化同步源选择的成员将会遍历所有副本集成员的列表两次： 同步源选择（第一次遍历） 当选择初始同步源进行第一次遍历时，执行同步源选择的成员将检查每个副本集成员是否满足如下条件： 同步源必须处于 PRIMARY 或者 SECONDARY 的复制状态。 同步源必须是在线且可访问的。 如果参数 initialSyncSourceReadPreference 设置为 secondary 或者 secondaryPreferred，则同步源必须是一个从节点。 同步源必须和主节点最新的oplog条目同步时间相差在30s之内。 如果该成员是可创建索引的，则同步源也必须可创建索引。 如果该成员可参与副本集选举投票，则同步源也必须具有投票权。 如果该成员不是一个延迟成员，则同步源也不能是延迟成员。 如果该成员是一个延迟成员，则同步源必须配置一个更短的延迟时间。 同步源必须比当前最好的同步源更快(即更低的时延)。 如果第一次遍历没有产生候选的同步源，则该成员会用更宽松的条件进行第二次遍历。请参考同步源选择（第二次遍历）。 同步源选择（第二次遍历） 当选择初始同步源进行第二次遍历时，执行同步源选择的成员将检查每个副本集成员是否满足如下条件： 同步源必须处于 PRIMARY 或者 SECONDARY 的复制状态。 同步源必须是在线且可访问的。 如果参数 initialSyncSourceReadPreference 设置为 secondary ，则同步源必须是一个从节点。 如果该成员是可创建索引的，则同步源也必须可创建索引。 同步源必须比当前最好的同步源更快(即更低的时延)。 如果该成员在两次遍历后依然无法选择出初始同步源，它会记录报错并在等待1s后重新发起选择的过程。从节点的Mongod进程在出现报错退出之前，最多会重试10次初始同步源选择的过程。 复制 从节点成员在初始化同步之后会不断地复制数据。从节点成员从同步源复制oplog ，并以异步的方式应用这些操作 [1]。 从节点可以根据ping时间和其他成员复制状态的变化，按需来自动调整它们的同步源。 3.2版本的变化：MongoDB 3.2中投票权为1的副本集成员无法从投票权为0的成员那里同步数据。 从节点应避免从延迟成员和隐藏成员中同步数据。 如果一个从节点成员的参数members[n].buildIndexes 设置为true，它只能从其他参数buildIndexes设置为true的成员同步数据。参数buildIndexes设置为false的成员可以从任何其他节点同步数据，除非有其他的同步限制。参数buildIndexes默认为true。 [1] | 从4.2版本开始（从4.0.6开始也是可行的），副本集的副本成员会记录oplog中应用时间超过慢操作阈值的慢操作条目。这些慢oplog信息被记录在从节点的诊断日志中，其路径位于REPL 组件的文本applied op: took ms中。这些慢日志条目仅仅依赖于慢操作阈值。它们不依赖于日志级别（无论是系统还是组件级别）、过滤级别，或者慢操作采样比例。过滤器不会捕获慢日志条目。 多线程复制 MongoDB通过使用多线程批量应用写操作来提高并发。MongoDB根据文档id （WiredTiger）进行分批，同时使用不同的线程应用每组操作。MongoDB总是按照原始的写顺序对给定的文档应用写操作。 4.0版本的变化。 从MongoDB 4.0开始，如果读取发生在正在应用批量复制的从节点上，那么针对从节点且读关注级别设置为“local”或“majority”的读取操作，现在将从WiredTiger数据快照中读取数据。从快照中读取数据可以保证数据的一致性视图，并且允许在进行复制的同时进行读取，而不需要使用锁。因此，这些读关注级别的从节点读取操作不再需要等待批量复制应用完成，并且可以在接收它们的同时进行处理。 流控制 从MongoDB 4.2开始，管理员可以限制主节点应用其写操作的速度，目的是将大多数提交延迟保持在可配置参数flowControlTargetLagSeconds最大值之下。 默认情况下，流控制是启用的。 说明 为了进行流控制，副本集/分片集群必须满足：参数featureCompatibilityVersion (FCV) 设置为4.2，并启用majority级别的读关注。也就是说，如果FCV不是4.2，或者读关注majority被禁用，那么流控制的启用将不会生效。 更多信息请参见流控制。 复制同步源的选择 复制同步源的选择取决于副本集参数chaining 的设置： 启用级联(默认)后，从副本集成员间执行同步源选择。 禁用级联后，选择主节点作为复制源。如果主服务器不可用或无法访问，则记录错误并定期检查主服务器的可用性。 Members performing replication sync source selection make two passes through the list of all replica set members: 执行复制同步源选择的成员将会遍历所有副本集成员的列表两次： 同步源选择（第一次） 当为选择复制同步源进行第一次遍历时，执行同步源选择的成员将检查每个副本集成员是否满足如下条件： 同步源必须处于 PRIMARY 或者 SECONDARY 的复制状态。 同步源必须是在线且可访问的。 同步源必须比该成员具有更新的oplog条目（即同步源数据同步领先于该成员）。 同步源必须是可见的。 同步源必须和主节点最新的oplog条目同步时间相差在30s之内。 如果该成员是可创建索引的，则同步源也必须可创建索引。 如果该成员可参与副本集选举投票，则同步源也必须具有投票权。 如果该成员不是一个延迟成员，则同步源也不能是延迟成员。 如果该成员是一个延迟成员，则同步源必须配置一个更短的延迟时间。 同步源必须比当前最好的同步源更快(即更低的时延)。 如果第一次遍历没有产生候选的同步源，则该成员会用更宽松的条件进行第二次遍历。请参考同步源选择（第二次遍历）。 同步源选择（第二次遍历） 当为选择复制同步源进行第二次遍历时，执行同步源选择的成员将检查每个副本集成员是否满足如下条件： 同步源必须处于 PRIMARY 或者 SECONDARY 的复制状态。 同步源必须是在线且可访问的。 如果该成员是可创建索引的，则同步源也必须可创建索引。 同步源必须比当前最好的同步源更快(即更低的时延)。 如果该成员在两次遍历后依然无法选择出初始同步源，它会记录报错并在等待1s后重新发起选择的过程。 说明 从MongoDB 4.2.7开始，当选择一个初始化同步源时，启动参数 initialSyncSourceReadPreference 是优先级高于副本集参数 settings.chainingAllowed。在副本集成员成功执行初始化同步之后，选择复制同步源时则取决于参数 chainingAllowed的值。 有关初始化同步源的选择的更多信息请参考初始化同步源的选择 。 原文链接：https://docs.mongodb.com/manual/core/replica-set-sync/ 译者：李正洋 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding.html":{"url":"12-sharding.html","title":"分片","keywords":"","body":"分片 分片是一种把数据分散到许多台计算机中的方法，MongoDB 使用分片技术来部署非常大的数据集，同时支持高吞吐量的数据操作。 大数据库系统与高吞吐量系统对于单机服务器提出了严峻的挑战。比如说高频查询会榨干一台服务器上的CPU时间，而大于单机内存容量的数据集将会占满磁盘的读写吞吐量。 一般寻址系统有两种扩展方式，一种是垂直扩展，一种是水平扩展。 垂直扩展指的是增加单台计算机的性能，例如使用更强劲的CPU、插入更多内存条、或者增加本地存储空间。可用技术中的限制可能会限制单台机器运行给定负载的能力。此外，基于云的提供商根据可用的硬件配置有严格的上限。 因此，垂直扩展有一个实际的最大值。 水平扩展指的是切分系统的数据集，把它们分散到多台服务器组成的集群上，根据日益增长的容量需求来增加服务器的数量，虽然集群每台机器的性能可能不会太高，但他们只需要负责处理总负载的一小部分，将其组织起来后便能提供强劲的数据存取能力，并以此胜过单台高性能高容量的服务器。扩展这种集群的存储性能仅仅需要增加更多的服务器。这样的成本远比把单台服务器升级成一台超级计算机。不过代价就是基础设施和部署维护方面的复杂性增加。 MongoDB 通过分片技术来支持水平扩展。 分片集群 一个分片集群，由以下组件组成： shard: 分片，每个分片都包含一个切分的数据子集，并且可以作为复制集部署。 mongos: 路由，每个路由作为数据分片和应用程序之间的数据接口，对应用程序来说它可被视为一个单机 MongoDB 服务器。从MongoDB 4.4开始，mongos可以支持对冲读取，以最小化延迟。 config server: 配置服务器，配置服务器存储集群的元数据和配置设置。 下图描述了分片集群内各组件的交互。 这是一个用于生产目的分片集群示例图。包含正好3个配置服务器（由复制集组成），1个或多个mongos查询路由，以及至少2个shard。这些shard内部是由复制集组成。 MongoDB在集合层对数据进行分片，将集合数据分布在集群中的各个shard上。 片键（Shard Key) MongoDB使用片键将集合的文档分布在不同的分片上。片键由文档中的一个字段或多个字段组成。 从 4.4 版本开始，分片集合中的文档可以缺少片键字段。缺少片键字段的文档在跨分片分发时将被视为具有空值，但在路由查询时则不会。有关更多信息，请参阅缺失的片键。 在 4.2 及更早的版本中，片键字段必须存在于分片集合的每个文档中。 在对集合进行分片时，你需要选择一个片键（比如 _id ）。 从MongoDB 4.2开始，您可以更新文档的片键值，除非您的片键字段是不可更改的 _id 字段。更多信息请参见更改文档的片键值。 在MongoDB 4.0和更早的版本中，文档的片键字段值是不可改变的。 片键索引 要对一个非空集合分片，该集合必须有一个以片键开始的索引。当对一个空的集合分片时，如果该集合还没有对应指定片键的索引，MongoDB 会自动创建对应的索引。请参阅片键索引。 选择片键 片键的选择会影响分片集群的性能、效率和可扩展性。一个拥有最佳硬件和基础架构的集群可能会因为片键的选择而陷入瓶颈。片键及其支持索引的选择也会影响您的集群可以使用的分片策略。 分块 MongoDB 将分片内的数据分区为chunks。每个分块都有一个基于片键的包含性下限和排他性上限范围（即左闭右开）。 平衡器和均匀分块分布 为了在集群中的所有分片上实现均匀分布的分块，一个平衡器在后台运行，以在分片上迁移分块。 分片的优势 读写速度 MongoDB将读写工作负载分布在分片集群中的各个分片上，允许每个分片处理集群操作的一个子集。读和写工作负载都可以通过添加更多的分片在集群中水平扩展。 对于包含片键或复合片键前缀的查询，mongos可以将查询锁定在特定的分片或分片集合上。这些有针对性的操作通常比向集群中的每个分片广播更有效率。 从 MongoDB 4.4 开始，mongos可以支持对冲读取，以最小化延迟。 存储容量 Sharding将数据分布在集群中的各个分片上，允许每个分片包含集群总数据的一个子集。随着数据集的增长，额外的分片会增加集群的存储容量。 高可用性 将配置服务器和分片部署为副本集，可以提高可用性。 即使一个或多个分片副本集变得完全不可用，分片集群仍可继续执行部分读写。也就是说，虽然无法访问不可用的分片上的数据，但针对可用分片的读或写仍然可以成功。 分片前的考虑因素 分片集群基础架构的要求和复杂性需要仔细规划、执行和维护。 一旦一个集合被分片，MongoDB 不提供任何方法来解除分片的集合。 为了确保集群的性能和效率，在选择片键时必须仔细考虑。请参阅选择片键。 分片有一定的操作要求和限制。请参阅分片集群中的操作限制了解更多信息。 如果查询不包括片键或复合片键的前缀，mongos会执行广播操作，查询分片集群中的所有shard。这些散布/收集查询可能是长期运行的操作。 注意： 如果您与MongoDB签订了有效的支持合同，请考虑联系您的客户代表，以获得分片集群规划和部署方面的帮助。 分片式和非分片式集合 一个数据库可以有混合的分片和未分片集合。分片集合被分割并分布在集群中的各个分片上。未分片的集合存储在一个主片上。每个数据库都有自己的主片。 主片的示意图。主片服务器上包含未分片的集合以及来自分片集合的文档块。图中 Shard A 是主片。 连接到分片 Cluster 您必须连接到 mongos 路由才能与分片集群中的任何集合进行交互。这包括分片和未分片的集合。客户端永远不应该连接到一个单一的分片服务器来执行读或写操作。 应用程序/驱动程序向 mongos 发出对未分片集合以及分片集合的查询的示意图。图中未显示配置服务器。 你可以像连接mongod一样连接到mongos，比如通过mongo shell或MongoDB驱动。 分片策略 MongoDB支持两种分片策略，用于在分片集群之间分发数据。 哈希分片 哈希分片涉及计算片键字段的哈希值。然后，根据散列的片键值为每个分块分配一个范围。 小贴士 MongoDB 在使用哈希索引解析查询时自动计算哈希值。应用程序不需要计算哈希值。 基于哈希的分割图 虽然一系列文档的片键值可能是 \"接近\" 的，但它们的哈希值不可能在同一个chunk上。基于哈希值的数据分布有利于数据分布更加均匀，尤其是在片键单调变化的数据集中。 然而，散列分布意味着基于范围的对片键的查询不太可能针对单个shard，从而导致更多的集群范围的广播操作。 更多信息请参见左边目录哈希分片。 范围分片 范围分片涉及根据片键值将数据划分为范围。然后根据片键值为每个分块分配一个范围。 片键值空间划分为更小的范围或块的示意图。 在范围分片中，取值\"相近\" 的一系列片键更有可能驻留在同一个chunk上。这样就可以进行有针对性的操作，因为 mongos 可以只将操作路由到包含所需数据的分片上。 范围分片的效率取决于选择的片键。考虑不周的片键会导致数据分布不均，这会失去分片的一些好处，或者会造成性能瓶颈。请参阅[基于范围分片的片键选择]。 更多信息请参见左边目录 \"范围分片\"。 分片集群中的区域 对于跨越多个数据中心的分片集群，区域可以帮助提高数据的定位性。 在分片集群中，您可以根据片键创建划分分片数据的区域。您可以将每个区域与集群中的一个或多个分片相关联。一个分片可以关联任意数量的区域。在平衡集群中，MongoDB仅将一个区域所覆盖的块迁移到与该区域相关联的分片上。 每个区域覆盖一个或多个片键值的范围。一个区域所覆盖的每个范围总是包含它的下边界，而不包含它的上边界。 基于分片集群中区域的数据分布图 为要覆盖的区段定义新范围时，必须使用片键中包含的字段。如果使用复合片键，则范围必须包括片键的前缀。更多信息请参见区块中的片键。 在选择片键时，应考虑到将来可能使用的区域。 小贴士 从MongoDB 4.0.3开始，设置区域和区域范围可以更快地铲除一个空的或不存在的集合。 更多信息请参见分片集群中的区域。 分片中的集合 使用 shardCollection 命令和 collation: { locale: \"simple\"} 选项，可以对一个有默认collation的集合进行分片。成功的分片需要以下条件。 这个集合必须有一个前缀是片键的索引。 索引必须有集合 { locale: \"simple\" } 在创建具有整理功能的新集合时，请确保在保护集合之前满足这些条件。 注意事项 对分片集合的查询继续使用为集合配置的默认整理方式。要使用片键索引的简单整理，请在查询的整理文档中指定{locale: \"simple\"}。 请参阅shardCollection了解更多关于sharding和co的信息。 关于分片和整理的更多信息，请参见shardCollection。 变化流 从MongoDB 3.6开始，变化流可用于复制集和分片集群。变化流允许应用程序访问实时数据变化，而无需引入尾随oplog的复杂性和风险。应用程序可以使用变化流来订阅一个或多个集合上的所有数据变更。 事务 从MongoDB 4.2开始，随着分布式事务的引入，多文档事务在分片集群上可以使用。 在一个事务提交之前，事务中所做的数据变化在事务外部是不可见的。 但是，当一个事务向多个分片写入时，并不是所有的外部读操作都需要等待提交的事务的结果在各分片中可见。例如，如果一个事务已提交，并且写1在A分片上可见，但写2在B分片上还不可见，那么在读关注 \"本地 \"的外部读可以在不看到写2的情况下读取写1的结果。 参见 事务 生产方面的考虑 生产方面的考虑因素（分片集群）。 参见 原文 - Sharding 译者：雪星 (snomiao@gmail.com) 于 2020 秋 校对：征集中！ ！本页校对征集中！ 请点击页面上方 EDIT THIS PAGE 参与校对。 详见： 贡献指南、 原文链接。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/01-sharded-cluster-components.html":{"url":"12-sharding/01-sharded-cluster-components.html","title":"分片集群组成]","keywords":"","body":" Sharded Cluster Components ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sharded Cluster Components Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/01-sharded-cluster-components/01-sharded-cluster-shards.html":{"url":"12-sharding/01-sharded-cluster-components/01-sharded-cluster-shards.html","title":"分片","keywords":"","body":" Shards ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Shards Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/01-sharded-cluster-components/02-sharded-cluster-config-servers.html":{"url":"12-sharding/01-sharded-cluster-components/02-sharded-cluster-config-servers.html","title":"配置服务器 (metadata)","keywords":"","body":" Config Servers (metadata) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Config Servers (metadata) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/01-sharded-cluster-components/03-sharded-cluster-query-router.html":{"url":"12-sharding/01-sharded-cluster-components/03-sharded-cluster-query-router.html","title":"路由 (mongos)","keywords":"","body":" Router (mongos) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Router (mongos) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/02-sharding-shard-key.html":{"url":"12-sharding/02-sharding-shard-key.html","title":"片键","keywords":"","body":" Shard Keys ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Shard Keys Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/03-hashed-sharding.html":{"url":"12-sharding/03-hashed-sharding.html","title":"哈希分片","keywords":"","body":" 哈希分片 哈希分片使用哈希索引来在分片集群中对数据进行划分。哈希索引计算某一个字段的哈希值作为索引值，这个值被用作片键。 哈希分片以减少定向操作和增加广播操作作为代价，分片集群内的数据分布更加均衡。在哈希之后，拥有比较“接近”的片键的文档将不太可能会分布在相同的数据库或者分片上。mongos更有可能执行广播操作来完成一个给定的范围查询。相对的，mongos可以将等值匹配的查询直接定位到单个分片上。 注意： 当使用哈希索引来解析查询时，MongoDB会自动计算哈希值。应用程序不需要计算哈希。 警告 MongoDB哈希索引在哈希计算之前会将浮点数截断为64位整数。 例如，哈希索引会将为具有2.3、2.2和2.9的值的字段存储为相同的值。 为了避免冲突，请勿对不能可靠地转换为64位整数（然后再返回到浮点）的浮点数使用哈希索引。 MongoDB哈希索引不支持大于2^53的浮点值。 如果想查看一个键的哈希值是什么，请参考 convertShardKeyToHashed()。 [1] 从4.0版开始，mongo shell提供了convertShardKeyToHashed（）方法。 此方法使用与哈希索引相同的哈希函数，可用于查看键的哈希值。 哈希分片的片键 您选择作为哈希片键的字段应具有良好的基数或者该字段包含大量不同的值。 哈希分片非常适合选取具有像ObjectId值或时间戳那样单调更改的字段作为片键。 一个很好的例子是默认的_id字段，假设它仅包含ObjectID值（而非用户自定义的_id）。 要使用哈希片键对集合进行分片，请参阅 对集合进行分片。 哈希分片 VS 范围分片 给定一个使用单调递增的值X作为片键的集合，使用范围分片会导致插入数据的分布类似于下面这样： 由于X的值始终在增加，因此具有maxKey(上限)的数据块将接收大多数传入的写操作。 这将插入操作限制在只能定向到包含此块的单个分片，从而减少或消除了分片集群中分布式写入的优势。 通过在X上使用哈希索引，插入的分布将类似于下面这样： 由于现在数据分布更加均匀，因此可以在整个集群中更高效地分布式插入数据。 对一个集合进行分片 使用 sh.shardCollection() 方法，指定集合的完整命名空间以及作为片键的目标哈希索引。 sh.shardCollection( \"database.collection\", { : \"hashed\" } ) 重要 一旦对某个集合进行分片后，片键的选择是不可变的。 也就是说，您不能再为该集合选择其他的片键。 从MongoDB 4.2开始，除非片键字段是不可变的_id字段，否则您可以更新文档的片键值。 有关更新片键的详细信息，请参阅更改文档的片键值。在MongoDB 4.2以前的版本，片键是不可变的。 对一个已有数据的集合进行分片 如果您使用哈希片键对一个已经包含数据的集合进行分片操作： 分片操作将创建初始数据块，以覆盖片键值的整个范围。 创建的数据块数取决于配置的数据块大小。 在初始数据块创建之后，均衡器会在分片上适当地迁移这些初始数据块，并管理后续的数据块分配。 对一个空集合进行分片 如果您使用哈希片键对一个空集合进行分片操作： 如果没有为空集合或不存在的集合指定区域和区域范围： 分片操作将创建空数据块，以覆盖片键值的整个范围，并执行初始数据块分配。默认情况下，该操作为每个分片创建2个数据块，并在整个集群中迁移。您可以使用numInitialChunks选项指定不同数量的初始块。数据块的这种初始创建和分配可以使分片设置更加快速。 初始分配之后，均衡器将管理后续的数据块分配。 如果已经为空集合或不存在的集合指定区域和区域范围（从MongoDB4.0.3版本起可用）： 分片操作会为定义的区域范围以及所有其他分片创建空数据块，以覆盖片键值的整个范围，并根据区域范围执行初始数据块分配。数据块的这种初始创建和分配可以使分片设置更加快速。 初始分配之后，均衡器将管理后续的数据块分配。 另请参考： 要了解如何部署分片集群和实现哈希分片，请参阅部署分片集群。 原文链接：https://docs.mongodb.com/v4.2/core/hashed-sharding/ 译者：刘翔 校对：牟天垒 参见 原文 - Hashed Sharding Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/04-ranged-sharding.html":{"url":"12-sharding/04-ranged-sharding.html","title":"范围分片","keywords":"","body":" 范围分片 基于范围的分片会将数据划分为由片键值确定的连续范围。 在此模型中，具有“接近”片键值的文档可能位于相同的块或分片中。 这允许在连续范围内读取目标文档的高效查询。 但是，如果片键选择不佳，则读取和写入性能均可能降低。 请参阅片键的选择。 如果未配置任何其他选项（例如哈希分片或区域所需的其他选项），则基于范围的分片是默认的分片方式。 片键的选择 当片键呈现出以下特征时，范围分片更高效： 基数 大 频率 低 非单调变更 下图说明了使用字段X作为片键的分片群集。 如果X的值具有大取值范围，低频率以及非单调变化的特征，则插入的分布可能类似于下面这样： 对一个集合进行分片 使用sh.shardCollection()方法，指定集合的完整命名空间以及作为片键的目标索引或复合索引。 sh.shardCollection( \"database.collection\", { } ) 重要 一旦对某个集合进行分片后，片键的选择是不可变的。 也就是说，您不能再为该集合选择其他片键。 从MongoDB 4.2开始，除非片键字段是不可变的_id字段，否则您可以更新文档的片键值。 有关更新片键的详细信息，请参阅更改文档的片键值。在MongoDB 4.2以前的版本，片键是不可变的. 对一个已有数据的集合进行分片 如果您对一个已经包含数据的集合进行分片操作： 分片操作将创建初始数据块，以覆盖片键值的整个范围。 创建的数据块数取决于配置的数据块大小。 在初始数据块创建之后，均衡器会在分片上适当地迁移这些初始数据块，并管理后续的数据块分配。 对一个空集合进行分片 如果您对一个空集合进行分片操作： 如果没有为空集合或不存在的集合指定区域和区域范围： 分片操作将创建一个空块，以覆盖片键值的整个范围。 在创建初始块之后，平衡器将在块之间适当地迁移初始块，并管理后续的块分配。 如果已经为空集合或不存在的集合指定区域和区域范围（从MongoDB4.0.3版本起可用）： 分片操作会为定义的区域范围以及覆盖该片键值的整个范围的任何其他块创建空数据块，并根据区域范围执行初始数据块分配。数据块的这种初始创建和分配可以使分片设置更加快速。 在初始分配之后，均衡器将管理后续的数据块分配。 另请参阅 要了解如何部署分片集群和实现范围分片，请参阅部署分片集群。 原文链接：https://docs.mongodb.com/v4.2/core/ranged-sharding/ 译者：刘翔 校对：牟天垒 参见 原文 - Ranged Sharding Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/05-deploy-shard-cluster.html":{"url":"12-sharding/05-deploy-shard-cluster.html","title":"部署分片集群","keywords":"","body":" Deploy a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Deploy a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding.html":{"url":"12-sharding/06-zone-sharding.html","title":"区域","keywords":"","body":" Zones ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Zones Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/01-manage-shard-zone.html":{"url":"12-sharding/06-zone-sharding/01-manage-shard-zone.html","title":"Manage Shard Zones","keywords":"","body":" Manage Shard Zones ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Shard Zones Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/02-sharding-segmenting-data-by-location.html":{"url":"12-sharding/06-zone-sharding/02-sharding-segmenting-data-by-location.html","title":"Segmenting Data by Location","keywords":"","body":" Segmenting Data by Location ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Segmenting Data by Location Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/03-sharding-tiered-hardware-for-varying-slas.html":{"url":"12-sharding/06-zone-sharding/03-sharding-tiered-hardware-for-varying-slas.html","title":"Tiered Hardware for Varying SLA or SLO","keywords":"","body":" Tiered Hardware for Varying SLA or SLO ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Tiered Hardware for Varying SLA or SLO Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/04-sharding-segmenting-shards.html":{"url":"12-sharding/06-zone-sharding/04-sharding-segmenting-shards.html","title":"Segmenting Data by Application or Customer","keywords":"","body":" Segmenting Data by Application or Customer ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Segmenting Data by Application or Customer Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/05-sharding-high-availability-writes.html":{"url":"12-sharding/06-zone-sharding/05-sharding-high-availability-writes.html","title":"Distributed Local Writes for Insert Only Workloads","keywords":"","body":" Distributed Local Writes for Insert Only Workloads ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Distributed Local Writes for Insert Only Workloads Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/06-zone-sharding/Data-Partitioning-with-Chunks/Split-Chunks-in-a-Sharded-Cluster.html":{"url":"12-sharding/06-zone-sharding/Data-Partitioning-with-Chunks/Split-Chunks-in-a-Sharded-Cluster.html","title":"在分片集群中拆分数据块","keywords":"","body":" 在分片集群中拆分数据块 通常，如果某个数据块超过最大块大小，则MongoDB会在插入后对数据块进行拆分。但是，在以下情况下，您可能需要手动拆分数据块： 您的集群中有大量数据，并且只有很少的数据块，就像使用现有数据部署集群后的情况一样 您希望添加大量最初驻留在单个数据块或分片中的数据。例如，您计划插入大量数据，这些数据的分片键值在300到400之间，但是所有分片键的值在250到500之间都在一个块中(且落在一个分片上)。 注意 MongoDB提供了 mergeChunks 命令以将连续的块范围合并为一个块。有关更多信息，请参考在分片群集中合并数据块。 如果移动有利于接下来的插入，则平衡器可以立即将最近拆分的数据块迁移到新的分片上。平衡器不会区分是手动拆分的数据块还是系统自动拆分的数据块。 警告 在分片集合中拆分数据以创建新数据块时，请务必小心。当你对一个已有数据的集合进行分片操作时，MongoDB会自动创建数据块以均匀分布该集合。为了有效地在分片群集中拆分数据，必须考虑单个数据块中的文档数和平均文档大小才能创建统一的数据块大小。当数据块的大小不规则时，分片间可能具有相同数量的数据块，但它们的数据大小却大不相同。应避免由于创建时的拆分而导致的分片集合具有大小不同的数据块现象。 使用sh.status()来确定当前集群中的数据块范围 想要手动进行数据块的拆分，使用带middle或者find字段的split命令。mongos shell提供了sh.splitFind()和sh.splitAt()帮助方法。 splitFind()将包含与该查询匹配的返回的第一个文档的数据块拆分为两个大小相等的数据块。 您必须将分片集合的完整命名空间（即“.”）指定给splitFind()。 splitFind()中的查询可以不使用分片键，尽管这样做几乎总是有意义的（指可以利用到分片键索引）。 示例 下面的命令对records数据库的people集合为包含zipcode字段值为63109的数据块进行拆分： sh.splitFind( \"records.people\", { \"zipcode\": \"63109\" } ) 使用splitAt（）将大块一分为二，将查询的文档用作新的块的下限： 示例 下面的命令对records数据库的people集合为包含zipcode字段值为63109的数据块进行拆分： sh.splitAt( \"records.people\", { \"zipcode\": \"63109\" } ) 注意 splitAt()不一定会将数据块平均为两个大小相等的块。拆分发生在于查询匹配的文档的位置，而不会考虑该文档在整个数据块中的位置。 另请参考空集合 原文链接：https://docs.mongodb.com/manual/tutorial/split-chunks-in-sharded-cluster/index.html 译者：刘翔 校对：徐雷 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/07-sharding-data-partitioning.html":{"url":"12-sharding/07-sharding-data-partitioning.html","title":"Data Partitioning with Chunks","keywords":"","body":" Data Partitioning with Chunks ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Partitioning with Chunks Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/07-sharding-data-partitioning/01-create-chunks-in-sharded-cluster.html":{"url":"12-sharding/07-sharding-data-partitioning/01-create-chunks-in-sharded-cluster.html","title":"Create Chunks in a Sharded Cluster","keywords":"","body":" Create Chunks in a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Create Chunks in a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/07-sharding-data-partitioning/02-split-chunks-in-sharded-cluster.html":{"url":"12-sharding/07-sharding-data-partitioning/02-split-chunks-in-sharded-cluster.html","title":"Split Chunks in a Sharded Cluster","keywords":"","body":" Split Chunks in a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Split Chunks in a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/07-sharding-data-partitioning/03-merge-chunks-in-sharded-cluster.html":{"url":"12-sharding/07-sharding-data-partitioning/03-merge-chunks-in-sharded-cluster.html","title":"Merge Chunks in a Sharded Cluster","keywords":"","body":" Merge Chunks in a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Merge Chunks in a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/07-sharding-data-partitioning/04-modify-chunk-size-in-sharded-cluster.html":{"url":"12-sharding/07-sharding-data-partitioning/04-modify-chunk-size-in-sharded-cluster.html","title":"Modify Chunk Size in a Sharded Cluster","keywords":"","body":" Modify Chunk Size in a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Modify Chunk Size in a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/08-sharding-balancer-administration.html":{"url":"12-sharding/08-sharding-balancer-administration.html","title":"Balancer","keywords":"","body":" Balancer ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Balancer Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/08-sharding-balancer-administration/01-manage-sharded-cluster-balancer.html":{"url":"12-sharding/08-sharding-balancer-administration/01-manage-sharded-cluster-balancer.html","title":"Manage Sharded Cluster Balancer","keywords":"","body":" Manage Sharded Cluster Balancer ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Sharded Cluster Balancer Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/08-sharding-balancer-administration/02-migrate-chunks-in-sharded-cluster.html":{"url":"12-sharding/08-sharding-balancer-administration/02-migrate-chunks-in-sharded-cluster.html","title":"Migrate Chunks in a Sharded Cluster","keywords":"","body":" Migrate Chunks in a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Migrate Chunks in a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration.html":{"url":"12-sharding/09-sharded-cluster-administration.html","title":"Administration","keywords":"","body":" Administration ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Administration Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/01-sharded-cluster-config-servers.html":{"url":"12-sharding/09-sharded-cluster-administration/01-sharded-cluster-config-servers.html","title":"Config Server Administration","keywords":"","body":" Config Server Administration ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Config Server Administration Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/01-sharded-cluster-config-servers/01-replace-config-server.html":{"url":"12-sharding/09-sharded-cluster-administration/01-sharded-cluster-config-servers/01-replace-config-server.html","title":"Replace a Config Server","keywords":"","body":" Replace a Config Server ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replace a Config Server Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/02-view-sharded-cluster-configuration.html":{"url":"12-sharding/09-sharded-cluster-administration/02-view-sharded-cluster-configuration.html","title":"View Cluster Configuration","keywords":"","body":" View Cluster Configuration ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - View Cluster Configuration Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/03-restart-sharded-cluster.html":{"url":"12-sharding/09-sharded-cluster-administration/03-restart-sharded-cluster.html","title":"Restart a Sharded Cluster","keywords":"","body":" Restart a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Restart a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/04-migrate-sharded-cluster-to-new-hardware.html":{"url":"12-sharding/09-sharded-cluster-administration/04-migrate-sharded-cluster-to-new-hardware.html","title":"Migrate a Sharded Cluster to Different Hardware","keywords":"","body":" Migrate a Sharded Cluster to Different Hardware ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Migrate a Sharded Cluster to Different Hardware Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/05-add-shards-to-shard-cluster.html":{"url":"12-sharding/09-sharded-cluster-administration/05-add-shards-to-shard-cluster.html","title":"Add Shards to a Cluster","keywords":"","body":" Add Shards to a Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Add Shards to a Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/06-remove-shards-from-cluster.html":{"url":"12-sharding/09-sharded-cluster-administration/06-remove-shards-from-cluster.html","title":"Remove Shards from an Existing Sharded Cluster","keywords":"","body":" Remove Shards from an Existing Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Remove Shards from an Existing Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/07-clear-jumbo-flag.html":{"url":"12-sharding/09-sharded-cluster-administration/07-clear-jumbo-flag.html","title":"Clear jumbo Flag","keywords":"","body":" Clear jumbo Flag ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Clear jumbo Flag Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/08-backup-sharded-cluster-metadata.html":{"url":"12-sharding/09-sharded-cluster-administration/08-backup-sharded-cluster-metadata.html","title":"Back Up Cluster Metadata","keywords":"","body":" Back Up Cluster Metadata ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Back Up Cluster Metadata Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/09-convert-sharded-cluster-to-replica-set.html":{"url":"12-sharding/09-sharded-cluster-administration/09-convert-sharded-cluster-to-replica-set.html","title":"Convert Sharded Cluster to Replica Set","keywords":"","body":" Convert Sharded Cluster to Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Convert Sharded Cluster to Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/10-convert-replica-set-to-replicated-shard-cluster.html":{"url":"12-sharding/09-sharded-cluster-administration/10-convert-replica-set-to-replicated-shard-cluster.html","title":"Convert a Replica Set to a Sharded Cluster","keywords":"","body":" Convert a Replica Set to a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Convert a Replica Set to a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/09-sharded-cluster-administration/11-convert-shard-standalone-to-shard-replica-set.html":{"url":"12-sharding/09-sharded-cluster-administration/11-convert-shard-standalone-to-shard-replica-set.html","title":"Convert a Shard Standalone to a Shard Replica Set","keywords":"","body":" Convert a Shard Standalone to a Shard Replica Set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Convert a Shard Standalone to a Shard Replica Set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/10-sharding.html":{"url":"12-sharding/10-sharding.html","title":"Sharding Reference","keywords":"","body":" Sharding Reference ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sharding Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/10-sharding/01-sharded-cluster-requirements.html":{"url":"12-sharding/10-sharding/01-sharded-cluster-requirements.html","title":"Operational Restrictions","keywords":"","body":" Operational Restrictions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Operational Restrictions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/10-sharding/02-troubleshoot-sharded-clusters.html":{"url":"12-sharding/10-sharding/02-troubleshoot-sharded-clusters.html","title":"Troubleshoot Sharded Clusters","keywords":"","body":" Troubleshoot Sharded Clusters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Troubleshoot Sharded Clusters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/10-sharding/03-config-database.html":{"url":"12-sharding/10-sharding/03-config-database.html","title":"Config Database","keywords":"","body":" Config Database ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Config Database Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/Shard-keys.html":{"url":"12-sharding/Shard-keys.html","title":"分片键","keywords":"","body":" 分片键 本页面中 分片键格式 改变一个文档的分片键值 分片键索引 选择一个分片键 分片键决定了集合内的文档如何在集群的多个分片间的分布状况。分片键要么是一个索引字段，要么是一个存在于集合内所有文档中的复合索引字段。 MongoDB使用分片键值范围对集合中的数据进行分区。每个范围都定义了一个分片键值的非重叠范围，并且与一个chunk(数据块，下同)相关联。 MongoDB尝试在集群中的各个分片之间平均分配数据块。 分片键与数据块分配的有效性直接相关。 请参阅选择分片键。 重要 一旦你对一个集合分片，那么其分片键就不可再改变；也就是说，你不可以对这个集合再重新选择另一个不一样的分片键。 从MongoDB4.2版本开始，除非分片键是不可变的_id字段，否则你可以更新文档的分片键值。有关更新分片键的详细信息，请参考【修改文档的分片键值】。 在MongoDB4.2之前的版本，文档的分片键字段值是不可变的。 分片键格式 为了将一个集合分片，你必须在sh.shardCollection（）方法中指定目标集合和分片键： sh.shardCollection( namespace, key ) namespace参数由字符串.组成，该字符串指定目标集合的完整命名空间。 key参数由包含一个字段和该字段的索引遍历方向的文档组成。 有关使用散列或范围分片策略对集合进行分片的说明，请参阅【对集合进行分片】。 改变一个文档的分片键值 更新分片键时 必须在事务中或以可重试写入方式在mongos上运行。 不要直接在分片上执行操作。 您必须在查询过滤器的完整分片键上包含相等条件。 例如，如果一个分片集合内使用{country：1，userid：1}作为分片键，要想更新文档的分片键，则必须在查询过滤器中包含country：，userid：。 也可以根据需要在查询中包括其他字段。 从MongoDB 4.2版本开始，除非分片键字段是不可变的_id字段，否则您可以更新文档的分片键值。 若要更新，请使用以下操作来更新文档的分片键值： 命令 方法 update with multi: false db.collection.replaceOne()db.collection.updateOne()db.collection.update() with multi: false findAndModify db.collection.findOneAndReplace()db.collection.findOneAndUpdate()db.collection.findAndModify() db.collection.bulkWrite()Bulk.find.updateOne()如果分片键修改导致将文档移动到另一个分片，则在批量操作中不能指定多个分片键修改；即批量大小为1。如果分片键修改不会导致将文档移动到另一个分片，则可以在批量操作中指定多个分片键修改。 分片键索引 所有分片集合都必须具有支持分片键的索引。 即索引可以是分片键的索引;也可以是复合索引，其中分片键是索引的前缀。 如果集合为空，则sh.shardCollection()在分片键上创建索引（如果该索引尚不存在）。 如果集合不为空，则必须先创建索引，然后再使用sh.shardCollection()。 如果你删除了分片键的最后一个有效索引，请通过仅在分片键上重新创建索引来恢复。 唯一索引 您不能在哈希索引上指定唯一约束。 对于一个范围分片的集合，只有以下索引可以是唯一的 分片键索引 一个已分片键为前缀的复合索引 默认的_id索引； 但是，如果_id字段不是分片键或分片键的前缀，则_id索引仅对每个分片强制执行唯一性约束。 关于_id索引和唯一性 如果_id字段不是分片键或分片键的前缀，则_id索引仅对每个分片（而非跨分片）强制实施唯一性约束。 例如，考虑一个跨越两个分片A和B的分片集合（具有分片键{x：1}）。由于_id键不是分片键的一部分，因此该集合可能在分片A中具有_id值为1的文档。 以及分片B中_id值为1的另一个文档。 如果_id字段不是分片键也不是分片键的前缀，则MongoDB期望应用程序来保证整个分片上_id值的唯一性。 唯一的索引约束意味着： 对于一个即将要分片的集合，如果该集合具有其他唯一索引，则无法分片该集合。 对于已分片的集合，不能在其他字段上创建唯一索引。 通过使用分片键上的唯一索引，MongoDB可以对分片键值实施唯一性约束。 MongoDB在整个键组合上（而不是分片键的单个组件）实施唯一性约束。 要对分片键值实施唯一性约束，请将unique参数设置为true传递给sh.shardCollection()方法： 如果集合为空，则sh.shardCollection()在分片键上创建唯一索引（如果该索引尚不存在）。 如果集合不为空，则必须先创建索引，然后再使用sh.shardCollection()。 尽管可以有一个唯一的复合索引，其中分片键是一个前缀，但是如果使用unique参数，则集合必须在分片键上具有唯一索引。 选择一个分片键 分片键的选择会影响可用分片中数据块的创建和分布。 这会影响分片群集内操作的整体效率和性能。 分片键会影响分片群集使用的分片策略的性能和效率。 理想的分片键允许MongoDB在整个集群中均匀地分布所有文档。 至少要综合考虑潜在分片键的基数，频率和变化率等指标。 限制 有关分片键的限制，请参阅分片键限制。 集合大小 在对一个不为空的集合进行分片时，分片键只能为初始分片操作限制最大支持的集合大小。 请参阅分片现有集合数据大小。 重要 一个分片集合在成功分片之后就可以增长到任意大小，没有上限。 分片键基数 分片键的基数确定平衡器可以创建的最大数据块的数目。这会降低或消除集群中水平缩放的有效性。 在任何给定时间，唯一的分片键值最多只能存在一个块上。 如果分片密钥的基数为4，则分片集群中最多只能有4个块，每个块存储一个唯一的分片密钥值。 这也将群集中的有效分片数量也限制为4个-添加额外的分片不会提供任何好处。 下图说明了使用字段X作为分片键的分片群集。 如果X具有低基数，则插入的分布可能类似于以下内容： 在此示例中，集群不会水平扩展，因为传入的写入将仅路由到分片的子集。 具有高基数的分片键虽然可以更好地促进水平扩展，但不能保证在分片集群中均匀分布数据。 分片键的频率和变化率也有助于数据分配。 选择分片键时，请考虑每个因素。 如果您的数据模型需要在具有低基数的键上分片，请考虑使用具有较高相对基数的字段的复合索引。 分片键频率 考虑一个代表分片键值范围的集合-分片键的频率代表给定值在数据中出现的频率。 如果大多数文档仅包含这些值的子集，那么存储这些文档的数据块将成为群集中的瓶颈。 此外，随着这些数据块的增长，它们可能会变成不可分割的数据块，因为它们无法进一步拆分。 这将降低或消除群集内水平扩展的有效性。 下图说明了使用字段X作为分片键的分片群集。 如果X值的子集高频出现，则插入的分布可能类似于以下内容： 低频的分片键不能保证整个分片群集中的数据均匀分布。 分片密钥的基数和变化率也有助于数据分配。 选择分片键时，请考虑每个因素。 如果您的数据模型需要在具有高频值的键上分片，请考虑使用具有唯一或低频值的复合索引。 单调变化的分片键 值单调增加或减少的分片键更有可能将插入内容分布到集群中的单个分片上。 发生这种情况是因为每个集群都有一个大数据块，该大数据块捕获具有maxKey上限的范围。 maxKey始终比所有其他值更高。 类似地，有一个块用minKey的下限捕获范围。 minKey总是比所有其他值都低。 如果分片键值始终在增加，则所有新插入都将路由到以maxKey为上限的块。 如果分片键值始终在减小，则所有新插入都将路由到以minKey为下限的块。 包含该块的分片将成为写操作的瓶颈。 下图说明了使用字段X作为分片键的分片群集。 如果X的值单调增加，则插入的分布可能类似于以下内容： 如果分片键值单调递减，则所有插入都将路由到数据块A。 不能单调更改的分片键不能保证整个分片群集中的数据均匀分布。 分片键的基数和频率也有助于数据分配。 选择分片键时，请考虑每一个因素。 如果您的数据模型需要对单调更改的键进行分片，请考虑使用哈希分片。 原文链接：https://docs.mongodb.com/manual/core/sharding-shard-key/ 译者：刘翔 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"12-sharding/Zones.html":{"url":"12-sharding/Zones.html","title":"Zone","keywords":"","body":" Zone 本页内容 行为和操作 在分片集群中，您可以基于 shard key 创建分片数据的 zones 。您可以将每个区域与集群中的一个或者更多分片关联起来。一个分片可以和任意数目的非冲突区域关联。在一个均衡的集群中，MongoDB只会将一个区域包含的 chunks 迁移到与该区域相关联的分片。 可以运用区域的一些常见开发模式如下： 在一个特定的分片集合中分隔一个特定的数据子集。 保证最相关的数据存储于与应用服务器地理上最相近的分片上。 基于硬件/分片硬件的性能将数据路由到分片。 下图展示了一个拥有三个分片和两个区域的分片集群。A 区域表示下限为 1 、上限为 10 的范围。B 区域则表示下限为 10 、上限为 20 的范围。 分片 Alpha 和 Beta 有 A 区域。分片 Beta 还拥有 B 区域。 分片 Charlie 没有区域与之相关、该集群在一个稳定的状态，没有数据块违背任何区域。 行为和操作 范围 每个区域设计一个或多个 shard key 值范围。每个区域覆盖的每个范围一般包含其下界，不包含其上界。 区域不能共享范围，它们也不能有交叉的范围。 均衡器 The balancer attempts to evenly distribute a sharded collection’s chunks across all shards in the cluster. 对于每一个标记为要迁移的 chunk ，均衡器检查所有配置区域内的每一个可能的目标分片。如果数据块范围属于某一个区域，那么均衡器就会将该数据块迁移到该区域上的一个分片。不属于任何区域的数据块可以存在于集群中的 任何 分片，并且正常迁移。 在均衡过程中，如果均衡器检测到任何违背已配置区域上给定的分片，均衡器将会把这些数据块迁移到不存在冲突的分片上。 在使用一个片键范围配置区域，并且将它与一个或多个分片关联起来之后，集群可能会花费一些时间来迁移影响的数据。这依赖于数据块的划分以及目前集群中数据的分布。当均衡完成之后，在某一给定区域的文档读取和写入将只会路由到该区域内的一个分片或几个分片。 一旦配置完成后，均衡器将在 balancing rounds 中重新检查区域。 片键 在定义一个区域覆盖的新范围时，您必须使用包含在 shard key 中的字段。如果使用一个 [compound]片键，则该范围必须包含该片键的前缀。 例如，给定一个片键 { a : 1, b : 2, c : 3 } ，创建或更新一个区域来覆盖 b 的值要求包括 a 作为前缀。创建或更新一个区域来覆盖 c 的值要求包括 a 和 b 作为前缀。 您不能使用片键中部包含的字段创建区域。例如，如果您先使用区域来对数据进行地理位置进行分区，片键中需要至少包括一个包含地理数据的字段。 为集合选择分片键时，请考虑您可能要用于配置区域的字段。有关选择分片键的注意事项，请参阅选择分片键。 哈希片键和区域 当在哈希片键上使用区域时，每个区域覆盖 哈希 片键值。给定一个片键值 { a : 1 } 和区域一个下界为 1 上界为 5 的区域 alpha ，边界表示 a 的 哈希 值，而不是真实值。因此，并不能保证 MongoDB将 a值为 1 到 5 之间的文档路由到 alpha 区域。MongoDB将任何 哈希 片键值落入到 1 到 5 范围内的文档路由到区域 alpha 内的分片上。 一般说来，一个覆盖哈希片键值顺序范围的区域可能会出现一些预计不到的行为。 可以通过使用 minkey 和 maxkey 创建覆盖片键值整个范围的区域，以保证MongoDB将某个特定集合的所有数据控制存储在该区域的一个分片或几个分片上。 分片区域边界 区域范围一般包含下界，不包含上界。 参见 [Manage Shard Zones] 译者：王恒 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration.html":{"url":"13-administration.html","title":"管理权限","keywords":"","body":"数据库管理文档 数据库管理文档涉及 MongoDB 实例和部署的持续操作和维护。该文档既包括对这些问题的高层概述，也包括涵盖操作 MongoDB 的具体程序和流程的教程。 参见 原文 - Administration 译者：雪星 (snomiao@gmail.com) 于 2020 秋 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/01-production-notes.html":{"url":"13-administration/01-production-notes.html","title":"产品说明","keywords":"","body":" 产品说明 MongoDB 二进制文件 MongoDB 文件存储路径 并发 数据一致性 联网 硬件注意事项 架构 压缩 时钟同步 平台特定注意事项 性能监控 备份 本文详细描述了影响MongoDB，特别是在生产环境中运行时的系统配置。 移除 MMAPV1： MongoDB 4.2 移除了已弃用的 MMAPv1 存储引擎。要将 MMAPv1 存储引擎部署更改为 WiredTiger存储引擎 ，请参见： 将单节点更改为WiredTiger 将复制集群更改为WiredTiger 将分片集群更改为WiredTiger 注意： MongoDB Atlas 是云端的数据库服务。MongoDB Cloud Manager：官方推出的运维自动化管理系统， 是一个托管服务； Ops Manager：用于监控和备份MongoDB的基础设施服务，是一个本地解决方案, 提供 MongoDB 实例的监视，备份和自动化。 有关文档，请参阅 Atlas 文档, MongoDB Cloud Manager 文档 和 Ops Manager 文档。 MongoDB 二进制文件 支持的平台 在生产环境中运行时，请参阅推荐的平台以获取推荐使用的操作系统。 注意： MongoDB 4.0 在 macOS 10.12.x 和 10.13.x 系统上当硬盘未正常关机时可能丢失数据。 对于更多的细节，参见WT-4018。 x86_64 平台支持的产品生命期结束通知 Ubuntu 14.04 在MongoDB 4.2+中移除了支持。 Debian 8 在MongoDB 4.2+中移除了支持。 macOS 10.11 在MongoDB 4.2+中移除了支持。 即将到来的的产品生命期结束通知 Windows 8.1/2012R2 MongoDB在接下来的版本中不再支持。 Windows 8/2012 MongoDB在接下来的版本中不再支持。 Windows 7/2008R2 MongoDB在接下来的版本中不再支持。 平台 4.2 社区版和企业版 4.0 社区版和企业版 3.6 社区版和企业版 3.4 社区版和企业版 亚马逊 Linux 2 ✓ ✓ 亚马逊 Linux 2013.03 和更高版本 ✓ ✓ ✓ ✓ Debian 10 4.2.1+ Debian 9 ✓ ✓ 3.6.5+ Debian 8 ✓ ✓ ✓ RHEL/CentOS/Oracle Linux [1] 8.0 and later 4.2.1+ 4.0.14+ 3.6.17+ RHEL/CentOS/Oracle Linux [1] 7.0 和更高版本 ✓ ✓ ✓ ✓ RHEL/CentOS/Oracle Linux [1] 6.2 和更高版本 ✓ ✓ ✓ ✓ SLES 15 4.2.1+ SLES 12 ✓ ✓ ✓ ✓ Solaris 11 64-bit 仅社区版本 Ubuntu 18.04 ✓ 4.0.1+ Ubuntu 16.04 ✓ ✓ ✓ ✓ Ubuntu 14.04 ✓ ✓ ✓ Windows Server 2019 ✓ Windows 10 / Server 2016 ✓ ✓ ✓ ✓ Windows 8.1 / Server 2012 R2 ✓ ✓ ✓ ✓ Windows 8 / Server 2012 ✓ ✓ ✓ ✓ Windows 7 / Server 2008 R2 ✓ ✓ ✓ ✓ Windows Vista ✓ macOS 10.13 和更高版本 ✓ ✓ macOS 10.12 ✓ ✓ ✓ ✓ macOS 10.11 ✓ ✓ ✓ macOS 10.10 ✓ ✓ [1] (1, 2, 3) MongoDB 仅支持 Oracle Linux 运行 Red Hat Compatible Kernel (RHCK). MongoDB 不支持Unbreakable Enterprise Kernel (UEK)。 ARM64 平台支持的 产品生命期结束通知 Ubuntu 16.04 ARM64 在MongoDB 社区版 4.2+中不再支持。 平台 4.2 社区版和企业版 4.0 社区版和企业版 3.6 社区版和企业版 3.4 社区版和企业版 Ubuntu 18.04 仅社区版 Ubuntu 16.04 仅企业版 ✓ ✓ ✓ PPC64LE (MongoDB 企业版) 平台支持的 产品生命期结束通知 Ubuntu 16.04 PPC64LE 在MongoDB 社区版 4.2+中不再支持。 平台 4.2 企业版 4.0 企业版 3.6 企业版 3.4 企业版 RHEL/CentOS 7 ✓ ✓ ✓ ✓ Ubuntu 18.04 ✓ Ubuntu 16.04 ✓ 在3.6.13版本中开始移除 在3.4.21版本中开始移除 s390x 平台 4.2 社区版和企业版 4.0 企业版 3.6 企业版 3.4 企业版 RHEL/CentOS 7 ✓ 4.0.6+ 在3.6.2版本中开始移除 在3.4.14版本中开始移除 RHEL/CentOS 6 ✓ ✓ 在3.6.14版本中开始移除 在3.4.22版本中开始移除 SLES12 ✓ 4.0.6+ 在3.6.2版本中开始移除 在3.4.15版本中开始移除 Ubuntu 18.04 4.2.1+ 4.0.6+ 推荐的平台 虽然 MongoDB 支持各种平台，但建议使用以下操作系统使用产品： Amazon Linux 2 Debian 9 and 10 RHEL / CentOS 6, 7, and 8 SLES 12 and 15 Ubuntu LTS 16.04 and 18.04 Windows Server 2016 and 2019 另见： 平台特定注意事项 使用最新的稳定包 确保您拥有最新的稳定版本。 所有 MongoDB 版本都可在 MongoDB 下载中心 页面获取. MongoDB 下载中心 页面可以找到当前稳定版本，即使您通过包管理进行安装。 对于其他 MongoDB 产品，请参阅 MongoDB 下载中心 页面或者 各自对应文档。 MongoDB 文件存储路径 dbPath目录中的文件必须与配置的存储引擎对应。如果文件存储路径 包含由 --storageEngine 指定的存储引擎以外的存储引擎创建的数据文件，mongod 将不会启动。 mongod必须对指定的文件存储路径拥有读写权限 并发 WiredTiger WiredTiger支持读写器对对集合中的文档进行并发访问。 客户端可以可以在进行写操作时读取文档，多个线程可以同时修改集合中的不同文档。 也可以看看 分配足够的 RAM 和 CPU 提供有关WiredTiger如何利用多个CPU核以及如何提高操作吞吐量的信息。 数据一致性 日志 MongoDB 使用预写式日志方式写入到磁盘日志。日志记录保证MongoDB可以快速从崩溃或其他严重错误中恢复写入日志但未写入数据文件的 写操作。 从MongoDB 4.0开始，不能为使用WiredTiger存储引擎的副本集成员 --nojournal 选项或者storage.journal.enabled: false 读操作安全机制 在 version 3.2 中的新内容 从 MongoDB 3.6 开始，如果写请求确认，则可以使用因果一致性会话来读取您自己的写入。 在 MongoDB 3.6 之前，您必须确保写操作使用了 { w: \"majority}\" 写入安全机制，然后对读取操作使用 \"majority\"或 \"linearizable\"读取安全机制，以确保单个线程可以读取自己的写入。 要使用 \"majority\"的级别的 读安全机制 ，副本集必须使用WiredTiger 存储引擎。 您可以禁用具有三个成员的主-副-仲裁(PSA)体系结构部署的读安全机制 \"majority\";但是，这对更改流(仅在MongoDB 4.0和更早的版本中)和分片集群上的事务有影响。有关更多信息，请参见Disable Read Concern Majority。 写操作安全机制 写操作安全机制](https://docs.mongodb.com/manual/reference/write-concern/) 描述 MongoDB 写操作时确认请求写入的安全机制级别。写操作安全机制的级别会影响写操作返回的速度。当写操作具有较弱的写入安全机制时，它们会快速返回。对于更强的写入安全机制，客户端必须在发送写入操作后等待，直到 MongoDB 在请求的写入安全机制级别上确认写入操作。由于写入安全机制级别不够，写操作可能会显示客户端成功，但在某些服务器故障情况下可能不会缓存。 有关选择适当的写操作安全机制级别的详细信息，请参阅 写操作安全机制文档。 联网 使用可信网络环境 始终在可信环境中运行 MongoDB，其网络规则阻止从所有未知计算机，系统和网络中进行访问。与依赖于网络访问的任何敏感系统一样，只有需要访问的特定系统才能访问 MongoDB 部署，例如应用服务器，监视服务和其他 MongoDB 组件。 重要 默认情况下，授权未启用， mongod默认为受信任的环境。根据需要启用authorization 模式。有关 MongoDB 中支持的身份验证机制以及 MongoDB 中的授权的详细信息，请参阅 授权和 基于角色的访问控制。 有关安全性的其他信息和注意事项，请参阅安全部分中的文档，具体如下： 安全检查列表 网络和配置强化 对于 Windows 用户，在 Windows 上部署 MongoDB 时请考虑 有关TCP配置的Windows Server Technet文章 。 禁用 HTTP 接口 3.6版本中的变化： MongoDB 3.6 移除了 HTTP 接口和 REST API 。 早期版本的 MongoDB 提供了一个 HTTP 接口来检查服务器的状态，还可以选择运行查询。默认情况下禁用 HTTP 接口。不要在生产环境中启用 HTTP 接口。 管理连接池大小 通过调整连接池大小以适合您的用例，避免重载 mongod 和 mongos 实例的连接资源。从当前数据库请求的典型数量的 110-115％开始，并根据需要修改连接池大小。请参阅连接池选项以调整连接池大小。 connPoolStats 命令返回有关分片集群中mongos 和 mongod实例的当前数据库打开连接数的信息。 另见 分配足够的 RAM 和 CPU. 硬件考虑因素 MongoDB 专为商用硬件而设计，几乎没有硬件要求或限制。 MongoDB 的核心组件运行在小端硬件上，主要是 x86/x86_64 处理器。客户端库（例如驱动程序）可以在大端或小端系统上运行。 分配足够的 RAM 和 CPU 至少，确保每个 mongod 或者 mongos实例可以访问两个实核或一个多核物理CPU。 WiredTiger WiredTiger 存储引擎是多线程的，可以利用额外的 CPU 内核。具体而言，相对于可用CPU的数量，活动线程（即并发操作）的总数会影响性能： 随着并发活动操作数量增加到 CPU 数量，吞吐量会增加。 当并发活动操作的数量超过CPU数量的某个阈值时，吞吐量会降低。 阈值取决于您的应用程序。您可以通过实验和测量吞吐量来确定应用程序的最佳并发活动操作数。 mongostat 的输出提供（ar | aw）列中活动读/写次数的统计信息。 使用 WiredTiger，MongoDB同时使用WiredTiger内部缓存和文件系统缓存。 从MongoDB 3.4开始，默认的WiredTiger内部缓存大小为以下两者中的较大者： 50% 的 (RAM - 1 GB), 或者 256 MB。 例如，在总共有4GB RAM的系统上，WiredTiger缓存将使用1.5GB RAM(0.5 (4 GB - 1 GB) = 1.5 GB)。相反，RAM总量为1.25GB的系统将为WiredTiger缓存分配256MB，因为这超过了RAM总量减去1GB（0.5（1.25GB-1GB）=128MB 注意 在某些情况下，例如在容器中运行时，数据库可能具有低于总系统内存的内存约束。在这种情况下，这个内存限制，而不是整个系统内存，被用作可用的最大RAM。 要查看内存限制，请参阅 hostInfo.system.memLimitMB。 默认情况下，WiredTiger对所有集合使用snapy块压缩，对所有索引使用前缀压缩。压缩默认值在全局级别上是可配置的，也可以在集合和索引创建期间根据每个集合和每个索引进行设置。 WiredTiger内部缓存中的数据与磁盘上的格式相比使用了不同的表示： 文件系统缓存中的数据与磁盘上的格式相同，包括对数据文件进行任何压缩的好处。操作系统使用文件系统缓存来减少磁盘I/O。 加载在WiredTiger内部缓存中的索引与磁盘上的格式具有不同的数据表示形式，但仍然可以利用索引前缀压缩来减少RAM的使用。索引前缀压缩从索引字段中删除常用前缀。 WiredTiger内部缓存中的收集数据是未压缩的，使用与磁盘格式不同的表示形式。块压缩可以显著节省磁盘存储空间，但数据必须解压缩才能由服务器操作。 MongoDB通过文件系统缓存自动使用WiredTiger缓存或其他进程未使用的所有可用内存。 要调整WiredTiger内部缓存的大小，请参见 storage.wiredTiger.engineConfig.cacheSizeGB 和 --wiredTigerCacheSizeGB。避免将WiredTiger内部缓存大小增加到其默认值以上。 注意 storage.wiredTiger.engineConfig.cacheSizeGB 限制了wiredTiger内部缓存的大小。操作系统将使用可用的空闲内存进行文件系统缓存，这将允许压缩的MongoDB数据文件保留在内存中。此外，操作系统将使用任何空闲RAM缓冲文件系统块和文件系统缓存。 为了适应RAM的其他使用者，您可能必须减小WiredTiger内部缓存的大小。 默认的WiredTiger内部缓存大小值假定每台计算机有一个mongod实例。如果一台机器包含多个MongoDB实例，那么您应该减少设置以适应其他mongod实例。 如果在无法访问系统中所有可用RAM的容器（例如lxc、cgroups、Docker等）中运行mongod，则必须将 storage.wiredTiger.engineConfig.cacheSizeGB设置为小于容器中可用RAM的值。具体数量取决于容器中运行的其他进程。参见 memLimitMB。 要查看缓存和逐出率的统计信息，请参阅从serverStatus 命令返回的 wiredTiger.cache 字段。 压缩和加密 当使用加密时，配备AES-NI指令集扩展的CPU可以显示出显著的性能优势。如果将MongoDB 企业版与 加密存储引擎一起使用，请选择支持AES-N指令集的CPU以获得更好的性能。 也可以看看 并发 使用固态硬盘（SSD） MongoDB使用SATA SSD能得到很好的效果和很好的性价比。 在可用且经济的情况下请使用SSD。 传统硬盘通常也是个好的选择，因为使用更昂贵的硬盘来提高随机IO性能并不是那么有效（只能是每次2倍）。使用SSD或增加RAM的容量可能对于提升IO更有效率。 MongoDB和NUMA硬件 在运行NUMA的系统中运行MongoDB可能造成一系列问题，包括一段时间内的效率低下和高系统进程使用率。 当在NUMA硬件上运行MongoDB服务器和客户端时，应配置内存交错策略，以便主机以非NUMA方式运行。MongoDB在Linux（2.0版以后）和Windows（2.6版以后）机器上部署时，会在启动时检查NUMA设置。如果NUMA配置可能会降低性能，MongoDB会打印一个警告。 也可以看看 MySQL的 “疯狂交换” 问题和 NUMA的影响 报告, ，它描述了NUMA对数据库造成的影响。这篇文章介绍了NUMA和它的目标，并指出了为什么这些目标和生产环境数据库的需求是不相容的。尽管这篇博文讨论了NUMA对于 MySQL的影响，但是MongoDB的问题是相似的。 NUMA: 综述。 在 Windows 上配置 NUMA 在 Windows 上，必须通过机器的 BIOS 启用内存交叉存取。有关详细信息，请参阅系统文档 在 Linux 上配置 NUMA 在 Linux上，您必须禁用内存区域回收，并确保您的 mongod and mongos 实例由 numactl命令启动，numactl 通常是通过平台的 init 系统配置的。您必须执行这两个操作才能正确禁用 NUMA 以便与 MongoDB 一起使用。 使用以下命令之一禁用内存区域回收: echo 0 | sudo tee /proc/sys/vm/zone_reclaim_mod sudo sysctl -w vm.zone_reclaim_mode=0 2.然后，您应该使用 numactl 来启动 mongod and mongos ，这通常是通过平台的 init 系统配置的。运行以下命令以确定平台上正在使用的init系统： ps --no-headers -o comm 1 如果是systemd，则您的平台使用 systemd init 系统，您必须按照下面 systemd 选项卡中的步骤来编辑MongoDB服务文件。 如果是init，则平台使用SysV init系统，不需要执行此步骤。SysV init 的默认MongoDB init 脚本默认包含通过numactl 启动 MongoDB 实例的必要步骤。 如果您管理自己的 init 脚本（例如没有使用这两个 init 系统中的任何一个），则必须按照下面自定义 init 脚本选项卡中的步骤编辑自定义 init 脚本。 systemd 你必须使用 numactl 启动每个 mongod 实例,包括所有 配置服务器, mongos实例,和客户端.。如下所示编辑每个系统的默认 systemd 服务文件： 复制默认MongoDB服务文件： sudo cp /lib/systemd/system/mongod.service /etc/systemd/system/ 编辑 /etc/systemd/system/mongod.service 文件，首先要更新 ExecStart 语句： /usr/bin/numactl --interleave=all 例如 如果现有的 ExecStart 语句为： ``` ExecStart=/usr/bin/mongod --config /etc/mongod.conf ``` 将该语句更新为： ``` ExecStart=/usr/bin/numactl --interleave=all /usr/bin/mongod --config /etc/mongod.conf ``` 将更改应用于 systemd： sudo systemctl daemon-reload 重新启动任何正在运行的 mongod 实例： sudo systemctl stop mongod sudo systemctl start mongod 如果适用，对任何mongos 重复这些步骤。 有关更多信息，请参见 Documentation for /proc/sys/vm/*。 自定义初始化脚本 你必须使用 numactl 启动每个 mongod 实例,包括所有 配置服务器, mongos实例和客户端。 1.如果尚未安装numactl，请为您的平台安装 numactl。有关安装 numactl 包的信息，请参阅操作系统的文档。 配置每个自定义init脚本以通过numactl启动每个MongoDB实例： numactl --interleave=all 其中是 是要启动的程序的路径，也是要传递给该程序的任何可选参数。 例如： numactl --interleave=all /usr/local/bin/mongod -f /etc/mongod.conf 有关更多信息，请参见 Documentation for /proc/sys/vm/*。 磁盘和存储系统 交换 MongoDB在可以避免交换或将交换保持在最低限度的地方表现最好，因为从交换中检索数据总是比访问RAM中的数据慢。但是，如果托管 MongoDB 的系统没有RAM，交换可以防止 Linux OOM Killer 终止 mongod 进程。 通常，您应该选择以下交换策略之一： 在系统上分配交换空间，并将内核配置为只允许在高内存负载下进行交换，或者 不要在系统上分配交换空间，并将内核配置为完全禁用交换 请参阅 Set vm.swappiness 以获取有关在Linux系统上按照这些指导原则配置swap的说明。 注意 如果MongoDB实例托管在同时运行其他软件（如Web服务器）的系统上，则应选择第一个交换策略。在这种情况下不要禁用交换。如果可能，强烈建议您在MongoDB自己的专用系统上运行MongoDB。 阵列 为了在存储层方面实现最佳性能，请使用 RAID-10 支持的磁盘。 RAID-5 和 RAID-6 通常不提供足够的 性能来支持 MongoDB 部署。 远程文件系统 使用 WiredTiger 存储引擎，如果远程文件系统符合 ISO/IEC 9945-1:1996(POSIX.1)，则 WiredTiger 对象 可以存储在远程文件系统上。由于远程文件系统通常比本地文件系统慢，因此使用 远程文件系统进行存储可能会降低性能。 如果决定使用网络文件系统，请在 /etc/fstab 文件中添加以下NFS选项：bg、nolock 和 noatime。 将组件分离到不同的存储设备上 为了提高性能，请考虑根据应用程序的访问和写入模式，将数据库的数据、logs 和 journal 分离到不同的存储设备上。将组件作为单独的文件系统挂载，并使用符号链接将每个组件的路径映射到存储它的设备。 对于WiredTiger存储引擎，还可以将索引存储在不同的存储设备上。见storage.wiredTiger.engineConfig.directoryForIndexes。 注意 使用不同的存储设备将影响您创建数据快照式备份的能力，因为文件将位于不同的设备和卷上。 调度 虚拟或云主机设备的调度 对于通过虚拟机监视器连接到虚拟机实例或由云托管提供商托管的本地块设备，客户操作系统应使用 noop 调度器以获得最佳性能。noop 调度器允许操作系统将 I/O 调度延缓到底层管理程序。 物理服务器的调度 对于物理服务器，操作系统应使用 deadline调度器。deadline调度器限制每个请求的最大延迟，并保持良好的磁盘吞吐量，这对于磁盘密集型数据库应用程序来说是最好的。 架构 副本集 有关副本集部署的体系结构注意事项的概述，请参阅 副本集体系结构文档。 分片集群 有关建议的用于生产部署的分片集群体系结构的概述，请参阅分片集群生产体系结构 。 也可以参阅 开发清单列表 压缩 WiredTiger可以使用以下压缩库之一压缩收集数据： snappy 提供比zlib或zstd更低的压缩率，但比任何一种的CPU成本都低。 zlib 提供了比 snappy 更好的压缩率，但比 snappy 和 zstd 的CPU成本都要高。 zstd (从 MongoDB 4.2 开始可以使用) 提供比 snappy 和 zlib 更好的压缩率，并且比 zlib 具有更低的CPU成本。 默认情况下，WiredTiger使用 snappy 压缩库。要更改压缩设置，请参见storage.wiredTiger.collectionConfig.blockCompressor。 默认情况下，WiredTiger对所有索引使用 前缀压缩 。 时钟同步 MongoDB 组件保留逻辑时钟以支持与时间相关的操作。使用网络时间协议同步主机时钟来降低组件之间时钟漂移的风险。组件之间的时钟漂移增加了时间相关操作不正确或异常行为的可能性，如下所示： 如果任何给定 MongoDB 组件的底层系统时钟偏离同一部署中的其他组件一年或更长时间，则这些成员之间的通信可能变得不可靠或完全停止。 maxAcceptableLogicalClockDriftSecs 参数控制组件之间可接受的时钟偏移量。MaxAcceptableLogicalClockDiftSecs值较低的集群对时钟漂移的容忍度相应较低。 对于返回当前集群或系统时间的操作，具有不同系统时钟的两个集群成员可能返回不同的值，例如 Date(), NOW, 和 CLUSTER_TIME。 在MongoDB组件之间存在时钟漂移的集群中，依赖于计时的特性可能会有不一致或不可预测的行为。 例如，TTL索引依赖于系统时钟来计算何时删除给定文档。如果两个成员有不同的系统时钟时间，则每个成员可以在不同的时间删除TTL索引覆盖的给定文档。由于客户端会话和因果一致性保证使用TTL索引来控制它们的寿命，时钟漂移可能导致不一致或不可预测的会话超时行为。 运行 MongoDB 低于 3.4.6 或 3.2.17 的部署需要 NTP 同步，使用 WiredTiger 存储引擎，时钟漂移可能导致检查点挂起。该问题在 MongoDB 3.4.6+ 和 MongoDB 3.2.17+ 中得到了修复，并在 MongoDB 3.6、4.0 和 4.2 版本中所有点得到了解决。 平台特定注意事项 Kernel and File Systems 内核和文件系统 在Linux上的生产环境中运行MongoDB时，应该使用 Linux 内核版本 2.6.36 或更高版本，并使用 XFS或 EXT4 文件系统。如果可能的话，使用 XFS，因为它通常在 MongoDB 中执行得更好。 对于 WiredTiger 存储引擎，强烈建议使用 XFS，以避免将 EXT4 与 WiredTiger 一起使用时可能出现的性能问题。 一般来说，如果您使用的是 XFS 文件系统，那么至少要使用 2.6.25 版本的Linux内核。 如果使用 EXT4 文件系统，请至少使用 2.6.28 版本的 Linux 内核。 在Red Hat 企业版 Linux 和 CentOS 上，至少使用 2.6.18-194 版 Linux 内核。 系统C库 MongoDB在Linux上使用 GNU C 库 (glibc)。一般来说，每个Linux发行版都提供了自己经过审查的版本。为了获得最佳结果，请使用此系统提供版本的最新更新。您可以使用系统的包管理器检查是否安装了最新版本。例如： 在 RHEL/CentOS 上，以下命令更新系统提供的 GNU C 库： sudo yum update glibc 在Ubuntu/Debian上，以下命令更新系统提供的 GNU C 库： sudo apt-get install libc6 目录中的 fsync() 重要 MongoDB要求文件系统对目录支持 fsync()。例如 HGFS 和 Virtual Box 的共享目录不支持这个操作。 将 vm.swappiness 设置为 1 或者 0 “Swappiness” 是一种影响虚拟内存管理器的 Linux 内核设置，vm.swappiness 设置的范围从0到100：该值越高，它越倾向于将内存页交换到磁盘，而不是从RAM中删除页。 设置为0将完全禁用交换 [2]。 设置为1只允许内核交换以避免内存不足问题。 设置60告诉内核经常交换到磁盘，这是许多Linux发行版的默认值。 设置为100将告诉内核尽可能交换到磁盘。 MongoDB 在可以避免或保持最小交换的地方表现最好。因此，您应该根据应用程序需要和集群配置将 vm.swappiness 设置为1或0。 [2] 对于3.5之前的Linux内核版本，或 2.6.32-303 之前的 RHEL/CentOS 内核版本，vm.swappiness 设置为0仍然允许内核在某些紧急情况下进行交换。 注意 如果 MongoDB 实例托管在同时运行其他软件（如Web服务器）的系统上，则应将 vm.swappiness 设置为1。如果可能，强烈建议您在MongoDB自己的专用系统上运行MongoDB。 要检查系统上的当前交换设置，请运行： cat /proc/sys/vm/swappiness 要更改系统上的交换设置： 编辑 /etc/sysctl.conf 文件并添加以下行： vm.swappiness = 1 运行以下命令以应用设置： sudo sysctl -p 注意 如果您正在运行 RHEL/CentOS 并使用优化的性能配置文件，则还必须编辑所选配置文件以将vm.swappiness 设置为1或0。 推荐配置 对于所有MongoDB部署： 在主机之间同步时间使用网络时间协议（NTP）。这在分片集群中尤为重要。 对于 WiredTiger 存储引擎，请考虑以下建议： 在包含数据库文件的存储卷关闭 atime 配置。 按照 ulimit 设置的推荐，设置描述符限制，-n 和用户进程限制（ulimit），-u 设置为20000以上。当大量使用时，低 ulimit 将影响 MongoDB，并可能产生错误，导致与MongoDB进程的连接失败和服务丢失。 不要使用透明大页，因为MongoDB在标准页中表现更好。参见 透明大页设置. 在BIOS中禁用NUMA。如果做不到，请参考 MongoDB 和 NUMA 硬件章节。 如果不使用默认的 MongoDB 目录路径或 端口，请为 MongoDB 配置 SELinux。 请参阅为 MongoDB 配置 SELinux 和 为 MongoDB 企业版配置 SELinux 以获得所需的配置。 注意 如果您使用的是 SELinux，任何需要 服务器端 javaScript 的 MongoDB 操作都会导致段错误。 禁用服务器端执行JavaScript 描述如何禁用服务器端 JavaScript 执行。 对于WiredTiger存储引擎： 无论存储介质类型（旋转磁盘、SSD等）如何，将 文件预读的值设置为8到32。 较高的预读通常有利于顺序 I/O 操作。由于MongoDB 磁盘访问模式通常是随机的，因此使用更高的文件预读设置提供的好处有限，或者可能会降低性能。因此，为了获得最佳的 MongoDB 性能，请将文件预读的值设置在8到32之间，除非测试在更高的文件预读值中显示出可测量、可重复和可靠的好处。 MongoDB 商业支持可以提供关于备用文件预读配置的建议和指导。 MongoDB 和 TLS/SSL 库 在 Linux 平台上，您可以在 MongoDB 日志中看到以下语句之一： /libssl.so.: no version information available (required by /usr/bin/mongod) /libcrypto.so.: no version information available (required by /usr/bin/mongod) 这些警告表示系统的 TLS/SSL 库与 mongod 编译时所依据的 TLS/SSL 库不同。通常这些消息不需要干预；但是，您可以使用以下操作来确定 mongod 期望的符号版本： objdump -T /mongod | grep \" SSL_\" objdump -T /mongod | grep \" CRYPTO_\" 这些操作将返回类似于以下行之一的输出： 0000000000000000 DF *UND* 0000000000000000 libssl.so.10 SSL_write 0000000000000000 DF *UND* 0000000000000000 OPENSSL_1.0.0 SSL_write 此输出中的最后两个字符串是符号版本和符号名。将这些值与以下操作返回的值进行比较，以检测符号版本是否匹配： objdump -T /libssl.so.1* objdump -T /libcrypto.so.1* 这个过程既不精确也不详尽： mongod 从 libcrypto 库中使用的许多符号不是以 CRYPTO_ 开头的。 Windows 上的 MongoDB 对于使用 WiredTiger 存储引擎的 MongoDB 实例，Windows 上的性能与 Linux 上的性能相当。 虚拟环境中的MongoDB 本章节描述了在常用虚拟环境中运行MongoDB需要考虑的问题。 对于所有平台，请考虑 调度. AWS EC2（亚马逊弹性计算云） 有两种性能配置需要考虑： 性能测试或基准测试的可复制性能，以及 原始最大性能 要为任一配置优化弹性计算云上的性能，应： 为您的实例启用亚马逊增强的网络。并非所有实例类型都支持增强的网络。 要了解有关增强联网的更多信息，请参阅AWS 文档。 如果您更关心弹性计算云的可重复性能，您还应该： 为存储使用配置的 IOPS，日志和数据使用单独的设备。不要使用大多数实例类型上可用的临时（SSD）存储，因为它们的性能会随时发生变化。（i 系列是一个显著的例外，但非常昂贵。） 禁用 DVFS 和 CPU 节能模式。 也可以看看 关于处理器状态控制的Amazon文档 禁用超线程。 也可以看看 亚马逊关于禁用超线程的博客文章. 使用 numactl 将内存局部性绑定到单个套接字。 Azure 使用高级存储。微软Azure提供了两种常见的存储类型：标准存储和高级存储。与标准存储相比，Azure上的MongoDB 在使用高级存储时具有更好的性能。 默认情况下，Azure 负载平衡器上的 TCP 空闲超时默认为240秒，如果 Azure 系统上的 TCP 长连接大于此值，则会导致它自动断开连接。您应该将 TCP 长连接时间设置为120以改善此问题。 注意 要使新的系统范围长连接设置生效，您需要重新启动 mongod 和mongos 进程。 要在 Linux 上查看长连接设置，请使用以下命令之一： sysctl net.ipv4.tcp_keepalive_time 或者： cat /proc/sys/net/ipv4/tcp_keepalive_time 该值以秒为单位。 注意 尽管设置名称包括IPv4 ，但 TCP 长连接时间值同时适用于 IPv4 和 IPv6。 要更改 TCP 长连接时间值，可以使用以下命令之一，以秒为单位提供：： sudo sysctl -w net.ipv4.tcp_keepalive_time= 或者： echo | sudo tee /proc/sys/net/ipv4/tcp_keepalive_time 这些操作不会在系统重新启动时保持。要保持设置，请将以下行添加到 /etc/sysctl.conf，以秒为单位提供 ，然后重新启动计算机： net.ipv4.tcp_keepalive_time = 长连接值大于300秒（5分钟）将在 mongod and mongos 套接字上重写，并设置为300秒。 要在 Windows 上查看长连接设置，请发出以下命令： reg query HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters /v KeepAliveTime 默认情况下不存在注册表值。如果该值不存在，则使用系统默认值7200000毫秒或0x6ddd00（十六进制）。 要更改长连接时间值，请在管理员命令提示符中使用以下命令，该命令以十六进制表示（例如120000是0x1d4c0）： reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\ /t REG_DWORD /v KeepAliveTime /d Windows用户应考虑 Windows服务器 Technet 关于长连接时间值的文章 以获取有关在 Windows系统上设置 MongoDB 部署长连接的详细信息。 mongod and mongos 将忽略大于或等于600000毫秒（10分钟）的长连接值。 VMware MongoDB 与 VMware 兼容。 VMware支持内存过量使用，在这里，您可以为虚拟机分配比物理机可用更多的内存。当内存被过度使用时，管理程序会在虚拟机之间重新分配内存。VMware 的气球驱动（vmmemctl）回收那些被认为价值最低的页面。 气球驱动程序位于客户操作系统中。当气球驱动程序扩展时，可能导致客户操作系统从客户端应用程序中回收内存，从而干扰 MongoDB 的内存管理，影响 MongoDB 的性能。 不要禁用气球驱动程序和内存过载使用功能。这会导致虚拟机监控程序使用其交换，从而影响性能。相反，映射并保留运行 MongoDB 的虚拟机的全部内存。这可以确保，如果管理程序中存在由于过度提交配置而导致的内存压力，则气球不会在本地操作系统中膨胀。 通过设置VMware的关联规则，确保虚拟机留在特定的 ESX/ESXi 主机上。如果必须手动将虚拟机迁移到另一个主机，并且虚拟机上的 mongod 实例是最重要的，则必须先逐步关闭最重要的实例，然后关闭实例。 遵循 vMotion的网络最佳实践和 VMKernel。未能遵循最佳实践可能会导致性能问题，并影响副本集和分片集群的高可用性机制。 可以克隆运行 MongoDB 的虚拟机。您可以使用此函数启动新的虚拟主机，将其添加为副本集的成员。如果克隆启用了日志记录的虚拟机，则克隆快照将有效。如果不使用日志记录，首先停止mongod，然后克隆虚拟机，最后重新启动 mongod。 KVM MongoDB 与 KVM 兼容。 KVM支持内存超载使用，在这里，您可以为虚拟机分配比物理机可用更多的内存。当内存被过度提交时，管理程序会在虚拟机之间重新分配内存。KVM的气球驱动程序回收被认为价值最低的页面。 气球驱动程序位于客户操作系统中。当气球驱动程序扩展时，可能导致客户操作系统从客户端应用程序中回收内存，从而干扰 MongoDB 的内存管理，影响 MongoDB 的性能。 不要禁用气球驱动程序和内存过载使用功能。这会导致虚拟机监控程序使用其交换，从而影响性能。相反，映射并保留运行 MongoDB 的虚拟机的全部内存。这可以确保，如果管理程序中存在由于过度提交配置而导致的内存压力，则气球不会在本地操作系统中膨胀。 性能监控 注意 从4.0版开始，MongoDB为标准和副本集提供免费云监控。有关更多信息，请参阅免费监控。 iostat 在 Linux 上，使用 iostat 命令检查磁盘 I/O 是否是数据库的瓶颈。指定运行 iostat 时的秒数，以避免显示信息为自服务器启动以来的统计信息。 例如，以下命令将每隔一秒显示扩展统计信息和每个显示报告的时间，流量单位为MB/s： iostat -xmt 1 iostat中的关键字段： %util: 这是快速检查最有用的字段，它表示设备/驱动器使用时间的百分比。 avgrq-sz:平均请求大小。此值的较小数字反映了更多的随机IO操作。 bwm-ng bwm-ng 是用于监视网络使用的命令行工具。如果怀疑是基于网络的瓶颈，可以使用 bwm-ng 开始诊断进程。 备份 要备份 MongoDB 数据库，请参阅 MongoDB 备份方法概述。 附录 原文链接：https://docs.mongodb.com/manual/administration/production-notes/ 译者：孔令升 参见 原文 - Production Notes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/02-production-checklist-operations.html":{"url":"13-administration/02-production-checklist-operations.html","title":"Operations Checklist","keywords":"","body":" Operations Checklist ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Operations Checklist Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/03-production-checklist-development.html":{"url":"13-administration/03-production-checklist-development.html","title":"Development Checklist","keywords":"","body":" Development Checklist ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Development Checklist Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/04-analyzing-mongodb-performance.html":{"url":"13-administration/04-analyzing-mongodb-performance.html","title":"Performance","keywords":"","body":" Performance ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Performance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/04-analyzing-mongodb-performance/01-manage-the-database-profiler.html":{"url":"13-administration/04-analyzing-mongodb-performance/01-manage-the-database-profiler.html","title":"Database Profiler","keywords":"","body":" Database Profiler ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Database Profiler Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/04-analyzing-mongodb-performance/01-manage-the-database-profiler/01-database-profiler.html":{"url":"13-administration/04-analyzing-mongodb-performance/01-manage-the-database-profiler/01-database-profiler.html","title":"Database Profiler Output","keywords":"","body":" Database Profiler Output ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Database Profiler Output Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/04-analyzing-mongodb-performance/02-transparent-huge-pages.html":{"url":"13-administration/04-analyzing-mongodb-performance/02-transparent-huge-pages.html","title":"Disable Transparent Huge Pages (THP)","keywords":"","body":" Disable Transparent Huge Pages (THP) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Disable Transparent Huge Pages (THP) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/04-analyzing-mongodb-performance/03-ulimit.html":{"url":"13-administration/04-analyzing-mongodb-performance/03-ulimit.html","title":"UNIX ulimit Settings","keywords":"","body":" UNIX ulimit Settings ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - UNIX ulimit Settings Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance.html":{"url":"13-administration/05-configuration-and-maintenance.html","title":"配置和维护","keywords":"","body":" 配置和维护 本节介绍常规管理操作，包括更新MongoDB部署的配置。 运行时数据库配置 概述了常见的MongoDB配置和常见用例的最佳实践配置的示例。 升级至MongoDB的最新版本 介绍在不同版本之间升级MongoDB部署的基本过程。 管理mongod进程 启动、配置和管理运行 mongod 进程。 终止运行操作 使用db.killOp()和maxTimeMS()停止正在进行的MongoDB客户端操作。 轮转日志文件 归档当前日志文件并启动新的日志文件。 附： 运行时数据库配置：https://docs.mongodb.com/v4.2/administration/configuration/ 升级至MongoDB的最新版本：https://docs.mongodb.com/v4.2/tutorial/upgrade-revision/ 管理mongod进程：https://docs.mongodb.com/v4.2/tutorial/manage-mongodb-processes/ 终止运行操作：https://docs.mongodb.com/v4.2/tutorial/terminate-running-operations/ 轮转日志文件：https://docs.mongodb.com/v4.2/tutorial/rotate-log-files/ 原文链接：https://docs.mongodb.com/v4.2/administration/configuration-and-maintenance/configuration-and-maintenance 译者：孔令升 校对：徐扬 参见 原文 - Configuration and Maintenance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance/01-configuration.html":{"url":"13-administration/05-configuration-and-maintenance/01-configuration.html","title":"Run-time Database Configuration","keywords":"","body":" Run-time Database Configuration ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Run-time Database Configuration Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance/02-upgrade-revision.html":{"url":"13-administration/05-configuration-and-maintenance/02-upgrade-revision.html","title":"Upgrade to the Latest Revision of MongoDB","keywords":"","body":" Upgrade to the Latest Revision of MongoDB ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade to the Latest Revision of MongoDB Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance/03-manage-mongodb-processes.html":{"url":"13-administration/05-configuration-and-maintenance/03-manage-mongodb-processes.html","title":"Manage mongod Processes","keywords":"","body":" Manage mongod Processes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage mongod Processes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance/04-terminate-running-operations.html":{"url":"13-administration/05-configuration-and-maintenance/04-terminate-running-operations.html","title":"Terminate Running Operations","keywords":"","body":" Terminate Running Operations ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Terminate Running Operations Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/05-configuration-and-maintenance/05-rotate-log-files.html":{"url":"13-administration/05-configuration-and-maintenance/05-rotate-log-files.html","title":"Rotate Log Files","keywords":"","body":" Rotate Log Files ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Rotate Log Files Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness.html":{"url":"13-administration/06-data-center-awareness.html","title":"Data Center Awareness","keywords":"","body":" Data Center Awareness ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Data Center Awareness Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/01-workload-isolation.html":{"url":"13-administration/06-data-center-awareness/01-workload-isolation.html","title":"Workload Isolation in MongoDB Deployments","keywords":"","body":" Workload Isolation in MongoDB Deployments ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Workload Isolation in MongoDB Deployments Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding.html","title":"Zones","keywords":"","body":" Zones ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Zones Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding/01-manage-shard-zone.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding/01-manage-shard-zone.html","title":"Manage Shard Zones","keywords":"","body":" Manage Shard Zones ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Shard Zones Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding/02-sharding-segmenting-data-by-location.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding/02-sharding-segmenting-data-by-location.html","title":"Segmenting Data by Location","keywords":"","body":" Segmenting Data by Location ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Segmenting Data by Location Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding/03-sharding-tiered-hardware-for-varying-slas.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding/03-sharding-tiered-hardware-for-varying-slas.html","title":"Tiered Hardware for Varying SLA or SLO","keywords":"","body":" Tiered Hardware for Varying SLA or SLO ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Tiered Hardware for Varying SLA or SLO Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding/04-sharding-segmenting-shards.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding/04-sharding-segmenting-shards.html","title":"Segmenting Data by Application or Customer","keywords":"","body":" Segmenting Data by Application or Customer ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Segmenting Data by Application or Customer Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/02-zone-sharding/05-sharding-high-availability-writes.html":{"url":"13-administration/06-data-center-awareness/02-zone-sharding/05-sharding-high-availability-writes.html","title":"Distributed Local Writes for Insert Only Workloads","keywords":"","body":" Distributed Local Writes for Insert Only Workloads ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Distributed Local Writes for Insert Only Workloads Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/06-data-center-awareness/03-manage-shard-zone.html":{"url":"13-administration/06-data-center-awareness/03-manage-shard-zone.html","title":"Manage Shard Zones","keywords":"","body":" Manage Shard Zones ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Shard Zones Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups.html":{"url":"13-administration/07-backups.html","title":"MongoDB Backup Methods","keywords":"","body":" MongoDB Backup Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - MongoDB Backup Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/01-backup-with-filesystem-snapshots.html":{"url":"13-administration/07-backups/01-backup-with-filesystem-snapshots.html","title":"Back Up and Restore with Filesystem Snapshots","keywords":"","body":" Back Up and Restore with Filesystem Snapshots ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Back Up and Restore with Filesystem Snapshots Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/02-backup-and-restore-tools.html":{"url":"13-administration/07-backups/02-backup-and-restore-tools.html","title":"Back Up and Restore with MongoDB Tools","keywords":"","body":" Back Up and Restore with MongoDB Tools ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Back Up and Restore with MongoDB Tools Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/03-restore-replica-set-from-backup.html":{"url":"13-administration/07-backups/03-restore-replica-set-from-backup.html","title":"Restore a Replica Set from MongoDB Backups","keywords":"","body":" Restore a Replica Set from MongoDB Backups ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Restore a Replica Set from MongoDB Backups Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/04-backup-sharded-clusters.html":{"url":"13-administration/07-backups/04-backup-sharded-clusters.html","title":"Backup and Restore Sharded Clusters","keywords":"","body":" Backup and Restore Sharded Clusters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Backup and Restore Sharded Clusters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/04-backup-sharded-clusters/01-backup-sharded-cluster-with-filesystem-snapshots.html":{"url":"13-administration/07-backups/04-backup-sharded-clusters/01-backup-sharded-cluster-with-filesystem-snapshots.html","title":"Back Up a Sharded Cluster with File System Snapshots","keywords":"","body":" Back Up a Sharded Cluster with File System Snapshots ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Back Up a Sharded Cluster with File System Snapshots Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/04-backup-sharded-clusters/02-backup-sharded-cluster-with-database-dumps.html":{"url":"13-administration/07-backups/04-backup-sharded-clusters/02-backup-sharded-cluster-with-database-dumps.html","title":"Back Up a Sharded Cluster with Database Dumps","keywords":"","body":" Back Up a Sharded Cluster with Database Dumps ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Back Up a Sharded Cluster with Database Dumps Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/04-backup-sharded-clusters/03-schedule-backup-window-for-sharded-clusters.html":{"url":"13-administration/07-backups/04-backup-sharded-clusters/03-schedule-backup-window-for-sharded-clusters.html","title":"Schedule Backup Window for Sharded Clusters","keywords":"","body":" Schedule Backup Window for Sharded Clusters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Schedule Backup Window for Sharded Clusters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/04-backup-sharded-clusters/04-restore-sharded-cluster.html":{"url":"13-administration/07-backups/04-backup-sharded-clusters/04-restore-sharded-cluster.html","title":"Restore a Sharded Cluster","keywords":"","body":" Restore a Sharded Cluster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Restore a Sharded Cluster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/07-backups/05-recover-data-following-unexpected-shutdown.html":{"url":"13-administration/07-backups/05-recover-data-following-unexpected-shutdown.html","title":"Recover a Standalone after an Unexpected Shutdown","keywords":"","body":" Recover a Standalone after an Unexpected Shutdown ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Recover a Standalone after an Unexpected Shutdown Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/08-monitoring.html":{"url":"13-administration/08-monitoring.html","title":"Monitoring for MongoDB","keywords":"","body":" Monitoring for MongoDB ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Monitoring for MongoDB Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/08-monitoring/01-free-monitoring.html":{"url":"13-administration/08-monitoring/01-free-monitoring.html","title":"Free Monitoring","keywords":"","body":" Free Monitoring ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Free Monitoring Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/08-monitoring/02-monitor-with-snmp.html":{"url":"13-administration/08-monitoring/02-monitor-with-snmp.html","title":"Monitor MongoDB With SNMP on Linux","keywords":"","body":" Monitor MongoDB With SNMP on Linux ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Monitor MongoDB With SNMP on Linux Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/08-monitoring/03-monitor-with-snmp-on-windows.html":{"url":"13-administration/08-monitoring/03-monitor-with-snmp-on-windows.html","title":"Monitor MongoDB Windows with SNMP","keywords":"","body":" Monitor MongoDB Windows with SNMP ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Monitor MongoDB Windows with SNMP Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/08-monitoring/04-troubleshoot-snmp.html":{"url":"13-administration/08-monitoring/04-troubleshoot-snmp.html","title":"Troubleshoot SNMP","keywords":"","body":" Troubleshoot SNMP ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Troubleshoot SNMP Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/Development-Checklist.html":{"url":"13-administration/Development-Checklist.html","title":"开发检查表","keywords":"","body":" 开发检查表 数据持久性 架构设计 复制 分片 驱动 下面的清单以及操作清单列表提供了一些建议，帮助我们在生产环境下，避免MongoDB部署出现中的问题。 数据持久性 确保您的副本集包含至少三个带有w:majority 写关注的数据承载节点。副本集范围内的数据持久性需要三个数据承载节点。 确保所有实例都使用日志。 架构设计 MongoDB中的数据有一个动态设计。集合强制执行文档结构。这有助于迭代开发和多态性。然而，集合通常保存具有高度同质结构的文档。 有关详细信息，请参阅数据建模概念。 确定支持查询所需的集合集和所需的索引。除了_id 索引之外，您必须显式地创建所有索引：MongoDB不会自动创建除_id之外的任何索引。 确保架构设计支持您的部署类型：如果您计划使用分片集群进行水平扩展，请设计您的架构以包含一个强健的片键。片键通过确定MongoDB如何划分数据来影响读写性能。请参见：片键对集群操作的影响以获取有关片键应具有哪些质量的信息。一旦设置了片键，就不能更改它。 请确保您的架构设计不依赖长度不受限制的索引数组。通常，当这种索引数组的元素少于1000个时，可以获得最佳性能。 设计架构时请考虑文档大小限制。BSON文档大小限制为每个文档16MB。如果需要更大的文档，请使用GridFS。 复制 使用奇数个有投票权的成员来确保选举顺利进行。最多可以有7个有投票权的成员。如果您有偶数个投票成员，并且限制条件（如成本）禁止添加另一个辅助成员作为投票成员，则可以添加仲裁节点以确保票数为奇数。有关对3成员副本集（P-S-a）使用仲裁节点时的其他注意事项，请参阅副本集仲裁节点。 注意 对于以下MongoDB版本，对于具有仲裁器的副本集，与pv0（MongoDB 4.0+中不再支持）相比， pv1增加了 w:1 回滚的可能性： MongoDB 3.4.1 MongoDB 3.4.1 MongoDB 3.4.0 MongoDB 3.4.0 MongoDB 3.2.11 or earlier MongoDB 3.2.11 或者更早的版本 参见副本集协议版本。 通过使用监视工具 和指定适当的写入机制,，确保您的辅助文件保持最新。 不要使用辅助读取来扩展总体读吞吐量。请参阅：是否可以使用更多副本节点进行扩展，以了解读取扩展的概述。有关辅助读取的信息，请参阅：读取偏好 。 分片 确保片键将负载均匀地分配到分片上。请参见：片键以获取更多信息。 对需要根据切片数量进行扩展的工作负载使用目标操作。 对于MongoDB 3.4和更早版本，从主节点读取非目标或广播查询，因为这些查询可能对过时或孤立的数据敏感。 对于MongoDB 3.6和更高版本，辅助设备不再返回孤立数据，除非使用可用的读策略（这是与因果一致会话不关联时针对辅助设备读取的默认读取策略）。 从 MongoDB 3.6 开始，分片副本集的所有成员都维护块元数据，允许它们在不使用“可用”时过滤出孤立的数据。因此，不使用“可用”的非目标或广播查询可以安全地在任何成员上运行，并且不会返回孤立的数据。 \"可用\"的读取策略可以从辅助成员返回孤立文档，因为它不检查更新的块元数据。但是如果孤立文档的返回对于应用程序来说无关紧要，那么\"可用\"的读取策略提供了各种读取关注点中可能的最低延迟读取。 在将大数据集插入新的非哈希分片集合时需要预分割并手动平衡块。预分割和手动平衡使插入负载能够在分片之间分布，从而提高初始负载的性能。 驱动 利用连接池。大多数MongoDB驱动程序支持连接池。调整连接池大小以适合您的用例，从典型并发数据库请求数的110-115%开始。 请确保您的应用程序在副本集选择期间处理短暂的写入和读取错误。 请确保应用程序处理失败的请求，并在适用的情况下重试。驱动程序不会自动重试失败的请求。 对数据库请求重试使用指数退避逻辑。 如果需要限制数据库操作的执行时间。使用 cursor.maxTimeMS()读取和 wtimeout 写入。 原文链接：https://docs.mongodb.com/v4.2/administration/production-checklist-development/ 译者：孔令升 校对：徐扬 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/MongoDB-Backup-Methods.html":{"url":"13-administration/MongoDB-Backup-Methods.html","title":"MogoDB 备份方法","keywords":"","body":" MogoDB 备份方法 在本页 使用 Atlas 备份 使用 MongoDB Cloud 或者 Ops Manager 备份 通过拷贝基础数据文件备份 使用 mongodump 备份 当在生产环境中部署 MongoDB 时，应该制定一种策略，以备在发生数据丢失事件时捕获和还原备份。 使用 Atlas 进行备份 MongoDB 官方云服务 MongoDB Atlas 提供2种完全托管的备份方法 连续备份，它对群集中的数据进行增量备份，从而确保备份通常仅比操作系统落后几秒钟。利用 Atlas 连续备份，您可以从存储的快照或最近24小时内的选定时间点还原。您还可以查询连续备份快照。 云提供商快照,使用集群的云服务提供商的原生快照功能提供的本地化的备份存储。 使用 MongoDB Cloud Manage 或者 Ops Manager MongoDB Cloud Manager 是针对 MongoDB 的托管备份，监控和自动化服务。MongoDB Cloud Manager 支持用户在图形化界面操作备份和还原 MongoDB 副本集和分片集群. MongoDB Cloud Manager MongoDB Cloud Manager 支持 MongoDB 部署的备份和恢复 通过从 MongoDB 部署中读取操作日志数据，MongoDB Cloud Manager 持续备份 MongoDB 副本集和分片群集。MongoDB Cloud Manager 会按设置的时间间隔创建数据快照，还可以提供 MongoDB 副本集和分片群集的时间点恢复。 提示 使用其他 MongoDB 备份方法很难实现分片群集快照。 要开始使用 MongoDB Cloud Manager 备份，请注册 MongoDB Cloud Manager。有关 MongoDB Cloud Manager 的文档，请参阅 MongoDB Cloud Manager 的文档。 Ops Manager 借助 Ops Manager，MongoDB 用户可以在自己的基础架构上安装和运行驱动 MongoDB Cloud Manager 的相同核心软件。Ops Manager 是一种本地解决方案，具有与 MongoDB Cloud Manager 相似的功能，可与订阅的企业版高级功能一起使用。 For more information about Ops Manager, see the MongoDB Enterprise Advanced page and the Ops Manager Manual. 有关更多 Ops Manager，请看MongoDB 企业版高级高级功能 和 Ops Manager 操作手册. 通过复制基础数据文件进行备份 使用 AES256-GCM 的加密存储引擎的注意事项 对于使用 AES256-GCM 加密模式的加密存储引擎，AES256-GCM 要求每个进程都使用唯一的计数器块值和密钥。 对于配置了 AES256-GCM 密码加密存储引擎: 从热备份还原 从 4.2 开始，如果您通过“热”备份(即 mongod 正在运行)获取的文件进行还原，MongoDB 可以在启动时检测“脏”密钥并自动翻转数据库密钥以避免IV（初始化向量）重用。 从冷备份还原 但是, 如果您通过“冷”备份获取的文件恢复(即 mongod 没有在运行),则MongoDB无法在启动时检测到“脏”密钥，并且IV的重用会使机密性和完整性保证无效。 从4.2开始, 为了避免从冷的文件系统快照还原后重新使用密钥，MongoDB 添加了一个新的命令行选项 --eseDatabaseKeyRollover. 使用--eseDatabaseKeyRollover 选项启动, mongod 实例将回滚使用 AES256-GCM 密码配置的数据库密钥，然后退出。 提示 In general, if using filesystem based backups for MongoDB Enterprise 4.2+, use the “hot” backup feature, if possible. 通常，如果对 MongoDB Enterprise 4.2+ 使用基于文件系统的备份，情尽可能使用“热”备份功能。 For MongoDB Enterprise versions 4.0 and earlier, if you use AES256-GCM encryption mode, do not make copies of your data files or restore from filesystem snapshots (“hot” or “cold”). 对于 MongoDB Enterprise 4.0 及更早版本，如果您使用 AES256-GCM 加密模式，请不要复制数据文件或从文件系统快照（“热”或“冷”）还原。 使用文件系统快照备份 您可以通过复制MongoDB的基础数据文件来创建MongoDB部署的备份。 如果 MongoDB 存储数据文件的卷支持时间点快照，则可以使用这些快照在确切的时间创建 MongoDB 系统的备份。文件系统快照是操作系统卷管理器功能，并非特定于 MongoDB。借助文件系统快照，操作系统可以获取卷的快照以用作数据备份的基准。快照的机制取决于基础存储系统。例如，在 Linux 上，逻辑卷管理器（LVM）可以创建快照。同样，Amazon 的 EC2 EBS 存储系统支持快照。 要获取正在运行的 mongod 进程的正确快照，您必须启用日记功能，并且日记必须与其他MongoDB 数据文件位于同一逻辑卷上。如果未启用日记功能，则无法保证快照将保持一致或有效。 要获得分片群集的一致快照，必须禁用平衡器并在大约同一时间从每个分片以及配置服务器捕获快照。 欲了解更多信息，请参阅使用文件系统快照备份和恢复 和 使用文件系统快照备份分片集群使用 LVM 创建快照的完整说明。 使用 cp 或者 rsync 备份 如果存储系统不支持快照，可以直接使用 cp，rsync 或类似的工具拷贝文件。由于复制多个文件不是原子操作，因此必须mongod在复制文件之前停止对的所有写操作。否则，您将以无效状态复制文件。 通过复制基础数据生成的备份不支持副本集的时间点恢复，并且对于较大的分片群集很难管理。此外，这些备份更大，因为它们包括索引以及重复的基础存储填充和碎片。mongodump 相反，创建的备份较小。 使用 mongodump 备份 mongodump 从 MongoDB 数据库读取数据，并创建高保真 BSON 文件，该 mongorestore 工具可用于填充 MongoDB 数据库。 mongodump 和 mongorestore 是用于备份和还原小型 MongoDB 部署的简单高效的工具，但是对于捕获大型系统的备份而言并不是理想的选择。 mongodump 和 mongorestore针对正在运行的 mongod 进程进行操作，并且可以直接操作基础数据文件。默认情况下，mongodump 不捕获本地数据库的内容。 mongodump 仅捕获数据库中的文档。生成的备份是节省空间的，但是mongorestore 或 mongod恢复数据后，必须重建索引。 当连接一个 MongoDB 实例时，mongodump可能会对mongod的性能产生不利影响。如果您的数据大于系统内存，则查询会将工作集推出内存，从而导致页面错误。 应用程序可以在 mongodump 捕获输出的同时继续修改数据，对于副本集，当进行mongodump 操作时，mongodump 提供 --oplog 选项来包括它输出的oplog 实体。这允许响应的mongorestore恢复捕获的 oplog。要恢复创建时带了--oplog选项的备份，进行mongorestore操作是需要有 --oplogReplay选项。 但是对于副本集，请考虑使用 MongoDB Cloud Manager 或 Ops Manager。 注意 mongodump 和 mongorestore不能作为正在进行分片事务的4.2+版本分片群集的备份策略的一部分，因为使用创建的备份不会保持跨分片事务的原子性保证。 对于具有正在进行的分片事务的 4.2+ 版本分片集群，请使用以下一个协调的备份和还原过程，这些过程确实维护了跨分片事务的原子性保证： MongoDB Atlas, MongoDB Cloud Manager, or 或 MongoDB Ops Manager. 有关更多信息请参阅Back Up and Restore with MongoDB Tools 和 Back Up a Sharded Cluster with Database Dumps 译者：谢伟成 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/Operations-Checklist.html":{"url":"13-administration/Operations-Checklist.html","title":"操作检查表","keywords":"","body":" 操作检查表 文件系統 复制 分片 日志：WiredTiger存储引擎 硬件 部署到云硬件 操作系统配置 备份 监控 负载均衡 下面的清单和开发清单列表一同提供了一些建议，帮助您避免生产环境下MongoDB部署中的问题。 文件系统 将磁盘分区与RAID配置对齐。 避免对 dbPath 使用 NFS 驱动器。使用 NFS 驱动器可能导致性能下降和不稳定。 有关详细信息，请参阅：远程文件系统 。 VMware 用户应该通过 NFS 使用 VMware 虚拟驱动器。 Linux/Unix：将驱动器格式化为 XFS 或 EXT4。如果可能的话，使用 XFS，因为它通常在MongoDB 中运行得更好。 对于 WiredTiger 存储引擎，强烈建议使用XFS，以避免在将 EXT4 与 WiredTiger 一起使用时产生性能问题。 如果使用 RAID，可能需要使用 RAID 几何阵列配置 XFS。 Windows：使用 NTFS 文件系统。不要使用任何 FAT 文件系统（例如 FAT 16/32/exFAT）。 复制 验证所有非隐藏副本集成员在 RAM，CPU，磁盘，网络设置等方面的配置是否相同。 配置 oplog 的大小 以适合您的使用案例： 复制 oplog 窗口包括正常维护和停机时间窗口，以避免需要完全重新同步。 复制 oplog 窗口应涵盖从上次备份还原副本集成员所需的时间。 在 3.4 版本中更改：复制 oplog 窗口不再需要覆盖通过初始同步还原副本集成员所需的时间，因为在数据复制期间会提取 oplog 记录。但是，正在还原的成员必须在本地数据库中具有足够的磁盘空间，以便在此数据复制阶段的持续时间内临时存储这些 oplog 记录。 对于早期版本的 MongoDB，复制 oplog 窗口应涵盖通过初始同步还原副本集成员所需的时间。 确保您的副本集至少包含三个数据承载节点，这些节点与日志记录一起运行，并且为了可用性和持久性，您使用 w:\"majority\" 写策略发出写操作。 配置副本集成员时使用主机名，而不是IP地址。 确保所有 mongod 实例之间的完全双向网络连接。 确保每个主机都可以自行解决。 确保副本集包含奇数个投票成员。 确保 mongod 实例有0票或1票。 对高可用性，将副本集部署到至少三个数据中心。 分片 将 配置服务器放在专用硬件上，以便在大型集群中获得最佳性能。确保硬件有足够的 RAM 将数据文件完全保存在内存中，并且有专用的存储器。 根据生产配置指南部署 mongos 前端路由。 使用NTP来同步切分集群所有组件上的时钟。 确保 mongod, mongos 和配置服务器之间的完全双向网络连接。 使用 CNAMEs 将配置服务器标识到集群，以便可以在不停机的情况下重命名和重新编号配置服务器。 日志：WiredTiger存储引擎 确保所有实例都使用日志。 将日志放在其自己的低延迟磁盘上，以适应写密集型的工作负载。请注意，这将影响快照样式备份，因为构成数据库状态的文件将位于单独的卷上。 硬件 使用 RAID10 和 SSD 驱动器可获得最佳性能。 SAN 和虚拟化： 确保每个mongod 已为其 数据库文件存储路径配置了 IOPS，或者具有自己的物理驱动器或 LUN。 在虚拟环境中运行时，请避免使用动态内存特性，如内存膨胀。 避免将所有副本集成员放在同一个 SAN 上，因为 SAN 可能是单点故障。 部署到云硬件 Windows Azure：将 TCP 长连接（TCP长连接时间）调整为100-120。Azure 负载均衡器上的 TCP 空闲超时对于 MongoDB 的连接池行为太慢。有关详细信息，请参阅 Azure产品说明。 在具有高延迟存储的系统（如Microsoft Azure）上使用 MongoDB 版本 2.6.4 或更高版本，因为这些版本包括这些系统性能的改进。 操作系统配置 Linux 关闭透明大页。有关更多信息，请参见透明大页设置。 在存储数据库文件的设备上调整文件预读设置 。 对于 WiredTiger 存储引擎，无论存储介质类型（旋转磁盘、固态硬盘等）如何，请将文件预读设置在8到32之间，除非测试显示在较高的文件预读值中有可测量、可重复和可靠的好处。 MongoDB专业支持 可以提供关于交替文件预读配置的建议和指导。 如果在 RHEL/CentOS 上使用 tuned（动态内核调优工具），则必须自定义您的 tuned 配置文件。RHEL/CentOS 附带的许多 tuned 文件可能会对其默认设置的性能产生负面影响。将您选择的 tuned 文件自定义为： 禁用透明大页。有关说明，请参见使用 tuned 和 ktune。 无论存储介质类型如何，都将文件预读设置为8到32之间。有关详细信息，请参阅预读设置。 对SSD驱动器使用 noop 或 deadline 磁盘调度程序。 对来宾虚拟机中的虚拟化驱动器使用 noop 磁盘调度程序。 禁用 NUMA 或将 vm.zone_reclaim_mode 设置为0并运行具有节点交错的 mongod 实例。请参阅：MongoDB和NUMA硬件了解更多信息。 调整硬件上的 ulimit 值以适合您的用例。如果多个 mongod 或者 mongos 实例在同一用户下运行，请相应地缩放 ulimit 值。有关详细信息，请参见：UNIX ulimit 设置。 使用noatime作为 dbPath 挂载点。 为部署配置足够的文件句柄（fs.file max）、内核 pid 限制（kernel.pid_max）、每个进程的最大线程数（kernel.threads max）和每个进程的最大内存映射区域数（vm.max_map_count）。对于大型系统，以下值提供了一个良好的起点： fs.file-max 值为98000, kernel.pid_max 值为64000, kernel.threads-max 值为64000, 和 vm.max_map_count 值为128000 确保系统已配置交换空间。有关适当大小的详细信息，请参阅操作系统的文档。 确保系统默认的 TCP 长连接设置正确。TCP 长连接时间值300通常为副本集和分片集群提供更好的性能。有关详细信息，请参阅常见问题中的 TCP 保持时间是否影响MongoDB部署? 。 Window 考虑禁用 NTFS “最后访问时间”更新。这类似于在 Unix-like 系统上禁用atime。 使用默认分配单元大小的4096 字节格式化NTFS磁盘。 备份 安排定期测试备份和恢复过程，以便手头有时间估计，并验证其功能。 监控 使用 MongoDB Cloud Manager或者MongoDB 企业高级版中提供的本地解决方案- Ops Manager 或者另一个监控系统来监控关键数据库指标并为它们设置警报。包括以下指标的警报: 复制滞后 复制 oplog 窗口 断言 队列 页面错误 监视服务器的硬件统计信息。尤其要注意磁盘使用、CPU 和可用磁盘空间。 在没有磁盘空间监视的情况下，以下方案作为预防措施： 在storage.dbPath驱动器上创建一个4 GB的虚拟文件，以确保磁盘满时有可用空间。 如果没有其他监视工具可用，cron+df 的组合可以在磁盘空间达到高水位时发出警报。 负载均衡 将负载平衡器配置为启用“粘滞会话”或“客户端亲和性”，并为现有连接提供足够的延时。 避免在 MongoDB 集群或副本集组件之间放置负载平衡器。 原文链接：https://docs.mongodb.com/manual/administration/production-checklist-operations/ 译者：孔令升 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"13-administration/Performance.html":{"url":"13-administration/Performance.html","title":"MongoDB性能","keywords":"","body":" MongoDB性能 在本页 锁性能 连接数 数据库性能 全时诊断数据采集 当您开发和操作基于MongoDB的应用时，您或许需要分析应用和数据库的性能表现。应用的性能降级通常是因为数据库访问策略、硬件可用性和数据库连接数设置不正确导致的。 一些用户可能因为采用不合适的索引策略，或使用糟糕的表设计模式，而遭遇应用或数据库性能瓶颈。锁性能章节 探讨这些因素如何对MongoDB内部的死锁产生影响。 性能问题可能说明数据库正在按容量临界值执行，是时候为数据库添加额外的服务器资源。通常应用程序的工作集需与服务器可用物理内存相匹配。 某些性能问题可能是暂时的，与不正常负载有关。连接数章节，讨论了一些通过数量缩放释放过度负载的措施。 Database Profiling can help you to understand what operations are causing degradation. 数据库性能章节或许可以帮助您了解什么类型的操作会造成性能降级。 锁性能 MongoDB使用一套锁机制确保数据集的一致性。如果某个操作执行时间较长或是一个队列表单，下一操作请求由于要等待当前操作释放锁而出现性能降级。 与锁相关的慢查询可能是间歇性的，确定是否由于死锁影响了应用性能，请参考serverStatus 输出内容中的 锁 部分和 全局锁 部分。 locks.timeAcquiringMicros除以locks.acquireWaitCount能计算出特定锁模式的平均等待时间。 locks.deadlockCount获取死锁次数。 如果 globalLock.currentQueue.total 值持续较高，有可能有大量的请求在等待锁释放。说明可能有影响性能的并发问题。 如果 globalLock.totalTime 相对于 uptime 较高，说明数据库的死锁已经维持一段时间了。 慢查询可能的原因：索引的无效使用；非最优表设计模式；糟糕的查询结构；系统架构问题；内存不足触发磁盘读取。 连接数 某些情形下，应用和数据之间的连接数可能超出了服务器能处理的请求数，serverStatus json文档中的一些属性可以提供一些洞察。 是如下两个字段的容器： connections.current 是连接到当前数据库实例的客户端连接总数。 connections.available 是可以给新客户端使用的剩余连接总数。 如果有大量的并发应用请求，数据库可能无法满足需求。您可能需要对数据库进行扩容。 对于“读”较频繁的应用，您需要增加 复制集 的大小并将读操作路由到 secondary 节点 对于“写”较频繁的应用，部署 分片 并添加多个 分片 到 分片集 分散 mongod 实例之间的负载。 连接数峰值也可能是应用程序或驱动程序错误的结果。所有官方MongoDB驱动均实现了连接池，支持客户端更高效的使用和复用连接对象。高连接数却未发现相匹配的负载，可能说明驱动或者其他配置发生错误。 通过设置maxIncomingConnections 配置指定mongoDB支持的最大传入连接数，该值不可超过操作系统最大范围限制。Unix类操作系统中，系统最大范围限制可以通过 ulimit 命令修改，或通过编辑 /etc/sysctl 文件修改。更多详情参见 UNIX ulimit 设置 章节。 数据库性能 数据库分析器 收集MongoDB实例上执行操作的详细信息。“分析器”的输出能帮助用户识别无效查询和操作。 您可以给一个 mongod 实例的单个或全部数据库开启和配置数据库分析器。分析器的配置仅作用于单个 mongod 实例，并不会在复制集 或 分片集 上传播。 开启和配置分析器参见 数据库分析器 章节。 以下分析级别可用： 级别 描述 0 分析器关闭且不收集数据，默认配置0。 1 分析器对执行时间超过 slowms 阈值的操作进行数据收集 2 分析器对所有操作进行数据收集 重要 分析器会影响性能且与系统日志共享配置。生产环境开启或设置分析器前请认证考虑性能和安全性影响。 分析器可能造成的潜在性能降级参见 分析器开销 章节 注意 当logLevel设置成0时，MongoDB慢查询将以slowOpSampleRate确定的采样速率发送到诊断日志。从MongoDB 4.2开始，复制集Secondaries节点的所有超过慢查询阈值的oplog条目信息都将输出 ，并不遵从这一采样速率。更高级别的 logLevel 配置下，所有操作都将显示在诊断日志中，无论其延迟时间如何，除了：secondaries节点的慢oplog条目消息的记录的日志。secondaries节点日志只记录慢的oplog条目；增加 logLevel 不会记录所有oplog条目。 从MongoDB 4.2开始， profiler entries(分析器实体) 和 读/写操作的diagnostic log messages (i.e. mongod/mongos log messages)(诊断日志消息，例如：mongod/mongos 日志消息)包括： queryHash 帮助判别有相同 query shape 的慢查询。 planCacheKey 对慢查询的 query plan cache 查询计划缓存 提供更多详情。 诠释诊断数据采集 “mongod”和“mongos”进程包括一个全时诊断数据收集（FTDC）机制，以便于MongoDB公司工程师对MongoDB服务器运行情况进行分析。FTDC数据文件是不可读压缩格式，并且继承与MongoDB数据文件相同的文件访问权限。只有能够访问FTDC数据文件的用户才能传输FTDC数据。工程师不能独立于系统所有者或运营人员访问FTDC数据。MongoDB进程默认运行FTDC。更多MongoDB支持选项请查看 Getting Started With MongoDB Support。 FTDC隐私 FTDC数据文件是的不可读压缩格式。MongoDB公司工程师没有系统所有者或运营者的明确许可和帮助，不能访问FTDC数据。 FTDC数据 从不 包含如下类型信息： 查询、查询谓词或查询结果的示例 从任何最终用户集合或索引中采样的数据 系统或MongoDB用户凭据或安全证书 FTDC data包含某些主机信息，例如：主机名称，操作系统信息，和用于启动mongod 或 mongos的配置。这些信息可能被某些组织或监管机构视为受保护或机密，但通常不被视为个人身份信息（PII）。对于这些字段配置了受保护、机密或PII数据的集群，请在发送FTDC数据之前通知MongoDB公司工程师，以便采取适当的措施。 FTDC定期收集由以下命令生成的统计信息： serverStatus replSetGetStatus(仅mongod) 对 local.oplog.rs 表的 collStats 命令。(仅mongod) connPoolStats(仅mongos) 依赖于主机操作系统，诊断数据可能包括如下统计： CPU使用率 内存使用率 与性能相关的磁盘利用率。FTDC不包括与存储容量相关的数据。 网络性能统计。FTDC只捕获元数据，不捕获或检查任何网络数据包。 FTDC收集在文件交换或启动时以下命令生成的统计信息 getCmdLineOpts buildInfo hostInfo mongod进程将FTDC数据文件存储在mongoDB实例 storage.dbPath 下的 diagnostic.data 目录中。所有诊断数据文件被存储在这个路径下。举例：dbPath 设置成 /data/db ，诊断数据路径则是 /data/db/diagnostic.data。 mongos 进程将FTDC数据文件存储在相对于 systemLog.path 日志路径设置的诊断目录中。MongoDB截断日志文件扩展名，并将 diagnostic.data 连接到剩余的名称。举例： path 设置/var/log/mongodb/mongos.log，诊断数据路径为/var/log/mongodb/mongos.diagnostic.data。 FTDC默认按如下执行： 每秒进行数据采集 最大200MB“diagnostic.data”文件夹大小。 这些默认设置旨在向MongoDB公司工程师提供有用的数据，对性能或存储大小的影响最小。这些值仅在MongoDB公司工程师出于特定诊断目的需求时才需修改。 您能在MongoDB Github Repository查看FTDC源代码。ftdc_system_stats_*.ccp 文件具体定义捕获的任何特定于系统的诊断数据。 以 diagnosticDataCollectionEnabled: false 启动mongod 或 mongos，或者在配置文件 setParameter 中设置该选项，可关闭FTDC。 setParameter: diagnosticDataCollectionEnabled: false 关闭FTDC可能增加MongDB公司工程师分析和调试问题的时间和资源。 原文链接：https://docs.mongodb.com/manual/administration/analyzing-mongodb-performance/mongodb-performance 译者：程哲欣 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage.html":{"url":"14-storage.html","title":"存储","keywords":"","body":"存储 存储引擎是MongoDB负责管理数据的主要组件。MongoDB提供了多种存储引擎，允许你选择一个最适合你应用的存储引擎。 日志是在数据库硬关机时帮助数据库恢复的日志。有几个可配置的选项，允许日志在性能和可靠性之间取得平衡，适合你的特定用例。 GridFS是一个多功能的存储系统，适合处理大文件，例如那些超过16 MB文件大小限制的文件。 参见 原文 - Storage 译者：雪星 (snomiao@gmail.com) 于 2020 秋 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines.html":{"url":"14-storage/01-storage-engines.html","title":"storage-engines","keywords":"","body":"Storage Engines The storage engine is the component of the database that is responsible for managing how data is stored, both in memory and on disk. MongoDB supports multiple storage engines, as different engines perform better for specific workloads. Choosing the appropriate storage engine for your use case can significantly impact the performance of your applications. NOTE Starting in version 4.2, MongoDB removes the deprecated MMAPv1 storage engine. ➤ WiredTiger Storage Engine (Default) WiredTiger is the default storage engine starting in MongoDB 3.2. It is well-suited for most workloads and is recommended for new deployments. WiredTiger provides a document-level concurrency model, checkpointing, and compression, among other features. In MongoDB Enterprise, WiredTiger also supports Encryption at Rest. See Encrypted Storage Engine. ➤ In-Memory Storage Engine In-Memory Storage Engine is available in MongoDB Enterprise. Rather than storing documents on-disk, it retains them in-memory for more predictable data latencies. 参见 原文 - Storage Engines Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines/01-wiredtiger.html":{"url":"14-storage/01-storage-engines/01-wiredtiger.html","title":"WiredTiger 存储引擎","keywords":"","body":" WiredTiger 存储引擎 从MongoDB 3.2开始，WiredTiger存储引擎开始作为默认的存储引擎。 对于现有部署，如果未指定参数--storageEngine或storage.engine设置，则版本3.2+ mongod实例可以自动确定用于在--dbpath或storage.dbPath中创建数据文件的存储引擎。 请参阅默认存储引擎配置参数更改文档。 文档级别的并发 WiredTiger使用文档级并发控制进行写操作。 因此，多个客户端可以并发同时修改集合的不同文档。 对于大多数读写操作，WiredTiger使用乐观并发控制模式。 WiredTiger仅在全局、数据库和集合级别使用意向锁。 当存储引擎检测到两个操作之间存在冲突时，将引发写冲突，从而导致MongoDB自动重试该操作。 一些全局操作（通常是涉及多个数据库的短暂操作）仍然需要全局“实例范围级别的”锁。 其他一些操作（例如删除集合）仍然需要独占数据库锁。 快照与检查点 WiredTiger使用MultiVersion并发控制（MVCC）方式。 在操作开始时，WiredTiger为操作提供数据的时间点快照。 快照提供了内存数据的一致视图。 写入磁盘时，WiredTiger将所有数据文件中的快照中的所有数据以一致的方式写入磁盘。 现在持久的数据充当数据文件中的检查点。 该检查点可确保数据文件直到最后一个检查点（包括最后一个检查点）都保持一致； 即检查点可以充当恢复点。 从3.6版本开始，MongoDB配置WiredTiger以60秒的间隔创建检查点（即将快照数据写入磁盘）。 在早期版本中，MongoDB将检查点设置为在WiredTiger中以60秒的间隔或在写入2GB日志数据时对用户数据进行检查，以先到者为准。 在写入新检查点期间，先前的检查点仍然有效。 这样，即使MongoDB在写入新检查点时终止或遇到错误，重启后，MongoDB仍可从上一个有效检查点恢复。 当WiredTiger的元数据表被原子更新以引用新的检查点时，新的检查点将变为可访问且永久的。 一旦可以访问新的检查点，WiredTiger就会从旧的检查点释放页面。 使用WiredTiger，即使没有日记，MongoDB也可以从最后一个检查点恢复； 但是，要恢复上一个检查点之后所做的更改，请运行日志功能。 注意 从MongoDB 4.0开始，您不能指定--nojournal选项或storage.journal.enabled：使用WiredTiger存储引擎的副本集成员为false。 日志 WiredTiger将预写日志（即日志）与检查点结合使用以确保数据持久性。 WiredTiger日记保留检查点之间的所有数据修改。 如果MongoDB在检查点之间退出，它将使用日志重播自上一个检查点以来修改的所有数据。 有关MongoDB将日记数据写入磁盘的频率的信息，请参阅日志处理。 WiredTiger日志使用快速压缩库进行压缩。 要指定其他压缩算法或不进行压缩，请使用storage.wiredTiger.engineConfig.journalCompressor设置参数。 有关更改日志压缩器的详细信息，请参阅“更改WiredTiger日志压缩器”文档。 注意 如果日志记录小于或等于128字节（WiredTiger的最小日志记录大小），则WiredTiger不会压缩该记录。 您可以通过将storage.journal.enabled设置为false来禁用独立实例的日志记录，这可以减少维护日志记录的开销。 对于独立实例，不使用日志意味着MongoDB意外退出时，您将丢失最后一个检查点之前的所有数据修改信息。 注意 从MongoDB 4.0开始，您不能指定--nojournal选项或storage.journal.enabled：使用WiredTiger存储引擎的副本集成员为false。SEE ALSO 也可以参考Journaling with WiredTiger使用WiredTiger日志 压缩 使用WiredTiger，MongoDB支持对所有集合和索引进行压缩。 压缩可最大程度地减少存储空间的使用量，但会增加CPU的开销。 默认情况下，WiredTiger对所有集合使用块压缩和snappy压缩库，对所有索引使用前缀压缩。 对于集合，还提供以下块压缩库： zlib zstd (Available starting in MongoDB 4.2) 要指定替代压缩算法或不压缩，请使用storage.wiredTiger.collectionConfig.blockCompressor参数设置。 zstd（从MongoDB 4.2开始支持） 对于索引，要禁用前缀压缩，请使用storage.wiredTiger.indexConfig.prefixCompression设置。 压缩设置还可以在集合和索引创建期间基于每个集合和每个索引进行配置。 请参见指定存储引擎选项和db.collection.createIndex（）storageEngine选项。 对于大多数压缩工作负载，默认压缩设置可以平衡存储效率和处理要求。 默认情况下，WiredTiger日志也被压缩。 有关日志压缩的信息，请参阅日记。 内存使用 通过WiredTiger，MongoDB可以利用WiredTiger内部缓存和文件系统缓存。 从MongoDB 3.4开始，默认的WiredTiger内部缓存大小是以下两者中的较大者： 50％（RAM-1 GB）或256 MB。 例如，在总共有4GB RAM的系统上，WiredTiger缓存将使用1.5GB RAM（0.5 （4 GB-1 GB）= 1.5 GB）。 相反，总内存为1.25 GB的系统将为WiredTiger缓存分配256 MB，因为这是总RAM的一半以上减去一GB（0.5 （1.25 GB-1 GB）= 128 MB 注意 在某些情况下，例如在容器中运行时，数据库的内存限制可能低于系统总内存。 在这种情况下，此内存限制而不是系统总内存将用作最大可用RAM。 要查看内存限制，请参阅hostInfo.system.memLimitMB。 默认情况下，WiredTiger对所有集合使用Snappy块压缩，对所有索引使用前缀压缩。 压缩默认值是可以在全局级别配置的，也可以在收集和索引创建期间基于每个集合和每个索引进行设置。 WiredTiger内部缓存中的数据与磁盘格式使用不同的表示形式： 文件系统缓存中的数据与磁盘上的格式相同，包括对数据文件进行任何压缩的好处。 操作系统使用文件系统缓存来减少磁盘I/O。 加载到WiredTiger内部缓存中的索引具有与磁盘上格式不同的数据表示形式，但仍可以利用索引前缀压缩来减少RAM使用量。 索引前缀压缩可从索引字段中删除通用前缀。 WiredTiger内部缓存中的集合数据未经压缩，并使用与磁盘格式不同的表示形式。 块压缩可以节省大量的磁盘存储空间，但是必须对数据进行解压缩才能由服务器进行处理。 通过文件系统缓存，MongoDB自动使用WiredTiger缓存或其他进程未使用的所有可用内存。 要调整WiredTiger内部缓存的大小，请参阅storage.wiredTiger.engineConfig.cacheSizeGB和--wiredTigerCacheSizeGB。 避免将WiredTiger内部缓存的大小超过其默认值以上。 译者：徐雷 参见 原文 - WiredTiger Storage Engine Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines/01-wiredtiger/01-change-standalone-wiredtiger.html":{"url":"14-storage/01-storage-engines/01-wiredtiger/01-change-standalone-wiredtiger.html","title":"Change Standalone to WiredTiger","keywords":"","body":" Change Standalone to WiredTiger ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change Standalone to WiredTiger Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines/01-wiredtiger/02-change-replica-set-wiredtiger.html":{"url":"14-storage/01-storage-engines/01-wiredtiger/02-change-replica-set-wiredtiger.html","title":"Change Replica Set to WiredTiger","keywords":"","body":" Change Replica Set to WiredTiger ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change Replica Set to WiredTiger Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines/01-wiredtiger/03-change-sharded-cluster-wiredtiger.html":{"url":"14-storage/01-storage-engines/01-wiredtiger/03-change-sharded-cluster-wiredtiger.html","title":"Change Sharded Cluster to WiredTiger","keywords":"","body":" Change Sharded Cluster to WiredTiger ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Change Sharded Cluster to WiredTiger Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/01-storage-engines/02-inmemory.html":{"url":"14-storage/01-storage-engines/02-inmemory.html","title":"内存存储引擎","keywords":"","body":" 内存存储引擎 从MongoDB Enterprise 3.2.6开始，In-Memory内存存储引擎是64位版本中通用可用性（GA）的一部分。 除某些元数据和诊断数据外，In-Memory内存存储引擎不维护任何磁盘上的数据，包括配置数据、索引、用户凭据等。 通过避免磁盘I / O，内存中存储引擎使数据库操作的延迟更可预测。 指定In-Memory存储引擎 要选择in-memory内存存储引擎，配置启动参数即可： 用于--storageEngine选项设置inMemory；或者如果使用配置文件方式，则为storage.engine设置。 --dbpath，如果使用配置文件，则为storage.dbPath。 尽管内存存储引擎不会将数据写入文件系统，但它会在--dbpath中维护小型元数据文件和诊断数据以及用于构建大型索引的临时文件。 例如，从命令行输入参数命令： mongod --storageEngine inMemory --dbpath 或者，如果使用[YAML配置文件格式]（https://docs.mongodb.com/manual/reference/configuration-options/）： storage: engine: inMemory dbPath: 请参阅内存选项中有关此存储引擎的配置选项。 除与数据持久性相关的那些选项参数（例如日志记录或静态配置加密）外，大多数mongod配置选项均可用于in-memory内存存储引擎。 警告 进程关闭后，内存中存储引擎不会保留数据。 并发 in-memory内存存储引擎将文档级并发控制用于写入操作。 因此，多个客户端可以同时修改集合的不同文档。 内存使用 内存存储引擎要求其所有数据（包括索引，oplog（如果mongod实例是副本集的一部分）等）必须适合指定的--inMemorySizeGB命令行选项或中的storage.inMemory.engineConfig.inMemorySizeGB设置。 YAML配置文件。 默认情况下，in-memory 内存存储引擎使用50％的（物理RAM减去1GB）。 如果写操作将导致数据超过指定的内存大小，则MongoDB返回错误： “ WT_CACHE_FULL：操作将溢出缓存” 要指定新大小，请使用YAML配置文件格式的storage.inMemory.engineConfig.inMemorySizeGB设置： 或使用命令行选项--inMemorySizeGB启动服务： mongod --storageEngine inMemory --dbpath --inMemorySizeGB Durability 持久性 内存中存储引擎是非持久性的，不会将数据写入持久性存储。 非持久数据包括应用程序数据和系统数据，例如用户，权限，索引，副本集配置，分片群集配置等。 因此，日志或等待数据变得持久的概念不适用于内存中的存储引擎。 如果副本集的任何有投票权的成员使用内存存储引擎，则必须将writeConcernMajorityJournalDefault设置为false。 注意 从版本4.2（以及4.0.13和3.6.14）开始，如果副本集成员使用内存中的存储引擎（投票或不投票），但是副本集的writeConcernMajorityJournalDefault设置为true，则副本集成员记录a 启动警告。 将writeConcernMajorityJournalDefault设置为false时，MongoDB不会等待w：在确认写入之前，“多数”写入将写入磁盘日志。 这样，如果给定副本集中大多数节点的瞬时丢失（例如崩溃和重新启动），多数写入操作可能会回滚。 立即记录指定日记记录的写关注点的写操作。 当mongod实例由于shutdown命令或由于系统错误而关闭时，无法恢复内存中的数据。 事务 从MongoDB 4.2开始，副本集和分片群集上支持事务，其中： 主要成员使用WiredTiger存储引擎，辅助成员使用WiredTiger存储引擎或内存中存储引擎。 在MongoDB 4.0中，仅使用WiredTiger存储引擎的副本集支持事务。 注意 您无法在具有将writeConcernMajorityJournalDefault设置为false的分片的分片群集上运行事务，例如，具有使用in-memory 内存存储引擎的投票成员的分片集群。 部署架构 除了独立运行外，使用in-memory内存存储引擎的mongod实例还可以作为副本集的一部分或分片群集的一部分运行。 复制集 可以部署将in-memory内存存储引擎用作副本集一部分的mongod实例。 例如，作为三副本集的一部分，您可能需要修改配置： 两个mongod实例与内存存储引擎一起运行。 一个使用WiredTiger存储引擎运行的mongod实例。 将WiredTiger成员配置为隐藏成员（即hidden：true和优先级：0）。 使用此部署模型，只有与in-memory内存存储引擎一起运行的mongod实例才能成为主要实例。 客户端仅连接到内存存储引擎mongod实例。 即使两个运行内存存储引擎的mongod实例都崩溃并重新启动，它们也可以从运行WiredTiger的成员进行同步。 与WiredTiger一起运行的隐藏mongod实例会将数据持久保存到磁盘，包括用户数据，索引和复制配置信息。 注意 In-memory内存存储引擎要求其所有数据（如果mongod是副本集的一部分，则包括oplog等）都应适合指定的--inMemorySizeGB命令行选项或storage.inMemory.engineConfig.inMemorySizeGB设置。 请参阅内存使用。 分片集群 可以将使用内存存储引擎的mongod实例部署为分片群集的一部分。 例如，在分片群集中，您可以拥有一个由以下副本集组成的分片： 两个mongod实例与内存存储引擎一起运行 一个WiredTiger存储引擎运行的mongod实例。 将WiredTiger成员配置为隐藏成员（即hidden：true和优先级：0）。 在此分片节点上，添加标记inmem。 例如，如果此分片的名称为shardC，请连接到mongos并运行sh.addShardTag（）命令，添加标签。 例如， 向其他分片添加一个单独的标签persisted。 sh.addShardTag(\"shardA\", \"persisted\") sh.addShardTag(\"shardB\", \"persisted\") 对于应驻留在inmem分片上的每个分片集合，将标签inmem分配给整个块范围： `sh.addTagRange(\"test.analytics\", { shardKey: MinKey }, { shardKey: MaxKey }, \"inmem\")` 对于应该驻留在持久化分片上的每个分片集合，将标签持久化分配给整个块范围： `sh.addTagRange(\"salesdb.orders\", { shardKey: MinKey }, { shardKey: MaxKey }, \"persisted\")` 译者：徐雷 参见 原文 - In-Memory Storage Engine Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/02-journaling.html":{"url":"14-storage/02-journaling.html","title":"Journaling","keywords":"","body":" Journaling ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Journaling Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/02-journaling/01-manage-journaling.html":{"url":"14-storage/02-journaling/01-manage-journaling.html","title":"Manage Journaling","keywords":"","body":" Manage Journaling ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Manage Journaling Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/03-gridfs.html":{"url":"14-storage/03-gridfs.html","title":"GridFS","keywords":"","body":" GridFS ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - GridFS Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"14-storage/04-storage.html":{"url":"14-storage/04-storage.html","title":"常见问题解答:MongoDB 存储","keywords":"","body":" 常见问题解答:MongoDB 存储 在本页 存储引擎基础 是否支持在副本集中混用存储引擎？ WiredTiger存储引擎 数据存储诊断 本文档回答了有关MongoDB存储系统的常见问题。 存储引擎基础 什么是存储引擎？ 存储引擎是数据库的一部分，负责管理如何在内存和磁盘上存储数据。许多数据库支持多个存储引擎，其中不同的引擎对于特定的工作负载可能性能更好。例如，一个存储引擎可能为包含大量读取操作的工作负载提供更好的性能，而另一个引擎则可能为写入操作提供更高的吞吐量。 另请参阅 存储引擎 是否可以在副本集中混用不同的存储引擎？ 可以。您可以让副本集成员使用不同的存储引擎（比如WiredTiger和内存引擎） 注意： 从4.2版本以后，MongoDB彻底移除了废弃的MMAPv1存储引擎。 WiredTiger存储引擎 是否可以将现有的部署升级到WiredTiger引擎? 可以，请参考： 将单机节点转为WiredTiger 将副本集转为WiredTiger 将分片集群转为WiredTiger WiredTiger引擎能提供多少的压缩（比例）？ 压缩数据与未压缩数据的比率取决于您的数据和所使用的压缩库。默认情况下，WiredTiger中的集合数据使用的是Snappy块压缩, 也可以使用zlib和zstd压缩。索引数据默认情况下使用prefix压缩。 我应该将WiredTiger内部缓存设置为多大？ 对于WiredTiger，MongoDB可以利用WiredTiger内部缓存和文件系统缓存。 从MongoDB 3.4开始，默认的WiredTiger内部缓存大小是以下两者中的较大者： （RAM - 1 GB）/2 256 MB. 例如，在总共有4GB RAM的系统上，WiredTiger缓存将使用1.5GB RAM（0.5 *（4 GB-1 GB）= 1.5 GB）。 相反，总内存为1.25GB的系统将为WiredTiger缓存分配256MB，因为256MB大于总RAM减去1GB的一半（0.5 *（1.25 GB-1 GB）= 128 MB 。 注意： 在某些情况下，例如在容器中运行时，数据库的内存限制可能低于系统总内存。在这种情况下，内存限制不再是系统总内存，而是最大可用RAM。 关于内存限制，请参考hostInfo.system.memLimitMB。 默认情况下，WiredTiger对所有集合使用Snappy块压缩，对所有索引使用prefix压缩。压缩默认值是可以在全局级别配置的，也可以在集合和索引创建期间基于每个集合和每个索引进行设置。 WiredTiger内部缓存中的数据与磁盘格式使用不同的表示形式： 文件系统缓存中的数据与磁盘上的格式相同，包括所有对数据文件进行压缩的收益。操作系统使用文件系统缓存来减少磁盘I/O。 加载到WiredTiger内部缓存中的索引具有与磁盘格式不同的数据表示形式，但仍可以利用索引prefix压缩来减少RAM使用量。索引prefix压缩从索引字段中删除通用前缀。 WiredTiger内部缓存中的集合数据未经压缩，并使用与磁盘格式不同的表示形式。块压缩可以节省大量的磁盘存储空间，但是必须对数据进行解压缩才能由服务器端进行处理。 通过文件系统缓存，MongoDB自动使用WiredTiger缓存或其他进程未使用的所有可用内存。 要调整WiredTiger引擎的内部缓存大小，请参考storage.wiredTiger.engineConfig.cacheSizeGB以及--wiredTigerCacheSizeGB参数。应避免将WiredTiger内部缓存的大小增加到其默认值以上。 注意： storage.wiredTiger.engineConfig.cacheSizeGB限制WiredTiger内部缓存的大小。操作系统将使用可用的空闲内存进行文件系统缓存，从而允许压缩的MongoDB数据文件保留在内存中。此外，操作系统将使用任何可用的RAM来缓冲文件系统块和文件系统缓存。 为了容纳更多的RAM使用者，您可能需要降低WiredTiger内部缓存的大小。 默认的WiredTiger内部缓存大小值假定每台计算机有且仅有一个 mongod 实例。如果一台机器包含多个MongoDB实例，则应减小设置以容纳其他 mongod 实例。 如果您在无法访问系统中所有可用RAM的容器（例如lxc，cgroups，Docker等）中运行 mongod ，则必须将storage.wiredTiger.engineConfig.cacheSizeGB设置为小于该容器中可用的RAM数量。确切的数量取决于容器中运行的其他进程。请参考memLimitMB。 要查看有关缓存和淘汰率的统计信息，请参阅serverStatus命令返回的wiredTiger.cache字段的相关内容。 WiredTiger引擎多久写一次磁盘？ 检查点 从3.6版开始，MongoDB将WiredTiger配置为以60秒的间隔创建检查点（即将快照数据写入磁盘）。在早期的版本中，MongoDB将在WiredTiger中以60秒的间隔或在写满2GB日志数据时对用户数据进行创建检查点操作，两个条件中任意一个满足即可。 日志数据 WiredTiger在以下任一情况满足时会将缓存的日记记录同步到磁盘： 对于副本集成员（主或者从节点成员）， 是否有等待oplog条目的操作。需要等待oplog条目的操作包括： 针对oplog转发扫描查询 读取操作作为因果一致性会话的一部分 另外，对于从节点成员，在每批oplog条目被应用之后。 如果写操作包括或隐含了 j: true的写关注。 注意： 当 writeConcernMajorityJournalDefault 为true时，设置为\"majority\"的写关注隐含了j:true。 每隔100ms（参考 storage.journal.commitIntervalMs） WiredTiger创建新的日志文件时。由于MongoDB使用的日志文件大小限制为100MB，因此WiredTiger大约每100MB数据创建一个新的日志文件。 如何在WiredTiger引擎中回收磁盘空间？ WiredTiger存储引擎在删除文档时会维护数据文件中的空记录列表。WiredTiger可以重用此空间，但是并不会将其返回给操作系统，除非是在非常特殊的情况下。 WiredTiger引擎的可用于重用的空闲空间反映在 db.collection.stats() 的结果的wiredTiger.block-manager.file bytes availablefor reuse字段中。 为了使WiredTiger存储引擎可以将这些空闲空间归还给操作系统，可以对数据文件进行碎片整理。这可以通过compact命令实现。更多相关信息及其他考虑，请参考 compact。 数据存储诊断 如何确认一个集合的大小？ 要查看集合的统计信息，包括数据大小，请使用mongoshell中的db.collection.stats()方法。以下示例为在order集合上执行db.collection.stats()： db.orders.stats(); MongoDB同样提供了以下方法来返回集合的具体大小： db.collection.dataSize() 会返回集合中未压缩的数据大小，以字节为单位。 db.collection.storageSize() 会返回集合在磁盘上占用的大小，以字节为单位。如果集合的数据是压缩过的（WiredTiger引擎默认带数据压缩），则存储大小反映的是压缩后的大小，可能会比db.collection.storageSize() 返回的结果小一些。 db.collection.totalIndexSize会返回集合中所有索引的大小，以字节为单位。如果一个索引使用了前缀压缩（WiredTiger引擎默认索引使用前缀压缩），则返回的大小反映的是压缩后的大小。 以下的脚本会输出每个数据库的统计信息： db.adminCommand(\"listDatabases\").databases.forEach(function (d) { mdb = db.getSiblingDB(d.name); printjson(mdb.stats()); }) 以下的脚本会输出每个数据库中每个集合的统计信息： db.adminCommand(\"listDatabases\").databases.forEach(function (d) { mdb = db.getSiblingDB(d.name); mdb.getCollectionNames().forEach(function(c) { s = mdb[c].stats(); printjson(s); }) }) 如何确认集合中每个索引的大小？ 要查看为每个索引分配的数据大小，使用 db.collection.stats() 方法，然后查看返回结果文档中的indexSizes字段。 如果索引使用前缀压缩（这也是WiredTiger引擎的默认设置），返回的大小代表了压缩后的大小。 如何获得有关数据库存储使用的相关信息？ mongo shell中的 db.stats() 方法返回“激活”数据库的当前状态。有关返回字段的描述，请参考dbStats输出。 译者：刘翔 校对：牟天垒 参见 原文 - FAQ: MongoDB Storage Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq.html":{"url":"15-faq.html","title":"常见问题","keywords":"","body":"Frequently Asked Questions 常见问题 常见问题解答：MongoDB基础知识 常见问题解答：索引 常见问题解答：并发 常见问题解答：使用MongoDB分片 常见问题解答：复制和副本集 常见问题解答：MongoDB存储 常见问题解答：MongoDB诊断 常见问题解答：复制和副本集 参见 原文 - Frequently Asked Questions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/01-fundamentals.html":{"url":"15-faq/01-fundamentals.html","title":"常见问题解答：MongoDB基础知识","keywords":"","body":" 常见问题解答：MongoDB基础知识¶ 在本页面 MongoDB支持哪些平台？ MongoDB是否作为托管服务提供？ 集合（collection）与表（table）有何不同？ 如何创建数据库和集合？ 如何定义或修改集合模式？ MongoDB是否支持SQL？ MongoDB是否支持事务？ MongoDB是否处理缓存？ MongoDB如何解决SQL或查询注入问题？ 本文档回答了有关MongoDB的一些常见问题。 MongoDB支持哪些平台？¶ 有关支持的列表平台，请参阅 支持的平台。 MongoDB是否作为托管服务提供？ 是的。MongoDB Atlas是一种云托管的数据库即服务。有关更多信息，请访问MongoDB Atlas。 集合与表格有何不同？¶ MongoDB数据库将数据存储在集合collections中，而不是表table。集合包含一个或多个 BSON文档。文档类似于关系数据库表中的记录或行。每个文档都有 一个或多个字段；字段类似于关系数据库表中的列。 也可以看看 SQL到MongoDB映射图， MongoDB简介 如何创建数据库和集合？¶ 如果数据库不存在，MongoDB会在您第一次为该数据库存储数据时创建该数据库。 如果集合不存在，则在您第一次为该集合存储数据时创建该集合。[1] 因此，您可以切换到一个不存在的数据库 (use) 并执行以下操作： 复制 use myNewDB db.myNewCollection1.insertOne( { x: 1 } ) db.myNewCollection2.createIndex( { a: 1 } ) 如果数据库myNewDB和集合myNewCollection1尚不存在，insert操作将同时创建它们。 发生在myNewDB库创建之后的createIndex操作，将创建索引，并且如果集合不存在的话也会创建myNewCollection2 集合。如果myNewDb不存在，则该 createIndex操作还将创建myNewDB。 [1] 如果要指定特定集合选项，您也可以也可以使用显式db.createCollection创建集合，例如制定最大大小或文档验证规则。 如何定义或修改集合模式？¶ 在MongoDB中您无需为集合指定模式。尽管集合中的文档通常具有很大程度上相同的结构，但这不是必需的；也就是说，单个集合中的文档不需要具有相同的字段集。字段的数据类型在集合中的文档之间也可能不同。 要更改集合中文档的结构，请将文档更新为新结构。例如，添加新字段，删除现有字段或将字段值更新为新类型。 在版本3.2中进行了更改：从MongoDB 3.2开始，您可以在更新和插入操作期间对集合强制执行文档验证规则。 可以在显式创建集合时指定某些集合属性，例如指定最大大小，然后对其进行修改。请参阅db.createCollection和collMod。如果未指定这些属性，则无需显式创建集合，因为在首次存储集合的数据时，MongoDB会创建新的集合。 MongoDB是否支持SQL？ 不直接支持。但是，MongoDB自身确实支持丰富的查询语言。有关使用MongoDB查询语言的示例，请参阅 MongoDB CRUD操作。 您还可以使用 MongoDB Connector for BI 来使用SQL查询MongoDB集合。 如果您正在考虑将SQL应用程序迁移到MongoDB，请下载《MongoDB应用程序现代化指南》以获取最佳实践迁移指南，参考模式和其他有用的资源。 也可以看看 SQL到MongoDB的映射图 MongoDB是否支持事务？¶ 由于单个文档可以包含相关数据，否则这些相关数据将在关系模式中的各个父子表之间建模，因此MongoDB的原子单文档操作已经提供了满足大多数应用程序数据完整性需求的事务语义。可以在单个操作中写入一个或多个字段，包括对多个子文档和数组元素的更新。MongoDB提供的保证可确保在文档更新时完全隔离。任何错误都会导致操作回滚，以使客户端获得一致的文档视图。 但是，对于需要对多个文档（在单个或多个集合中）进行读写原子性的情况，MongoDB支持多文档事务： 在版本4.0中，MongoDB支持副本集上的多文档事务。 在版本4.2中，MongoDB引入了分布式事务，它增加了对分片群集上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。 有关MongoDB中事务的详细信息，请参阅 事务页面。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应代替高效的模式设计。对于许多应用场景， 非规范化数据模型（嵌入式文档和数组）将继续为您的数据和用例的最佳选择。也就是说，对于许多场景，对数据进行适当的建模将最大程度地减少对多文档事务的需求。 有关其他事务使用方面的注意事项（例如运行时限制和oplog大小限制），另请参见 生产注意事项。 MongoDB是否处理缓存？ 是的。MongoDB将最近使用的数据保留在RAM中。如果您为查询创建了索引，并且您的工作数据集适合RAM，那么MongoDB将从内存中进行所有查询。 MongoDB不缓存查询结果，以便为相同查询返回缓存结果。 有关MongoDB和内存使用的更多信息，请参阅WiredTiger和内存使用。 MongoDB如何解决SQL或查询注入问题？¶ BSON 当客户端程序在MongoDB中组合查询时，将构建BSON对象而不是字符串。因此，传统的SQL注入攻击并不是问题。更多细节和一些细微差别将在下面介绍。 MongoDB将查询表示为BSON对象。通常， 客户端驱动库提供了一个方便的，无注入的过程来构建这些对象。考虑下面的C ++示例： 复制 BSONObj my_query = BSON( \"name\" cursor = c.query(\"tutorial.persons\", my_query); 示例中，my_query将有一个诸如{ name : \"Joe\" }的值。如果my_query包含特殊字符，例如，,，:和{，查询将不匹配任何文档。例如，用户无法劫持查询并将其转换为删除。 JavaScript 注意 您可以通过--noscripting在命令行中传递选项或security.javascriptEnabled在配置文件中进行设置来禁用所有服务器端JavaScript的执行 。 以下所有MongoDB操作都允许您直接在服务器上运行任意JavaScript表达式： $where mapReduce 在这些情况下，您必须格外小心，以防止用户提交恶意JavaScript。 幸运的是，您可以在没有JavaScript的MongoDB中表达大多数查询，对于需要JavaScript的查询，可以在单个查询中混合使用JavaScript和非JavaScript。将所有用户提供的字段直接放在BSON字段中，并将JavaScript代码传递给该$where字段。 如果需要在$where子句中传递用户提供的值，则可以使用该CodeWScope机制来转义这些值。在范围文档中将用户提交的值设置为变量时，可以避免在数据库服务器上评估它们。 原文链接：https://docs.mongodb.com/manual/faq/fundamentals/ 译者：钟秋 update：小芒果 参见 原文 - FAQ: MongoDB Fundamentals Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/02-indexes.html":{"url":"15-faq/02-indexes.html","title":"常见问题解答：索引","keywords":"","body":" 常见问题解答：索引¶ 在本页面 如何创建索引？ 索引构建如何影响数据库性能？ 如何查看集合中存在哪些索引？ 如何查看查询是否使用索引？ 如何确定要索引的字段？ 如何查看索引的大小？ 写操作如何影响索引？ 本文档解决了有关MongoDB 索引的一些常见问题 。有关索引的更多信息，请参见 Indexes。 如何创建索引？¶ 要在集合上创建索引，请使用 db.collection.createIndex()方法。创建索引是一种管理性操作。通常，应用程序不应定期调用 db.collection.createIndex()。 注意 索引构建会影响性能；请参见 索引构建如何影响数据库性能？。管理员应在建立索引之前考虑性能影响。 索引构建如何影响数据库性能？¶ 针对已填充集合的MongoDB索引构建，需要针对该集合进行排他性读写锁定。在mongod释放锁定之前需要对集合进行读取或写入锁定的操作必须等待。 *在版本4.2中进行了更改。 对于功能兼容版本（fcv） \"4.2\"，MongoDB使用优化的构建过程，该过程仅在索引构建的开始和结束时都保留排他锁。其余的构建过程将产生交叉的读写操作。 对于功能兼容版本（fcv） \"4.0\"，默认的前台索引构建过程将保留整个索引构建的互斥锁。background索引在构建过程中不会获得排他锁。 有关索引构建过程的更多信息，请参见填充集合上的索引构建 。 基于副本集的索引具有特定的性能考虑因素和风险。有关更多信息，请参见复制环境中的索引构建。为了最大程度地减少对副本集（包括分片副本集）建立索引的影响，请使用在副本集上建立索引中所述的滚动索引生成过程。 要返回当前正在运行的索引创建操作的相关信息，请参阅Active Indexing Operations。要在主数据库或独立数据库上终止正在运行的索引创建操作mongod，请使用 db.killOp()。部分构建的索引将被删除。 您不能在副本集的辅助成员上终止复制索引构建。您必须首先在主数据库上删除索引。二级服务器将复制删除操作，并在索引构建完成后删除索引。索引建立和删除之后的所有其他复制将会终止。 如何查看集合中存在哪些索引？¶ 要列出集合的索引，请使用 db.collection.getIndexes()方法。 如何查看查询是否使用索引？ 要检查MongoDB如何处理查询，请使用 explain()方法。 如何确定要索引的字段？ 许多因素决定要索引的字段，包括 选择性，对多种查询的支持 以及索引的大小。更多信息，请参见 索引操作注意事项和 索引策略。 如何查看索引的大小？¶ db.collection.stats()包括一个为集合中的每个索引提供了大小信息的indexSizes文档。 根据其大小，一个索引可能无法放入内存。当您的服务器具有足够的RAM用于索引和其余工作集时，索引将加载进内存。当索引太大而无法放入RAM时，MongoDB必须从磁盘读取索引，这比从RAM读取要慢得多。 在某些情况下，索引不必完全适合RAM。有关详细信息，请参阅仅在RAM中保存最近使用值的索引。 写操作如何影响索引？ 写操作可能需要更新索引： 如果写入操作修改了索引字段，则MongoDB将更新所有键中包含该字段的索引。 因此，如果您的应用程序是大量写入操作，则索引可能会影响性能。 原文链接：https://docs.mongodb.com/manual/faq/indexes/ 译者：钟秋 update：小芒果 参见 原文 - FAQ: Indexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/03-concurrency.html":{"url":"15-faq/03-concurrency.html","title":"常见问题解答：并发","keywords":"","body":" 常见问题解答：并发 在本页面 MongoDB使用哪种类型的锁定？ MongoDB中中锁的粒度有多细？ 如何查看mongod实例上锁的状态？ 读或写操作是否会产生锁定？ 一些常见的客户端操作会采取什么锁定？ 哪些管理命令可以锁定数据库？ 哪些管理命令可以锁定集合？ MongoDB操作是否可以锁定多个数据库？ 分片如何影响并发？ 并发性如何影响副本集的主节点？ 并发如何影响副本集的从节点？ MongoDB是否支持事务？ MongoDB提供什么隔离保证？ MongoDB允许多个客户端读取和写入相同的数据。为了确保一致性，它使用锁定和其他 并发控制措施来防止多个客户端同时修改同一数据。这些机制共同保证了对单个文档的所有写入全部发生或完全不发生，并且客户端永远不会看到不一致的数据视图。 MongoDB使用哪种类型的锁定？ MongoDB使用多粒度锁定[1]，它允许操作锁定在全局，数据库或集合级别，并允许各个存储引擎在集合级别以下实现自己的并发控制（例如，在WiredTiger中的文档级别）。 MongoDB使用读-写锁，允许并发的读写操作以共享的方式访问资源（例如数据库或集合）。 除了用于读取的共享（S）锁定模式和用于写操作的排他（X）锁定模式之外，意向共享（IS）和意向排他（IX）模式还表明使用更精细的锁定粒度来读取或写入资源的意图 。当以一定的粒度锁定时，所有更高级别的锁定都使用意向锁来锁定。 例如，当锁定用于写的集合（使用排它X锁定模式）时，必须同时在意向排他（IX）锁定模式下锁定相应的数据库锁和全局锁。单个数据库可以同时在IS和IX模式下锁定，但是独占（X）锁不能与任何其他模式共存，共享（S）锁只能与意向共享（IS）锁共存。 锁是公平的，读取和写入按顺序排队。但是，为了优化吞吐量，当一个请求被授予时，所有其他兼容请求将同时被授予，从而有可能在冲突请求之前释放它们。例如，考虑X锁（排它锁）被释放的情况，并且冲突队列包含以下各项： IS → IS → X → X → S → IS 在严格的先进先出（FIFO）顺序中，将仅授予前两个IS模式。相反，MongoDB实际上将授予所有IS和S模式，一旦它们全部完成，它将授予X，即使在此期间新的IS或S请求已进入排队。由于授予将始终将所有其他请求移到队列中，因此任何请求都不会存在饿死等待问题。 在db.serverStatus()和db.currentOp()输出中，锁定模式表示如下： 锁模式 Description R 代表共享锁(S) W 代表排它锁(X) r 代表意向共享锁 (IS) w 代表意向排它锁 (IX) [1] 有关更多信息，请参见Wikipedia页面上的 多粒度锁定。 MongoDB中锁的粒度有多细？¶ 对于大多数读取和写入操作，WiredTiger使用乐观并发控制。WiredTiger仅在全局，数据库和集合级别使用意向锁。当存储引擎检测到两个操作之间存在冲突时，将引发写冲突，从而导致MongoDB对用户而言透明地重试该操作。 一些全局操作（通常是涉及多个数据库的短暂操作）仍然需要全局“实例范围”锁定。其他一些操作（如collMod）仍需要排他数据库锁。 如何查看mongod实例上的锁状态？¶ 要报告有关锁的锁使用率信息，请使用以下任何一种方法： db.serverStatus()， db.currentOp()， mongotop， mongostat，和/或 在MongoDB Cloud Manager或 Ops Manager，MongoDB企业版提供的先进的解决方案 具体而言，serverStatus输出中的locks文档或当前操作报告中的字段可提供有关 mongod 实例中锁的类型和锁争用的数量。 在db.serverStatus()和db.currentOp()输出中，锁定模式表示如下： 锁定模式 描述 R 表示共享（S）锁。 W 表示排他（X）锁。 r 表示共享意图（IS）锁。 w 表示意向排他（IX）锁。 要终止操作，请使用db.killOp()。 读或写操作是否会产生锁定？¶ 在某些情况下，读和写操作可以产生它持有的锁。 长时间运行的读写操作（例如查询，更新和删除）在许多情况下都会产生。MongoDB如果单个修改文档的操作，影响带有multi参数修改多个文档 update()操作，MongoDB也会产生锁定。 对于支持文档级并发控制的存储引擎（例如WiredTiger），当使用意向锁访问存储时不需要锁定，因为该锁是数据库和集合级别的全局锁定，不会阻塞其他读取和写入操作。但是，操作将定期产生锁定，例如： 避免长时间执行的存储性事务，因为这些事务可能需要在内存中保存大量数据； 作为中断响应点（interruption points），以便您可以取消长时间运行的操作； 允许需要排他访问集合的操作，例如索引/集合删除和创建。 一些常见的客户端操作会采取什么锁定？ 下表列出了一些操作以及它们用于文档级锁定存储引擎的锁定类型： 操作 数据库 集合级别锁 发出查询 r （意向共享） r （意向共享） 插入资料 w （意向排他） w （意向排他） 删除资料 w （意向排他） w （意向排他） 更新数据 w （意向排他） w （意向排他） 执行聚合操作 r （意向共享） r （意向共享） 创建索引（前台） W （排他） 创建索引（后台） w （意向排他） w （意向排他） 列出集合列表 r （意向共享）在版本4.0中更改。 映射减少操作 W（排他）和R（共享） w（意向排他）和r（意向共享） 哪些管理命令可以锁定数据库？ 某些管理命令可以较长时间排他锁定数据库。在某些部署中，对于大型数据库，您可以考虑使mongod实例脱机，以便客户端不受影响。例如，如果 mongod是副本集的一部分，请执行mongod脱机操作，让集合服务的其他成员请求负载。 以下管理操作需要在数据库级别上长时间进行排他锁定： 运作方式 方法 cloneCollectionAsCapped collMod compact convertToCapped renameCollectiondb.collection.renameCollection() 在版本4.2中进行了更改。如果在同一数据库中重命名集合，则该操作将对源集合和目标集合进行排他（W）锁定。在MongoDB 4.2之前的版本中，在同一数据库中重命名时，该操作将对数据库使用排他（W）锁。（仅）如果目标名称空间与源集合位于不同的数据库中，则锁定行为取决于版本：renameCollection（MongoDB 4.2.2和更高版本）在跨数据库重命名集合时，该操作在目标数据库上获得排他（W）锁，并阻塞该数据库上的其他操作，直到操作完成。（MongoDB 4.2.1和更早版本）在跨数据库重命名集合时，该操作采用全局排他（W）锁，并阻止其他操作，直到操作完成。 以下管理操作将锁定数据库，但仅在很短的时间内保持锁定： 运作方式 方法 authenticatedb.auth() createUserdb.createUser() 也可以看看 MongoDB操作是否可以锁定多个数据库？ 哪些管理命令可以锁定集合？¶ 在版本4.2中进行了更改。 以下管理操作需要在集合级别具有排他锁定： 运作方式 方法 createdb.createCollection()db.createView() createIndexesdb.collection.createIndex()db.collection.createIndexes() dropdb.collection.drop() dropIndexesdb.collection.dropIndex()db.collection.dropIndexes() renameCollectiondb.collection.renameCollection() 在版本4.2中进行了更改。如果在同一数据库中重命名集合，则该操作将对源集合和目标集合进行排他（W）锁定。在MongoDB 4.2之前的版本中，在同一数据库中重命名时，该操作将对数据库使用排他（W）锁。（仅）如果目标名称空间与源集合位于不同的数据库中，则锁定行为取决于版本：renameCollectionMongoDB 4.2.2及更高版本在跨数据库重命名集合时，该操作将对目标数据库进行排他（W）锁定，并阻塞该数据库上的其他操作，直到操作完成。MongoDB 4.2.1和更早版本在跨数据库重命名集合时，该操作将使用全局排他（W）锁，并阻止其他操作，直到操作完成。 reIndexdb.collection.reIndex() 在版本4.2中进行了更改。对于MongoDB 4.2.2和更高版本，这些操作在集合上获得排他（W）锁，并在集合上阻止其他操作，直到完成。对于MongoDB 4.0.0到4.2.1，这些操作采用全局排他（W）锁定并阻止其他操作，直到完成。 replSetResizeOplog 在版本4.2中进行了更改。对于MongoDB 4.2.2及更高版本，此操作对oplog集合进行排他（W）锁定，并阻止对集合的其他操作，直到完成。对于MongoDB 4.2.1和更早版本，此操作采用全局排他（W）锁定并阻止其他操作，直到完成。 在MongoDB 4.2之前的版本，以上命令操作了对数据库的排他锁，阻止所有数据库操作和它的汇集，直到操作完成。 MongoDB操作是否可以锁定多个数据库？ 以下MongoDB操作可能会在多个数据库上获得并持有锁： 运作方式 方法 db.copyDatabase() 此操作获得全局（W）排他锁，并阻止其他操作，直到完成为止。 reIndexdb.collection.reIndex() 在版本4.2中进行了更改。对于MongoDB 4.0.0到4.2.1，这些操作采用全局排他（W）锁定并阻止其他操作，直到完成。从MongoDB 4.2.2开始，这些操作仅获得排他（W）集合锁，而不是全局排他锁。在MongoDB 4.0之前，这些操作获得了排他（W）数据库锁。 renameCollection 在版本4.2中进行了更改。对于MongoDB 4.2.1和更早版本，此操作在重命名数据库之间的集合时会获得全局排他（W）锁，并阻止其他操作直到完成。从MongoDB 4.2.2开始，此操作仅在目标数据库上获得互斥（W）锁定，在源数据库上获得意向共享（r）锁定，并在源集合上获得共享（S）锁定，而不是全局排他锁。 replSetResizeOplog 在版本4.2中进行了更改。对于MongoDB 4.2.1和更早版本，此操作获得全局排他（W）锁并阻止其他操作，直到完成。从MongoDB 4.2.2开始，此操作仅在oplog 集合上获得排他（W）锁，而不是全局排他锁。 分片如何影响并发性？¶ [分片通过将集合分布在多个mongod实例，提高并发的能力，允许分片服务器（即mongos进程）来并发地执行针对下游mongod 实例的任意数量的操作。 在分片群集中，锁适用于每个单独的分片，而不适用于整个群集。也就是说，每个mongod实例都独立于分片群集中的其他实例，并使用自己的 锁。一个 mongod实例上的操作不会阻止任何其他实例上的操作。 并发性如何影响副本集上的主节点？¶ 对于副本集，当MongoDB写入主节点上的集合时 ，MongoDB还将写入主节点上的oplog-local数据库中的特殊集合。因此，MongoDB必须同时锁定集合所在的数据库和local 数据库。mongod必须同时锁定这两个库保持数据库一致，并确保写入操作，甚至包括复制，是“全有或全无”的操作。 写入副本集时，锁的范围适用于主节点。 并发如何影响副本集的从节点？¶ 在进行副本集复制同步时，MongoDB不会将写入连续的应用到 从节点。从节点批量收集oplog记录，然后并行应用这些批处理。从节点将按照出现在操作日志中的顺序应用写入操作。 从MongoDB 4.0开始，如果从节点正在复制，则读取从数据的WiredTiger快照读取的 目标从节点数据。这允许读取与复制同时进行，同时仍保证数据的一致视图。在MongoDB 4.0之前的版本中，将在所有正在进行的复制完成之前阻止对从节点的读取操作。有关更多信息，请参见多线程复制。 MongoDB是否支持事务？ 由于单个文档可以包含关联数据（译者注：通过内嵌文档或数组的方式），否则它们将在关系模式中的各个父子表之间建模，因此MongoDB的单文档原子操作已经提供了满足大多数应用程序数据完整性需求的事务语义。可以在单个操作中写入一个或多个字段，包括对多个子文档和数组元素的更新。MongoDB提供的保证可确保在文档更新时完全隔离。任何错误都会导致操作回滚，以使客户端获得一致的文档视图。 但是，对于需要对多个文档（在单个或多个集合中）进行读写原子性的情况，MongoDB支持多文档事务： 在版本4.0中，MongoDB支持副本集上的多文档事务。 在版本4.2中，MongoDB引入了分布式事务，它增加了对分片群集上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。 有关MongoDB中事务的详细信息，请参阅 事务页面。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应代替高效的模式设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，对数据进行适当的建模将最大程度地减少对多文档事务的需求。 有关其他事务使用方面的注意事项（例如运行时限制和oplog大小限制），另请参见 生产注意事项。 MongoDB提供什么隔离保证？ 根据读取的关注点，客户端可以在持久写入之前看到写入结果。要控制是否可以回滚读取的数据，客户端可以使用该readConcern选项。 有关信息，请参阅： 读取隔离，一致性和因近原则 原子性和事务 读关注 原文链接：https://docs.mongodb.com/manual/faq/concurrency/ 译者：钟秋 update:小芒果 参见 原文 - FAQ: Concurrency Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/04-sharding.html":{"url":"15-faq/04-sharding.html","title":"常见问题解答：使用MongoDB分片","keywords":"","body":" 常见问题解答：使用MongoDB分片 在本页面 新部署是否适合进行分片？ 在对集合进行分片后是否可以更改片键？ 为什么文档没有分布在各个分片上？ mongos如何检测分片群集配置中的更改？ 日志中出现的writebacklisten是什么意思？ mongos是如何使用连接的？ 本文档回答有关分片的常见问题。参见手册的分片章节，它提供了一个 分片的概述，包括如下细节： 片键和选择片键的注意事项 查询路由 高可用性 数据分块和 数据块迁移过程数据分区 对分片群集进行故障排除 新部署是否适合进行分片？¶ 有时适合。但是，如果您的数据集适合放在一台服务器上，则应从非分片的部署开始，因为分片的数据集很小，几乎没有优势。 在对集合进行分片后是否可以更改片键？ 不可以。 MongoDB中没有对集合进行分片后更改片键的自动支持。这一现实情况强调了选择好的片键的重要性。如果 必须在对集合进行分片之后更改片键，最佳选择是： 将MongoDB中的所有数据转储为外部格式。 删除原始分片集合。 使用更理想的片键配置分片。 预分割片键范围，以确保初始均匀分配。 将转储的数据恢复到MongoDB中。 尽管您不能为分片集合选择其他片键，但是从MongoDB 4.2开始，您可以更新文档的片键值，除非分片键字段是不可变_id字段。有关更新片键值的详细信息，请参阅“ 更改文档的片键值”。 在MongoDB 4.2之前，文档的片键字段值是不可变的。 参见片键 为什么文档没有分布在各个分片上？ 一旦数据块的分布达到特定阈值，均衡器就开始在各个分片之间迁移均衡数据。请参阅 迁移阈值。 此外，如果块中的文档数超过一定数量，MongoDB将无法移动块。请参阅 每个要迁移的块的最大文档数和不可分割的块。 mongos如何检测分片群集配置中的更改？¶ mongos实例维护配置数据库的缓存，该缓存包含分片集群的元数据。 mongos通过向分片发出请求并发现其元数据已过期，从而延迟更新其缓存。要强制 mongos重新加载其缓存，您可以针对每个mongos`直接运行flushRouterConfig命令。 日志中出现的writebacklisten是什么意思？ 回写监听器是一个进程，它打开一个长轮询，在迁移mongod或mongos后回写，以确保他们没有将其发送到错误的服务器。如果需要，回写监听器会将写入发送到正确的服务器。 这些消息是分片基础结构的关键部分，不需要引起关注。 mongos是如何使用连接的？ 每个mongos实例都维护一个与分片集群成员的连接池。客户端请求一次使用一个连接；即，请求不是多路复用或流水线的。 客户端请求完成后，mongos将连接返回到池中。当客户端数量减少时，这些池不会缩小。这可能会导致未使用的mongos占用大量打开的连接。如果mongos不再使用，则可以安全地重新启动进程以关闭现有连接。 要返回与mongos所使用的所有对外连接池相关的聚合统计信息，请将mongoshell 连接 到mongos，然后运行以下 connPoolStats命令： 复制 db.adminCommand(\"connPoolStats\"); 请参阅“ UNIX ulimit设置” 文档的“ 系统资源利用率”部分。 原文链接：https://docs.mongodb.com/manual/faq/sharding/ 译者：钟秋 update：小芒果 参见 原文 - FAQ: Sharding with MongoDB Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/05-replica-sets.html":{"url":"15-faq/05-replica-sets.html","title":"FAQ: Replication and Replica Sets","keywords":"","body":"常见问题解答：复制和副本集 在本页面 MongoDB支持哪种复制？ 复制是否可以通过Internet和WAN连接进行？ MongoDB可以通过“noisy”连接进行复制吗？ 如果复制已经提供了数据冗余，为什么还要使用journaling(预写日志，WAL)功能？ 仲裁节点与副本集的其它节点交换哪些信息？ 副本集成员使用不同大小的磁盘空间是否正常？ 我可以重命名副本集吗？ 本文档回答了有关MongoDB中复制的常见问题。另请参见手册中的“ 复制”部分，其中概述了复制，包括有关以下方面的详细信息： 副本集成员 副本集部署体系结构 副本集选举 MongoDB支持哪种复制？ MongoDB支持副本集，副本集最多可包含50个节点。 复制是否可以通过Internet和WAN连接进行？ 可以。 例如，在东海岸数据中心可以部署一个主节点和一个副节点 ，以及在西海岸数据中心部署一个作为灾难恢复的从节点成员。 参见 部署异地冗余的副本集 MongoDB可以通过“noisy”的连接进行复制吗？ 是的，但连接失败和非常明显的延迟的情况下不行。 集合中的成员将尝试重新连接到集合中的其他成员，以响应网络波动。这不需要管理员干预。但是，如果副本集中节点之间的网络连接非常慢，则节点成员可能无法跟上复制。 参见 副本集选举 如果复制已经提供了数据冗余，为什么还要使用journaling（预写日志，WAL）功能？ Journaling功能有助于加快崩溃恢复速度。 Journaling功能对于防止电源故障特别有用，尤其是当副本集位于单个数据中心或电源电路中时。 当副本集与Journaling一起运行时，您可以安全地重新启动 mongod实例，而无需其他干预。 注意 Journaling记录需要一些资源开销来进行写操作。但是，Journaling对读取性能没有影响。 默认情况下，在MongoDB v2.0及更高版本的所有64位版本上都启用Journaling功能。 仲裁节点与副本集的其余节点交换哪些信息？ 仲裁节点永远不会复制集合的数据内容，但会与副本集的其余节点交换以下数据： 用于副本集认证仲裁节点的凭据。这些交换数据是加密的。 副本集配置数据和投票数据。此信息未加密。仅加密交换凭证。 如果您的MongoDB部署使用TLS / SSL，则仲裁节点与副本集其他成员之间的所有通信都是安全的。 有关更多信息，请参阅有关为TLS / SSL配置mongod和mongos的文档。与所有MongoDB组件一样，应该在安全网络上运行仲裁节点。 参见 副本集仲裁成员概述 。 副本集成员使用不同大小的磁盘空间是否正常？ 正常。 因素包括：不同的oplog大小，不同程度的存储碎片以及MongoDB的数据文件预分配，都可能导致节点之间的存储利用率发生一些变化。当您在不同时间添加成员时，存储使用差异将最为明显。（译者注：可以理解为先后添加，因此上述存储碎片程度等差异就会比较明显，从而导致影响磁盘占用不同）。 我可以重命名副本集吗？ 不可以。 您可以使用“ 从MongoDB备份还原副本集”教程中描述的备份和还原过程来创建具有所需名称的新副本集。为了确保原始副本集和新副本集之间的奇偶校验，可能需要停机。 原文链接：https://docs.mongodb.com/manual/faq/replica-sets/ 译者：钟秋 update：小芒果 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/06-storage.html":{"url":"15-faq/06-storage.html","title":"常见问题解答：MongoDB存储","keywords":"","body":" 常见问题解答：MongoDB存储 在本页面 存储引擎基础知识 您可以在副本集中混用存储引擎吗？ WiredTiger存储引擎 数据存储诊断 本文档解决了有关MongoDB存储系统的常见问题。 存储引擎基础知识 什么是存储引擎？¶ 存储引擎是数据库的一部分，负责管理如何在内存和磁盘上存储数据。许多数据库支持多个存储引擎，其中不同的引擎在特定工作负载下性能更好。例如，一个存储引擎可能为读取大量工作负载提供更好的性能，而另一个可能为写入操作提供更高的吞吐量。 参见 储存引擎 您可以在副本集中混用存储引擎吗？ 可以。您可以让副本集成员使用不同的存储引擎（WiredTiger和内存中） 注意 从4.2版开始，MongoDB删除不推荐使用的MMAPv1存储引擎。 WiredTiger存储引擎 我可以将现有部署升级到WiredTiger吗？ 可以。参见： 将单机部署的存储引擎更改为WiredTiger 将副本集的存储引擎更改为WiredTiger 将分片集群的存储引擎更改为WiredTiger WiredTiger提供的压缩比率是多少？ 压缩数据与未压缩数据的比率取决于您的数据和使用的压缩算法库。默认情况下，WiredTiger中的集合数据使用Snappy块压缩；也可以使用zlib 和zstd压缩。索引数据默认使用前缀压缩。 我应该将WiredTiger内部缓存设置为多大？ 通过WiredTiger，MongoDB可以利用WiredTiger内部缓存和文件系统缓存。 从MongoDB 3.4开始，默认的WiredTiger内部缓存大小是以下两者中的较大者： 50％（内存大小 -1 GB），或 256 MB。 例如，在总共有4GB 内存的系统上，WiredTiger缓存将使用1.5GB RAM（0.5 * (4 GB - 1 GB) = 1.5 GB）。相反，总内存为1.25 GB的系统将为WiredTiger缓存分配256 MB，因为这是总内存的一半以上减去1 GB （0.5 * (1.25 GB - 1 GB) = 128 MB ）。 注意 在某些情况下，例如在容器中运行时，数据库的内存限制可能低于系统总内存。在这种情况下，此内存限制而不是系统总内存将用作最大可用内存。 要查看内存限制，请参阅hostInfo.system.memLimitMB。 默认情况下，WiredTiger对所有集合使用Snappy块压缩，对所有索引使用前缀压缩。压缩默认值是可以在全局级别配置的，也可以在每个集合和每个索引创建期间单独进行设置。 WiredTiger内部缓存中的数据与磁盘上的数据使用不同表示形式的数据格式： 文件系统缓存中的数据与磁盘格式相同，包括对数据文件进行的任何压缩的好处也是一样的。操作系统使用文件系统缓存来减少磁盘I / O。 加载到WiredTiger内部缓存中的索引的数据表示形式与磁盘格式不同，但是仍可以利用索引前缀压缩来减少内存使用量。索引前缀压缩可从索引字段中删除通用前缀。 WiredTiger内部缓存中的集合数据是未压缩的，并使用与磁盘格式不同的表示形式。块压缩可以节省大量的磁盘存储空间，但数据必须解压缩才能由服务器操作。 通过文件系统缓存，MongoDB自动使用WiredTiger缓存或其他进程未使用的所有可用内存。 要调整WiredTiger内部缓存的大小，请参阅 storage.wiredTiger.engineConfig.cacheSizeGB和 --wiredTigerCacheSizeGB。避免将WiredTiger内部缓存的大小增加到其默认值以上。 注意 storage.wiredTiger.engineConfig.cacheSizeGB限制WiredTiger内部缓存的大小。操作系统将使用可用的空闲内存进行文件系统缓存，从而允许压缩的MongoDB数据文件保留在内存中。此外，操作系统将使用任何可用的内存来缓冲文件系统块和文件系统缓存。 为了容纳更多的RAM使用者，您可能必须减小WiredTiger内部缓存的大小。 默认的WiredTiger内部缓存大小值假定每台计算机有一个mongod实例。如果一台机器包含多个MongoDB实例，则应减小设置以容纳其他mongod 实例。 如果您的mongod是运行在无法访问所有系统中所有可用的内存的容器（例如lxc， cgroups，Docker，等等）中时，您必须将storage.wiredTiger.engineConfig.cacheSizeGB的值设置为小于容器中可用内存大小的值。确切的大小取决于容器中运行的其他进程。请参阅 memLimitMB。 要查看有关缓存和缓存淘汰率的统计信息，请参阅wiredTiger.cache命令返回的serverStatus字段。 WiredTiger写入磁盘的频率如何？¶ Checkpoints（检查点） 从版本3.6开始，MongoDB将WiredTiger配置为以60秒的间隔创建检查点（即，将快照数据写入磁盘）。在早期版本中，MongoDB将检查点设置为在WiredTiger中以60秒的间隔或在写入2 GB的预写日志数据时，对用户数据进行检查，以先发生者为准。 Journal Data（预写日志数据） WiredTiger根据以下间隔或条件写入磁盘： 对于副本集成员（主节点和次节点成员）， 如果有等待操作日志输入的操作，可以等待操作日志条目的操作包括: 针对oplog转发扫描查询 读取操作，作为因果一致会话的一部分 另外，对于从节点成员，在每次批量处理oplog条目之后。 如果写入操作包括写关注的j参数： j: true 注意 如果writeConcernMajorityJournalDefault是真的，写关注\"majority\"参数为j: true。 每隔100毫秒（请参阅storage.journal.commitIntervalMs）。 WiredTiger创建新的日记文件时。由于MongoDB使用的预写日志文件大小限制为100 MB，因此WiredTiger大约每100 MB数据创建一个新的日志文件。 如何在WiredTiger中回收磁盘空间？ WiredTiger存储引擎在删除文档时会维护数据文件中的空记录列表。WiredTiger可以重用此空间，但是除非在非常特定的情况下，否则不会将其返回给操作系统。 WiredTiger可以重用的可用空间量反映在db.collection.stats()标题下的wiredTiger.block-manager.file bytes available for reuse输出中。 为了使WiredTiger存储引擎可以将此空白空间释放给操作系统，可以对数据文件进行碎片整理。这可以使用compact命令来实现。有关其行为和其他注意事项的更多信息，请参见compact。 数据存储诊断¶ 如何查看集合的大小？ 要查看集合的统计信息，包括数据大小，请使用mongo shell程序中的db.collection.stats()方法(https://docs.mongodb.com/manual/reference/program/mongo/bin.mongo)。以下示例为`orders`集合执行[db.collection.stats()`](https://docs.mongodb.com/manual/reference/method/db.collection.stats/db.collection.stats)： 复制 db.orders.stats(); MongoDB还提供以下方法来返回集合的特定大小信息： db.collection.dataSize() 返回该集合的未压缩数据大小（以字节为单位）。 db.collection.storageSize()返回磁盘存储上集合的大小（以字节为单位）。如果集合数据被压缩（即default for WiredTiger），则存储大小将反映压缩后的大小，并且可能小于db.collection.dataSize()所返回的值 。 db.collection.totalIndexSize()返回集合的索引大小（以字节为单位）。如果索引使用前缀压缩（即default for WiredTiger），则返回的大小将反映压缩后的大小。 以下脚本打印每个数据库的统计信息： 复制 db.adminCommand(\"listDatabases\").databases.forEach(function (d) { mdb = db.getSiblingDB(d.name); printjson(mdb.stats()); }) 以下脚本打印每个数据库中每个集合的统计信息： 复制 db.adminCommand(\"listDatabases\").databases.forEach(function (d) { mdb = db.getSiblingDB(d.name); mdb.getCollectionNames().forEach(function(c) { s = mdb[c].stats(); printjson(s); }) }) 如何检查集合的各个索引的大小？¶ 要查看为每个索引分配的数据大小，请使用 db.collection.stats()方法并检查返回文档中的indexSizes字段。 如果索引使用前缀压缩（即default for WiredTiger），则该索引的返回大小将反映压缩后的大小。 如何获得有关数据库存储使用的信息？¶ mongo shell中的db.stats()方法返回“活跃”数据库的当前状态。有关返回的字段的说明，参见dbStats Output。 原文链接：https://docs.mongodb.com/manual/faq/storage/ 译者：钟秋 update:小芒果 参见 原文 - FAQ: MongoDB Storage Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"15-faq/07-diagnostics.html":{"url":"15-faq/07-diagnostics.html","title":"常见问题解答：MongoDB诊断","keywords":"","body":" 常见问题解答：MongoDB诊断 在本页面 在哪里可以找到有关mongod进程意外停止运行的信息？ TCP keepalive时间会影响MongoDB部署吗？ 为什么MongoDB会记录这么多“Connection Accepted”事件？ 哪些工具可用于监视MongoDB？ WiredTiger存储引擎的内存诊断 分片集群诊断 本文档提供了常见诊断问题的答案。 如果找不到所需的答案，请查看常见问题解答的完整列表或将问题发布到 MongoDB社区。 在哪里可以找到有关mongod进程意外停止运行的信息？ 如果mongod在UNIX或基于UNIX的平台上意外关闭，并且mongod无法记录关闭或错误消息，请检查系统日志中与MongoDB有关的消息。例如，使用以下命令查看位于/var/log/messages中的日志： 复制 sudo grep mongod /var/log/messages sudo grep score /var/log/messages TCP keepalive时间会影响MongoDB部署吗？¶ （译者注：tcp keepalive时间设置，主要用来探测连接对端是否还存活。当你建立一个TCP连接的时候，便有一组定时器与之绑定在一起。其中的一些定时器就用于处理keepalive过程。当keepalive定时器到0的时候，我们便会给对端发送一个不包含数据部分的keepalive探测包。如果我们收到了keepalive探测包的回复消息，那么我们就可以断定连接依然是OK的。如果我们没有收到对端keepalive探测包的回复消息，我们便可以断定连接已经不可用，进而可以采取一些措施。） 在客户端和服务器之间或者分片集群或副本集的成员之间，如果通信中遇到网络超时或套接字错误，请检查受影响系统的TCP keepalive值。 许多操作系统默认将TCP keepalive值设置为7200秒（两个小时）。对于MongoDB，通常情况下，保持较短时间值（120几秒钟（两分钟）），您将获得更好的结果。 如果您的MongoDB部署遇到与keepalive相关的问题，则必须更改所有受影响系统上的keepalive价值。这些系统包括所有正在运行mongod或mongos 的计算机以及连接到MongoDB的客户端进程的所有计算机。 调整TCP keepalive值：¶ Linux Windows macOS 要在Linux上查看keepalive设置，请使用以下命令之一： 复制 sysctl net.ipv4.tcp_keepalive_time Or: 复制 cat /proc/sys/net/ipv4/tcp_keepalive_time 该值以秒为单位测量。 注意 尽管设置名称包括ipv4，但该 tcp_keepalive_time值同时适用于IPv4和IPv6。 要更改该tcp_keepalive_time值，可以使用以下命令之一，以秒为单位提供一个： 复制 sudo sysctl -w net.ipv4.tcp_keepalive_time= 或者: 复制 echo | sudo tee /proc/sys/net/ipv4/tcp_keepalive_time 这些操作不会在系统重新启动后持续存在。要保留设置，请将以下行添加到中/etc/sysctl.conf，在几秒钟内提供一个，然后重新启动计算机： 复制 net.ipv4.tcp_keepalive_time = mongod和 mongos进程将设置Keepalive值为300秒（5分钟），来重写覆盖大于5分钟的设置。 要在Windows上查看keepalive设置，请使用以下命令之一： 复制 reg query HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters /v KeepAliveTime 注册表值默认情况下不存在。如果没有该值，则使用系统默认值，以7200000毫秒为单位或 0x6ddd00以十六进制表示。 要改变KeepAliveTime值，在管理员使用以下命令提示符，其中以十六进制（例如，表示120000为0x1d4c0）： 复制 reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\ /t REG_DWORD /v KeepAliveTime /d Windows用户应该查看KeepAliveTime上的Windows Server Technet章节，以获取有关在Windows系统上为MongoDB部署设置keepalive的更多信息。mongod和mongos会忽略大于或等于600000毫秒（10分钟）的 keepalive值 。 要在macOS上查看keepalive设置，请使用以下命令之一： 复制 sysctl net.inet.tcp.keepidle 该值以秒为单位测量。 要更改该net.inet.tcp.keepidle值，可以使用以下命令，以毫秒为单位提供一个 ： 复制 sudo sysctl net.inet.tcp.keepidle= 此操作不会在系统重新启动后持续存在，必须在每次系统重新启动时进行设置。请参阅操作系统的文档，以获取有关持久设置此值的说明。mongod和mongos 会忽略大于或等于600000毫秒（10分钟）的keepalive值。 注意 在macOS 10.15 Catalina中，Apple不再允许配置该net.inet.tcp.keepidle选项。 您将需要重新启动mongod并mongos 进程，新的Keepalive系统设置才能生效。 为什么MongoDB记录这么多“Connection Accepted” 事件？¶ 如果您在MongoDB日志中看到大量的连接和重新连接消息，则说明客户端与MongoDB服务器经常连接和断开。对于不使用请求池的应用程序（例如CGI），这是正常的行为。考虑使用FastCGI，Apache模块或其他某种持久性应用程序服务器来减少连接开销。 如果这些连接不影响性能，则可以使用运行时quiet选项或命令行选项 --quiet从日志中禁止显示这些消息。 哪些工具可用于监视MongoDB？¶ 从版本4.0开始，MongoDB 为单机部署和副本集提供免费的云监控。免费监控可提供如下部署的信息： 操作执行时间 内存使用情况 CPU使用率 操作计数 有关更多信息，请参见免费监控。 在MongoDB Cloud Manager和 在MongoDB的企业提供先进的内部部署解决方案的Ops Manager包括监控功能，其收集运行的MongoDB部署数据，并提供基于数据的可视化和警报。 有关更多信息，另请参阅MongoDB Cloud Manager文档和 Ops Manager文档。 Monitoring for MongoDB文档中提供了完整的第三方工具列表。 WiredTiger存储引擎的内存诊断 我的working set必须适合内存吗？ 不需要。 如果缓存没有足够的空间来加载其他数据，则WiredTiger会将页面从缓存中逐出以释放空间。 注意 该storage.wiredTiger.engineConfig.cacheSizeGB限制WiredTiger内部缓存的大小。操作系统将使用可用的空闲内存进行文件系统缓存，从而允许压缩的MongoDB数据文件保留在内存中。此外，操作系统将使用任何可用的RAM来缓冲文件系统块和文件系统缓存。 为了容纳更多的内存使用者，您可能必须减小WiredTiger内部缓存的大小。 默认的WiredTiger内部缓存大小值假定每台计算机有一个mongod实例。如果一台机器包含多个MongoDB实例，则您应减小设置以容纳其他mongod 实例。 如果你在一个容器（例如lxc， cgroups，Docker，等等）运行mongod，它没有访问所有系统中可用的RAM，您必须设置storage.wiredTiger.engineConfig.cacheSizeGB的值小于容器使用的内存量。确切的数量取决于容器中运行的其他进程。请参阅 memLimitMB。 要查看有关缓存和逐出的统计信息，请使用 serverStatus命令。该 wiredTiger.cache字段保存有关缓存和逐出的信息。 复制 ... \"wiredTiger\" : { ... \"cache\" : { \"tracked dirty bytes in the cache\" : , \"bytes currently in the cache\" : , \"maximum bytes configured\" : , \"bytes read into cache\" :, \"bytes written from cache\" : , \"pages evicted by application threads\" : , \"checkpoint blocked page eviction\" : , \"unmodified pages evicted\" : , \"page split during eviction deepened the tree\" : , \"modified pages evicted\" : , \"pages selected for eviction unable to be evicted\" : , \"pages evicted because they exceeded the in-memory maximum\" : ,, \"pages evicted because they had chains of deleted items\" : , \"failed eviction of pages that exceeded the in-memory maximum\" : , \"hazard pointer blocked page eviction\" : , \"internal pages evicted\" : , \"maximum page size at eviction\" : , \"eviction server candidate queue empty when topping up\" : , \"eviction server candidate queue not empty when topping up\" : , \"eviction server evicting pages\" : , \"eviction server populating queue, but not evicting pages\" : , \"eviction server unable to reach eviction goal\" : , \"pages split during eviction\" : , \"pages walked for eviction\" : , \"eviction worker thread evicting pages\" : , \"in-memory page splits\" : , \"percentage overhead\" : , \"tracked dirty pages in the cache\" : , \"pages currently held in the cache\" : , \"pages read into cache\" : , \"pages written from cache\" : , }, ... 有关某些关键高速缓存和逐出统计信息（例如wiredTiger.cache.bytes currently in the cache和wiredTiger.cache.tracked dirty bytes in the cache）的说明，请参见wiredTiger.cache。 要调整WiredTiger内部缓存的大小，请参阅 storage.wiredTiger.engineConfig.cacheSizeGB和 --wiredTigerCacheSizeGB。避免将WiredTiger内部缓存的大小增加到其默认值以上。 如何计算应用程序需要多少内存？¶ 通过WiredTiger，MongoDB可以利用WiredTiger内部缓存和文件系统缓存。 从MongoDB 3.4开始，默认的WiredTiger内部缓存大小是以下两者中的较大者： 50% of (RAM - 1 GB), or 256 MB. 例如，在总共有4GB内存的系统上，WiredTiger缓存将使用1.5GB 内存（0.5 * (4 GB - 1 GB) = 1.5）。相反，总内存为1.25 GB的系统将为WiredTiger高速缓存分配256 MB，因为这是总内存的一半以上减去1 GB 。(0.5 * (1.25 GB - 1 GB) = 128 MB ). 注意 在某些情况下，例如在容器中运行时，数据库的内存限制可能低于系统总内存。在这种情况下，此内存限制而不是系统总内存将用作最大可用内存。 要查看内存限制，请参阅hostInfo.system.memLimitMB。 默认情况下，WiredTiger对所有集合使用Snappy块压缩，对所有索引使用前缀压缩。压缩默认设置可在全局级别配置，也可以在每个集合和每个索引创建期间单独进行设置。 WiredTiger内部缓存中的数据与磁盘上的格式使用不同的形式的数据格式： 文件系统缓存中的数据与磁盘格式相同，包括对数据文件进行任何压缩的好处。操作系统使用文件系统缓存来减少磁盘I / O。 加载到WiredTiger内部缓存中的索引的数据表示形式与磁盘格式不同，但是仍可以利用索引前缀压缩来减少n内存使用量。索引前缀压缩可从索引字段中删除通用前缀。 WiredTiger内部缓存中的集合数据是未压缩的，并使用与磁盘格式不同的表示形式。块压缩可以节省大量的磁盘存储空间，但数据解压缩才能由服务器操作。 通过文件系统缓存，MongoDB自动使用WiredTiger缓存或其他进程未使用的所有可用内存。 要调整WiredTiger内部缓存的大小，请参阅 storage.wiredTiger.engineConfig.cacheSizeGB和 --wiredTigerCacheSizeGB。避免将WiredTiger内部缓存的大小增加到其默认值以上。 注意 该storage.wiredTiger.engineConfig.cacheSizeGB限制WiredTiger内部缓存的大小。操作系统将使用可用的空闲内存进行文件系统缓存，从而允许压缩的MongoDB数据文件保留在内存中。此外，操作系统将使用任何可用的内存来缓冲文件系统块和文件系统缓存。 为了容纳更多的内存使用者，您可能必须减小WiredTiger内部缓存的大小。 默认的WiredTiger内部缓存大小值假定每台计算机有一个mongod实例。如果单个机器包含多个MongoDB实例，则应减小设置以容纳其他mongod 实例。 如果你在一个容器（例如lxc， cgroups，Docker，等等）运行mongod，它没有访问所有系统中可用的内存，您必须将storage.wiredTiger.engineConfig.cacheSizeGB`的值设置为小于容器可用内存大小的值。确切的大小取决于容器中运行的其他进程。参见 memLimitMB。 要查看有关缓存和缓存淘汰率的统计信息，请参阅wiredTiger.cache命令返回的serverStatus 字段。 分片群集诊断 成功维护分片集群的两个最重要的因素是： 选择适当的片键， 足以支持当前和将来的运营的容量。 通过确保为部署选择最佳的片键，并确保始终在当前资源饱和之前为集群添加额外的容量，可以避免分片遇到的大多数问题。继续阅读，查看您在生产环境中可能遇到的特定问题。 在新的分片集群中，为什么所有数据都保留在一个分片上？ 您的集群必须具有足够的数据才能进行分片。分片的工作原理是在分片之间迁移数据块，直到每个分片具有大致相同数量的分块。 默认的块大小为64 MB。在集群中的大块不平衡量超过迁移阈值之前，MongoDB不会开始迁移 。此行为有助于防止不必要的块迁移降低整个集群的性能。 如果您刚刚部署了分片集群，请确保您有足够的数据使分片有效。如果没有足够的数据来创建八个以上的64 MB数据块，则所有数据将保留在一个分片上。降低块大小设置，或向集群添加更多数据。 作为一个相关问题，系统将仅在插入或更新时拆分块，这意味着，如果您配置了分片并且不继续执行插入和更新操作，则数据库将不会创建任何块。您可以等待，直到应用程序插入数据或 手动拆分块。 最后，如果片键的基数较低，则MongoDB可能无法在数据之间创建足够的拆分（chunk将无法继续分裂）。 为什么一个分片会在分片集群中会收到不均衡的流量？ 在某些情况下，单个分片或集群的子集将接收不均衡的流量和工作负载。在几乎所有情况下，这都是因为片键无法高效地允许写缩放。 您也可能有“hot chunks”。在这种情况下，您可以通过拆分然后迁移部分块来解决问题。 在最坏的情况下，您可能必须考虑重新分拆数据并选择其他片键 来更正此模式。 什么可以阻止分片集群均衡？¶ 如果您刚刚部署了分片群集，则可能需要考虑针对新集群数据仍保留在单个分片上的故障排除建议。 如果集群最初是均衡的，但后来却出现了数据分布不均的情况，请考虑以下可能的原因： 您已从集群中删除或移除了大量数据。如果添加了其他数据，则其片键的分配可能会有所不同。 您的片键具有较低的基数， 并且MongoDB无法进一步拆分块。 您的数据集增长速度超过了均衡器可以在集群中分发数据的速度。这种情况并不常见，通常是由于以下原因造成的： 相对于数据增长的速度，这个均衡窗口太短。 写操作分布不均，需要更多的数据迁移。您可能必须选择其他分片键才能解决此问题。 分片之间的网络连接不良，这可能会导致需要很长时间才能完成数据块迁移。检查您的网络配置和分片之间的互连。 为什么块迁移会影响分片集群的性能？ 如果迁移会影响您的集群或应用程序的性能，请根据影响的性质考虑以下选项： 1.如果迁移仅偶尔中断集群，则可以限制均衡窗口以防止高峰时段进行均衡活动。确保有足够的时间来防止数据再次失去均衡。 2.如果均衡器始终在迁移块而不利于整体集群性能： 您可能想要尝试减小块大小 以限制迁移的大小。 您的集群可能超载，您可能想尝试向该集群添加一个或两个分片以分摊负载。 您的片键还可能导致应用程序将所有写入指向单个分片。这种活动模式可能要求均衡器在写入数据后立即迁移大部分数据。请考虑使用提供更好写入扩展的片键重新部署集群。 原文链接：https://docs.mongodb.com/manual/faq/diagnostics/ 译者：钟秋 update:小芒果 参见 原文 - FAQ: MongoDB Diagnostics Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference.html":{"url":"16-reference.html","title":"参考","keywords":"","body":" Reference 文档操作 增删改查与聚合操作参考。 数据库命令 所有 MongoDB 数据库的操作，语法使用参考 mongo Shell 方法 在 Mongo shell 中的所有 javascript 方法与指令的参考 MongoDB 包组件 mongod 和 mongos 以及所有其它已发布的工具。 配置文件选项 MongoDB 服务器参数 MongoDB 限制与阈值 关于返回值的解释 系统集合 连接字符串URI格式 排序 MongoDB的Wire协议 日志消息 退出码和状态 词汇表 默认的MongoDB端口 MongoDB 默认的读写关注 服务器会话 配置文件选项 默认的MongoDB读/写关注 退出代码和状态 MongoDB Limits and Thresholds ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Reference Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator.html":{"url":"16-reference/01-operator.html","title":"Operators","keywords":"","body":" Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query.html":{"url":"16-reference/01-operator/01-query.html","title":"Query and Projection Operators","keywords":"","body":" Query and Projection Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Query and Projection Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison.html":{"url":"16-reference/01-operator/01-query/01-query-comparison.html","title":"Comparison Query Operators","keywords":"","body":" Comparison Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Comparison Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/01-eq.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/01-eq.html","title":"$eq","keywords":"","body":" $eq 在本页面 行为 例子 $eq 指定相等条件。$eq操作符匹配字段的值等于指定值的文档。 { : { $eq: } } $eq表达式等效于。{ field: } 行为 比较顺序 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 匹配一个文献价值 如果指定的是文档，则文档中字段的顺序很重要。 匹配一个数组值 如果指定的是数组，则MongoDB将匹配与该数组完全匹配的文档，或者 包含包含与该数组完全匹配的元素的文档。元素的顺序很重要。有关示例，请参见等于数组值。 例子 以下示例inventory使用以下文档查询集合： { _id: 1, item: { name: \"ab\", code: \"123\" }, qty: 15, tags: [ \"A\", \"B\", \"C\" ] } { _id: 2, item: { name: \"cd\", code: \"123\" }, qty: 20, tags: [ \"B\" ] } { _id: 3, item: { name: \"ij\", code: \"456\" }, qty: 25, tags: [ \"A\", \"B\" ] } { _id: 4, item: { name: \"xy\", code: \"456\" }, qty: 30, tags: [ \"B\", \"A\" ] } { _id: 5, item: { name: \"mn\", code: \"000\" }, qty: 20, tags: [ [ \"A\", \"B\" ], \"C\" ] } 等于指定值 下面的示例查询inventory集合以选择qty字段值等于的所有文档20： db.inventory.find( { qty: { $eq: 20 } } ) 该查询等效于： db.inventory.find( { qty: 20 } ) 这两个查询都匹配以下文档： { _id: 2, item: { name: \"cd\", code: \"123\" }, qty: 20, tags: [ \"B\" ] } { _id: 5, item: { name: \"mn\", code: \"000\" }, qty: 20, tags: [ [ \"A\", \"B\" ], \"C\" ] } 嵌入式文档中的字段等于值 以下示例查询inventory集合以选择文档中name字段值item 等于\"ab\"的所有文档。要在嵌入式文档中的字段上指定条件，请使用点符号。 db.inventory.find( { \"item.name\": { $eq: \"ab\" } } ) 该查询等效于： db.inventory.find( { \"item.name\": \"ab\" } ) 这两个查询都与以下文档匹配： { _id: 1, item: { name: \"ab\", code: \"123\" }, qty: 15, tags: [ \"A\", \"B\", \"C\" ] } 也可以看看 查询嵌入式文档 数组元素等于一个值 下面的示例查询inventory集合以选择tags数组包含值\"B\" [1]的元素的所有文档： db.inventory.find( { tags: { $eq: \"B\" } } ) 该查询等效于： db.inventory.find( { tags: \"B\" } ) 这两个查询都匹配以下文档： { _id: 1, item: { name: \"ab\", code: \"123\" }, qty: 15, tags: [ \"A\", \"B\", \"C\" ] } { _id: 2, item: { name: \"cd\", code: \"123\" }, qty: 20, tags: [ \"B\" ] } { _id: 3, item: { name: \"ij\", code: \"456\" }, qty: 25, tags: [ \"A\", \"B\" ] } { _id: 4, item: { name: \"xy\", code: \"456\" }, qty: 30, tags: [ \"B\", \"A\" ] } 也可以看看 $elemMatch，查询数组 [1] 该查询还将匹配文档，其中tags字段的值为字符串\"B\"。 等于一个数组值 以下示例查询inventory集合，以选择该tags数组与指定数组完全相等或该tags数组包含等于该数组[ \"A\", \"B\" ]的元素的所有文档。 db.inventory.find( { tags: { $eq: [ \"A\", \"B\" ] } } ) 该查询等效于： db.inventory.find( { tags: [ \"A\", \"B\" ] } ) 这两个查询都匹配以下文档： { _id: 3, item: { name: \"ij\", code: \"456\" }, qty: 25, tags: [ \"A\", \"B\" ] } { _id: 5, item: { name: \"mn\", code: \"000\" }, qty: 20, tags: [ [ \"A\", \"B\" ], \"C\" ] } 译者：李冠飞 校对： 参见 原文 - $eq Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/02-gt.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/02-gt.html","title":"$gt","keywords":"","body":" $gt $gt 语法：{field: {$gt: value} } $gt选择的值field大于（即>）指定的那些文档 value。 对于大多数数据类型，比较运算符仅对BSON类型与查询值的类型匹配的字段执行比较 。MongoDB通过Type Bracketing支持有限的跨BSON比较。 考虑以下示例： db.inventory.find( { qty: { $gt: 20 } } ) 此查询将选择inventory集合中qty字段值大于20的所有文档。 考虑以下示例，该示例将$gt运算符与嵌入式文档中的字段一起使用： db.inventory.update( { \"carrier.fee\": { $gt: 2 } }, { $set: { price: 9.99 } } ) update()操作将设置price找到的第一个文档中包含嵌入文档carrier的fee字段的值，该嵌入文档的字段值大于2。 要price在包含嵌入文档的所有文档中设置该字段的值，该嵌入文档carrier的fee字段值大于2，请在update()方法中指定multi:true选项： db.inventory.update( { \"carrier.fee\": { $gt: 2 } }, { $set: { price: 9.99 } }, { multi: true } ) 也可以看看 find()，update()，$set。 译者：李冠飞 校对： 参见 原文 - $gt Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/03-gte.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/03-gte.html","title":"$gte","keywords":"","body":" $gte $gte 语法：{field: {$gte: value} } $gte选择的值field大于或等于（即>=）指定值（例如value）的文档 。 对于大多数数据类型，比较运算符仅对BSON类型与查询值的类型匹配的字段执行比较 。MongoDB通过Type Bracketing支持有限的跨BSON比较。 考虑以下示例： db.inventory.find( { qty: { $gte: 20 } } ) 此查询将选择的所有文件inventory，其中qty字段的值大于或等于20。 考虑以下示例，该示例将$gte运算符与嵌入式文档中的字段一起使用： db.inventory.update( { \"carrier.fee\": { $gte: 2 } }, { $set: { price: 9.99 } } ) update()操作将设置price包含嵌入文档carrier的fee字段的值，该嵌入文档 的字段值大于或等于 2。 也可以看看 find()，update()，$set。 译者：李冠飞 校对： 参见 原文 - $gte Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/04-in.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/04-in.html","title":"$in","keywords":"","body":" $in 在本页面 例子 $in $in操作符选择字段值等于指定数组中任何值的文档。要指定一个$in表达式，使用下面的原型: 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 { field: { $in: [, , ... ] } } 如果field持有的阵列，则$in操作符选择字段中包含至少一个与指定数组中的值匹配的元素的文档（例如，，等） 例子 使用$in运算符来匹配值 考虑以下示例： db.inventory.find( { qty: { $in: [ 5, 15 ] } } ) 该查询选择inventory 集合中qty字段值为5或的15所有文档。尽管可以使用$or运算符表示此查询 ，但是在同一字段上执行相等性检查时，请选择$in运算符而不是$or运算符。 使用$in运算符匹配数组中的值 集合inventory包含包含字段的文档， tags如下所示： { _id: 1, item: \"abc\", qty: 10, tags: [ \"school\", \"clothing\" ], sale: false } 然后，下面的update()操作将设定的sale字段值true，其中tags字段保持与至少一个元素匹配任一阵列\"appliances\"或 \"school\"。 db.inventory.update( { tags: { $in: [\"appliances\", \"school\"] } }, { $set: { sale:true } } ) 有关查询数组的其他示例，请参见： 查询数组 查询嵌入式文档数组 有关查询的其他示例，请参见： 查询文件 将$in运算符与正则表达式一起使用 $in操作符可利用形式的正则表达式匹配指定值/pattern/。您不能在$in中使用$regex运算符表达式。 考虑以下示例： db.inventory.find( { tags: { $in: [ /^be/, /^st/ ] } } ) 此查询选择inventory集合中的所有文档，其中tags字段包含以be或st开头的字符串，或至少有一个以be或st开头的元素的数组。 也可以看看 find()，update()，$or，$set，$elemMatch。 译者：李冠飞 校对： 参见 原文 - $in Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/05-lt.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/05-lt.html","title":"$lt","keywords":"","body":" $lt ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $lt Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/06-lte.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/06-lte.html","title":"$lte","keywords":"","body":" $lte $lte 语法：{field: {$lte: value} } $lte选择的值field小于或等于指定value的文档 。 对于大多数数据类型，比较运算符仅对BSON类型与查询值的类型匹配的字段执行比较 。MongoDB通过Type Bracketing支持有限的跨BSON比较。 考虑以下示例： db.inventory.find( { qty: { $lte: 20 } } ) 此查询将选择inventory集合中qty字段值小于或等于20的所有文档。 考虑以下示例，该示例将$lte运算符与嵌入式文档中的字段一起使用： db.inventory.update( { \"carrier.fee\": { $lte: 5 } }, { $set: { price: 9.99 } } ) update()操作将price在包含嵌入式文档的文档中设置字段值，该嵌入式文档carrier的fee字段值小于或等于5。 也可以看看 find()，update()，$set。 译者：李冠飞 校对： 参见 原文 - $lte Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/07-ne.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/07-ne.html","title":"$ne","keywords":"","body":" $ne ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ne Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/01-query-comparison/08-nin.html":{"url":"16-reference/01-operator/01-query/01-query-comparison/08-nin.html","title":"$nin","keywords":"","body":" $nin $nin 语法：{ field: { $nin: [ , ... ]} } $nin选择以下位置的文档： 该field值不在指定的范围内array 或 在field不存在。 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 考虑以下查询： db.inventory.find( { qty: { $nin: [ 5, 15 ] } } ) 这个查询将选择库存集合中qty字段值不等于5或15的所有文档。所选文档将包括那些不包含qty字段的文档。 如果字段包含数组，那么$nin操作符将选择字段中没有元素等于指定数组中的值的文档(例如， ，等等)。 考虑以下查询： db.inventory.update( { tags: { $nin: [ \"appliances\", \"school\" ] } }, { $set: { sale: false } } ) 这个update()操作将设置库存集合中的sale字段值，其中，tags字段包含一个数组，数组中没有与数组[\"appliances\"， \"school\"]中的元素匹配的元素，或者文档不包含tags字段。 不等运算符$nin的选择性不是很强，因为它经常匹配索引的很大一部分。因此，在许多情况下，带有索引的$nin查询的性能可能不比必须扫描集合中所有文档的$nin查询好。请参见查询选择性。 也可以看看 find()，update()，$set。 译者：李冠飞 校对： 参见 原文 - $nin Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/02-query-logical.html":{"url":"16-reference/01-operator/01-query/02-query-logical.html","title":"Logical Query Operators","keywords":"","body":" Logical Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Logical Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/02-query-logical/01-and.html":{"url":"16-reference/01-operator/01-query/02-query-logical/01-and.html","title":"$and","keywords":"","body":" $and ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $and Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/02-query-logical/02-not.html":{"url":"16-reference/01-operator/01-query/02-query-logical/02-not.html","title":"$not","keywords":"","body":" $not ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $not Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/02-query-logical/03-nor.html":{"url":"16-reference/01-operator/01-query/02-query-logical/03-nor.html","title":"$nor","keywords":"","body":" $nor ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $nor Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/02-query-logical/04-or.html":{"url":"16-reference/01-operator/01-query/02-query-logical/04-or.html","title":"$or","keywords":"","body":" $or ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $or Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/03-query-element.html":{"url":"16-reference/01-operator/01-query/03-query-element.html","title":"Element Query Operators","keywords":"","body":" Element Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Element Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/03-query-element/01-exists.html":{"url":"16-reference/01-operator/01-query/03-query-element/01-exists.html","title":"$exists","keywords":"","body":" $exists ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $exists Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/03-query-element/02-type.html":{"url":"16-reference/01-operator/01-query/03-query-element/02-type.html","title":"$type","keywords":"","body":" $type ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $type Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation.html","title":"Evaluation Query Operators","keywords":"","body":" Evaluation Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Evaluation Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/01-expr.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/01-expr.html","title":"$expr","keywords":"","body":" $expr ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $expr Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/02-jsonSchema.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/02-jsonSchema.html","title":"$jsonSchema","keywords":"","body":" $jsonSchema ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $jsonSchema Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/03-mod.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/03-mod.html","title":"$mod","keywords":"","body":" $mod ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $mod Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/04-regex.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/04-regex.html","title":"$regex","keywords":"","body":" $regex ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $regex Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/05-text.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/05-text.html","title":"$text","keywords":"","body":" $text ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $text Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/04-query-evaluation/06-where.html":{"url":"16-reference/01-operator/01-query/04-query-evaluation/06-where.html","title":"$where","keywords":"","body":" $where ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $where Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial.html","title":"Geospatial Query Operators","keywords":"","body":" Geospatial Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Geospatial Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/01-geoIntersects.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/01-geoIntersects.html","title":"$geoIntersects","keywords":"","body":" $geoIntersects ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $geoIntersects Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/02-geoWithin.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/02-geoWithin.html","title":"$geoWithin","keywords":"","body":" $geoWithin ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $geoWithin Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/03-near.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/03-near.html","title":"$near","keywords":"","body":" $near ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $near Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/04-nearSphere.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/04-nearSphere.html","title":"$nearSphere","keywords":"","body":" $nearSphere ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $nearSphere Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/05-box.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/05-box.html","title":"$box","keywords":"","body":" $box ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $box Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/06-center.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/06-center.html","title":"$center","keywords":"","body":" $center ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $center Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/07-centerSphere.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/07-centerSphere.html","title":"$centerSphere","keywords":"","body":" $centerSphere ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $centerSphere Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/08-geometry.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/08-geometry.html","title":"$geometry","keywords":"","body":" $geometry ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $geometry Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/09-maxDistance.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/09-maxDistance.html","title":"$maxDistance","keywords":"","body":" $maxDistance ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $maxDistance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/10-minDistance.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/10-minDistance.html","title":"$minDistance","keywords":"","body":" $minDistance ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $minDistance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/11-polygon.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/11-polygon.html","title":"$polygon","keywords":"","body":" $polygon ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $polygon Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/05-query-geospatial/12-uniqueDocs.html":{"url":"16-reference/01-operator/01-query/05-query-geospatial/12-uniqueDocs.html","title":"$uniqueDocs","keywords":"","body":" $uniqueDocs ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $uniqueDocs Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/06-query-array.html":{"url":"16-reference/01-operator/01-query/06-query-array.html","title":"Array Query Operators","keywords":"","body":" Array Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Array Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/06-query-array/01-all.html":{"url":"16-reference/01-operator/01-query/06-query-array/01-all.html","title":"$all","keywords":"","body":" $all ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $all Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/06-query-array/02-elemMatch.html":{"url":"16-reference/01-operator/01-query/06-query-array/02-elemMatch.html","title":"$elemMatch (query)","keywords":"","body":" $elemMatch (query) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $elemMatch (query) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/06-query-array/03-size.html":{"url":"16-reference/01-operator/01-query/06-query-array/03-size.html","title":"$size","keywords":"","body":" $size ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $size Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/07-query-bitwise.html":{"url":"16-reference/01-operator/01-query/07-query-bitwise.html","title":"Bitwise Query Operators","keywords":"","body":" Bitwise Query Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bitwise Query Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/07-query-bitwise/01-bitsAllClear.html":{"url":"16-reference/01-operator/01-query/07-query-bitwise/01-bitsAllClear.html","title":"$bitsAllClear","keywords":"","body":" $bitsAllClear ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bitsAllClear Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/07-query-bitwise/02-bitsAllSet.html":{"url":"16-reference/01-operator/01-query/07-query-bitwise/02-bitsAllSet.html","title":"$bitsAllSet","keywords":"","body":" $bitsAllSet ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bitsAllSet Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/07-query-bitwise/03-bitsAnyClear.html":{"url":"16-reference/01-operator/01-query/07-query-bitwise/03-bitsAnyClear.html","title":"$bitsAnyClear","keywords":"","body":" $bitsAnyClear ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bitsAnyClear Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/07-query-bitwise/04-bitsAnySet.html":{"url":"16-reference/01-operator/01-query/07-query-bitwise/04-bitsAnySet.html","title":"$bitsAnySet","keywords":"","body":" $bitsAnySet ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bitsAnySet Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/08-comment.html":{"url":"16-reference/01-operator/01-query/08-comment.html","title":"$comment","keywords":"","body":" $comment ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $comment Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection.html":{"url":"16-reference/01-operator/01-query/09-projection.html","title":"查询与映射运算符","keywords":"","body":" 查询与映射运算符 在本页面 查询选择器 映射运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 查询选择器 比较 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 名称 描述 $eq 匹配等于指定值的值。 $gt 匹配大于指定值的值。 $gte 匹配大于或等于指定值的值。 $in 匹配数组中指定的任何值。 $lt 匹配小于指定值的值。 $lte 匹配小于或等于指定值的值。 $ne 匹配所有不等于指定值的值。 $nin 不匹配数组中指定的任何值。 逻辑 名称 描述 $and 使用逻辑AND连接查询子句，返回与这两个子句条件匹配的所有文档。 $not 反转查询表达式的效果，并返回与查询表达式不匹配的文档。 $nor 用逻辑NOR连接查询子句，返回所有不能匹配这两个子句的文档。 $or 用逻辑OR连接查询子句，返回与任一子句条件匹配的所有文档。 元素 名称 描述 $exists 匹配具有指定字段的文档。 $type 如果字段是指定类型，则选择文档。 评估 名称 描述 $expr 允许在查询语言中使用聚合表达式。 $jsonSchema 根据给定的JSON Schema验证文档。 $mod 对字段的值执行模运算并选择具有指定结果的文档。 $regex 选择值与指定的正则表达式匹配的文档。 $text 执行文本搜索。 $where 匹配满足JavaScript表达式的文档。 地理空间 名称 描述 $geoIntersects 选择与GeoJSON几何形状相交的几何形状。2dsphere索引支持 $geoIntersects。 $geoWithin 选择边界GeoJSON几何内的几何。2dsphere和2D指标支持 $geoWithin。 $near 返回点附近的地理空间对象。需要地理空间索引。2dsphere和2D指标支持 $near。 $nearSphere 返回球体上某个点附近的地理空间对象。需要地理空间索引。2dsphere和2D指标支持 $nearSphere。 数组 名称 描述 $all 匹配包含查询中指定的所有元素的数组。 $elemMatch 如果array字段中的元素符合所有指定$elemMatch条件，则选择文档。 $size 如果数组字段为指定大小，则选择文档。 按位 名称 描述 $bitsAllClear 匹配数字或二进制值，其中一组位的所有值均为0。 $bitsAllSet 匹配数字或二进制值，其中一组位的所有值均为1。 $bitsAnyClear 匹配数值或二进制值，在这些数值或二进制值中，一组位的位置中任何位的值为0。 $bitsAnySet 匹配数值或二进制值，在这些数值或二进制值中，一组位的位置中任何位的值为1。 注释 名称 描述 $comment 向查询谓词添加注释。 映射运算符 名称 描述 $ 数组中匹配查询条件的第一个元素。 $elemMatch 符合指定$elemMatch条件的数组中的第一个元素。 $meta 项目在$text操作期间分配的文档分数。 $slice 限制从数组中投影的元素数量。支持limit和skip。 译者：李冠飞 校对： 参见 原文 - Projection Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/01-positional.html":{"url":"16-reference/01-operator/01-query/09-projection/01-positional.html","title":"$ (projection)","keywords":"","body":" $ (projection) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ (projection) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/02-elemMatch.html":{"url":"16-reference/01-operator/01-query/09-projection/02-elemMatch.html","title":"$elemMatch (projection)","keywords":"","body":" $elemMatch (projection) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $elemMatch (projection) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/03-slice.html":{"url":"16-reference/01-operator/01-query/09-projection/03-slice.html","title":"$slice (projection)","keywords":"","body":" $slice (projection) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $slice (projection) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Array-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Array-Query-Operators.html","title":"数组查询运算符","keywords":"","body":" 数组查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $all 匹配包含查询中指定的所有元素的数组。 $elemMatch 如果array字段中的元素符合所有指定$elemMatch条件，则选择文档。 $size 如果数组字段为指定大小，则选择文档。 有关查询数组字段的示例，请参见： 查询数组 查询嵌入式文档数组 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Bitwise-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Bitwise-Query-Operators.html","title":"按位查询运算符","keywords":"","body":" 按位查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $bitsAllClear 匹配数字或二进制值，其中一组位的所有值均为0。 $bitsAllSet 匹配数字或二进制值，其中一组位的所有值均为1。 $bitsAnyClear 匹配数值或二进制值，在这些数值或二进制值中，一组位的位置中任何位的值为0。 $bitsAnySet 匹配数值或二进制值，在这些数值或二进制值中，一组位的位置中任何位的值为1。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/comment.html":{"url":"16-reference/01-operator/01-query/09-projection/comment.html","title":"$comment","keywords":"","body":" $comment 在本页面 定义 行为 例子 定义 $comment $comment查询操作符将注释与任何具有查询谓词的表达式关联起来。 由于注释会传播到profile日志，因此添加注释可以使您的个人资料数据更易于解释和跟踪。 $comment运算符的形式为： db.collection.find( { , $comment: } ) 行为 您可以将_ $comment与任何带查询谓词的表达式一起使用，例如聚合管道中db.collection.update()或聚合$match阶段中的查询谓词 。有关示例，请参见对聚合表达式附加注释。 例子 附加评论到find 以下示例$comment在 find()操作中添加了： db.records.find( { x: { $mod: [ 2, 0 ] }, $comment: \"Find even values.\" } ) 在聚合表达式上附加注释 您可以对$comment带查询谓词的任何表达式使用。 以下示例在$match阶段中使用运算符$comment来阐明操作： db.records.aggregate( [ { $match: { x: { $gt: 0 }, $comment: \"Don't allow negative inputs.\" } }, { $group : { _id: { $mod: [ \"$x\", 2 ] }, total: { $sum: \"$x\" } } } ] ) 也可以看看 $comment 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators.html","title":"比较查询运算符","keywords":"","body":" 比较查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 名称 结果 $eq 匹配等于指定值的值。 $gt 匹配大于指定值的值。 $gte 匹配大于或等于指定值的值。 $in 匹配数组中指定的任何值。 $lt 匹配小于指定值的值。 $lte 匹配小于或等于指定值的值。 $ne 匹配所有不等于指定值的值。 $nin 不匹配数组中指定的任何值。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators/lt.html":{"url":"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators/lt.html","title":"$lt","keywords":"","body":" $lt $lt 语法：{field: {$lt: value} } $lt选择的值field小于（即）指定的文档 value。 对于大多数数据类型，比较运算符仅对BSON类型与查询值的类型匹配的字段执行比较 。MongoDB通过Type Bracketing支持有限的跨BSON比较。 考虑以下示例： db.inventory.find( { qty: { $lt: 20 } } ) 此查询将选择inventory集合中qty字段值小于20的所有文档。 考虑以下示例，该示例将$lt运算符与嵌入式文档中的字段一起使用： db.inventory.update( { \"carrier.fee\": { $lt: 20 } }, { $set: { price: 9.99 } } ) update()操作将price在包含嵌入文档的文档中设置字段值，该嵌入文档carrier的fee字段值小于20。 也可以看看 find()，update()，$set。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators/ne.html":{"url":"16-reference/01-operator/01-query/09-projection/Comparison-Query-Operators/ne.html","title":"$ne","keywords":"","body":" $ne $ne 语法：{field: {$ne: value} } $ne选择的值field不等于指定的文档 value。这包括不包含的文档field。 有关不同BSON类型值的比较，请参见指定的BSON比较顺序。 考虑以下示例： db.inventory.find( { qty: { $ne: 20 } } ) 此查询将选择inventory集合中qty字段值不等于20的所有文档，包括不包含该qty字段的那些文档。 考虑以下示例，该示例$ne在嵌入式文档中使用运算符和字段： db.inventory.update( { \"carrier.state\": { $ne: \"NY\" } }, { $set: { qty: 20 } } ) update()操作将qty在包含嵌入式文档的文档中设置字段值，该嵌入式文档carrier的state字段值不等于“ NY”，或者该state字段或carrier嵌入式文档不存在。 不等式操作符$ne是不非常有选择性的，因为它往往是指数的很大一部分相匹配。结果，在许多情况下，$ne带有索引的查询的性能可能不比$ne必须扫描集合中所有文档的查询更好。另请参阅查询选择性。 也可以看看 find()，update()，$set。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Element-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Element-Query-Operators.html","title":"元素查询运算符","keywords":"","body":" 元素查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $exists 匹配具有指定字段的文档。 $type 如果字段是指定类型，则选择文档。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Evaluation-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Evaluation-Query-Operators.html","title":"评估查询运算符","keywords":"","body":" 评估查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $expr 允许在查询语言中使用聚合表达式。 $jsonSchema 根据给定的JSON Schema验证文档。 $mod 对字段的值执行模运算并选择具有指定结果的文档。 $regex 选择值与指定的正则表达式匹配的文档。 $text 执行文本搜索。 $where 匹配满足JavaScript表达式的文档。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Geospatial-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Geospatial-Query-Operators.html","title":"地理空间查询运算符","keywords":"","body":" 地理空间查询运算符 在本页面 运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 运算符 查询选择器 名称 描述 $geoIntersects 选择与GeoJSON几何形状相交的几何形状。2dsphere索引支持 $geoIntersects。 $geoWithin 选择边界GeoJSON几何内的几何。2dsphere和2D指标支持 $geoWithin。 $near 返回点附近的地理空间对象。需要地理空间索引。2dsphere和2D指标支持 $near。 $nearSphere 返回球体上某个点附近的地理空间对象。需要地理空间索引。2dsphere和2D指标支持 $nearSphere。 几何说明符 名称 描述 $box 使用传统坐标对来指定一个矩形框进行 $geoWithin查询。所述2D指数支持 $box。 $center 使用平面几何时，使用旧坐标对指定圆以进行$geoWithin查询。所述2D指数支持$center。 $centerSphere 使用球形几何图形时，使用传统坐标对或GeoJSON格式指定一个圆 用于$geoWithin查询。2dsphere和 2D指标支持$centerSphere。 $geometry 为地理空间查询运算符指定GeoJSON格式的几何。 $maxDistance 指定最大距离以限制$near 和$nearSphere查询的结果。2dsphere和2D指标支持 $maxDistance。 $minDistance 指定最小距离以限制$near 和$nearSphere查询的结果。2dsphere仅用于索引。 $polygon 指定用于$geoWithin查询的旧坐标对的多边形。2d索引支持$center。 $uniqueDocs 不推荐使用。修改$geoWithin和$near查询以确保即使文档多次匹配查询，查询也只返回一次文档。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators.html":{"url":"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators.html","title":"逻辑查询运算符","keywords":"","body":" 逻辑查询运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $and 使用逻辑AND连接查询子句，返回与这两个子句条件匹配的所有文档。 $not 反转查询表达式的效果，并返回与查询表达式不匹配的文档。 $nor 用逻辑NOR连接查询子句，返回所有不能匹配这两个子句的文档。 $or 用逻辑OR连接查询子句，返回与任一子句条件匹配的所有文档。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/and.html":{"url":"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/and.html","title":"$and","keywords":"","body":" $and 在本页面 例子 $and 语法：{ $and: [ { }, { } , ... , { } ] } $and执行的逻辑AND的阵列上操作的一个或多个表达式（例如， 等），并且选择满足该文件 的所有阵列中的表达式。$and运算符使用短路计算。如果第一个表达式（例如）的计算结果为false，则MongoDB将不计算其余的表达式。 注意 AND当指定逗号分隔的表达式列表时，MongoDB提供隐式操作。 例子 AND使用指定同一字段的多个表达式进行查询 考虑以下示例： db.inventory.find( { $and: [ { price: { $ne: 1.99 } }, { price: { $exists: true } } ] } ) 此查询将选择inventory 集合中的所有文档，其中： price字段值不等于1.99 与 price字段存在。 AND 通过组合price 字段的运算符表达式，也可以使用隐式操作构造此查询。例如，此查询可以写为： db.inventory.find( { price: { $ne: 1.99, $exists: true } } ) AND使用指定相同运算符的多个表达式进行查询 考虑以下示例： db.inventory.find( { $and: [ { $or: [ { qty: { $lt : 10 } }, { qty : { $gt: 50 } } ] }, { $or: [ { sale: true }, { price : { $lt : 5 } } ] } ] } ) 该查询将选择以下位置的所有文档： qty字段值小于20或大于50，和 sale字段值是等于true 或所述price 字段值小于5。 无法使用隐式AND操作构造此查询，因为它$or多次使用运算符。 也可以看看 find()，update()， $ne，$exists，$set。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/nor.html":{"url":"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/nor.html","title":"$nor","keywords":"","body":" $nor 在本页面 例子 $nor $nor对包含一个或多个查询表达式的数组执行逻辑nor操作，并选择数组中所有查询表达式失败的文档。$nor有以下语法: { $nor: [ { }, { }, ... { } ] } 也可以看看 find(), update(), $or, $set, and $exists. 例子 $nor查询有两种表述 考虑以下仅使用$nor操作符的查询: db.inventory.find( { $nor: [ { price: 1.99 }, { sale: true } ] } ) 此查询将返回以下所有文档: 包含值不等于1.99的price字段和不等于true或的sale字段 包含price字段，其值不等于1.99，但不包含sale字段 不包含price字段，但sale包含值不等于true 不包含price字段和不包含sale字段 $nor和另外的比较 考虑以下查询: db.inventory.find( { $nor: [ { price: 1.99 }, { qty: { $lt: 20 } }, { sale: true } ] } ) 此查询将选择库存集合中的所有文档，其中: price字段值不等于1.99和 qty字段值不小于20和 sales字段的值不等于true 包括那些不包含这些字段的文档。 返回不包含$nor表达式中字段的文档的例外情况是，$nor操作符与$exists操作符一起使用。 $nor和$exists 下面的查询使用$nor操作符和$exists操作符: db.inventory.find( { $nor: [ { price: 1.99 }, { price: { $exists: false } }, { sale: true }, { sale: { $exists: false } } ] } ) 此查询将返回以下所有文档: 包含值不等于1.99的price字段和值不等于true的sale字段 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/not.html":{"url":"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/not.html","title":"$not","keywords":"","body":" $not 在本页面 行为 $not 语法：{ field: { $not: { } } } $not对指定的执行逻辑NOT操作，并选择与不匹配的文档。这包括不包含该字段的文档。 考虑以下查询： db.inventory.find( { price: { $not: { $gt: 1.99 } } } ) 此查询将选择inventory集合中的所有文档，其中： price字段的值小于或等于1.99 或 price字段不存在 {$not: {$gt: 1.99}}与$lte运算符不同。{$lte: 1.99}只返回price字段存在且其值小于或等于1.99的文档。 请记住，$not操作符只影响其他操作符，不能独立地检查字段和文档。因此，使用$not操作符进行逻辑分离，使用$ne操作符直接测试字段的内容。 行为 $not和数据类型 $not运算符的操作与其他运算符的行为一致，但对于某些数据类型（如数组）可能会产生意外结果。 $not和正则表达式 $not操作符可以对以下内容执行逻辑NOT运算： 正则表达式对象(例如：/pattern/) 例如：下面的查询选择inventory集合中item字段值不以字母p开头的所有文档。 db.inventory.find( { item: { $not: /^p.*/ } } ) $regex运算符表达式(从MongoDB 4.0.7开始) 例如，下面的查询选择inventory集合中item字段值不以字母p开头的所有文档。 db.inventory.find( { item: { $not: { $regex: \"^p.*\" } } } ) db.inventory.find( { item: { $not: { $regex: /^p.*/ } } } ) 驱动程序语言的正则表达式对象 例如，下面的PyMongo查询使用Python的re.compile()方法编译一个正则表达式: import re for noMatch in db.inventory.find( { \"item\": { \"$not\": re.compile(\"^p.*\") } } ): print noMatch 也可以看看 find(), update(), $set, $gt, $regex, PyMongo, driver. 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/or.html":{"url":"16-reference/01-operator/01-query/09-projection/Logical-Query-Operators/or.html","title":"$or","keywords":"","body":" $or 在本页面 行为 $or $or操作符对包含两个或多个的数组执行逻辑或操作，并选择满足至少一个的文档。$or的语法如下: { $or: [ { }, { }, ... , { } ] } 考虑下面的例子: db.inventory.find( { $or: [ { quantity: { $lt: 20 } }, { price: 10 } ] } ) 该查询将选择inventory集合中quantity字段值小于20或price字段值等于10的所有文档。 行为 $or子句和索引 当对$or表达式中的子句求值时，MongoDB要么执行集合扫描，要么执行索引扫描(如果所有子句都被索引支持)。也就是说，MongoDB要使用索引对$or表达式求值，索引必须支持$or表达式中的所有子句。否则，MongoDB将执行一次收集扫描。 当对$or查询使用索引时，$or的每个子句都可以使用自己的索引。考虑以下查询: db.inventory.find( { $or: [ { quantity: { $lt: 20 } }, { price: 10 } ] } ) 为了支持此查询，而不是复合索引，您将创建一个关于quantity的索引和另一个关于price的索引: db.inventory.createIndex( { quantity: 1 } ) db.inventory.createIndex( { price: 1 } ) MongoDB可以使用除geoHaystack索引之外的所有索引来支持$or子句。 $not和正则表达式 如果$or包含$text查询，则$or数组中的所有子句必须由索引支持。这是因为$text查询必须使用索引，而$or只能在索引支持其所有子句的情况下使用索引。如果$text查询不能使用索引，则查询将返回一个错误。 $or和地理空间查询 $or支持地理空间子句，但near子句有以下例外(near子句包括$nearSphere和$near)。$or不能包含任何其他子句的near子句。 $or和排序操作 当使用sort()执行$or查询时，MongoDB现在可以使用支持$or子句的索引。以前的版本不使用索引。 $or与$in 当使用$or 来检查相同字段的值时，使用$in操作符而不是$or操作符。 例如，要选择数量字段值为20或50的库存集合中的所有文档，使用$in操作符: db.inventory.find ( { quantity: { $in: [20, 50] } } ) Nested $or Clauses 你可能会嵌套$or操作。 也可以看看 $and, find(), sort(), $in 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update.html":{"url":"16-reference/01-operator/02-update.html","title":"更新运算符","keywords":"","body":" 更新运算符 在本页面 更新运算符 以下修饰符可用于更新操作；例如在db.collection.update()和中 db.collection.findAndModify()。 在以下格式的文档中指定运算符表达式： { : { : , ... }, : { : , ... }, ... } 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 更新运算符 字段 名称 描述 $currentDate 将字段的值设置为当前日期，即日期或时间戳。 $inc 将字段的值增加指定的数量。 $min 仅当指定值小于现有字段值时才更新该字段。 $max 仅当指定值大于现有字段值时才更新该字段。 $mul 将字段的值乘以指定的数量。 $rename 重命名字段。 $set 设置文档中字段的值。 $setOnInsert 如果更新导致插入文档，则设置字段的值。对修改现有文档的更新操作没有影响。 $unset 从文档中删除指定的字段。 数组 运算符 名称 描述 $ 充当占位符，以更新与查询条件匹配的第一个元素。 $[] 充当占位符，以更新匹配查询条件的文档的数组中的所有元素。 $[] 充当占位符，以更新arrayFilters与查询条件匹配的文档中所有与条件匹配的元素。 $addToSet 仅当元素不存在于集合中时才将它们添加到数组中。 $pop 删除数组的第一项或最后一项。 $pull 删除与指定查询匹配的所有数组元素。 $push 将项目添加到数组。 $pullAll 从数组中删除所有匹配的值。 修饰符 名称 描述 $each 修改$push和$addToSet运算符以附加多个项以进行数组更新。 $position 修改$push运算符以指定要添加元素的数组中的位置。 $slice 修改$push运算符以限制更新数组的大小。 $sort 修改$push运算符以对存储在数组中的文档重新排序。 按位 名称 描述 $bit 执行按位AND，OR和XOR整数值的更新。 译者：李冠飞 校对： 参见 原文 - Update Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field.html":{"url":"16-reference/01-operator/02-update/01-update-field.html","title":"Field Update Operators","keywords":"","body":" Field Update Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Field Update Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/01-currentDate.html":{"url":"16-reference/01-operator/02-update/01-update-field/01-currentDate.html","title":"$currentDate","keywords":"","body":" $currentDate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $currentDate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/02-inc.html":{"url":"16-reference/01-operator/02-update/01-update-field/02-inc.html","title":"$inc","keywords":"","body":" $inc ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $inc Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/03-min.html":{"url":"16-reference/01-operator/02-update/01-update-field/03-min.html","title":"$min","keywords":"","body":" $min ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $min Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/04-max.html":{"url":"16-reference/01-operator/02-update/01-update-field/04-max.html","title":"$max","keywords":"","body":" $max ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $max Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/05-mul.html":{"url":"16-reference/01-operator/02-update/01-update-field/05-mul.html","title":"$mul","keywords":"","body":" $mul ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $mul Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/06-rename.html":{"url":"16-reference/01-operator/02-update/01-update-field/06-rename.html","title":"$rename","keywords":"","body":" $rename ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $rename Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/07-set.html":{"url":"16-reference/01-operator/02-update/01-update-field/07-set.html","title":"$set","keywords":"","body":" $set ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $set Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/08-setOnInsert.html":{"url":"16-reference/01-operator/02-update/01-update-field/08-setOnInsert.html","title":"$setOnInsert","keywords":"","body":" $setOnInsert ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setOnInsert Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/01-update-field/09-unset.html":{"url":"16-reference/01-operator/02-update/01-update-field/09-unset.html","title":"$unset","keywords":"","body":" $unset ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $unset Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array.html":{"url":"16-reference/01-operator/02-update/02-update-array.html","title":"Array Update Operators","keywords":"","body":" Array Update Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Array Update Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/01-positional.html":{"url":"16-reference/01-operator/02-update/02-update-array/01-positional.html","title":"$ (update)","keywords":"","body":" $ (update) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ (update) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/02-positional-all.html":{"url":"16-reference/01-operator/02-update/02-update-array/02-positional-all.html","title":"$[]","keywords":"","body":" $[] ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $[] Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/03-positional-filtered.html":{"url":"16-reference/01-operator/02-update/02-update-array/03-positional-filtered.html","title":"$[]","keywords":"","body":" $[] ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $[] Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/04-addToSet.html":{"url":"16-reference/01-operator/02-update/02-update-array/04-addToSet.html","title":"$addToSet","keywords":"","body":" $addToSet ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $addToSet Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/05-pop.html":{"url":"16-reference/01-operator/02-update/02-update-array/05-pop.html","title":"$pop","keywords":"","body":" $pop ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $pop Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/06-pull.html":{"url":"16-reference/01-operator/02-update/02-update-array/06-pull.html","title":"$pull","keywords":"","body":" $pull ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $pull Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/07-push.html":{"url":"16-reference/01-operator/02-update/02-update-array/07-push.html","title":"$push","keywords":"","body":" $push ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $push Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/08-pullAll.html":{"url":"16-reference/01-operator/02-update/02-update-array/08-pullAll.html","title":"$pullAll","keywords":"","body":" $pullAll ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $pullAll Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/09-each.html":{"url":"16-reference/01-operator/02-update/02-update-array/09-each.html","title":"$each","keywords":"","body":" $each ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $each Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/10-position.html":{"url":"16-reference/01-operator/02-update/02-update-array/10-position.html","title":"$position","keywords":"","body":" $position ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $position Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/11-slice.html":{"url":"16-reference/01-operator/02-update/02-update-array/11-slice.html","title":"$slice","keywords":"","body":" $slice ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $slice Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/02-update-array/12-sort.html":{"url":"16-reference/01-operator/02-update/02-update-array/12-sort.html","title":"$sort","keywords":"","body":" $sort ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sort Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/03-update-bitwise.html":{"url":"16-reference/01-operator/02-update/03-update-bitwise.html","title":"Bitwise Update Operator","keywords":"","body":" Bitwise Update Operator ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bitwise Update Operator Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/03-update-bitwise/01-bit.html":{"url":"16-reference/01-operator/02-update/03-update-bitwise/01-bit.html","title":"$bit","keywords":"","body":" $bit ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bit Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/Update-Operators/Array-Update-Operators.html":{"url":"16-reference/01-operator/02-update/Update-Operators/Array-Update-Operators.html","title":"数组更新运算符","keywords":"","body":" 数组更新运算符 在本页面 更新运算符 更新运算符修饰符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 更新运算符 名称 描述 $ 充当占位符，以更新与查询条件匹配的第一个元素。 $[] 充当占位符，以更新匹配查询条件的文档的数组中的所有元素。 $[] 充当占位符，以更新arrayFilters与查询条件匹配的文档中所有与条件匹配的元素。 $addToSet 仅当元素不存在于集合中时才将它们添加到数组中。 $pop 删除数组的第一项或最后一项。 $pull 删除与指定查询匹配的所有数组元素。 $push 将项目添加到数组。 $pullAll 从数组中删除所有匹配的值。 更新运算符修饰符 名称 描述 $each 修改$push和$addToSet运算符以附加多个项以进行数组更新。 $position 修改$push运算符以指定要添加元素的数组中的位置。 $slice 修改$push运算符以限制更新数组的大小。 $sort 修改$push运算符以对存储在数组中的文档重新排序。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/Update-Operators/Bitwise-Update-Operator.html":{"url":"16-reference/01-operator/02-update/Update-Operators/Bitwise-Update-Operator.html","title":"按位更新运算符","keywords":"","body":" 按位更新运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $bit 执行按位AND，OR和XOR整数值的更新。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/02-update/Update-Operators/Field-Update-Operators.html":{"url":"16-reference/01-operator/02-update/Update-Operators/Field-Update-Operators.html","title":"字段更新运算符","keywords":"","body":" 字段更新运算符 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 名称 描述 $currentDate 将字段的值设置为当前日期，即日期或时间戳。 $inc 将字段的值增加指定的数量。 $min 仅当指定值小于现有字段值时才更新该字段。 $max 仅当指定值大于现有字段值时才更新该字段。 $mul 将字段的值乘以指定的数量。 $rename 重命名字段。 $set 设置文档中字段的值。 $setOnInsert 如果更新导致插入文档，则设置字段的值。对修改现有文档的更新操作没有影响。 $unset 从文档中删除指定的字段。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline.html":{"url":"16-reference/01-operator/03-aggregation-pipeline.html","title":"Aggregation Pipeline Stages","keywords":"","body":" Aggregation Pipeline Stages ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Aggregation Pipeline Stages Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/01-addFields.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/01-addFields.html","title":"$addFields (aggregation)","keywords":"","body":" $addFields (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $addFields (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/02-bucket.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/02-bucket.html","title":"$bucket (aggregation)","keywords":"","body":" $bucket (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bucket (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/03-bucketAuto.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/03-bucketAuto.html","title":"$bucketAuto (aggregation)","keywords":"","body":" $bucketAuto (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bucketAuto (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/04-collStats.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/04-collStats.html","title":"$collStats (aggregation)","keywords":"","body":" $collStats (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $collStats (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/05-count.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/05-count.html","title":"$count (aggregation)","keywords":"","body":" $count (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $count (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/06-currentOp.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/06-currentOp.html","title":"$currentOp (aggregation)","keywords":"","body":" $currentOp (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $currentOp (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/07-facet.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/07-facet.html","title":"$facet (aggregation)","keywords":"","body":" $facet (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $facet (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/08-geoNear.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/08-geoNear.html","title":"$geoNear (aggregation)","keywords":"","body":" $geoNear (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $geoNear (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/09-graphLookup.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/09-graphLookup.html","title":"$graphLookup (aggregation)","keywords":"","body":" $graphLookup (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $graphLookup (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/10-group.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/10-group.html","title":"$group (aggregation)","keywords":"","body":" $group (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $group (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/11-indexStats.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/11-indexStats.html","title":"$indexStats (aggregation)","keywords":"","body":" $indexStats (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $indexStats (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/12-limit.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/12-limit.html","title":"$limit (aggregation)","keywords":"","body":" $limit (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $limit (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/13-listLocalSessions.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/13-listLocalSessions.html","title":"$listLocalSessions","keywords":"","body":" $listLocalSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $listLocalSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/14-listSessions.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/14-listSessions.html","title":"$listSessions","keywords":"","body":" $listSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $listSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/15-lookup.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/15-lookup.html","title":"$lookup (aggregation)","keywords":"","body":" $lookup (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $lookup (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/16-match.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/16-match.html","title":"$match (aggregation)","keywords":"","body":" $match (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $match (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/17-merge.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/17-merge.html","title":"$merge (aggregation)","keywords":"","body":" $merge (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $merge (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/18-out.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/18-out.html","title":"$out (aggregation)","keywords":"","body":" $out (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $out (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/19-planCacheStats.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/19-planCacheStats.html","title":"$planCacheStats","keywords":"","body":" $planCacheStats ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $planCacheStats Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/20-project.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/20-project.html","title":"$project (aggregation)","keywords":"","body":" $project (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $project (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/21-redact.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/21-redact.html","title":"$redact (aggregation)","keywords":"","body":" $redact (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $redact (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/22-replaceRoot.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/22-replaceRoot.html","title":"$replaceRoot (aggregation)","keywords":"","body":" $replaceRoot (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $replaceRoot (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/23-replaceWith.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/23-replaceWith.html","title":"$replaceWith (aggregation)","keywords":"","body":" $replaceWith (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $replaceWith (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/24-sample.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/24-sample.html","title":"$sample (aggregation)","keywords":"","body":" $sample (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sample (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/25-set.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/25-set.html","title":"$set (aggregation)","keywords":"","body":" $set (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $set (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/26-skip.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/26-skip.html","title":"$skip (aggregation)","keywords":"","body":" $skip (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $skip (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/27-sort.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/27-sort.html","title":"$sort (aggregation)","keywords":"","body":" $sort (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sort (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/28-sortByCount.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/28-sortByCount.html","title":"$sortByCount (aggregation)","keywords":"","body":" $sortByCount (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sortByCount (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/29-unionWith.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/29-unionWith.html","title":"$unionWith (aggregation)","keywords":"","body":" $unionWith (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $unionWith (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/30-unset.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/30-unset.html","title":"$unset (aggregation)","keywords":"","body":" $unset (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $unset (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/03-aggregation-pipeline/31-unwind.html":{"url":"16-reference/01-operator/03-aggregation-pipeline/31-unwind.html","title":"$unwind (aggregation)","keywords":"","body":" $unwind (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $unwind (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation.html":{"url":"16-reference/01-operator/04-aggregation.html","title":"Aggregation Pipeline Operators","keywords":"","body":" Aggregation Pipeline Operators ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Aggregation Pipeline Operators Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/00-sin.html":{"url":"16-reference/01-operator/04-aggregation/00-sin.html","title":"$sin (aggregation)","keywords":"","body":" $sin (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sin (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/01-abs.html":{"url":"16-reference/01-operator/04-aggregation/01-abs.html","title":"$abs (aggregation)","keywords":"","body":" $abs (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $abs (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/01-slice.html":{"url":"16-reference/01-operator/04-aggregation/01-slice.html","title":"$slice (aggregation)","keywords":"","body":" $slice (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $slice (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/02-accumulator.html":{"url":"16-reference/01-operator/04-aggregation/02-accumulator.html","title":"$accumulator (aggregation)","keywords":"","body":" $accumulator (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $accumulator (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/02-split.html":{"url":"16-reference/01-operator/04-aggregation/02-split.html","title":"$split (aggregation)","keywords":"","body":" $split (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $split (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/03-acos.html":{"url":"16-reference/01-operator/04-aggregation/03-acos.html","title":"$acos (aggregation)","keywords":"","body":" $acos (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $acos (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/03-sqrt.html":{"url":"16-reference/01-operator/04-aggregation/03-sqrt.html","title":"$sqrt (aggregation)","keywords":"","body":" $sqrt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sqrt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/04-acosh.html":{"url":"16-reference/01-operator/04-aggregation/04-acosh.html","title":"$acosh (aggregation)","keywords":"","body":" $acosh (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $acosh (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/05-add.html":{"url":"16-reference/01-operator/04-aggregation/05-add.html","title":"$add (aggregation)","keywords":"","body":" $add (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $add (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/06-addToSet.html":{"url":"16-reference/01-operator/04-aggregation/06-addToSet.html","title":"$addToSet (aggregation)","keywords":"","body":" $addToSet (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $addToSet (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/07-allElementsTrue.html":{"url":"16-reference/01-operator/04-aggregation/07-allElementsTrue.html","title":"$allElementsTrue (aggregation)","keywords":"","body":" $allElementsTrue (aggregation) 在本页面 定义 行为 例子 定义 $allElementsTrue 将数组评估为集合，如果 array 中没有元素为false，则返回true。否则，返回false。空 array 返回true。 $allElementsTrue具有以下语法： { $allElementsTrue: [ ] } 本身必须解析为 array，与表示参数列表的外部 array 分开。有关表达式的更多信息，请参阅表达式。 行为 如果集合包含嵌套的 array 元素，则$allElementsTrue不会降级到嵌套的 array 中，而是在 top-level 处计算 array。 除了false 布尔值之外，$allElementsTrue还将false计算为以下值：null，0和undefined值。 $allElementsTrue将所有其他值计算为true，包括非零数值和数组。 例子 结果 { $allElementsTrue: [ [ true, 1, \"someString\" ] ] } true { $allElementsTrue: [ [ [ false ] ] ] } true { $allElementsTrue: [ [ ] ] } true { $allElementsTrue: [ [ null, false, 0 ] ] } true 例子 考虑带有以下文档的survey集合： { \"_id\" : 1, \"responses\" : [ true ] } { \"_id\" : 2, \"responses\" : [ true, false ] } { \"_id\" : 3, \"responses\" : [ ] } { \"_id\" : 4, \"responses\" : [ 1, true, \"seven\" ] } { \"_id\" : 5, \"responses\" : [ 0 ] } { \"_id\" : 6, \"responses\" : [ [ ] ] } { \"_id\" : 7, \"responses\" : [ [ 0 ] ] } { \"_id\" : 8, \"responses\" : [ [ false ] ] } { \"_id\" : 9, \"responses\" : [ null ] } { \"_id\" : 10, \"responses\" : [ undefined ] } 以下操作使用$allElementsTrue operator 来确定responses array 是否仅包含求值为true的值： db.survey.aggregate( [ { $project: { responses: 1, isAllTrue: { $allElementsTrue: [ \"$responses\" ] }, _id: 0 } } ] ) 该操作返回以下结果： { \"responses\" : [ true ], \"isAllTrue\" : true } { \"responses\" : [ true, false ], \"isAllTrue\" : false } { \"responses\" : [ ], \"isAllTrue\" : true } { \"responses\" : [ 1, true, \"seven\" ], \"isAllTrue\" : true } { \"responses\" : [ 0 ], \"isAllTrue\" : false } { \"responses\" : [ [ ] ], \"isAllTrue\" : true } { \"responses\" : [ [ 0 ] ], \"isAllTrue\" : true } { \"responses\" : [ [ false ] ], \"isAllTrue\" : true } { \"responses\" : [ null ], \"isAllTrue\" : false } { \"responses\" : [ null ], \"isAllTrue\" : false } 译者：李冠飞 校对： 参见 原文 - $allElementsTrue (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/08-and.html":{"url":"16-reference/01-operator/04-aggregation/08-and.html","title":"$and (aggregation)","keywords":"","body":" $and (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $and (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/09-anyElementTrue.html":{"url":"16-reference/01-operator/04-aggregation/09-anyElementTrue.html","title":"$anyElementTrue (aggregation)","keywords":"","body":" $anyElementTrue (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $anyElementTrue (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/10-arrayElemAt.html":{"url":"16-reference/01-operator/04-aggregation/10-arrayElemAt.html","title":"$arrayElemAt (aggregation)","keywords":"","body":" $arrayElemAt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $arrayElemAt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/11-arrayToObject.html":{"url":"16-reference/01-operator/04-aggregation/11-arrayToObject.html","title":"$arrayToObject (aggregation)","keywords":"","body":" $arrayToObject (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $arrayToObject (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/12-asin.html":{"url":"16-reference/01-operator/04-aggregation/12-asin.html","title":"$asin (aggregation)","keywords":"","body":" $asin (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $asin (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/13-asinh.html":{"url":"16-reference/01-operator/04-aggregation/13-asinh.html","title":"$asinh (aggregation)","keywords":"","body":" $asinh (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $asinh (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/13-sum.html":{"url":"16-reference/01-operator/04-aggregation/13-sum.html","title":"$sum (aggregation)","keywords":"","body":" $sum (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sum (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/14-atan.html":{"url":"16-reference/01-operator/04-aggregation/14-atan.html","title":"$atan (aggregation)","keywords":"","body":" $atan (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $atan (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/15-atan2.html":{"url":"16-reference/01-operator/04-aggregation/15-atan2.html","title":"$atan2 (aggregation)","keywords":"","body":" $atan2 (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $atan2 (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/15-tan.html":{"url":"16-reference/01-operator/04-aggregation/15-tan.html","title":"$tan (aggregation)","keywords":"","body":" $tan (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $tan (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/16-atanh.html":{"url":"16-reference/01-operator/04-aggregation/16-atanh.html","title":"$atanh (aggregation)","keywords":"","body":" $atanh (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $atanh (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/17-avg.html":{"url":"16-reference/01-operator/04-aggregation/17-avg.html","title":"$avg (aggregation)","keywords":"","body":" $avg (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $avg (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/18-binarySize.html":{"url":"16-reference/01-operator/04-aggregation/18-binarySize.html","title":"$binarySize (aggregation)","keywords":"","body":" $binarySize (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $binarySize (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/19-bsonSize.html":{"url":"16-reference/01-operator/04-aggregation/19-bsonSize.html","title":"$bsonSize (aggregation)","keywords":"","body":" $bsonSize (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $bsonSize (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/20-ceil.html":{"url":"16-reference/01-operator/04-aggregation/20-ceil.html","title":"$ceil (aggregation)","keywords":"","body":" $ceil (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ceil (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/20-toInt.html":{"url":"16-reference/01-operator/04-aggregation/20-toInt.html","title":"$toInt (aggregation)","keywords":"","body":" $toInt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toInt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/21-cmp.html":{"url":"16-reference/01-operator/04-aggregation/21-cmp.html","title":"$cmp (aggregation)","keywords":"","body":" $cmp (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $cmp (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/22-concat.html":{"url":"16-reference/01-operator/04-aggregation/22-concat.html","title":"$concat (aggregation)","keywords":"","body":" $concat (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $concat (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/23-concatArrays.html":{"url":"16-reference/01-operator/04-aggregation/23-concatArrays.html","title":"$concatArrays (aggregation)","keywords":"","body":" $concatArrays (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $concatArrays (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/24-cond.html":{"url":"16-reference/01-operator/04-aggregation/24-cond.html","title":"$cond (aggregation)","keywords":"","body":" $cond (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $cond (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/25-convert.html":{"url":"16-reference/01-operator/04-aggregation/25-convert.html","title":"$convert (aggregation)","keywords":"","body":" $convert (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $convert (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/26-cos.html":{"url":"16-reference/01-operator/04-aggregation/26-cos.html","title":"$cos (aggregation)","keywords":"","body":" $cos (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $cos (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/27-dateFromParts.html":{"url":"16-reference/01-operator/04-aggregation/27-dateFromParts.html","title":"$dateFromParts (aggregation)","keywords":"","body":" $dateFromParts (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dateFromParts (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/28-dateToParts.html":{"url":"16-reference/01-operator/04-aggregation/28-dateToParts.html","title":"$dateToParts (aggregation)","keywords":"","body":" $dateToParts (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dateToParts (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/28-type.html":{"url":"16-reference/01-operator/04-aggregation/28-type.html","title":"$type (aggregation)","keywords":"","body":" $type (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $type (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/29-dateFromString.html":{"url":"16-reference/01-operator/04-aggregation/29-dateFromString.html","title":"$dateFromString (aggregation)","keywords":"","body":" $dateFromString (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dateFromString (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/29-week.html":{"url":"16-reference/01-operator/04-aggregation/29-week.html","title":"$week (aggregation)","keywords":"","body":" $week (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $week (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/30-dateToString.html":{"url":"16-reference/01-operator/04-aggregation/30-dateToString.html","title":"$dateToString (aggregation)","keywords":"","body":" $dateToString (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dateToString (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/30-year.html":{"url":"16-reference/01-operator/04-aggregation/30-year.html","title":"$year (aggregation)","keywords":"","body":" $year (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $year (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/31-dayOfMonth.html":{"url":"16-reference/01-operator/04-aggregation/31-dayOfMonth.html","title":"$dayOfMonth (aggregation)","keywords":"","body":" $dayOfMonth (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dayOfMonth (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/31-zip.html":{"url":"16-reference/01-operator/04-aggregation/31-zip.html","title":"$zip (aggregation)","keywords":"","body":" $zip (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $zip (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/32-dayOfWeek.html":{"url":"16-reference/01-operator/04-aggregation/32-dayOfWeek.html","title":"$dayOfWeek (aggregation)","keywords":"","body":" $dayOfWeek (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dayOfWeek (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/33-dayOfYear.html":{"url":"16-reference/01-operator/04-aggregation/33-dayOfYear.html","title":"$dayOfYear (aggregation)","keywords":"","body":" $dayOfYear (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $dayOfYear (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/34-degreesToRadians.html":{"url":"16-reference/01-operator/04-aggregation/34-degreesToRadians.html","title":"$degreesToRadians (aggregation)","keywords":"","body":" $degreesToRadians (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $degreesToRadians (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/35-divide.html":{"url":"16-reference/01-operator/04-aggregation/35-divide.html","title":"$divide (aggregation)","keywords":"","body":" $divide (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $divide (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/36-eq.html":{"url":"16-reference/01-operator/04-aggregation/36-eq.html","title":"$eq (aggregation)","keywords":"","body":" $eq (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $eq (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/37-exp.html":{"url":"16-reference/01-operator/04-aggregation/37-exp.html","title":"$exp (aggregation)","keywords":"","body":" $exp (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $exp (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/38-filter.html":{"url":"16-reference/01-operator/04-aggregation/38-filter.html","title":"$filter (aggregation)","keywords":"","body":" $filter (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $filter (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/39-first.html":{"url":"16-reference/01-operator/04-aggregation/39-first.html","title":"$first (aggregation accumulator)","keywords":"","body":" $first (aggregation accumulator) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $first (aggregation accumulator) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/40-first-array-element.html":{"url":"16-reference/01-operator/04-aggregation/40-first-array-element.html","title":"$first (aggregation)","keywords":"","body":" $first (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $first (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/41-floor.html":{"url":"16-reference/01-operator/04-aggregation/41-floor.html","title":"$floor (aggregation)","keywords":"","body":" $floor (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $floor (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/42-function.html":{"url":"16-reference/01-operator/04-aggregation/42-function.html","title":"$function (aggregation)","keywords":"","body":" $function (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $function (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/43-gt.html":{"url":"16-reference/01-operator/04-aggregation/43-gt.html","title":"$gt (aggregation)","keywords":"","body":" $gt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $gt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/44-gte.html":{"url":"16-reference/01-operator/04-aggregation/44-gte.html","title":"$gte (aggregation)","keywords":"","body":" $gte (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $gte (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/45-hour.html":{"url":"16-reference/01-operator/04-aggregation/45-hour.html","title":"$hour (aggregation)","keywords":"","body":" $hour (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $hour (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/46-ifNull.html":{"url":"16-reference/01-operator/04-aggregation/46-ifNull.html","title":"$ifNull (aggregation)","keywords":"","body":" $ifNull (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ifNull (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/47-in.html":{"url":"16-reference/01-operator/04-aggregation/47-in.html","title":"$in (aggregation)","keywords":"","body":" $in (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $in (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/48-indexOfArray.html":{"url":"16-reference/01-operator/04-aggregation/48-indexOfArray.html","title":"$indexOfArray (aggregation)","keywords":"","body":" $indexOfArray (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $indexOfArray (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/49-indexOfBytes.html":{"url":"16-reference/01-operator/04-aggregation/49-indexOfBytes.html","title":"$indexOfBytes (aggregation)","keywords":"","body":" $indexOfBytes (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $indexOfBytes (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/50-indexOfCP.html":{"url":"16-reference/01-operator/04-aggregation/50-indexOfCP.html","title":"$indexOfCP (aggregation)","keywords":"","body":" $indexOfCP (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $indexOfCP (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/51-isArray.html":{"url":"16-reference/01-operator/04-aggregation/51-isArray.html","title":"$isArray (aggregation)","keywords":"","body":" $isArray (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $isArray (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/52-isNumber.html":{"url":"16-reference/01-operator/04-aggregation/52-isNumber.html","title":"$isNumber (aggregation)","keywords":"","body":" $isNumber (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $isNumber (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/53-isoDayOfWeek.html":{"url":"16-reference/01-operator/04-aggregation/53-isoDayOfWeek.html","title":"$isoDayOfWeek (aggregation)","keywords":"","body":" $isoDayOfWeek (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $isoDayOfWeek (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/54-isoWeek.html":{"url":"16-reference/01-operator/04-aggregation/54-isoWeek.html","title":"$isoWeek (aggregation)","keywords":"","body":" $isoWeek (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $isoWeek (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/55-isoWeekYear.html":{"url":"16-reference/01-operator/04-aggregation/55-isoWeekYear.html","title":"$isoWeekYear (aggregation)","keywords":"","body":" $isoWeekYear (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $isoWeekYear (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/56-last.html":{"url":"16-reference/01-operator/04-aggregation/56-last.html","title":"$last (aggregation accumulator)","keywords":"","body":" $last (aggregation accumulator) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $last (aggregation accumulator) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/57-last-array-element.html":{"url":"16-reference/01-operator/04-aggregation/57-last-array-element.html","title":"$last (aggregation)","keywords":"","body":" $last (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $last (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/58-let.html":{"url":"16-reference/01-operator/04-aggregation/58-let.html","title":"$let (aggregation)","keywords":"","body":" $let (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $let (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/59-literal.html":{"url":"16-reference/01-operator/04-aggregation/59-literal.html","title":"$literal (aggregation)","keywords":"","body":" $literal (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $literal (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/60-ln.html":{"url":"16-reference/01-operator/04-aggregation/60-ln.html","title":"$ln (aggregation)","keywords":"","body":" $ln (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ln (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/61-log.html":{"url":"16-reference/01-operator/04-aggregation/61-log.html","title":"$log (aggregation)","keywords":"","body":" $log (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $log (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/62-log10.html":{"url":"16-reference/01-operator/04-aggregation/62-log10.html","title":"$log10 (aggregation)","keywords":"","body":" $log10 (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $log10 (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/63-lt.html":{"url":"16-reference/01-operator/04-aggregation/63-lt.html","title":"$lt (aggregation)","keywords":"","body":" $lt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $lt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/64-lte.html":{"url":"16-reference/01-operator/04-aggregation/64-lte.html","title":"$lte (aggregation)","keywords":"","body":" $lte (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $lte (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/65-ltrim.html":{"url":"16-reference/01-operator/04-aggregation/65-ltrim.html","title":"$trim (aggregation)","keywords":"","body":" $trim (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $trim (aggregation) 参见 原文 - $ltrim (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/66-map.html":{"url":"16-reference/01-operator/04-aggregation/66-map.html","title":"$map (aggregation)","keywords":"","body":" $map (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $map (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/67-max.html":{"url":"16-reference/01-operator/04-aggregation/67-max.html","title":"$max (aggregation)","keywords":"","body":" $max (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $max (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/68-mergeObjects.html":{"url":"16-reference/01-operator/04-aggregation/68-mergeObjects.html","title":"$mergeObjects (aggregation)","keywords":"","body":" $mergeObjects (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $mergeObjects (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/69-meta.html":{"url":"16-reference/01-operator/04-aggregation/69-meta.html","title":"$meta","keywords":"","body":" $meta ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $meta Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/70-min.html":{"url":"16-reference/01-operator/04-aggregation/70-min.html","title":"$min (aggregation)","keywords":"","body":" $min (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $min (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/71-millisecond.html":{"url":"16-reference/01-operator/04-aggregation/71-millisecond.html","title":"$millisecond (aggregation)","keywords":"","body":" $millisecond (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $millisecond (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/72-minute.html":{"url":"16-reference/01-operator/04-aggregation/72-minute.html","title":"$minute (aggregation)","keywords":"","body":" $minute (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $minute (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/73-mod.html":{"url":"16-reference/01-operator/04-aggregation/73-mod.html","title":"$mod (aggregation)","keywords":"","body":" $mod (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $mod (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/74-month.html":{"url":"16-reference/01-operator/04-aggregation/74-month.html","title":"$month (aggregation)","keywords":"","body":" $month (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $month (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/75-multiply.html":{"url":"16-reference/01-operator/04-aggregation/75-multiply.html","title":"$multiply (aggregation)","keywords":"","body":" $multiply (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $multiply (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/76-ne.html":{"url":"16-reference/01-operator/04-aggregation/76-ne.html","title":"$ne (aggregation)","keywords":"","body":" $ne (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $ne (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/77-not.html":{"url":"16-reference/01-operator/04-aggregation/77-not.html","title":"$not (aggregation)","keywords":"","body":" $not (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $not (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/78-objectToArray.html":{"url":"16-reference/01-operator/04-aggregation/78-objectToArray.html","title":"$objectToArray (aggregation)","keywords":"","body":" $objectToArray (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $objectToArray (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/79-or.html":{"url":"16-reference/01-operator/04-aggregation/79-or.html","title":"$or (aggregation)","keywords":"","body":" $or (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $or (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/80-pow.html":{"url":"16-reference/01-operator/04-aggregation/80-pow.html","title":"$pow (aggregation)","keywords":"","body":" $pow (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $pow (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/81-push.html":{"url":"16-reference/01-operator/04-aggregation/81-push.html","title":"$push (aggregation)","keywords":"","body":" $push (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $push (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/82-radiansToDegrees.html":{"url":"16-reference/01-operator/04-aggregation/82-radiansToDegrees.html","title":"$radiansToDegrees (aggregation)","keywords":"","body":" $radiansToDegrees (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $radiansToDegrees (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/83-range.html":{"url":"16-reference/01-operator/04-aggregation/83-range.html","title":"$range (aggregation)","keywords":"","body":" $range (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $range (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/84-reduce.html":{"url":"16-reference/01-operator/04-aggregation/84-reduce.html","title":"$reduce (aggregation)","keywords":"","body":" $reduce (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $reduce (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/85-regexFind.html":{"url":"16-reference/01-operator/04-aggregation/85-regexFind.html","title":"$regexFind (aggregation)","keywords":"","body":" $regexFind (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $regexFind (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/86-regexFindAll.html":{"url":"16-reference/01-operator/04-aggregation/86-regexFindAll.html","title":"$regexFindAll (aggregation)","keywords":"","body":" $regexFindAll (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $regexFindAll (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/87-regexMatch.html":{"url":"16-reference/01-operator/04-aggregation/87-regexMatch.html","title":"$regexMatch (aggregation)","keywords":"","body":" $regexMatch (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $regexMatch (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/88-replaceOne.html":{"url":"16-reference/01-operator/04-aggregation/88-replaceOne.html","title":"$replaceOne (aggregation)","keywords":"","body":" $replaceOne (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $replaceOne (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/89-replaceAll.html":{"url":"16-reference/01-operator/04-aggregation/89-replaceAll.html","title":"$replaceAll (aggregation)","keywords":"","body":" $replaceAll (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $replaceAll (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/90-reverseArray.html":{"url":"16-reference/01-operator/04-aggregation/90-reverseArray.html","title":"$reverseArray (aggregation)","keywords":"","body":" $reverseArray (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $reverseArray (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/91-round.html":{"url":"16-reference/01-operator/04-aggregation/91-round.html","title":"$round (aggregation)","keywords":"","body":" $round (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $round (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/92-rtrim.html":{"url":"16-reference/01-operator/04-aggregation/92-rtrim.html","title":"$rtrim (aggregation)","keywords":"","body":" $rtrim (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $rtrim (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/93-second.html":{"url":"16-reference/01-operator/04-aggregation/93-second.html","title":"$second (aggregation)","keywords":"","body":" $second (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $second (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/94-setDifference.html":{"url":"16-reference/01-operator/04-aggregation/94-setDifference.html","title":"$setDifference (aggregation)","keywords":"","body":" $setDifference (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setDifference (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/95-setEquals.html":{"url":"16-reference/01-operator/04-aggregation/95-setEquals.html","title":"$setEquals (aggregation)","keywords":"","body":" $setEquals (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setEquals (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/96-setIntersection.html":{"url":"16-reference/01-operator/04-aggregation/96-setIntersection.html","title":"$setIntersection (aggregation)","keywords":"","body":" $setIntersection (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setIntersection (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/97-setIsSubset.html":{"url":"16-reference/01-operator/04-aggregation/97-setIsSubset.html","title":"$setIsSubset (aggregation)","keywords":"","body":" $setIsSubset (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setIsSubset (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/98-setUnion.html":{"url":"16-reference/01-operator/04-aggregation/98-setUnion.html","title":"$setUnion (aggregation)","keywords":"","body":" $setUnion (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $setUnion (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99-size.html":{"url":"16-reference/01-operator/04-aggregation/99-size.html","title":"$size (aggregation)","keywords":"","body":" $size (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $size (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+02-slice.html":{"url":"16-reference/01-operator/04-aggregation/99+02-slice.html","title":"$slice (aggregation)","keywords":"","body":" $slice (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $slice (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+03-split.html":{"url":"16-reference/01-operator/04-aggregation/99+03-split.html","title":"$split (aggregation)","keywords":"","body":" $split (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $split (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+04-sqrt.html":{"url":"16-reference/01-operator/04-aggregation/99+04-sqrt.html","title":"$sqrt (aggregation)","keywords":"","body":" $sqrt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sqrt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+05-stdDevPop.html":{"url":"16-reference/01-operator/04-aggregation/99+05-stdDevPop.html","title":"$stdDevPop (aggregation)","keywords":"","body":" $stdDevPop (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $stdDevPop (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+06-stdDevSamp.html":{"url":"16-reference/01-operator/04-aggregation/99+06-stdDevSamp.html","title":"$stdDevSamp (aggregation)","keywords":"","body":" $stdDevSamp (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $stdDevSamp (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+07-strcasecmp.html":{"url":"16-reference/01-operator/04-aggregation/99+07-strcasecmp.html","title":"$strcasecmp (aggregation)","keywords":"","body":" $strcasecmp (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $strcasecmp (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+08-strLenBytes.html":{"url":"16-reference/01-operator/04-aggregation/99+08-strLenBytes.html","title":"$strLenBytes (aggregation)","keywords":"","body":" $strLenBytes (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $strLenBytes (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+09-strLenCP.html":{"url":"16-reference/01-operator/04-aggregation/99+09-strLenCP.html","title":"$strLenCP (aggregation)","keywords":"","body":" $strLenCP (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $strLenCP (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+10-substr.html":{"url":"16-reference/01-operator/04-aggregation/99+10-substr.html","title":"$substr (aggregation)","keywords":"","body":" $substr (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $substr (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+11-substrBytes.html":{"url":"16-reference/01-operator/04-aggregation/99+11-substrBytes.html","title":"$substrBytes (aggregation)","keywords":"","body":" $substrBytes (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $substrBytes (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+12-substrCP.html":{"url":"16-reference/01-operator/04-aggregation/99+12-substrCP.html","title":"$substrCP (aggregation)","keywords":"","body":" $substrCP (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $substrCP (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+13-subtract.html":{"url":"16-reference/01-operator/04-aggregation/99+13-subtract.html","title":"$subtract (aggregation)","keywords":"","body":" $subtract (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $subtract (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+14-sum.html":{"url":"16-reference/01-operator/04-aggregation/99+14-sum.html","title":"$sum (aggregation)","keywords":"","body":" $sum (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $sum (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+15-switch.html":{"url":"16-reference/01-operator/04-aggregation/99+15-switch.html","title":"$switch (aggregation)","keywords":"","body":" $switch (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $switch (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+16-tan.html":{"url":"16-reference/01-operator/04-aggregation/99+16-tan.html","title":"$tan (aggregation)","keywords":"","body":" $tan (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $tan (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+17-toBool.html":{"url":"16-reference/01-operator/04-aggregation/99+17-toBool.html","title":"$toBool (aggregation)","keywords":"","body":" $toBool (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toBool (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+18-toDate.html":{"url":"16-reference/01-operator/04-aggregation/99+18-toDate.html","title":"$toDate (aggregation)","keywords":"","body":" $toDate (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toDate (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+19-toDecimal.html":{"url":"16-reference/01-operator/04-aggregation/99+19-toDecimal.html","title":"$toDecimal (aggregation)","keywords":"","body":" $toDecimal (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toDecimal (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+20-toDouble.html":{"url":"16-reference/01-operator/04-aggregation/99+20-toDouble.html","title":"$toDouble(aggregation)","keywords":"","body":" $toDouble(aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toDouble(aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+21-toInt.html":{"url":"16-reference/01-operator/04-aggregation/99+21-toInt.html","title":"$toInt (aggregation)","keywords":"","body":" $toInt (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toInt (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+22-toLong.html":{"url":"16-reference/01-operator/04-aggregation/99+22-toLong.html","title":"$toLong (aggregation)","keywords":"","body":" $toLong (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toLong (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+23-toObjectId.html":{"url":"16-reference/01-operator/04-aggregation/99+23-toObjectId.html","title":"$toObjectId (aggregation)","keywords":"","body":" $toObjectId (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toObjectId (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+24-toString.html":{"url":"16-reference/01-operator/04-aggregation/99+24-toString.html","title":"$toString (aggregation)","keywords":"","body":" $toString (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toString (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+25-toLower.html":{"url":"16-reference/01-operator/04-aggregation/99+25-toLower.html","title":"$toLower (aggregation)","keywords":"","body":" $toLower (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toLower (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+26-toUpper.html":{"url":"16-reference/01-operator/04-aggregation/99+26-toUpper.html","title":"$toUpper (aggregation)","keywords":"","body":" $toUpper (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $toUpper (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+27-trim.html":{"url":"16-reference/01-operator/04-aggregation/99+27-trim.html","title":"$trim (aggregation)","keywords":"","body":" $trim (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $trim (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+28-trunc.html":{"url":"16-reference/01-operator/04-aggregation/99+28-trunc.html","title":"$trunc (aggregation)","keywords":"","body":" $trunc (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $trunc (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+29-type.html":{"url":"16-reference/01-operator/04-aggregation/99+29-type.html","title":"$type (aggregation)","keywords":"","body":" $type (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $type (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+30-week.html":{"url":"16-reference/01-operator/04-aggregation/99+30-week.html","title":"$week (aggregation)","keywords":"","body":" $week (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $week (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+31-year.html":{"url":"16-reference/01-operator/04-aggregation/99+31-year.html","title":"$year (aggregation)","keywords":"","body":" $year (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $year (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/04-aggregation/99+32-zip.html":{"url":"16-reference/01-operator/04-aggregation/99+32-zip.html","title":"$zip (aggregation)","keywords":"","body":" $zip (aggregation) ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $zip (aggregation) Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier.html":{"url":"16-reference/01-operator/05-query-modifier.html","title":"查询修饰符","keywords":"","body":" 查询修饰符 除了MongoDB查询运算符外，还有许多meta运算符可让您修改查询的输出或行为。 注意 mongo从v3.2开始在Shell中不推荐使用 从v3.2开始，mongoshell 中不建议使用查询meta运算符。在mongoshell程序中，改用游标方法 。 驱动程序接口可以提供包装这些选项的游标方法。如果可能，请使用这些方法。否则，您可以使用以下两种语法之一添加这些选项： db.collection.find( { } )._addSpecial( ) db.collection.find( { $query: { }, } ) 运算符 修饰符 注意 mongo从v3.2开始在Shell中不推荐使用 从v3.2开始，mongoshell 中不建议使用查询meta运算符。在mongoshell程序中，改用游标方法 。 名称 描述 $comment 向查询添加注释，以标识数据库探查器输出中的查询。 $explain 强制MongoDB报告查询执行计划。请参阅explain()。 $hint 仅强制MongoDB使用特定索引。请看hint() $max 指定要在查询中使用的索引的排他上限。请参阅max()。 $maxTimeMS 指定对游标进行处理操作的累积时间限制（以毫秒为单位）。请参阅maxTimeMS()。 $min 指定一个包容性的下限为索引在查询中使用。请参阅min()。 $orderby 返回带有根据排序规范排序的文档的游标。请参阅sort()。 $query 包装查询文档。 $returnKey 强制游标仅返回索引中包含的字段。 $showDiskLoc 修改返回的文档以包括对每个文档在磁盘上位置的引用。 排序顺序 名称 描述 $natural 一种特殊的排序顺序，使用磁盘上的文档顺序对文档进行排序。 译者：李冠飞 校对： 参见 原文 - Query Modifiers Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/01-comment.html":{"url":"16-reference/01-operator/05-query-modifier/01-comment.html","title":"$comment","keywords":"","body":" $comment ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $comment Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/02-explain.html":{"url":"16-reference/01-operator/05-query-modifier/02-explain.html","title":"$explain","keywords":"","body":" $explain ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $explain Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/03-hint.html":{"url":"16-reference/01-operator/05-query-modifier/03-hint.html","title":"$hint","keywords":"","body":" $hint ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $hint Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/04-max.html":{"url":"16-reference/01-operator/05-query-modifier/04-max.html","title":"$max","keywords":"","body":" $max ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $max Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/05-maxTimeMS.html":{"url":"16-reference/01-operator/05-query-modifier/05-maxTimeMS.html","title":"$maxTimeMS","keywords":"","body":" $maxTimeMS ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $maxTimeMS Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/06-min.html":{"url":"16-reference/01-operator/05-query-modifier/06-min.html","title":"$min","keywords":"","body":" $min ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $min Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/07-orderby.html":{"url":"16-reference/01-operator/05-query-modifier/07-orderby.html","title":"$orderby","keywords":"","body":" $orderby ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $orderby Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/08-query.html":{"url":"16-reference/01-operator/05-query-modifier/08-query.html","title":"$query","keywords":"","body":" $query ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $query Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/09-returnKey.html":{"url":"16-reference/01-operator/05-query-modifier/09-returnKey.html","title":"$returnKey","keywords":"","body":" $returnKey ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $returnKey Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/10-showDiskLoc.html":{"url":"16-reference/01-operator/05-query-modifier/10-showDiskLoc.html","title":"$showDiskLoc","keywords":"","body":" $showDiskLoc ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $showDiskLoc Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/05-query-modifier/11-natural.html":{"url":"16-reference/01-operator/05-query-modifier/11-natural.html","title":"$natural","keywords":"","body":" $natural ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - $natural Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators.html","title":"聚合管道操作符","keywords":"","body":" 聚合管道操作符 注意： 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 表达式运算符 在这个部分 算术表达式运算符 列表表达式运算符 布尔表达式运算符 比较表达式运算符 条件表达式运算符 日期表达式运算符 文字表达式运算符 对象表达式运算符 集合表达式运算符 字符串表达式运算符 文本表达式运算符 三角表达式运算符 类型表达式运算符 累加器($group) 累加器(处于其他阶段) 变量表达式运算符 这些表达式运算符可用于构造表达式以在聚合管道阶段中使用。 运算符表达式类似于带有参数的函数。通常，这些表达式采用参数数组并具有以下形式： { : [ , ... ] } 如果 operator 接受单个参数，可以省略指定参数列表的外部数组： { : } 为了避免在参数是文字数组的情况下解析歧义，必须将文字数组包装在$literal表达式中，或者保留指定参数列表的外部数组。 算术表达式运算符 算术表达式对 numbers 执行数学运算。一些算术表达式也可以支持 date 算术。 名称 描述 $abs 返回数字的绝对 value。 $add 添加 numbers 以 return 总和，或添加 numbers 和 date 以 return 新的 date。如果添加 numbers 和 date，则将 numbers 视为毫秒。接受任意数量的参数表达式，但最多只能有一个表达式解析为 date。 $ceil 返回大于或等于指定数字的最小 integer。 $divide 返回将第一个数除以第二个数的结果。接受两个参数表达式。 $exp 将 e 提高到指定的指数。 $floor 返回小于或等于指定数字的最大 integer。 $ln 计算数字的自然 log。 $log 计算指定基数中的数字的 log。 $log10 计算数字的 log 基数 10。 $mod 返回第一个数字的余数除以第二个数字。接受两个参数表达式。 $multiply 将 numbers 乘以_return 产品。接受任意数量的参数表达式。 $pow 将数字提高到指定的指数。 $round 将数字四舍五入为整数或指定的小数位。 $sqrt 计算平方根。 $subtract 返回从第一个中减去第二个 value 的结果。如果这两个值是 numbers，返回差异。如果这两个值是日期，则返回差异(以毫秒为单位)。如果这两个值是 date 和一个以毫秒为单位的数字，_return 结果 date。接受两个参数表达式。如果这两个值是 date 和数字，请首先指定 date 参数，因为从数字中减去 date 没有意义。 $trunc 截断其整数的数字。 列表表达式运算符 名称 描述 $arrayElemAt 返回指定的数组索引处的元素。 $arrayToObject 将键值对的数组转换为文档。 $concatArrays 连接数组以返回连接的数组。 $filter 选择数组的子集以返回仅包含与过滤条件匹配的元素的数组。 $in 返回一个布尔值，指示指定的值是否在数组中。 $indexOfArray 在数组中搜索指定值的出现，并返回第一个出现的数组索引。如果未找到子字符串，则返回-1。 $isArray 确定操作数是否为数组。返回一个布尔值。 $map 对数组的每个元素应用子表达式，并按顺序返回结果值的数组。接受命名参数。 $objectToArray 将文档转换为代表键值对的文档数组。 $range 根据用户定义的输入输出包含整数序列的数组。 $reduce 将表达式应用于数组中的每个元素，并将它们组合为单个值。 $reverseArray 返回具有相反顺序元素的数组。 $size 返回数组中元素的数量。接受单个表达式作为参数。 $slice 返回数组的子集。 $zip 合并两个数组。 布尔表达式运算符 布尔表达式将其参数表达式计算为布尔值，并返回布尔值作为结果。 除了false布尔值，布尔表达式为false如下：null，0，和undefined 的值。布尔表达式将所有其他值评估为true，包括非零数字值和数组。 名称 描述 $and 仅当其所有表达式求值为true时才返回true。接受任意数量的参数表达式。 $not 返回与其参数表达式相反的 boolean value。接受单个参数表达式。 $or 当任何表达式求值为true时返回true。接受任意数量的参数表达式。 比较表达式运算符 比较表达式返回一个布尔值，但$cmp返回一个数字。 比较表达式采用两个参数表达式并比较 value 和 type，使用指定的 BSON 比较顺序表示不同类型的值。 名称 描述 $cmp 如果两个值相等则返回0，如果第一个 value 大于第二个值则返回1，如果第一个 value 小于第二个值，则返回-1。 $eq 如果值相等，则返回true。 $gt 如果第一个 value 大于第二个，则返回true。 $gte 如果第一个 value 大于或等于第二个，则返回true。 $lt 如果第一个 value 小于第二个，则返回true。 $lte 如果第一个 value 小于或等于第二个值，则返回true。 $ne 如果值不相等，则返回true。 条件表达式运算符 名称 描述 $cond 一个三元运算符，它计算一个表达式，并根据结果返回另外两个表达式之一的值。接受有序列表中的三个表达式或三个命名参数。 $ifNull 如果第一个表达式导致结果为null ，则返回第一个表达式的非空结果或第二个表达式的结果。空结果包含未定义值或缺少字段的实例。接受两个表达式作为参数。第二个表达式的结果可以为 null。 $switch 计算一系列案例表达式。当它找到一个计算结果为true的表达式时，$switch执行一个指定的表达式并退出控制流。 日期表达式运算符 以下运算符返回日期对象或日期对象的组成部分： 名称 描述 $dateFromParts 给出日期的组成部分，构造一个 BSON Date对象。 $dateFromString 将 date/time 字符串转换为 date 对象。 $dateToParts 返回包含 date 组成部分的文档。 $dateToString 将 date 作为格式化的 string 返回。 $dayOfMonth 将 date 的月中某天返回为 1 到 31 之间的数字。 $dayOfWeek 将 date 的星期几返回为 1(星期日)和 7(星期六)之间的数字。 $dayOfYear 将 date 的年中日期作为 1 到 366(闰年)之间的数字返回。 $hour 将 date 的小时数作为 0 到 23 之间的数字返回。 $isoDayOfWeek 返回 ISO 8601 格式的工作日编号，范围从1(星期一)到7(星期日)。 $isoWeek 返回 ISO 8601 格式的周数，范围从1到53。 星期数从1开始，周(星期一到星期日)包含年份的第一个星期四。 $isoWeekYear 以 ISO 8601 格式返回年份编号。年份从第 1 周的星期一(ISO 8601)开始，结束于上周的星期日(ISO 8601)。 $millisecond 返回 date 的毫秒数，作为 0 到 999 之间的数字。 $minute 将 date 的分钟作为 0 到 59 之间的数字返回。 $month 将 date 的月份返回为 1(1 月)和 12(12 月)之间的数字。 $second 返回 date 的秒数，作为 0 到 60 之间的数字(闰秒)。 $toDate 将值转换为日期。版本4.0中的新功能。 $week 返回 date 的周数，作为 0(在一年的第一个星期日之前的部分周)和 53(闰年)之间的数字。 $year 将 date 的年份作为数字返回(例：2014)。 以下算术运算符可以使用 date 操作数： 名称 描述 $add 添加 numbers 和 date 以返回新的 date。如果添加 numbers 和 date，则将 numbers 视为毫秒。接受任意数量的参数表达式，但最多只能有一个表达式解析为 date。 $subtract 返回从第一个中减去第二个值的结果。如果这两个值是日期，则返回差异(以毫秒为单位)。如果这两个值是 date 和一个以毫秒为单位的数字，返回结果 date。接受两个参数表达式。如果这两个值是 date 和数字，请首先指定 date 参数，因为从数字中减去 date 没有意义。 文字表达式运算符 名称 描述 $literal 无需解析即可返回 value。用于聚合管道可以将其解释为表达式的值。例如，对以$开头的字符串使用]$literal表达式，以避免解析为字段路径。 对象表达式运算符 名称 描述 $mergeObjects 将多个文档合并为一个文档。 version 3.6 中的新内容。 $objectToArray 将文档转换为表示 key-value 对的文档的 array。 version 3.6 中的新内容。 集合表达式运算符 Set 表达式对数组执行 set 操作，将数组视为 sets。 Set 表达式忽略每个输入数组中的重复条目和元素的顺序。 如果 set 操作返回一个 set，则该操作会过滤掉结果中的重复项，以输出仅包含唯一条目的 array。输出 array 中元素的顺序未指定。 如果集合包含嵌套的 array 元素，则 set 表达式不会下降到嵌套的 array 中，而是在顶层level 处计算 array。 名称 描述 $allElementsTrue 如果没有集合的元素计算为false，则返回true，否则返回false。接受单个参数表达式。 $anyElementTrue 如果集合中的任何元素求值为true，则返回true;否则，返回false。接受单个参数表达式。 $setDifference 返回一个集合，其中的元素出现在第一个集合中但不出现在第二个集合中; 即：相对于第一组执行第二组的相对补充。接受两个参数表达式。 $setEquals 如果输入 sets 具有相同的不同元素，则返回true。接受两个或多个参数表达式。 $setIntersection 返回一个包含所有输入 sets 中出现的元素的集合。接受任意数量的参数表达式。 $setIsSubset 如果第一组的所有元素出现在第二组中，则返回true，包括第一组的等于第二组的时间; 即：不是严格的子集。接受两个参数表达式。 $setUnion 返回一个包含任何输入 sets 中出现的元素的集合。 字符串表达式运算符 字符串表达式（除外 $concat）仅对ASCII字符字符串具有明确定义的行为。 $concat 行为是明确定义的，与所使用的字符无关。 名称 描述 $concat 连接任意数量的 strings。 $dateFromString 将 date/time string 转换为 date object。 $dateToString 将 date 作为格式化的 string 返回。 $indexOfBytes 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 字节索引。如果未找到子字符串，则返回-1。 $indexOfCP 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 code 点索引。如果找不到子字符串，则返回-1 $ltrim 从字符串开头删除空格或指定的字符。版本4.0中的新功能。 $regexFind 将正则表达式（regex）应用于字符串，并返回第一个匹配的子字符串的信息。4.2版中的新功能。 $regexFindAll 将正则表达式（regex）应用于字符串，并返回所有匹配的子字符串的信息。4.2版中的新功能。 $regexMatch 将正则表达式（regex）应用于字符串，并返回一个布尔值，该布尔值指示是否找到匹配项。4.2版中的新功能。 $rtrim 从字符串末尾删除空格或指定的字符。版本4.0中的新功能。 $split 根据分隔符将 string 拆分为子字符串。返回子字符串的 array。如果在 string 中找不到分隔符，则返回包含原始 string 的 array。 $strLenBytes 返回 string 中 UTF-8 编码字节的数量。 $strLenCP 返回 string 中 UTF-8 code 点的数量。 $strcasecmp 执行 case-insensitive string 比较并返回：如果两个 strings 相等则返回0，如果第一个 string 大于第二个，则返回1，如果第一个 string 小于第二个，则返回-1。 $substr 已过时。使用$substrBytes或$substrCP。 $substrBytes 返回 string 的子字符串。从 string 中指定的 UTF-8 字节索引(zero-based)处的字符开始，并继续指定的字节数。 $substrCP 返回 string 的子字符串。从 string 中指定的 UTF-8 code point(CP)索引(zero-based)处的字符开始，并继续指定的 code 点数。 $toLower 将 string 转换为小写。接受单个参数表达式。 $toString 将值转换为字符串。版本4.0中的新功能。 $trim 从字符串的开头和结尾删除空格或指定的字符。版本4.0中的新功能。 $toUpper 将 string 转换为大写。接受单个参数表达式。 文本表达式运算符 名称 描述 $meta 访问文本搜索元数据。 三角表达式运算符 三角表达式对数字执行三角运算。表示角度的值始终以弧度为单位输入或输出。使用 $degreesToRadians和$radiansToDegrees在度和弧度测量之间转换。 名称 描述 $sin 返回以弧度为单位的值的正弦值。 $cos 返回以弧度为单位的值的余弦值。 $tan 返回以弧度为单位的值的切线。 $asin 返回弧度值的反正弦（弧正弦）。 $acos 返回弧度值的反余弦（弧余弦）。 $atan 返回弧度值的反正切（弧切）。 $atan2 返回弧度表示的y / x的反正切（弧切线），其中y和x是分别传递给表达式的第一个和第二个值。 $asinh 返回弧度值的反双曲正弦（双曲反正弦）。 $acosh 返回弧度值的反双曲余弦（双曲反余弦）。 $atanh 返回弧度值的反双曲正切（双曲反正切）。 $degreesToRadians 将值从度转换为弧度。 $radiansToDegrees 将值从弧度转换为度。 类型表达式运算符 名称 描述 $convert 将值转换为指定的类型。版本4.0中的新功能。 $toBool 将值转换为布尔值。版本4.0中的新功能。 $toDate 将值转换为日期。版本4.0中的新功能。 $toDecimal 将值转换为Decimal128。版本4.0中的新功能。 $toDouble 将值转换为双精度。版本4.0中的新功能。 $toInt 将值转换为整数。版本4.0中的新功能。 $toLong 将值转换为long。版本4.0中的新功能。 $toObjectId 将值转换为ObjectId。版本4.0中的新功能。 $toString 将值转换为字符串。版本4.0中的新功能。 $type 返回该字段的BSON数据类型。 累加器($group) 累加器是可以在$group阶段使用的运算符，它们在文档通过管道时保持其状态(例如： 总计，最大值，最小值和相关数据)。 当在$group阶段用作累加器时，这些运算符将单个表达式作为输入，为每个输入文档计算一次表达式，并为共享相同 group key 的 group 文档保持其阶段。 名称 描述 $addToSet 返回每个 group 的唯一表达式值的 array。 数组元素的顺序是未定义的。 $avg 返回数值的平均值。忽略非数字值。 $first 从每个 group 的第一个文档返回一个值。仅当文档按定义的顺序定义顺序。 $last 从每个 group 的最后一个文档返回一个值。仅当文档按定义的顺序定义顺序。 $max 返回每个 group 的最高表达式值。 $mergeObjects 返回通过组合每个 group 的输入文档创建的文档。 $min 返回每个 group 的最低表达式值。 $push 返回每个 group 的表达式值的 array。 $stdDevPop 返回输入值的总体标准偏差。 $stdDevSamp 返回输入值的 sample 标准偏差。 $sum 返回数值的总和。忽略非数字值。 累加器(处于其他阶段) 一些可用作$group阶段累加器的运算符也可用于$project阶段，但不能用作累加器。在$project阶段使用时，这些 operator 不会维护它们的 state，并且可以将单个参数或多个 arguments 作为输入。 更改了 version 3.2. 以下累加器 operators 也可用于$project、$addFields和$set阶段。 名称 描述 $avg 返回每个文档的指定表达式或表达式列表的平均值。忽略非数字值。 $max 返回每个文档的指定表达式或表达式列表的最大值。 $min 返回每个文档的指定表达式或表达式列表的最小值。 $stdDevPop 返回输入值的总体标准偏差。 $stdDevSamp 返回输入值的样本标准偏差。 $sum 返回数值的总和。忽略非数字值。 变量表达式运算符 名称 描述 $let 定义在子表达式范围内使用的变量，并返回子表达式的结果。接受命名参数。 接受任意数量的参数表达式。 表达式运算符的字母顺序列表 名称 描述 $abs 返回数字的绝对值。 $acos 返回弧度值的反余弦（弧余弦）。 $acosh 返回弧度值的反双曲余弦（双曲反余弦）。 $add 添加数字以返回总和，或者添加数字和日期以返回新日期。如果添加数字和日期，则将数字视为毫秒。接受任意数量的参数表达式，但最多只能一个表达式解析为日期。 $addToSet 返回每个 group 的唯一表达式值的 array。 数组元素的顺序是未定义的。 仅适用于$group阶段 $allElementsTrue 如果没有集合的元素计算为false，则返回true，否则返回false。接受单个参数表达式。 $and 仅当其所有表达式求值为true时才返回true。接受任意数量的参数表达式。 $anyElementTrue 如果集合中的任何元素求值为true，则返回true;否则，返回false。接受单个参数表达式。 $arrayElemAt 返回指定的 array 索引处的元素。 $arrayToObject 将键值对的 array 转换为文档。 $asin 返回弧度值的反正弦（弧正弦）。 $asinh 返回弧度值的反双曲正弦（双曲反正弦）。 $atan 返回弧度值的反正切（弧切）。 $atan2 返回弧度表示的y / x的反正切（弧切线），其中y和x是分别传递给表达式的第一个和第二个值。 $atanh 返回弧度值的反双曲正切（双曲反正切）。 $avg 返回数值的平均值。忽略非数字值。 在 version 3.2 中更改：在$group和$project阶段均可用。 $ceil 返回大于或等于指定数字的最小整数。 $cmp 如果两个值相等则返回0，如果第一个 value 大于第二个值则返回1，如果第一个 value 小于第二个值，则返回-1。 $concat 连接任意数量的字符串。 $concatArrays 连接数组以返回连接的数组。 $cond 一个三元运算符，它计算一个表达式，并根据结果返回另外两个表达式之一的值。接受有序列表中的三个表达式或三个命名参数。 $convert 将值转换为指定的类型。 $cos 返回以弧度为单位的值的余弦值。 $dateFromParts 给出 date 的组成部分，构造一个 BSON Date对象。 $dateToParts 返回包含 date 组成部分的文档。 $dateFromString 返回 date/time 作为 date 对象。 $dateToString 将 date 作为格式化的 string 返回。 $dayOfMonth 将 date 的月中某天返回为 1 到 31 之间的数字。 $dayOfWeek 将 date 的星期几返回为 1(星期日)和 7(星期六)之间的数字。 $dayOfYear 将 date 的年中日期作为 1 到 366(闰年)之间的数字返回。 $degreesToRadians 将值从度转换为弧度。 $divide 返回将第一个数除以第二个数的结果。接受两个参数表达式。 $eq 如果值相等，则返回true。 $exp 将 e 提高到指定的指数。 $filter 选择 array 的子集以返回 array 仅包含 match 过滤条件的元素。 $first 从每个 group 的第一个文档返回一个 value。仅当文档位于已定义的 order 中时才定义 Order。 仅适用于$group阶段。 $floor 返回小于或等于指定数字的最大 integer。 $gt 如果第一个 value 大于第二个，则返回true。 $gte 如果第一个 value 大于或等于第二个，则返回true。 $hour 将 date 的小时数作为 0 到 23 之间的数字返回。 $ifNull 如果第一个表达式导致 null 结果，则返回第一个表达式的 non-null 结果或第二个表达式的结果。空结果包含未定义值或缺少字段的实例。接受两个表达式作为参数。第二个表达式的结果可以为 null。 $in 返回一个 boolean，指示指定的 value 是否在 array 中。 $indexOfArray 搜索 array 以查找指定 value 的出现并返回第一次出现的 array 索引。如果未找到子字符串，则返回-1。 $indexOfBytes 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 字节索引。如果未找到子字符串，则返回-1。 $indexOfCP 搜索 string 以查找子字符串的出现并返回第一次出现的 UTF-8 code 点索引。如果未找到子字符串，则返回-1。 $isArray 确定操作数是否为 array。返回 boolean。 $isoDayOfWeek 返回 ISO 8601 格式的工作日编号，范围从1(星期一)到7(星期日)。 $isoWeek 返回 ISO 8601 格式的周数，范围从1到53。 Week numbers 从1开始，周(星期一到星期日)包含年份的第一个星期四。 $isoWeekYear 以 ISO 8601 格式返回年份编号。年份从第 1 周的星期一(ISO 8601)开始，结束于上周的星期日(ISO 8601)。 $last 从每个 group 的最后一个文档返回一个 value。仅当文档位于已定义的 order 中时才定义 Order。 仅适用于$group阶段。 $let 定义在子表达式范围内使用的变量，并返回子表达式的结果。接受命名参数。 接受任意数量的参数表达式。 $literal 无需解析即可返回 value。用于聚合管道可以将其解释为表达式的值。例如，对以$开头的字符串使用$literal表达式，以避免解析为字段路径。 $ln 计算数字的自然对数。 $log 计算指定基数中的数字的对数。 $log10 计算数字的以10为底的对数。 $lt 如果第一个 value 小于第二个，则返回true。 $lte 如果第一个 value 小于或等于第二个值，则返回true。 $ltrim 从字符串开头删除空格或指定的字符。 $map 将子表达式应用于 array 的每个元素，并按顺序返回结果值的 array。接受命名参数。 $max 返回每个 group 的最高表达式 value。 在 version 3.2 中更改：在$group和$project阶段均可用。 $mergeObjects 将多个文档合并为一个文档。 $meta 访问文本搜索元数据。 $min 返回每个 group 的最低表达式 value。 在 version 3.2 中更改：在$group和$project阶段均可用。 $millisecond 返回 date 的毫秒数，作为 0 到 999 之间的数字。 $minute 将 date 的分钟作为 0 到 59 之间的数字返回。 $mod 返回第一个数字的余数除以第二个数字。接受两个参数表达式。 $month 将 date 的月份返回为 1(1 月)和 12(12 月)之间的数字。 $multiply 乘以数字可返回乘积。接受任意数量的参数表达式。 $ne 如果值不相等，则返回true。 $not 返回与其参数表达式相反的布尔值。接受单个参数表达式。 $objectToArray 将文档转换为表示键值对的文档的 array。 $or 当任何表达式求值为true时返回true。接受任意数量的参数表达式。 $pow 将数字提高到指定的指数。 $push 返回每个 group 的表达式值的 array。 仅适用于$group阶段。 $range 根据用户定义输入输出包含整数序列的 array。 $reduce 将表达式应用于 array 中的每个元素，并将它们组合为单个 value。 $regexFind 将正则表达式（regex）应用于字符串，并返回第一个匹配的子字符串的信息。 $regexFindAll 将正则表达式（regex）应用于字符串，并返回所有匹配的子字符串的信息。 $regexMatch 将正则表达式（regex）应用于字符串，并返回一个布尔值，该布尔值指示是否找到匹配项。 $reverseArray 返回具有相反顺序元素的 array。 $round 将数字四舍五入为整数或指定的小数位。 $rtrim 从字符串末尾删除空格或指定的字符。 $second 返回 date 的秒数，作为 0 到 60 之间的数字(闰秒)。 $setDifference 返回一个集合，其中的元素出现在第一个集合中但不出现在第二个集合中; 即：相对于第一组执行第二组的相对补充)。接受两个参数表达式。 $setEquals 如果输入集合具有相同的不同元素，则返回true。接受两个或多个参数表达式。 $setIntersection 返回一个包含所有输入集合中出现的元素的集合。接受任意数量的参数表达式。 $setIsSubset 如果第一组的所有元素出现在第二组中，则返回true，包括第一组的等于第二组的时间; 即：不是严格的子集。接受两个参数表达式。 $setUnion 返回一个包含任何输入集合中出现的元素的集合。 $size 返回 array 中的元素数。接受单个表达式作为参数。 $sin 返回以弧度为单位的值的正弦值。 $slice 返回 array 的子集。 $split 根据分隔符将 string 拆分为子字符串。返回子字符串的 array。如果在 string 中找不到分隔符，则返回包含原始 string 的 array。 $sqrt 计算平方根。 $stdDevPop 返回输入值的总体标准偏差。 在 version 3.2 中更改：在$group和$project阶段均可用。 $stdDevSamp 返回输入值的样本标准偏差。 在 version 3.2 中更改：在$group和$project阶段均可用。 $strcasecmp 执行不区分大小写的字符串比较并返回：如果两个字符串相等则返回0，如果第一个字符串大于第二个，则返回1，如果第一个字符串小于第二个，则返回-1。 $strLenBytes 返回 string 中 UTF-8 编码字节的数量。 $strLenCP 返回 string 中 UTF-8 code 点的数量。 $substr 已过时。使用$substrBytes或$substrCP。 $substrBytes 返回 string 的子字符串。从 string 中指定的 UTF-8 字节索引(从零开始)处的字符开始，并继续指定的字节数。 $substrCP 返回 string 的子字符串。从 string 中指定的 UTF-8 code point(CP)索引(从零开始)处的字符开始，并继续指定的 code 点数 $subtract 返回从第一个中减去第二个 value 的结果。如果这两个值是数字，返回差值。如果这两个值是日期，则返回差值(以毫秒为单位)。如果这两个值是 date 和一个以毫秒为单位的数字，则返回结果 date。接受两个参数表达式。如果这两个值是 date 和数字，请首先指定 date 参数，因为从数字中减去 date 没有意义。 $sum 返回数值的总和。忽略非数字值。 在 version 3.2 中更改：在$group和$project阶段均可用。 $switch 计算一系列案例表达。当它找到一个计算结果为true的表达式时，$switch执行一个指定的表达式并退出控制流。 $tan 返回以弧度为单位的值的切线。 $toBool 将值转换为布尔值。 $toDate 将值转换为日期。 $toDecimal 将值转换为Decimal128。 $toDouble 将值转换为双精度。 $toInt 将值转换为整数。 $toLong 将值转换为long。 $toObjectId 将值转换为ObjectId。 $toString 将值转换为字符串。 $toLower 将 string 转换为小写。接受单个参数表达式。 $toUpper 将 string 转换为大写。接受单个参数表达式。 $trim 从字符串的开头和结尾删除空格或指定的字符。 $trunc 截断其整数的数字。 $type 返回该字段的 BSON 数据类型。 $week 返回 date 的周数，作为 0(在一年的第一个星期日之前的部分周)和 53(闰年)之间的数字。 $year 将 date 的年份作为数字返回(例：2014)。 $zip 将两个数组合并在一起。 对于管道阶段，请参见聚合管道阶段。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/abs-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/abs-aggregation.html","title":"$abs (aggregation)","keywords":"","body":" $abs (aggregation) 在本页面 定义 行为 例子 定义 $abs version 3.2 中的新内容。 返回数字的绝对 value。 $abs具有以下语法： { $abs: } 表达式可以是任何有效的表达，因为它解析为数字。有关表达式的更多信息，请参阅表达式。 行为 如果参数解析为的值或引用缺少的字段，则$abs返回null。如果参数解析为NaN，则$abs返回NaN。 例子 结果 { $abs: -1 } 1 { $abs: 1 } 1 { $abs: null } null 例子 集合ratings包含以下文档： { _id: 1, start: 5, end: 8 } { _id: 2, start: 4, end: 4 } { _id: 3, start: 9, end: 7 } { _id: 4, start: 6, end: 7 } 以下 example 计算start和end评级之间的差异大小： db.ratings.aggregate([ { $project: { delta: { $abs: { $subtract: [ \"$start\", \"$end\" ] } } } } ]) 该操作返回以下结果： { \"_id\" : 1, \"delta\" : 3 } { \"_id\" : 2, \"delta\" : 0 } { \"_id\" : 3, \"delta\" : 2 } { \"_id\" : 4, \"delta\" : 1 } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/acos-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/acos-aggregation.html","title":"$acos (aggregation)","keywords":"","body":" $acos (aggregation) 在本页面 行为 例子 $acos 4.2版中的新功能。 返回值的反余弦（弧余弦）。 $acos具有以下语法： { $acos: } $acos接受任何有效的表达式，该表达式可解析为-1 和之间的数字1，例如。-1 $acos返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$acos返回值double。 $acos也可以返回值作为 128-bit小数 ，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 如果参数解析为null的值或指向缺少的字段，则$acos返回null。如果参数解析为NaN，则$acos返回NaN。如果参数解析为包含[-1, 1] 范围之外的值 ，则$acos会引发错误。。 例子 结果 { $acos: NaN } NaN { $acos: null } null { $acos : Infinity}or{ $acos : -Infinity } 引发类似于以下格式化输出的错误消息：\"errmsg\" : \"Failed to optimize pipeline :: caused by :: cannot apply $acos to -inf, value must in [-1,1]\" 例子 度数的反余弦值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $acos表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $radiansToDegrees : { $acos : { $divide : [ \"$side_b\", \"$hypotenuse\" ] } } } } } ]) $radiansToDegrees表达式将返回的弧度值转换为$acos以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"36.86989764584402129685561255909341\") } 由于side_b和hypotenuse被存储为 128-bit小数，因此输出 $acos为128-bit小数。 弧度的反余弦值 trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $acos表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $acos : { $divide : [ \"$side_b\", \"$hypotenuse\" ] } } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"0.6435011087932843868028092287173226\") } 由于side_b和hypotenuse被存储为 128-bit小数，因此输出 $acos为128-bit小数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/acosh-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/acosh-aggregation.html","title":"$acosh (aggregation)","keywords":"","body":" $acosh (aggregation) 在本页面 行为 例子 $acosh 4.2版中的新功能。 返回值的反双曲余弦（双曲反余弦）。 $acosh 具有以下语法： { $acosh: } $acosh接受任何有效的表达式，该表达式可解析为1 和之间的数字+Infinity，例如：1 $acosh返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$acosh返回值double。 $acosh也可以返回值作为 128-bit小数，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null，NaN和+/- Infinity 如果参数解析为的值null或指向缺少的字段，则$acosh返回null。如果参数解析为NaN，则$acosh返回NaN。如果参数解析为负无穷大， $acosh则会引发错误。如果参数解析为Infinity，则$acosh返回Infinity。如果参数解析为包含[-1, Infinity]范围之外的值 ，则$acosh会引发错误。 例子 结果 { $acosh: NaN } NaN { $acosh: null } null { $acosh : Infinity} Infinity { $acosh : 0 } 引发类似于以下格式化输出的错误消息：\"errmsg\" : \"Failed to optimize pipeline :: caused by :: cannot apply $acosh to -inf, value must in (1,inf)\" 例子 度数的反双曲余弦值 trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"3\") } 以下聚合操作使用该 $acosh表达式计算的反双曲余弦值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $radiansToDegrees : { $acosh : \"$x-coordinate\" } } } } ]) $radiansToDegrees表达式将返回的弧度值转换为$acosh以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"3\"), \"y-coordinate\" : NumberDecimal(\"100.9979734210524228844295260083432\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $acosh为128-bit十进制数。 弧度的反双曲余弦值 trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"3\") } 以下聚合操作使用该 $acosh表达式计算的反双曲余弦值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $acosh : \"$x-coordinate\" } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"3\"), \"y-coordinate\" : NumberDecimal(\"1.762747174039086050465218649959585\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $acosh为128-bit十进制数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/add-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/add-aggregation.html","title":"$add (aggregation)","keywords":"","body":" $add (aggregation) 在本页面 定义 例子 定义 $add 添加数字或添加数字和日期。如果其中一个参数是 date，则$add将其他参数视为要添加到 date 的毫秒数。 $add表达式具有以下语法： { $add: [ , , ... ] } 参数可以是任何有效的表达，只要它们可以解析为所有数字或数字和日期。有关表达式的更多信息，请参阅表达式。 例子 以下示例使用带有以下文档的sales集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 10, \"fee\" : 2, date: ISODate(\"2014-03-01T08:00:00Z\") } { \"_id\" : 2, \"item\" : \"jkl\", \"price\" : 20, \"fee\" : 1, date: ISODate(\"2014-03-01T09:00:00Z\") } { \"_id\" : 3, \"item\" : \"xyz\", \"price\" : 5, \"fee\" : 0, date: ISODate(\"2014-03-15T09:00:00Z\") } 添加数字 以下聚合使用$project管道中的$add表达式来计算总成本： db.sales.aggregate( [ { $project: { item: 1, total: { $add: [ \"$price\", \"$fee\" ] } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"item\" : \"abc\", \"total\" : 12 } { \"_id\" : 2, \"item\" : \"jkl\", \"total\" : 21 } { \"_id\" : 3, \"item\" : \"xyz\", \"total\" : 5 } 在 Date 上执行加法 以下聚合使用$add表达式billing_date通过将3*24*60*60000毫秒(即：3 天)添加到date字段来计算： db.sales.aggregate( [ { $project: { item: 1, billing_date: { $add: [ \"$date\", 3*24*60*60000 ] } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"item\" : \"abc\", \"billing_date\" : ISODate(\"2014-03-04T08:00:00Z\") } { \"_id\" : 2, \"item\" : \"jkl\", \"billing_date\" : ISODate(\"2014-03-04T09:00:00Z\") } { \"_id\" : 3, \"item\" : \"xyz\", \"billing_date\" : ISODate(\"2014-03-18T09:00:00Z\") } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/addToSet-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/addToSet-aggregation.html","title":"$addToSet (aggregation)","keywords":"","body":" $addToSet (aggregation) 在本页面 定义 行为 例子 定义 $addToSet 返回所有唯一值的数组，这些值是通过将表达式应用于一组按键共享相同组的文档中的每个文档而得到的。未指定输出数组中元素的顺序。 $addToSet仅在$group阶段可用。 $addToSet具有以下语法： { $addToSet: } 有关表达式的更多信息，请参阅表达式。 行为 数组表达式 如果表达式的 value 是 array，则$addToSet将整个 array 作为单个元素追加。 文档表达 如果表达式的值是一个文档，则如果数组中的另一个文档与要添加的文档完全匹配，则MongoDB将确定该文档是重复的。也就是说，现有文档具有完全相同的字段和值，并且顺序完全相同 内存限制 从版本4.2.3（和4.0.14、3.6.17）开始， $addToSet内存限制也为100 MiB（100 1024 1024），即使db.collection.aggregate()使用allowDiskUse：true运行 。 有关更多信息，请参见聚集管道限制。 例子 考虑带有以下文档的sales集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 2, \"date\" : ISODate(\"2014-01-01T08:00:00Z\") } { \"_id\" : 2, \"item\" : \"jkl\", \"price\" : 20, \"quantity\" : 1, \"date\" : ISODate(\"2014-02-03T09:00:00Z\") } { \"_id\" : 3, \"item\" : \"xyz\", \"price\" : 5, \"quantity\" : 5, \"date\" : ISODate(\"2014-02-03T09:05:00Z\") } { \"_id\" : 4, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 10, \"date\" : ISODate(\"2014-02-15T08:00:00Z\") } { \"_id\" : 5, \"item\" : \"xyz\", \"price\" : 5, \"quantity\" : 10, \"date\" : ISODate(\"2014-02-15T09:12:00Z\") } 按date字段的日期和年份对文档进行分组，以下操作使用$addToSet累加器计算为每个 group 销售的唯一商品的列表： db.sales.aggregate( [ { $group:{ _id: { day: { $dayOfYear: \"$date\"}, year: { $year: \"$date\" } }, itemsSold: { $addToSet: \"$item\" } } } ] ) 该操作返回以下结果： { \"_id\" : { \"day\" : 46, \"year\" : 2014 }, \"itemsSold\" : [ \"xyz\", \"abc\" ] } { \"_id\" : { \"day\" : 34, \"year\" : 2014 }, \"itemsSold\" : [ \"xyz\", \"jkl\" ] } { \"_id\" : { \"day\" : 1, \"year\" : 2014 }, \"itemsSold\" : [ \"abc\" ] } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/and-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/and-aggregation.html","title":"$and (aggregation)","keywords":"","body":" $and (aggregation) 在本页面 定义 行为 例子 定义 $and 计算一个或多个表达式，如果所有表达式都为true，或者如果没有参数表达式调用，则返回true。否则，$and返回false。 $and 具有以下语法： { $and: [ , , ... ] } 有关表达式的更多信息，请参见 表达式。 行为 $and使用短路逻辑：遇到第一个false表达式后，运算将停止评估。 除了false布尔值，$and计算为false如下：null，0，和undefined 的值。在$and评估所有其它值true，包括非零数值和阵列。 例子 结果 { $and: [ 1, \"green\" ] } true { $and: [ ] } true { $and: [ [ null ], [ false ], [ 0 ] ] } true { $and: [ null, true ] } true { $and: [ 0, true ] } true 例子 inventory使用以下文档创建示例集合： db.inventory.insertMany([ { \"_id\" : 1, \"item\" : \"abc1\", description: \"product 1\", qty: 300 }, { \"_id\" : 2, \"item\" : \"abc2\", description: \"product 2\", qty: 200 }, { \"_id\" : 3, \"item\" : \"xyz1\", description: \"product 3\", qty: 250 }, { \"_id\" : 4, \"item\" : \"VWZ1\", description: \"product 4\", qty: 300 }, { \"_id\" : 5, \"item\" : \"VWZ2\", description: \"product 5\", qty: 180 } ]) 以下操作使用$and运算符确定是否qty大于100 并小于250： db.inventory.aggregate( [ { $project: { item: 1, qty: 1, result: { $and: [ { $gt: [ \"$qty\", 100 ] }, { $lt: [ \"$qty\", 250 ] } ] } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"item\" : \"abc1\", \"qty\" : 300, \"result\" : false } { \"_id\" : 2, \"item\" : \"abc2\", \"qty\" : 200, \"result\" : true } { \"_id\" : 3, \"item\" : \"xyz1\", \"qty\" : 250, \"result\" : false } { \"_id\" : 4, \"item\" : \"VWZ1\", \"qty\" : 300, \"result\" : false } { \"_id\" : 5, \"item\" : \"VWZ2\", \"qty\" : 180, \"result\" : true } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/anyElementTrue-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/anyElementTrue-aggregation.html","title":"$anyElementTrue (aggregation)","keywords":"","body":" $anyElementTrue (aggregation) 在本页面 定义 行为 例子 定义 $anyElementTrue 将数组作为集合求值，true如果有则返回true，false否则返回。返回一个空数组false。 $anyElementTrue具有以下语法： { $anyElementTrue: [ ] } 本身必须解析为一个阵列，分离从表示参数列表中的外部阵列。有关表达式的更多信息，请参见表达式。 行为 如果集合包含嵌套数组元素，$anyElementTrue则不会降级到嵌套数组中，而是在顶级对数组进行求值。 除了false布尔值，$anyElementTrue计算为false如下：null，0，和undefined 的值。在$anyElementTrue评估所有其它值true，包括非零数值和阵列。 例子 结果 { $anyElementTrue: [ [ true, false ] ] } true { $anyElementTrue: [ [ [ false ] ] ] } true { $anyElementTrue: [ [ null, false, 0 ] ] } false { $anyElementTrue: [ [ ] ] } false 例子 创建一个示例集合，其名称survey包含以下文档： db.survey.insertMany([ { \"_id\" : 1, \"responses\" : [ true ] }, { \"_id\" : 2, \"responses\" : [ true, false ] }, { \"_id\" : 3, \"responses\" : [ ] }, { \"_id\" : 4, \"responses\" : [ 1, true, \"seven\" ] }, { \"_id\" : 5, \"responses\" : [ 0 ] }, { \"_id\" : 6, \"responses\" : [ [ ] ] }, { \"_id\" : 7, \"responses\" : [ [ 0 ] ] }, { \"_id\" : 8, \"responses\" : [ [ false ] ] }, { \"_id\" : 9, \"responses\" : [ null ] }, { \"_id\" : 10, \"responses\" : [ undefined ] } ]) 以下操作使用$anyElementTrue运算符来确定responses数组是否包含任何计算结果为true： db.survey.aggregate( [ { $project: { responses: 1, isAnyTrue: { $anyElementTrue: [ \"$responses\" ] }, _id: 0 } } ] ) 该操作返回以下结果： { \"responses\" : [ true ], \"isAnyTrue\" : true } { \"responses\" : [ true, false ], \"isAnyTrue\" : true } { \"responses\" : [ ], \"isAnyTrue\" : false } { \"responses\" : [ 1, true, \"seven\" ], \"isAnyTrue\" : true } { \"responses\" : [ 0 ], \"isAnyTrue\" : false } { \"responses\" : [ [ ] ], \"isAnyTrue\" : true } { \"responses\" : [ [ 0 ] ], \"isAnyTrue\" : true } { \"responses\" : [ [ false ] ], \"isAnyTrue\" : true } { \"responses\" : [ null ], \"isAnyTrue\" : false } { \"responses\" : [ undefined ], \"isAnyTrue\" : false } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/arrayElemAt-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/arrayElemAt-aggregation.html","title":"$arrayElemAt (aggregation)","keywords":"","body":" $arrayElemAt (aggregation) 在本页面 定义 行为 例子 定义 $arrayElemAt 3.2版中的新功能。 返回指定数组索引处的元素。 $arrayElemAt 具有以下语法： { $anyElement: [ ] } 表达式可以是任何有效的表达式，只要它可以解析为数组。 表达式可以是任何有效表达式，只要它可以解析为整数。 如果为正，则从数组开始算起$arrayElemAt返回该idx位置的元素 。 如果为负，则从数组末尾算起$arrayElemAt返回该idx位置处的元素 。 如果idx超过了数组界限，$arrayElemAt则不返回任何结果。 有关表达式的更多信息，请参见 表达式。 行为 有关表达式的更多信息，请参见 表达式。 例子 结果 { $arrayElemAt: [ [ 1, 2, 3 ], 0 ] } 1 { $arrayElemAt: [ [ 1, 2, 3 ], -2 ] } 2 { $arrayElemAt: [ [ 1, 2, 3 ], 15 ] } 例子 名为的集合users包含以下文档： { \"_id\" : 1, \"name\" : \"dave123\", favorites: [ \"chocolate\", \"cake\", \"butter\", \"apples\" ] } { \"_id\" : 2, \"name\" : \"li\", favorites: [ \"apples\", \"pudding\", \"pie\" ] } { \"_id\" : 3, \"name\" : \"ahn\", favorites: [ \"pears\", \"pecans\", \"chocolate\", \"cherries\" ] } { \"_id\" : 4, \"name\" : \"ty\", favorites: [ \"ice cream\" ] } 下面的示例返回favorites数组中的第一个和最后一个元素 ： db.users.aggregate([ { $project: { name: 1, first: { $arrayElemAt: [ \"$favorites\", 0 ] }, last: { $arrayElemAt: [ \"$favorites\", -1 ] } } } ]) 该操作返回以下结果： { \"_id\" : 1, \"name\" : \"dave123\", \"first\" : \"chocolate\", \"last\" : \"apples\" } { \"_id\" : 2, \"name\" : \"li\", \"first\" : \"apples\", \"last\" : \"pie\" } { \"_id\" : 3, \"name\" : \"ahn\", \"first\" : \"pears\", \"last\" : \"cherries\" } { \"_id\" : 4, \"name\" : \"ty\", \"first\" : \"ice cream\", \"last\" : \"ice cream\" } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/arrayToObject-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/arrayToObject-aggregation.html","title":"$arrayToObject (aggregation)","keywords":"","body":" $arrayToObject (aggregation) 在本页面 定义 行为 例子 定义 $arrayToObject 3.4.4版中的新功能。 将数组转换为单个文档；数组必须为： 一个由两个元素组成的数组，其中第一个元素是字段名称，第二个元素是字段值： [ [ \"item\", \"abc123\"], [ \"qty\", 25 ] ] -OR- 文件数组，包含两个字段，k并且v 其中： 该k字段包含字段名称。 该v字段包含该字段的值。 [ { \"k\": \"item\", \"v\": \"abc123\"}, { \"k\": \"qty\", \"v\": 25 } ] $arrayToObject具有以下语法： { $arrayToObject: } 可以是任何有效的表达解析为两个元件阵列或包含“k”和“V”域的文档阵列的阵列。 有关表达式的更多信息，请参见 表达式。 行为 如果字段名称在数组中重复， 从4.0.5开始，$arrayToObject使用该字段的最后一个值。对于4.0.0-4.0.4，使用的值取决于驱动程序。 从3.6.10开始，$arrayToObject使用该字段的最后一个值。对于3.6.0-3.6.9，使用的值取决于驱动程序。 从3.4.19开始，$arrayToObject使用该字段的最后一个值。对于3.4.0-3.4.19，使用的值取决于驱动程序。 例子 结果 { $arrayToObject: { $literal: [ { \"k\": \"item\", \"v\": \"abc123\"}, { \"k\": \"qty\", \"v\": 25 } ] } } { \"item\" : \"abc123\", \"qty\" : 25 } { $arrayToObject: { $literal: [ [ \"item\", \"abc123\"], [ \"qty\", 25 ] ] } } { \"item\" : \"abc123\", \"qty\" : 25 } { $arrayToObject: { $literal: [ { \"k\": \"item\", \"v\": \"123abc\"}, { \"k\": \"item\", \"v\": \"abc123\" } ] } } { \"item\" : \"abc123\" }从版本4.0.5+（3.6.10+和3.4.19+）开始，如果字段名称在数组中重复，则$arrayToObject 使用该字段的最后一个值。 例子 $arrayToObject 例子 考虑inventory包含以下文档的集合： { \"_id\" : 1, \"item\" : \"ABC1\", dimensions: [ { \"k\": \"l\", \"v\": 25} , { \"k\": \"w\", \"v\": 10 }, { \"k\": \"uom\", \"v\": \"cm\" } ] } { \"_id\" : 2, \"item\" : \"ABC2\", dimensions: [ [ \"l\", 50 ], [ \"w\", 25 ], [ \"uom\", \"cm\" ] ] } { \"_id\" : 3, \"item\" : \"ABC3\", dimensions: [ [ \"l\", 25 ], [ \"l\", \"cm\" ], [ \"l\", 50 ] ] } 以下聚合管道操作使用 $arrayToObject将该dimensions字段作为文档返回： db.inventory.aggregate( [ { $project: { item: 1, dimensions: { $arrayToObject: \"$dimensions\" } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"item\" : \"ABC1\", \"dimensions\" : { \"l\" : 25, \"w\" : 10, \"uom\" : \"cm\" } } { \"_id\" : 2, \"item\" : \"ABC2\", \"dimensions\" : { \"l\" : 50, \"w\" : 25, \"uom\" : \"cm\" } } { \"_id\" : 3, \"item\" : \"ABC3\", \"dimensions\" : { \"l\" : 50 } } 从版本4.0.5+（3.6.10+和3.4.19+）开始，如果字段名称在数组中重复，则$arrayToObject使用该字段的最后一个值。 $objectToArray+ $arrayToObject示例 考虑inventory包含以下文档的集合： { \"_id\" : 1, \"item\" : \"ABC1\", instock: { warehouse1: 2500, warehouse2: 500 } } { \"_id\" : 2, \"item\" : \"ABC2\", instock: { warehouse2: 500, warehouse3: 200} } 以下聚合管道操作将计算每个物料的总存货并将其添加到instock凭证中： db.inventory.aggregate( [ { $addFields: { instock: { $objectToArray: \"$instock\" } } }, { $addFields: { instock: { $concatArrays: [ \"$instock\", [ { \"k\": \"total\", \"v\": { $sum: \"$instock.v\" } } ] ] } } } , { $addFields: { instock: { $arrayToObject: \"$instock\" } } } ] ) 该操作返回以下内容： { \"_id\" : 1, \"item\" : \"ABC1\", \"instock\" : { \"warehouse1\" : 2500, \"warehouse2\" : 500, \"total\" : 3000 } } { \"_id\" : 2, \"item\" : \"ABC2\", \"instock\" : { \"warehouse2\" : 500, \"warehouse3\" : 200, \"total\" : 700 } } 也可以看看 $objectToArray 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/asin-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/asin-aggregation.html","title":"$asin (aggregation)","keywords":"","body":" $asin (aggregation) 在本页面 定义 行为 例子 定义 $asin 4.2版中的新功能。 返回值的反正弦（弧正弦）。 $asin具有以下语法： { $asin: } $asin接受任何有效的表达式，该表达式可解析为-1 和之间的数字1，例如。-1 $asin返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$asin返回值double。 $asin也可以返回值作为 128-bit小数 ，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 如果参数解析为的值null或指向缺少的字段，则$asin返回null。如果参数解析为NaN，则$asin返回NaN。如果参数解析为包含[-1, 1]范围之外的值 ，则$asin会引发错误。 例子 结果 { $asin: NaN } NaN { $asin: null } null { $asin : Infinity}OR{ $asin : -Infinity } 引发类似于以下格式化输出的错误消息：\"errmsg\" : \"Failed to optimize pipeline :: caused by :: cannot apply $asin to -inf, value must in [-1,1]\" 例子 度数的反正弦值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $asin表达式计算与之成反角，side_a并使用$addFields管道阶段将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $radiansToDegrees : { $asin : { $divide : [ \"$side_a\", \"$hypotenuse\" ] } } } } } ]) 该$radiansToDegrees表达式将返回的弧度值转换为$asin以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"36.86989764584402129685561255909341\") } 由于side_a和hypotenuse被存储为 128-bit小数，因此输出 $asin为128-bit小数。 弧度的反正弦 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $asin表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $asin : { $divide : [ \"$side_a\", \"$hypotenuse\" ] } } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"0.6435011087932843868028092287173226\") } 由于side_a和hypotenuse被存储为 128-bit小数，因此输出 $asin为128-bit小数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/asinh-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/asinh-aggregation.html","title":"$asinh (aggregation)","keywords":"","body":" $asinh (aggregation) 在本页面 定义 行为 例子 定义 $asinh 4.2版中的新功能。 返回值的反双曲正弦（双曲反正弦）。 $asinh 具有以下语法： { $asinh: } $asinh接受可解析为数字的任何有效表达式。 $asinh返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$asinh返回值double。 $asinh也可以返回值作为 128-bit小数，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null，NaN和+/- Infinity 如果参数解析为的值null或指向缺少的字段，则$asinh返回null。如果参数解析为NaN，则$asinh返回NaN。如果参数解析为负无穷大或正无穷大，则$asinh分别返回负无穷大或正无穷大。 例子 结果 { $asinh: NaN } NaN { $asinh: null } null { $asinh : Infinity} Infinity { $asinh : -Infinity } -Infinity 例子 度数的反双曲正弦值 该trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"1\") } 以下聚合操作使用该 $asinh表达式计算的反双曲正弦值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $radiansToDegrees : { $asinh : \"$x-coordinate\" } } } } ]) 该$radiansToDegrees表达式将返回的弧度值转换为$asinh以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"1\"), \"y-coordinate\" : NumberDecimal(\"50.49898671052621144221476300417157\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $asinh为128-bit十进制数。 弧度的反双曲正弦值 该trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"1\") } 以下聚合操作使用该 $asinh表达式计算的反双曲正弦值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $asinh : \"$x-coordinate\" } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"1\"), \"y-coordinate\" : NumberDecimal(\"1.818446459232066823483698963560709\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $asinh为128-bit十进制数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/atan-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/atan-aggregation.html","title":"$atan (aggregation)","keywords":"","body":" $atan (aggregation) 在本页面 定义 行为 例子 定义 $atan 4.2版中的新功能。 返回值的反正切（弧正切）。 $atan 具有以下语法： { $atan: } $atan接受可解析为数字的任何有效表达式。 $atan返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$atan返回值double。 $atan也可以返回值作为 128-bit小数 ，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null和NaN 如果参数解析为的值null或指向缺少的字段，则$atan返回null。如果参数解析为NaN，则$tan返回NaN。 例子 结果 { $atan: NaN } NaN { $atan: null } null 例子 度数的反正切值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $atan表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $radiansToDegrees : { $atan : { $divide : [ \"$side_b\", \"$side_a\" ] } } } } } ]) 该$radiansToDegrees表达式将返回的弧度值转换为$atan以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"53.13010235415597870314438744090658\") } 由于side_b和side_a被存储为 128-bit小数，因此输出 $atan为128-bit小数。 弧度的反正切值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $atan表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $atan : { $divide : [ \"$side_b\", \"$side_a\" ] } } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"0.9272952180016122324285124629224287\") } 由于side_b和side_a被存储为 128-bit小数，因此输出 $atan为128-bit小数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/atan2-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/atan2-aggregation.html","title":"$atan2 (aggregation)","keywords":"","body":" $atan2 (aggregation) 在本页面 定义 行为 例子 定义 $atan2 4.2版中的新功能。 返回y / x的反正切（弧形切线），其中y和x是分别传递给表达式的第一个和第二个值。 $atan2具有以下语法： { $atan2: [ , ] } $atan2接受可解析为数字的任何有效表达式。 $atan2返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$atan2返回值double。 $atan2也可以返回值作为 128-bit小数，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null和NaN 如果的第一个参数$atan2是null，则 $atan2返回null。如果的第一个参数 $atan2是NaN，则$atan2返回NaN。如果第一个参数解析为数字，第二个参数解析为NaN或null， $atan2则分别返回NaN或null。 例子 结果 { $atan2: [ NaN, ] }or{ $atan2: [ , NaN ] } NaN { $atan2: [ null, ] }or{ $atan2: [ , null ] } null 例子 度数的反正切值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $atan2表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $radiansToDegrees : { $atan2 : [ \"$side_b\", \"$side_a\" ] } } } } ]) $radiansToDegrees表达式将返回的弧度值转换为$atan2以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"53.13010235415597870314438744090658\") } 由于side_b和side_a被存储为 128-bit小数，因此输出 $atan2为128-bit小数。 弧度的反正切值 该trigonometry集合包含一个文档，该文档存储直角三角形的三个边： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $atan2表达式来计算side_a与$addFields管道之间相邻的角度并将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"angle_a\" : { $atan2 : [ \"$side_b\", \"$side_a\" ] } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"side_a\" : NumberDecimal(\"3\"), \"side_b\" : NumberDecimal(\"4\"), \"hypotenuse\" : NumberDecimal(\"5\"), \"angle_a\" : NumberDecimal(\"0.9272952180016122324285124629224287\") } 由于side_b和side_a被存储为 128-bit小数，因此输出 $atan2为128-bit小数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/atanh-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/atanh-aggregation.html","title":"$atanh (aggregation)","keywords":"","body":" $atanh (aggregation) 在本页面 定义 行为 例子 定义 $asinh 4.2版中的新功能。 返回值的反双曲正切（双曲反正切）。 $atanh具有以下语法： { $atanh: } $atanh接受任何有效的表达式，该表达式可解析为-1 和之间的数字1，例如。-1 $atanh返回以弧度为单位的值。使用 $radiansToDegrees运算符将输出值从弧度转换为度。 默认情况下以形式$atanh返回值double。 $atanh也可以返回值作为 128-bit小数 ，只要该解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null，NaN和+/- Infinity 如果参数解析为的值null或指向缺少的字段，则$atanh返回null。如果参数解析为NaN，则$atanh返回NaN。如果参数解析为负无穷大或正无穷大， $atanh则会引发错误。如果参数解析为 +1或-1，则分别$atanh返回Infinity和 -Infinity。 例子 结果 { $atanh: NaN } NaN { $atanh: null } null { $atanh: 1 } Infinity { $atanh: -1} -Infinity { $atanh : Infinity}or{ $atanh : -Infinity } 引发类似于以下格式化输出的错误消息：\"errmsg\" : \"Failed to optimize pipeline :: caused by :: cannot apply $atanh to -inf, value must in (-inf,inf)\" 例子 度数的反双曲正切值 该trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"0.5\") } 以下聚合操作使用该 $atanh表达式计算的反双曲正切值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $radiansToDegrees : { $atanh : \"$x-coordinate\" } } } } ]) $radiansToDegrees表达式将返回的弧度值转换为$atanh以度为单位的等效值。 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"0.5\"), \"y-coordinate\" : NumberDecimal(\"31.47292373094538001977241539068589\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $atanh为128-bit十进制数。 弧度的反双曲正切值 trigonometry集合包含一个文档，该文档沿x二维图形的轴存储值： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"0.5\") } 以下聚合操作使用该 $atanh表达式计算的反双曲正切值，x-coordinate并使用$addFields管道阶段将其添加到输入文档中。 db.trigonometry.aggregate([ { $addFields : { \"y-coordinate\" : { $atanh : \"$x-coordinate\" } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"x-coordinate\" : NumberDecimal(\"0.5\"), \"y-coordinate\" : NumberDecimal(\"0.5493061443340548456976226184612628\") } 由于x-coordinate存储为 128-bit十进制数，因此输出 $asin为128-bit十进制数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/avg-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/avg-aggregation.html","title":"$avg (aggregation)","keywords":"","body":" $avg (aggregation) 在本页面 定义 行为 例子 定义 $avg 返回数值的平均值。$avg忽略非数字值。 $avg在以下阶段可用： $group $project $addFields（从MongoDB 3.4开始可用） $set（从MongoDB 4.2开始可用） $replaceRoot（从MongoDB 3.4开始可用） $replaceWith（从MongoDB 4.2开始可用） $match包含$expr表达的阶段 在MongoDB 3.2和更早版本中，$avg仅在此$group阶段可用 。 在$group阶段中使用时，$avg具有以下语法，并返回通过将指定的表达式应用于按键共享同一组的一组文档中的每个文档而得到的所有数值的总平均值： { $avg: } 在其他受支持的阶段中使用时，$avg返回每个文档的指定表达式或表达式列表的平均值，并具有以下两种语法之一： $avg 有一个指定的表达式作为其操作数： { $avg: } $avg 有一个指定表达式的列表作为其操作数： { $avg: [ , ... ] } 有关表达式的更多信息，请参见 表达式。 行为 非数值或缺失值 $avg忽略非数字值，包括缺失值。如果平均值的所有操作数均为非数值，则由于未定义零值的平均值，因此$avg返回 null。 数组操作数 在此$group阶段，如果表达式解析为数组，$avg则将操作数视为非数值。 在其他受支持的阶段： 使用单个表达式作为其操作数，如果表达式解析为数组，则$avg遍历数组以对数组的数字元素进行操作以返回单个值。 使用表达式列表作为其操作数，如果任何表达式都解析为数组，$avg则不会遍历数组，而是将数组视为非数字值。 例子 在$group阶段上使用 考虑sales包含以下文档的集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 2, \"date\" : ISODate(\"2014-01-01T08:00:00Z\") } { \"_id\" : 2, \"item\" : \"jkl\", \"price\" : 20, \"quantity\" : 1, \"date\" : ISODate(\"2014-02-03T09:00:00Z\") } { \"_id\" : 3, \"item\" : \"xyz\", \"price\" : 5, \"quantity\" : 5, \"date\" : ISODate(\"2014-02-03T09:05:00Z\") } { \"_id\" : 4, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 10, \"date\" : ISODate(\"2014-02-15T08:00:00Z\") } { \"_id\" : 5, \"item\" : \"xyz\", \"price\" : 5, \"quantity\" : 10, \"date\" : ISODate(\"2014-02-15T09:12:00Z\") } 按item字段对文档进行分组，以下操作使用$avg累加器计算每个分组的平均数量和平均数量。 db.sales.aggregate( [ { $group: { _id: \"$item\", avgAmount: { $avg: { $multiply: [ \"$price\", \"$quantity\" ] } }, avgQuantity: { $avg: \"$quantity\" } } } ] ) 该操作返回以下结果： { \"_id\" : \"xyz\", \"avgAmount\" : 37.5, \"avgQuantity\" : 7.5 } { \"_id\" : \"jkl\", \"avgAmount\" : 20, \"avgQuantity\" : 1 } { \"_id\" : \"abc\", \"avgAmount\" : 60, \"avgQuantity\" : 6 } 在$project阶段上使用 集合students包含以下文档： { \"_id\": 1, \"quizzes\": [ 10, 6, 7 ], \"labs\": [ 5, 8 ], \"final\": 80, \"midterm\": 75 } { \"_id\": 2, \"quizzes\": [ 9, 10 ], \"labs\": [ 8, 8 ], \"final\": 95, \"midterm\": 80 } { \"_id\": 3, \"quizzes\": [ 4, 5, 5 ], \"labs\": [ 6, 5 ], \"final\": 78, \"midterm\": 70 } 以下示例$avg在 $project阶段中使用来计算平均测验分数，平均实验室分数以及期末和期中考试的平均值： db.students.aggregate([ { $project: { quizAvg: { $avg: \"$quizzes\"}, labAvg: { $avg: \"$labs\" }, examAvg: { $avg: [ \"$final\", \"$midterm\" ] } } } ]) 该操作产生以下文档： { \"_id\" : 1, \"quizAvg\" : 7.666666666666667, \"labAvg\" : 6.5, \"examAvg\" : 77.5 } { \"_id\" : 2, \"quizAvg\" : 9.5, \"labAvg\" : 8, \"examAvg\" : 87.5 } { \"_id\" : 3, \"quizAvg\" : 4.666666666666667, \"labAvg\" : 5.5, \"examAvg\" : 74 } 在其他受支持的阶段： 使用单个表达式作为其操作数，如果表达式解析为数组，则$avg遍历数组以对数组的数字元素进行操作以返回单个值。 使用表达式列表作为其操作数，如果任何表达式都解析为数组，$avg则不会遍历数组，而是将数组视为非数字值。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/ceil-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/ceil-aggregation.html","title":"$ceil (aggregation)","keywords":"","body":" $ceil (aggregation) 在本页面 定义 行为 例子 定义 $ceil 3.2版中的新功能。 返回大于或等于指定数字的最小整数。 $ceil具有以下语法： { $ceil: } 表达式可以是任何有效的表达，因为它解析为数字。有关表达式的更多信息，请参阅表达式。 行为 如果参数解析为的值或引用缺少的字段，则$ceil返回null。如果参数解析为NaN，则$ceil返回NaN。 例子 结果 { $ceil: 1 } 1 { $ceil: 7.80 } 8 { $ceil: -2.8 } -2 例子 名为samples的集合包含以下文档： { _id: 1, value: 9.25 } { _id: 2, value: 8.73 } { _id: 3, value: 4.32 } { _id: 4, value: -5.34 } 以下事例返回原始值和上限值： db.samples.aggregate([ { $project: { value: 1, ceilingValue: { $ceil: \"$value\" } } } ]) 该操作返回以下结果： { \"_id\" : 1, \"value\" : 9.25, \"ceilingValue\" : 10 } { \"_id\" : 2, \"value\" : 8.73, \"ceilingValue\" : 9 } { \"_id\" : 3, \"value\" : 4.32, \"ceilingValue\" : 5 } { \"_id\" : 4, \"value\" : -5.34, \"ceilingValue\" : -5 } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/cmp-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/cmp-aggregation.html","title":"$cmp (aggregation)","keywords":"","body":" $cmp (aggregation) 在本页面 定义 例子 定义 $cmp 比较两个值并返回： -1 如果第一个值小于第二个值。 1 如果第一个值大于第二个值。 0 如果两个值相等。 在$cmp使用两个值和类型进行比较， 指定比较BSON为了 用于不同类型的值。 $cmp具有以下语法： { $cmp: [ , ] } 有关表达式的更多信息，请参见表达式。 例子 考虑包含inventory以下文档的集合： { \"_id\" : 1, \"item\" : \"abc1\", description: \"product 1\", qty: 300 } { \"_id\" : 2, \"item\" : \"abc2\", description: \"product 2\", qty: 200 } { \"_id\" : 3, \"item\" : \"xyz1\", description: \"product 3\", qty: 250 } { \"_id\" : 4, \"item\" : \"VWZ1\", description: \"product 4\", qty: 300 } { \"_id\" : 5, \"item\" : \"VWZ2\", description: \"product 5\", qty: 180 } 以下操作使用$cmp运算符将qty值与进行比较250： db.inventory.aggregate( [ { $project: { item: 1, qty: 1, cmpTo250: { $cmp: [ \"$qty\", 250 ] }, _id: 0 } } ] ) 该操作返回以下结果： { \"item\" : \"abc1\", \"qty\" : 300, \"cmpTo250\" : 1 } { \"item\" : \"abc2\", \"qty\" : 200, \"cmpTo250\" : -1 } { \"item\" : \"xyz1\", \"qty\" : 250, \"cmpTo250\" : 0 } { \"item\" : \"VWZ1\", \"qty\" : 300, \"cmpTo250\" : 1 } { \"item\" : \"VWZ2\", \"qty\" : 180, \"cmpTo250\" : -1 } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/concat-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/concat-aggregation.html","title":"$concat (aggregation)","keywords":"","body":" $concat (aggregation) 在本页面 定义 例子 定义 $concat 连接字符串并返回连接的字符串。 $concat具有以下语法： { $concat: [ , , ... ] } 参数可以解析为字符串，可以是任何有效的表达式。有关表达式的更多信息，请参见 表达式。 如果参数解析为的值null或指向缺少的字段，则$concat返回null。 例子 考虑inventory包含以下文档的集合： { \"_id\" : 1, \"item\" : \"ABC1\", quarter: \"13Q1\", \"description\" : \"product 1\" } { \"_id\" : 2, \"item\" : \"ABC2\", quarter: \"13Q4\", \"description\" : \"product 2\" } { \"_id\" : 3, \"item\" : \"XYZ1\", quarter: \"14Q2\", \"description\" : null } 以下操作使用$concat运算符将item字段和description带有“-”定界符的字段连接起来。 db.inventory.aggregate( [ { $project: { itemDescription: { $concat: [ \"$item\", \" - \", \"$description\" ] } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"itemDescription\" : \"ABC1 - product 1\" } { \"_id\" : 2, \"itemDescription\" : \"ABC2 - product 2\" } { \"_id\" : 3, \"itemDescription\" : null } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/concatArrays-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/concatArrays-aggregation.html","title":"$concatArrays (aggregation)","keywords":"","body":" $concatArrays (aggregation) 在本页面 定义 行为 例子 定义 $concatArrays 3.2版中的新功能。 连接数组以返回连接的数组。 $concatArrays具有以下语法： { $concatArrays: [ , , ... ] } 该表达式可以是任何有效的表达式，只要它们解析为一个数组。有关表达式的更多信息，请参见表达式。 如果有任何参数解析为null或指向缺少的字段，则$concatArrays返回null。 行为 例子 结果 { $concatArrays: [ [ \"hello\", \" \"], [ \"world\" ] ] } [ \"hello\", \" \", \"world\" ] { $concatArrays: [ [ \"hello\", \" \"], [ [ \"world\" ], \"again\"] ] } [ \"hello\", \" \", [ \"world\" ], \"again\" ] 例子 名为的集合warehouses包含以下文档： { \"_id\" : 1, instock: [ \"chocolate\" ], ordered: [ \"butter\", \"apples\" ] } { \"_id\" : 2, instock: [ \"apples\", \"pudding\", \"pie\" ] } { \"_id\" : 3, instock: [ \"pears\", \"pecans\"], ordered: [ \"cherries\" ] } { \"_id\" : 4, instock: [ \"ice cream\" ], ordered: [ ] } 以下示例将instock和ordered 数组串联在一起： db.warehouses.aggregate([ { $project: { items: { $concatArrays: [ \"$instock\", \"$ordered\" ] } } } ]) { \"_id\" : 1, \"items\" : [ \"chocolate\", \"butter\", \"apples\" ] } { \"_id\" : 2, \"items\" : null } { \"_id\" : 3, \"items\" : [ \"pears\", \"pecans\", \"cherries\" ] } { \"_id\" : 4, \"items\" : [ \"ice cream\" ] } 也可以看看 $push 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/cond-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/cond-aggregation.html","title":"$cond (aggregation)","keywords":"","body":" $cond (aggregation) 在本页面 定义 例子 定义 $cond 计算一个布尔表达式以返回两个指定的返回表达式之一。 该$cond表达式具有以下两种语法之一： { $cond: { if: , then: , else: } } or { $cond: [ , , ] } $cond要求任何（if-then-else）一种语法的所有三个参数。 如果将计算结果为true，则 $cond计算并返回表达式的值 。否则，$cond求值并返回表达式的值。 参数可以是任何有效的表达式。有关表达式的更多信息，请参见 表达式。 也可以看看 $switch 例子 以下示例将inventory集合与以下文档一起使用： { \"_id\" : 1, \"item\" : \"abc1\", qty: 300 } { \"_id\" : 2, \"item\" : \"abc2\", qty: 200 } { \"_id\" : 3, \"item\" : \"xyz1\", qty: 250 } 下面的聚合操作使用$cond表达式，如果qty值大于或等于250，将折扣值设置为30，如果qty值小于250，则设置为20: db.inventory.aggregate( [ { $project: { item: 1, discount: { $cond: { if: { $gte: [ \"$qty\", 250 ] }, then: 30, else: 20 } } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"item\" : \"abc1\", \"discount\" : 30 } { \"_id\" : 2, \"item\" : \"abc2\", \"discount\" : 20 } { \"_id\" : 3, \"item\" : \"xyz1\", \"discount\" : 30 } 以下操作使用$cond表达式的数组语法， 并返回相同的结果： db.inventory.aggregate( [ { $project: { item: 1, discount: { $cond: [ { $gte: [ \"$qty\", 250 ] }, 30, 20 ] } } } ] ) 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/convert-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/convert-aggregation.html","title":"$convert (aggregation)","keywords":"","body":" $convert (aggregation) 在本页面 定义 行为 例子 定义 $convert 版本4.0中的新功能。 将值转换为指定的类型。 $convert具有以下语法： { $convert: { input: , to: , onError: , // Optional. onNull: // Optional. } } 在$convert需要具有以下字段的文档： 字段 描述 input 参数可以是任何有效的表达式。有关表达式的更多信息，请参见表达式。 to 该参数可以是任何可解析为以下数字或字符串标识符之一的有效表达式，见下表 onError 可选的。在转换过程中遇到错误（包括不支持的类型转换）时返回的值。参数可以是任何有效的表达式。如果未指定，则操作在遇到错误时将引发错误并停止。 onNull 可选的。如果input为null或缺失，则返回的值。参数可以是任何有效的表达式。如果未指定，$convert则如果inputnull为null或缺少，则返回null 。 字符串标识符 数值标识符 笔记 “double” 1 有关转换为double的更多信息，请参见 转换为Double。 “string” 2 有关转换为字符串的更多信息，请参见 转换为字符串。 “objectId” 7 有关转换为objectId的更多信息，请参见 转换为ObjectId。 “bool” 8 有关转换为布尔值的更多信息，请参见 转换为布尔值。 “date” 9 有关转换为日期的更多信息，请参见 转换为日期。 “int” 16 有关转换为整数的更多信息，请参见 转换为整数。 “long” 18 有关转换为long的更多信息，请参见 转换为long。 “decimal” 19 有关转换为十进制的更多信息，请参见 转换为十进制。 除$convert之外，当默认的“ onError”和“ onNull”行为可以接受时，MongoDB还提供以下聚合运算符作为速记： $toBool $toDate $toDecimal $toDouble $toInt $toLong $toObjectId $toString 行为 转换为布尔值 下表列出了可以转换为布尔值的输入类型： 输入类型 行为 Boolean 无操作，返回布尔值。 Double 如果不为零，则返回true。如果为零，则返回false。 Decimal 如果不为零，则返回true。如果为零，则返回false。 Integer 如果不为零，则返回true。如果为零，则返回false。 Long 如果不为零，则返回true。如果为零，则返回false。 ObjectId 返回true。 String 返回true。 Date 返回true。 下表列出了一些转换为布尔值的示例： 例子 结果 { input: true, to: \"bool\"} true { input: false, to: \"bool\" } false { input: 1.99999, to: \"bool\" } true { input: NumberDecimal(\"5\"), to: \"bool\"} true { input: NumberDecimal(\"0\"), to: \"bool\"} false { input: 100, to: \"bool\" } true { input: ISODate(\"2018-03-26T04:38:28.044Z\"), to: \"bool\" } true { input: \"hello\", to: \"bool\" } true { input: \"false\", to: \"bool\" } true { input: \"\", to: \"bool\" } true { input: null, to: \"bool\" } Null 也可以看看 $toBool 转换为整数 下表列出了可以转换为整数的输入类型： 输入类型 行为 Boolean 返回0的 false。返回1的true。 Double 返回截断值。截断后的double值必须在整数的最大值和最小值之内。您不能转换其截断值小于最小整数值或大于最大整数值的double值。 Decimal 返回截断值。截断的十进制值必须在整数的最大值和最小值之内。您不能转换截断值小于最小整数值或大于最大整数值的十进制值。 Integer 无操作，返回整数值。 Long 以整数形式返回long值。long值必须落在整数的最小值和最大值之间。您不能转换小于最小整数值或大于最大整数值的长值。 String 以整数形式返回字符串的数值。字符串值必须是base 10的整数（例如 \"-5\"，\"123456\"）并落在整数的最小值和最大值之内。不能转换浮点数、十进制数或非base10数字的字符串值（例如\"-5.0\"，\"0x6400\"）或低于整数的最小和最大值的值。 下表列出了一些转换为整数的示例： 例子 结果 { input: true, to: \"int\"} 1 { input: false, to: \"int\" } 0 { input: 1.99999, to: \"int\" } 1 { input: NumberDecimal(\"5.5000\"), to: \"int\"} 5 { input: NumberDecimal(\"9223372036000.000\"), to: \"int\"} Error { input: NumberDecimal(\"9223372036000.000\"), to: \"int\", onError: \"Could not convert to type integer.\" } “Could not convert to type integer.” { input: NumberLong(\"5000\"), to: \"int\"} 5000 { input: NumberLong(\"922337203600\"), to: \"int\"} Error { input: \"-2\", to: \"int\" } -2 { input: \"2.5\", to: \"int\" } Error { input: null, to: \"int\" } null 也可以看看 $toInt操作符。 转换为十进制 下表列出了可以转换为十进制的输入类型： 输入类型 行为 Boolean false返回NumberDecimal(\"0\")true返回NumberDecimal(\"1\") Double 返回双精度值作为十进制数。 Decimal 无操作，返回小数。 Integer 以小数形式返回int值。 Long 返回long值（十进制）。 String 以十进制形式返回字符串的数值。字符串值必须是base 10数字值（例如 \"-5.5\"，\"123456\"）。您不能转换非base10数字的字符串值 （例如\"0x6400\"） Date 返回自与日期值相对应的纪元以来的毫秒数。 下表列出了一些转换为十进制的示例： 例子 结果 { input: true, to: \"decimal\"} NumberDecimal(“1”) { input: false, to: \"decimal\" } NumberDecimal(“0”) { input: 2.5, to: \"decimal\" } NumberDecimal(“2.50000000000000”) { input: NumberInt(5), to: \"decimal\"} NumberDecimal(“5”) { input: NumberLong(10000), to: \"decimal\"} NumberDecimal(“10000”) { input: \"-5.5\", to: \"decimal\" } NumberDecimal(“-5.5”) { input: ISODate(\"2018-03-27T05:04:47.890Z\"), to: \"decimal\" } NumberDecimal(“1522127087890”) 也可以看看 $toDecimal 转换为Double 下表列出了可以转换为双精度型的输入类型： 输入类型 行为 Boolean false返回的NumberLong（0）true返回的NumberLong（1） Double 无操作，返回双精度型。 Decimal 以双精度值返回十进制值。小数值必须在双精度的最小值和最大值之内。不能转换一个小于最小双精度值或大于最大双精度值的十进制值。 Integer 以双精度值返回int值。 Long 将long值作为双精度值返回。 String 以双精度值形式返回字符串的数值。字符串值必须是一个以10为基的数值(例如:\"-5.5\"， \"123456\")，并落在双精度的最小值和最大值之内。不能转换非base10数字的字符串值。“0x6400”)或低于双精度的最小值和最大值的值。 Date 返回自纪元以来对应于日期值的毫秒数。 下表列出了一些转换为Double的示例： 例子 结果 { input: true, to: \"double\"} 1 { input: false, to: \"double\" } 0 { input: 2.5, to: \"double\" } 2.5 { input: NumberInt(5), to: \"double\"} 5 { input: NumberLong(10000), to: \"double\"} 10000 { input: \"-5.5\", to: \"double\" } -5.5 { input: \"5e10\", to: \"double\" } 50000000000 { input: \"5e550\", to: \"double\", onError: \"Could not convert to type double.\" } “Could not convert to type double.” { input: ISODate(\"2018-03-27T05:04:47.890Z\"), to: \"double\" } 1522127087890 也可以看看 $toDouble 转换为Long 下表列出了可以转换为long的输入类型： 输入类型 行为 Boolean false返回0true返回1 Double 返回截断值。截断后的double值必须长时间处于最小值和最大值之间。不能转换其截断值小于最小长整型值或大于最大长整型值的双精度值。 Decimal 返回截断值。截断的十进制值必须在Long的最大值和最小值之间。不能转换截断值小于最小长值或大于最大长值的十进制值。 Integer 以long形式返回int值。 Long 无操作。返回Long值。 String 返回字符串的数值。字符串值必须是base10长度的(例如。“-5”，“123456”)，并落在Long最大值和最小值之内。不能转换浮点数、十进制数或非base10数字的字符串值。(例如 “-5.0”、“0x6400”)或处于Long最小和最大值之外的值。 Date 将日期转换为纪元以来的毫秒数。 下表列出了一些到长示例的转换： 例子 结果 { input: true, to: \"long\" } NumberLong(“1”) { input: false, to: \"long\" } NumberLong(“0”) { input: 1.99999, to: \"long\" } NumberLong(“1”) { input: NumberDecimal(\"5.5000\"), to: \"long\" } NumberLong(“5”) { input: NumberDecimal(\"9223372036854775808.0\"), to: \"long\" } Error { input: NumberDecimal(\"9223372036854775808.000\"), to: \"long\", onError: \"Could not convert to type long.\" } “Could not convert to type long.” { input: NumberInt(8), to: \"long\" } NumberLong(8) { input: ISODate(\"2018-03-26T04:38:28.044Z\"), to: \"long\" } NumberLong(“1522039108044”) { input: \"-2\", to: \"long\" } NumberLong(“-2”) { input: \"2.5\", to: \"long\" } Error { input: null, to: \"long\" } null 也可以看看 $toLong 转换为日期 下表列出了可以转换为日期的输入类型： 输入类型 行为 Double 返回一个日期，该日期对应于被截断的双精度值所表示的毫秒数。正值对应自1970年1月1日以来的毫秒数。负数对应于1970年1月1日之前的毫秒数。 Decimal 返回一个日期，该日期对应于被截断的十进制值所表示的毫秒数。正值对应自1970年1月1日以来的毫秒数。负数对应于1970年1月1日之前的毫秒数。 Long 返回一个日期，该日期对应于Long值所表示的毫秒数。正值对应自1970年1月1日以来的毫秒数。负数对应于1970年1月1日之前的毫秒数。 String 返回与日期字符串对应的日期。字符串必须是一个有效的日期字符串，例如:1. “2018-03-03”2. “2018-03-03T12:00:00Z”3. “2018-03-03T12:00:00+0500” ObjectId 返回与ObjectId的时间戳相对应的日期。 下表列出了一些转换日期的示例： 例子 结果 { input: 120000000000.5, to: \"date\"} ISODate(“1973-10-20T21:20:00Z”) { input: NumberDecimal(\"1253372036000.50\"), to: \"date\"} ISODate(“2009-09-19T14:53:56Z”) { input: NumberLong(\"1100000000000\"), to: \"date\"} ISODate(“2004-11-09T11:33:20Z”) { input: NumberLong(\"-1100000000000\"), to: \"date\"} ISODate(“1935-02-22T12:26:40Z”) { input: ObjectId(\"5ab9c3da31c2ab715d421285\"), to: \"date\" } ISODate(“2018-03-27T04:08:58Z”) { input: \"2018-03-03\", to: \"date\" } ISODate(“2018-03-03T00:00:00Z”) { input: \"2018-03-20 11:00:06 +0500\", to: \"date\" } ISODate(“2018-03-20T06:00:06Z”) { input: \"Friday\", to: \"date\" } Error { input: \"Friday\", to: \"date\", onError: \"Could not convert to type date.\" } “Could not convert to type date.” 也可以看看 $toDate操作符， $dateFromString 转换成的ObjectId 下表列出了可以转换为ObjectId的输入类型： 输入类型 行为 String 返回长度为24的十六进制字符串的ObjectId。不能转换长度为24的十六进制字符串以外的字符串值。 下表列出了一些转换日期的示例： 例子 结果 { input: \"5ab9cbfa31c2ab715d42129e\", to: \"objectId\"} ObjectId(“5ab9cbfa31c2ab715d42129e”) { input: \"5ab9cbfa31c2ab715d42129\", to: \"objectId\"} Error { input: \"5ab9cbfa31c2ab715d42129\", to: \"objectId\", onError: \"Could not convert to type ObjectId.\" } “Could not convert to type ObjectId.” 也可以看看 $toObjectId操作符。 转换为字符串 下表列出了可以转换为字符串的输入类型： 输入类型 行为 Boolean 以字符串形式返回布尔值。 Double 以字符串形式返回双精度值。 Decimal 以字符串形式返回十进制值。 Integer 以字符串的形式返回整数值。 Long 以字符串形式返回长值。 ObjectId 以十六进制字符串的形式返回ObjectId值。 String 无操作。返回字符串值。 Date 以字符串形式返回日期。 下表列出了一些转换为字符串的示例： 例子 结果 { input: true, to: \"string\" } “true” { input: false, to: \"string\" } “false” { input: 2.5, to: \"string\"} “2.5” { input: NumberInt(2), to: \"string\"} “2” { input: NumberLong(1000), to: \"string\"} “1000” { input: ObjectId(\"5ab9c3da31c2ab715d421285\"), to: \"string\" } “5ab9c3da31c2ab715d421285” { input: ISODate(\"2018-03-27T16:58:51.538Z\"), to: \"string\" } { input: ISODate(\"2018-03-27T16:58:51.538Z\"), to: \"string\" }“2018-03-27T16:58:51.538Z” 也可以看看 $toString操作符。 $dateToString 例子 orders使用以下文档创建一个集合： db.orders.insert( [ { _id: 1, item: \"apple\", qty: 5, price: 10 }, { _id: 2, item: \"pie\", qty: 10, price: NumberDecimal(\"20.0\") }, { _id: 3, item: \"ice cream\", qty: 2, price: \"4.99\" }, { _id: 4, item: \"almonds\" }, { _id: 5, item: \"bananas\", qty: 5000000000, price: NumberDecimal(\"1.25\") } ] ) 集合上的以下汇总操作orders会将转换price为小数： // 定义使用转换后的价格和数量值添加convertedPrice和convertedQty字段的阶段 // 如果没有price或qty值，则返回十进制值或整数值 // 如果不能转换价格或数量值，将返回一个字符串 priceQtyConversionStage = { $addFields: { convertedPrice: { $convert: { input: \"$price\", to: \"decimal\", onError: \"Error\", onNull: NumberDecimal(\"0\") } }, convertedQty: { $convert: { input: \"$qty\", to: \"int\", onError:{$concat:[\"Could not convert \", {$toString:\"$qty\"}, \" to type integer.\"]}, onNull: NumberInt(\"0\") } }, } }; totalPriceCalculationStage = { $project: { totalPrice: { $switch: { branches: [ { case: { $eq: [ { $type: \"$convertedPrice\" }, \"string\" ] }, then: \"NaN\" }, { case: { $eq: [ { $type: \"$convertedQty\" }, \"string\" ] }, then: \"NaN\" }, ], default: { $multiply: [ \"$convertedPrice\", \"$convertedQty\" ] } } } } }; db.orders.aggregate( [ priceQtyConversionStage, totalPriceCalculationStage ]) 该操作返回以下文档： { \"_id\" : 1, \"totalPrice\" : NumberDecimal(\"50.0000000000000\") } { \"_id\" : 2, \"totalPrice\" : NumberDecimal(\"200.0\") } { \"_id\" : 3, \"totalPrice\" : NumberDecimal(\"9.98\") } { \"_id\" : 4, \"totalPrice\" : NumberDecimal(\"0\") } { \"_id\" : 5, \"totalPrice\" : \"NaN\" } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/cos-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/cos-aggregation.html","title":"$cos (aggregation)","keywords":"","body":" $cos (aggregation) 在本页面 定义 行为 例子 定义 $cos 4.2版中的新功能。 返回以弧度为单位的值的余弦值。 $cos 具有以下语法： { $cos: } $cos接受可解析为数字的任何有效表达式。如果表达式返回以度为单位的值，请使用$degreesToRadians运算符将结果转换为弧度。 默认情况下以形式$cos返回值是double。 $cos$cos还可以以128-bit小数的形式返回值，只要解析为一个128-bit的十进制值。 有关表达式的更多信息，请参见 表达式。 行为 null，NaN和+/- Infinity 如果参数解析的值为null或指向缺少的字段，则$cos返回null。如果参数解析为NaN，则$cos返回NaN。如果参数解析为负无穷大或正无穷大， $cos则会引发错误。 例子 结果 { $cos: NaN } NaN { $cos: null } null { $cos : Infinity}or{ $cos : -Infinity } 引发类似于以下格式化输出的错误消息：\"errmsg\" : \"Failed to optimize pipeline :: caused by :: cannot apply $cos to -inf, value must in (-inf,inf)\" 例子 度数的余弦值 该trigonometry集合包含一个文档，该文档存储斜边和直角三角形中的一个角度： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"angle_a\" : NumberDecimal(\"53.13010235415597870314438744090659\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $cos表达式来计算相邻的边，angle_a并使用$addFields管道阶段将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"side_a\" : { $multiply : [ { $cos : {$degreesToRadians : \"$angle_a\"} }, \"$hypotenuse\" ] } } } ]) $degreesToRadians表达式将的度数值转换为angle_a以弧度为单位的等效值。 该操作返回以下结果： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"angle_a\" : NumberDecimal(\"53.13010235415597870314438744090659\"), \"side_a\" : NumberDecimal(\"2.999999999999999999999999999999999\"), \"hypotenuse\" : NumberDecimal(\"5\"), } 由于angle_a和hypotenuse被存储为 128-bit小数，因此输出 $cos为128-bit小数。 弧度中的正弦值 trigonometry集合包含一个文档，该文档存储斜边和直角三角形中的一个角度： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"angle_a\" : NumberDecimal(\"0.9272952180016122324285124629224288\"), \"hypotenuse\" : NumberDecimal(\"5\") } 以下聚合操作使用该 $cos表达式来计算相邻的边，angle_a并使用$addFields管道阶段将其添加到输入文档中 。 db.trigonometry.aggregate([ { $addFields : { \"side_b\" : { $multiply : [ { $cos : \"$angle_a\" }, \"$hypotenuse\" ] } } } ]) 该命令返回以下输出： { \"_id\" : ObjectId(\"5c50782193f833234ba90d85\"), \"angle_a\" : NumberDecimal(\"0.9272952180016122324285124629224288\"), \"side_b\" : NumberDecimal(\"3.000000000000000000000000000000000\"), \"hypotenuse\" : NumberDecimal(\"5\"), } 由于angle_a和hypotenuse被存储为 128-bit小数，因此输出 $cos为128-bit小数。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/dateFromParts-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/dateFromParts-aggregation.html","title":"$dateFromParts (aggregation)","keywords":"","body":" $dateFromParts (aggregation) 在本页面 定义 行为 例子 定义 $dateFromParts 3.6版的新功能。 给定日期的组成属性，构造并返回Date对象。 $dateFromParts表达式具有以下语法： { $dateFromParts : { 'year': , 'month': , 'day': , 'hour': , 'minute': , 'second': , 'millisecond': , 'timezone': } } 您还可以 使用以下语法以ISO周日期格式指定组成日期字段 ： { $dateFromParts : { 'isoWeekYear': , 'isoWeek': , 'isoDayOfWeek': , 'hour': , 'minute': , 'second': , 'millisecond': , 'timezone': } } 在$dateFromParts需要具有以下字段的文档： 重要 构造$dateFromParts输入文档时，不能将日历日期字段和ISO周日期字段组合使用。 字段 必选/可选 描述 year 如果不使用isoWeekYear，则为必需的 公历年。可以是任何计算结果为数字的表达式。值范围：0-9999 isoWeekYear 如果不使用year，是必需的 ISO周日期年份。可以是任何计算结果为数字的表达式。值范围： 0-9999 month 可选。只能与year一起使用。 month。可以是任何计算结果为数字的表达式。默认为1。值范围：1-12从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 isoWeek 可选。只能与isoWeekYear一起使用。 一年中的一周。可以是任何计算结果为数字的表达式。默认为1。值范围：1-53从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 day 可选的。只能与year一起使用。 一个月中的某天。可以是任何计算结果为数字的表达式。默认为1。值范围： 1-31从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 isoDayOfWeek 可选。只能与isoWeekYear一起使用。 星期几（星期一1-星期日7）。可以是任何计算结果为数字的表达式。默认为1。值范围：1-7从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 hour 可选 可以是任何计算结果为数字的表达式。默认为0。值范围： 0-23从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 minute 可选 可以是任何计算结果为数字的表达式。默认为0。值范围： 0- 59从MongoDB 4.0开始，如果指定的数字超出此范围，$dateFromParts则将日期计算中的差值纳入考虑范围。有关示例，请参见值范围。 second 可选 可以是任何计算结果为数字的表达式。默认为0。值范围：0-59从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 millisecond 可选 。可以是任何计算结果为数字的表达式。默认为0。值范围： 0-999从MongoDB 4.0开始，如果指定的数字超出此范围，则会$dateFromParts在日期计算中纳入差异。有关示例，请参见值范围。 timezone 可选 可以是任何表达式，其值是字符串，其值可以是：一个奥尔森时区标识符，例如\"Europe/London\"或\"America/New_York\"UTC偏移量，格式为：1. +/-[hh]:[mm]，例如\"+04:45\"2. +/-[hh][mm]，例如\"-0530\"3. +/-[hh]例如\"+03\"有关表达式的更多信息，请参见 表达式。 行为 值范围 在MongoDB中4.0开始，如果比其它字段中指定的值 year，isoYear和timezone是在有效范围之外， $dateFromParts携带或减去从其它日期的差来计算的日期。 值大于范围 考虑以下$dateFromParts表达式，其中month字段值为14，比12个月（或1年）的最大值大2个月： { $dateFromParts: { 'year' : 2017, 'month' : 14, 'day': 1, 'hour' : 12 } } 该表达式通过将year乘以1并将设置month为2来返回来计算日期： ISODate(\"2018-02-01T12:00:00Z\") 值小于的范围 考虑以下$dateFromParts表达式，其中month字段值为0，比最小值1个月小1个月： { $dateFromParts: { 'year' : 2017, 'month' : 0, 'day': 1, 'hour' : 12 } } 该表达式通过将减少year1并将设置month为12来返回，以计算日期： ISODate(\"2016-12-01T12:00:00Z\") 时区 在 字段中使用Olson时区标识符时，如果适用于指定的时区，MongoDB将应用DST偏移量。 例如，考虑sales包含以下文档的集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 20, \"quantity\" : 5, \"date\" : ISODate(\"2017-05-20T10:24:51.303Z\") } 以下汇总说明了MongoDB如何处理Olson时区标识符的DST偏移量。该示例使用 $hourand $minute运算符返回date字段的相应部分： db.sales.aggregate([ { $project: { \"nycHour\": { $hour: { date: \"$date\", timezone: \"-05:00\" } }, \"nycMinute\": { $minute: { date: \"$date\", timezone: \"-05:00\" } }, \"gmtHour\": { $hour: { date: \"$date\", timezone: \"GMT\" } }, \"gmtMinute\": { $minute: { date: \"$date\", timezone: \"GMT\" } }, \"nycOlsonHour\": { $hour: { date: \"$date\", timezone: \"America/New_York\" } }, \"nycOlsonMinute\": { $minute: { date: \"$date\", timezone: \"America/New_York\" } } } }]) 该操作返回以下结果： { \"_id\": 1, \"nycHour\" : 5, \"nycMinute\" : 24, \"gmtHour\" : 10, \"gmtMinute\" : 24, \"nycOlsonHour\" : 6, \"nycOlsonMinute\" : 24 } 例子 以下聚合用于$dateFromParts从提供的输入字段构造三个日期对象： db.sales.aggregate([ { $project: { date: { $dateFromParts: { 'year' : 2017, 'month' : 2, 'day': 8, 'hour' : 12 } }, date_iso: { $dateFromParts: { 'isoWeekYear' : 2017, 'isoWeek' : 6, 'isoDayOfWeek' : 3, 'hour' : 12 } }, date_timezone: { $dateFromParts: { 'year' : 2016, 'month' : 12, 'day' : 31, 'hour' : 23, 'minute' : 46, 'second' : 12, 'timezone' : 'America/New_York' } } } }]) 该操作返回以下结果： { \"_id\" : 1, \"date\" : ISODate(\"2017-02-08T12:00:00Z\"), \"date_iso\" : ISODate(\"2017-02-08T12:00:00Z\"), \"date_timezone\" : ISODate(\"2017-01-01T04:46:12Z\") } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/dateFromString-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/dateFromString-aggregation.html","title":"$dateFromString (aggregation)","keywords":"","body":" $dateFromString (aggregation) 在本页面 定义 行为 格式说明 例子 定义 $dateFromString 3.6版的新功能。 将日期/时间字符串转换为日期对象。 该$dateFromString表达式具有以下语法： { $dateFromString: { dateString: , format: , timezone: , onError: , onNull: } } 在$dateFromString需要具有以下字段的文档： 字段 描述 dateString 要转换为日期对象的日期/时间字符串。有关日期/时间格式的更多信息，请参见日期。注意:如果timezone为操作符指定选项，请不要在dateString中包含时区信息。 format 可选的。dateString的日期格式规范 。format可以是计算结果为字符串文字的任何表达式，其中包含0个或多个格式说明符。有关可用的说明符列表，请参见格式说明符。如果未指定，则$dateFromString使用 \"%Y-%m-%dT%H:%M:%S.%LZ\"默认格式。版本4.0中的新功能。 timezone 可选的。用于格式化日期的时区。注意:如果dateString参数的格式类似于“ 2017-02-08T12：10：40.787Z”，其中末尾的“ Z”表示祖鲁时间（UTC时区），则无法指定timezone参数。 允许使用以下选项和对其求值的表达式：1. 一个奥尔森时区标识符，例如\"Europe/London\"或\"America/New_York\"，2. UTC偏移量，格式为：a. +/-[hh]:[mm]，例如\"+04:45\"b. +/-[hh][mm]，例如\"-0530\"c. +/-[hh]，例如\"+03\"3. 字符串“ Z”，“ UTC”或“ GMT”有关表达式的更多信息，请参见表达式。 onError 可选的。如果$dateFromString在解析给定dateString时遇到错误，则输出所提供onError 表达式的结果值。此结果值可以是任何类型。如果未指定onError，$dateFromString 则无法解析dateString时将引发错误。 onNull 可选的。如果提供给$dateFromString的dateString为空或缺失，则输出提供的onNull表达式的结果值。这个结果值可以是任何类型。如果不指定onNull，并且dateString为null 或丢失，然后$dateFromString输出null。 也可以看看 $toDate和 $convert 行为 例子 结果 { $dateFromString: { dateString: \"2017-02-08T12:10:40.787\" } } ISODate(\"2017-02-08T12:10:40.787Z\") { $dateFromString: { dateString: \"2017-02-08T12:10:40.787\", timezone: \"America/New_York\" } } ISODate(\"2017-02-08T17:10:40.787Z\") { $dateFromString: { dateString: \"2017-02-08\" } } ISODate(\"2017-02-08T00:00:00Z\") { $dateFromString: { dateString: \"06-15-2018\", format: \"%m-%d-%Y\" } } ISODate(\"2018-06-15T00:00:00Z\") { $dateFromString: { dateString: \"15-06-2018\", format: \"%d-%m-%Y\" } } ISODate(\"2018-06-15T00:00:00Z\") 格式说明 以下格式说明符可用于 ： 说明符 描述 可能的值 %d 每月的日期（2位数字，零填充） 01--31 %G ISO 8601格式的年份 0000--9999 %H 小时（2位数字，零填充，24小时制） 00--23 %L 毫秒（3位数字，零填充） 000--999 %m 月（2位数字，零填充） 01--12 %M 分钟（2位数字，零填充） 00--59 %S 秒（2位数字，零填充） 00--60 %u ISO 8601格式的星期几编号（1-Monday，7-Sunday） 1--7 %V 一年中的星期，采用ISO 8601格式 1--53 %Y 年（4位数字，零填充） 0000--9999 %z 与UTC的时区偏移量。 +/-[hh][mm] %Z 分钟数从UTC偏移为数字。例如，如果时区偏移量（+/-[hhmm]）为+0445，则分钟偏移量为+285。 +/-mmm %% 文字字符百分比 % 例子 转换日期 考虑一个logmessages包含以下带有日期的文档的集合。 { _id: 1, date: \"2017-02-08T12:10:40.787\", timezone: \"America/New_York\", message: \"Step 1: Started\" }, { _id: 2, date: \"2017-02-08\", timezone: \"-05:00\", message: \"Step 1: Ended\" }, { _id: 3, message: \" Step 1: Ended \" }, { _id: 4, date: \"2017-02-09\", timezone: \"Europe/London\", message: \"Step 2: Started\"} { _id: 5, date: \"2017-02-09T03:35:02.055\", timezone: \"+0530\", message: \"Step 2: In Progress\"} 以下聚合使用$dateFromString将date值转换为日期对象： db.logmessages.aggregate( [ { $project: { date: { $dateFromString: { dateString: '$date', timezone: 'America/New_York' } } } } ] ) 上述汇总返回以下文档，并将每个date字段转换为东部时区： { \"_id\" : 1, \"date\" : ISODate(\"2017-02-08T17:10:40.787Z\") } { \"_id\" : 2, \"date\" : ISODate(\"2017-02-08T05:00:00Z\") } { \"_id\" : 3, \"date\" : null } { \"_id\" : 4, \"date\" : ISODate(\"2017-02-09T05:00:00Z\") } { \"_id\" : 5, \"date\" : ISODate(\"2017-02-09T08:35:02.055Z\") } timezone参数也可以通过一个文档字段，而不是硬编码参数提供的。例如： db.logmessages.aggregate( [ { $project: { date: { $dateFromString: { dateString: '$date', timezone: '$timezone' } } } } ] ) 上面的汇总返回以下文档，并将每个date字段转换为其各自的UTC表示形式。 { \"_id\" : 1, \"date\" : ISODate(\"2017-02-08T17:10:40.787Z\") } { \"_id\" : 2, \"date\" : ISODate(\"2017-02-08T05:00:00Z\") } { \"_id\" : 3, \"date\" : null } { \"_id\" : 4, \"date\" : ISODate(\"2017-02-09T00:00:00Z\") } { \"_id\" : 5, \"date\" : ISODate(\"2017-02-08T22:05:02.055Z\") } onError 如果您的集合包含带有$dateFromString无法解析的日期字符串的文档， 除非您向可选参数提供聚合表达式， 否则将引发错误 onError。 例如，给定一个dates具有以下文档的集合： { \"_id\" : 1, \"date\" : \"2017-02-08T12:10:40.787\", timezone: \"America/New_York\" }, { \"_id\" : 2, \"date\" : \"20177-02-09T03:35:02.055\", timezone: \"America/New_York\" } 您可以使用onError参数以其原始字符串形式返回无效日期： db.dates.aggregate( [ { $project: { date: { $dateFromString: { dateString: '$date', timezone: '$timezone', onError: '$date' } } } } ] ) 这将返回以下文档： { \"_id\" : 1, \"date\" : ISODate(\"2017-02-08T17:10:40.787Z\") } { \"_id\" : 2, \"date\" : \"20177-02-09T03:35:02.055\" } onNull 如果您的集合包含带有null日期字符串的文档，则 $dateFromString返回null，除非您为可选的onNull参数的聚合表达式。 例如，给定一个dates具有以下文档的集合： { \"_id\" : 1, \"date\" : \"2017-02-08T12:10:40.787\", timezone: \"America/New_York\" }, { \"_id\" : 2, \"date\" : null, timezone: \"America/New_York\" } 您可以使用onNull参数让$dateFromString返回代表Unix纪元的日期，而不是null： db.dates.aggregate( [ { $project: { date: { $dateFromString: { dateString: '$date', timezone: '$timezone', onNull: new Date(0) } } } } ] ) 这将返回以下文档： { \"_id\" : 1, \"date\" : ISODate(\"2017-02-08T17:10:40.787Z\") } { \"_id\" : 2, \"date\" : ISODate(\"1970-01-01T00:00:00Z\") } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/dateToParts-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/dateToParts-aggregation.html","title":"$dateToParts (aggregation)","keywords":"","body":" $dateToParts (aggregation) 在本页面 定义 行为 例子 定义 $dateToParts 3.6版的新功能。 返回包含给定BSON日期值的组成部分作为单个属性的文档。返回的属性year，month，day，hour，minute，second 和millisecond。 您可以将iso8601属性设置为true，以返回代表ISO周日期的部分 。这将返回一个文档，其中的属性是 isoWeekYear，isoWeek，isoDayOfWeek，hour， minute，second和millisecond。 $dateToParts表达式具有以下语法： { $dateToParts: { 'date' : , 'timezone' : , 'iso8601' : } } 在$dateToParts需要具有以下字段的文档： 字段 必选/可选 描述 year 必选 在版本3.6中更改。返回部分的输入日期。可以是解析为日期、时间戳或ObjectID的任何表达式。有关表达式的更多信息，请参见表达式。 timezone 可选 用于格式化日期的时区。默认情况下， $dateToParts使用UTC。可以是任何表达式，该表达式的值可以是:1. 一个奥尔森时区标识符，例如\"Europe/London\"或\"America/New_York\"，2. UTC偏移量，格式为：a. +/-[hh]:[mm]，例如\"+04:45\"b. +/-[hh][mm]，例如\"-0530\"c. +/-[hh]例如\"+03\"有关表达式的更多信息，请参见 表达式。 iso8601 可选 如果设置为true，则修改输出文档以使用ISO周日期字段。默认为false。 行为 在 字段中使用Olson时区标识符时，如果适用于指定的时区，MongoDB将应用DST偏移量。 例如，考虑sales包含以下文档的集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 20, \"quantity\" : 5, \"date\" : ISODate(\"2017-05-20T10:24:51.303Z\") } 以下汇总说明了MongoDB如何处理Olson时区标识符的DST偏移量。该示例使用 $hour和 $minute运算符返回date字段的相应部分： db.sales.aggregate([ { $project: { \"nycHour\": { $hour: { date: \"$date\", timezone: \"-05:00\" } }, \"nycMinute\": { $minute: { date: \"$date\", timezone: \"-05:00\" } }, \"gmtHour\": { $hour: { date: \"$date\", timezone: \"GMT\" } }, \"gmtMinute\": { $minute: { date: \"$date\", timezone: \"GMT\" } }, \"nycOlsonHour\": { $hour: { date: \"$date\", timezone: \"America/New_York\" } }, \"nycOlsonMinute\": { $minute: { date: \"$date\", timezone: \"America/New_York\" } } } }]) 该操作返回以下结果： { \"_id\": 1, \"nycHour\" : 5, \"nycMinute\" : 24, \"gmtHour\" : 10, \"gmtMinute\" : 24, \"nycOlsonHour\" : 6, \"nycOlsonMinute\" : 24 } 例子 考虑sales包含以下文档的集合： { \"_id\" : 2, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 2, \"date\" : ISODate(\"2017-01-01T01:29:09.123Z\") } 以下聚合用于$dateToParts返回包含date字段组成部分的文档。 db.sales.aggregate([ { $project: { date: { $dateToParts: { date: \"$date\" } }, date_iso: { $dateToParts: { date: \"$date\", iso8601: true } }, date_timezone: { $dateToParts: { date: \"$date\", timezone: \"America/New_York\" } } } }]) 该操作返回以下结果： { \"_id\" : 2, \"date\" : { \"year\" : 2017, \"month\" : 1, \"day\" : 1, \"hour\" : 1, \"minute\" : 29, \"second\" : 9, \"millisecond\" : 123 }, \"date_iso\" : { \"isoWeekYear\" : 2016, \"isoWeek\" : 52, \"isoDayOfWeek\" : 7, \"hour\" : 1, \"minute\" : 29, \"second\" : 9, \"millisecond\" : 123 }, \"date_timezone\" : { \"year\" : 2016, \"month\" : 12, \"day\" : 31, \"hour\" : 20, \"minute\" : 29, \"second\" : 9, \"millisecond\" : 123 } } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/dateToString-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/dateToString-aggregation.html","title":"$dateToString (aggregation)","keywords":"","body":" $dateToString (aggregation) 在本页面 定义 格式说明符 例子 定义 $dateToString 根据用户指定的格式将日期对象转换为字符串。 $dateToString表达式具有以下 运算符表达式语法： { $dateToString: { date: , format: , timezone: , onNull: } } 在$dateToString需要具有以下字段的文档： 字段 描述 date 在版本3.6中更改。转换为字符串的日期。必须是可解析为Date， Timestamp或 ObjectID的有效表达式。 format 可选的。日期格式规范。可以是任何字符串文字，包含0或多个格式说明符。有关可用说明符的列表，请参阅“ 格式说明符” 。如果未指定，则$dateToString使用 \"%Y-%m-%dT%H:%M:%S.%LZ\"默认格式。在版本4.0中更改：format如果featureCompatibilityVersion（fCV）设置为\"4.0\"或更大，则此字段为可选 。有关fCV的更多信息，请参见 setFeatureCompatibilityVersion。 timezone Optional.运算结果的时区。 必须是一个有效的表达式，可以解析为格式为Olson时区标识符或 UTC偏移量的字符串。如果未timezone提供，结果将显示在中UTC。1. 奥尔森时区标识符：a. \"America/New_York\"b. \"Europe/London\"c. \"GMT\"2. UTC偏移：a. +/-[hh]:[mm], e.g. \"+04:45\"b. +/-[hh][mm], e.g. \"-0530\"c. +/-[hh], e.g. \"+03\"3.6版的新功能。 onNull 可选的。如果date为null或缺少，则返回的值。参数可以是任何有效的表达式。如果未指定，$dateToString则如果datenull为null或缺少，则返回null 。版本4.0中的新功能：要求featureCompatibilityVersion（fCV）设置为 \"4.0\"或更高。有关fCV的更多信息，请参见 setFeatureCompatibilityVersion。 也可以看看 $toString和 $convert 格式说明符 以下格式说明符可用于 ： 说明符 描述 可能的值 %d 每月的日期（2位数字，零填充） 01--31 %G ISO 8601格式的年份3.4版的新功能。 0000--9999 %H 小时（2位数字，零填充，24小时制） 00--23 %j 一年中的某天（3位数字，零填充） 001--366 %L 毫秒（3位数字，零填充） 000--999 %m 月（2位数字，零填充） 01--12 %M 分钟（2位数字，零填充） 00--59 %S 秒（2位数字，零填充） 00--60 %w 星期几（1-星期日，7-星期六） 1--7 %u ISO 8601格式的星期几编号（1-Monday，7-Sunday）3.4版的新功能。 1--7 %U 一年中的星期（2位数字，零填充） 00--53 %V 一年中的星期，采用ISO 8601格式3.4版的新功能。 01--53 %Y 年（4位数字，零填充） 0000--9999 %z 与UTC的时区偏移量。3.6版的新功能。 +/-[hh][mm] %Z 分钟数从UTC偏移为数字。例如，如果时区偏移量（+/-[hhmm]）为+0445，则分钟偏移量为+285。3.6版的新功能。 +/-mmm %% 文字字符百分比 % 例子 考虑sales包含以下文档的集合： { \"_id\" : 1, \"item\" : \"abc\", \"price\" : 10, \"quantity\" : 2, \"date\" : ISODate(\"2014-01-01T08:15:39.736Z\") } 以下聚合用于$dateToString将date字段作为格式化的字符串返回： db.sales.aggregate( [ { $project: { yearMonthDayUTC: { $dateToString: { format: \"%Y-%m-%d\", date: \"$date\" } }, timewithOffsetNY: { $dateToString: { format: \"%H:%M:%S:%L%z\", date: \"$date\", timezone: \"America/New_York\"} }, timewithOffset430: { $dateToString: { format: \"%H:%M:%S:%L%z\", date: \"$date\", timezone: \"+04:30\" } }, minutesOffsetNY: { $dateToString: { format: \"%Z\", date: \"$date\", timezone: \"America/New_York\" } }, minutesOffset430: { $dateToString: { format: \"%Z\", date: \"$date\", timezone: \"+04:30\" } } } } ] ) 该操作返回以下结果： { \"_id\" : 1, \"yearMonthDayUTC\" : \"2014-01-01\", \"timewithOffsetNY\" : \"03:15:39:736-0500\", \"timewithOffset430\" : \"12:45:39:736+0430\", \"minutesOffsetNY\" : \"-300\", \"minutesOffset430\" : \"270\" } 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Operators/literal-aggregation.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Operators/literal-aggregation.html","title":"$literal (aggregation)","keywords":"","body":" $literal (aggregation) 在本页面 定义 行为 例子 定义 $literal 返回 value 而不解析。用于聚合管道可以将其解释为表达式的值。 $literal表达式具有以下语法： { $literal: } 行为 如果是表达，$literal不会计算表达式，而是返回未解析的表达式。 例 结果 { $literal: { $add: [ 2, 3 ] } } { “$add“ : [ 2, 3 ] } { $literal: { $literal: 1 } } { “$literal“ : 1 } 例子 将$视为文字 在表达中，美元符号$评估为字段路径; 即：提供对该字段的访问。对于 example，$eq expression $eq: [ “$price“, “$1“ ]在名为price的字段中的 value 与文档中名为1的字段中的 value 之间执行相等性检查。 以下 example 使用$literal表达式将包含美元符号“$1“的 string 视为常量 value。 集合records具有以下文档： { “_id“ : 1, “item“ : “abc123“, price: “$2.50“ } { “_id“ : 2, “item“ : “xyz123“, price: “1“ } { “_id“ : 3, “item“ : “ijk123“, price: “$1“ } db.records.aggregate( [ { $project: { costsOneDollar: { $eq: [ “$price“, { $literal: “$1“ } ] } } } ] ) 此操作投影名为costsOneDollar的字段，该字段包含 boolean value，指示price字段的 value 是否等于 string “$1“： { “_id“ : 1, “costsOneDollar“ : false } { “_id“ : 2, “costsOneDollar“ : false } { “_id“ : 3, “costsOneDollar“ : true } 使用 Value 1 投影新字段 $project阶段使用表达式: 1在输出中包含。以下 example 使用$literal来_return 将新字段设置为1的 value。 集合bids具有以下文档： { “_id“ : 1, “item“ : “abc123“, condition: “new“ } { “_id“ : 2, “item“ : “xyz123“, condition: “new“ } 以下聚合计算表达式item: 1以表示 return 输出中的现有字段item，但使用{$literal：1 }表达式 return 新字段startAt设置为 value 1： db.bids.aggregate( [ { $project: { item: 1, startAt: { $literal: 1 } } } ] ) 该操作产生以下文件： { “_id“ : 1, “item“ : “abc123“, “startAt“ : 1 } { “_id“ : 2, “item“ : “xyz123“, “startAt“ : 1 } Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/01-operator/Aggregation-Pipeline-Stages.html":{"url":"16-reference/01-operator/Aggregation-Pipeline-Stages.html","title":"聚合管道阶段","keywords":"","body":" 聚合管道阶段 在db.collection.aggregate和db.aggregate方法中 ，管道阶段出现在列表中。文档按顺序通过各个阶段。 阶段 db.collection.aggregate()阶段 除了$out、$merge和$geoNear阶段之外，所有阶段都可以在管道中出现多次。 注意 有关特定运算符的详细信息，包括语法和示例，请单击特定运算符以转到其参考页。 db.collection.aggregate( [ { }, ... ] ) 阶段 描述 $addFields 向文档添加新字段。与$project类似，$addFields重塑了流中的每个文档;具体而言，通过向输出文档添加新字段，该文档包含输入文档和新添加字段中的现有字段。$set是的别名$addFields。 $bucket 根据指定的表达式和存储段边界将传入文档分类为称为存储段的组。 $bucketAuto 根据指定的表达式将传入的文档分类为特定数量的组(称为存储桶)。自动确定存储桶边界，以尝试将文档均匀地分配到指定数量的存储桶中。 $collStats 返回有关集合或视图的统计信息。 $count 返回聚合管道此阶段的文档数量计数。 $facet 在同一阶段的同一组输入文档上处理多个聚合管道。支持在一个阶段中创建能够表征多维或多面数据的多面聚合。 $geoNear 基于与地理空间点的接近度返回有序的文档流。将$match，$sort和$limit的功能合并到地理空间数据中。输出文档包括附加距离字段，并且可以包括位置标识符字段。 $graphLookup 对集合执行递归搜索。对于每个输出文档，添加一个新的 array 字段，该字段包含该文档的递归搜索的遍历结果。 $group 按指定的标识符表达式对文档进行分组，并将累加器表达式(如果指定)应用于每个 group。消耗所有输入文档，并为每个不同的 group 输出一个文档。输出文档仅包含标识符字段，如果指定，则包含累积字段。 $indexStats 返回有关集合的每个索引的使用的统计信息。 $limit 将未修改的前 n 个文档传递给管道，其中 n 是指定的限制。对于每个输入文档，输出一个文档(对于前 n 个文档)或零文档(在前 n 个文档之后)。 $listSessions 列出所有活动时间已足够长以传播到system.sessions集合的会话。 $lookup 对同一数据库中的另一个集合执行左外连接，以从“已连接”集合中过滤文档以进行处理。 $match 过滤文档流以仅允许匹配的文档未经修改地传递到下一个管道阶段。 $match使用标准的 MongoDB 查询。对于每个输入文档，输出一个文档(匹配)或零文档(不匹配)。 $merge 将聚合管道的结果文档写入集合。该阶段可以将结果合并（插入新文档，合并文档，替换文档，保留现有文档，使操作失败，使用自定义更新管道处理文档）将结果合并到输出集合中。要使用该$merge阶段，它必须是管道中的最后一个阶段。4.2版中的新功能。 $out 将聚合管道的结果文档写入集合。要使用$out阶段，它必须是管道中的最后一个阶段。 $planCacheStats 返回集合的计划缓存信息。 $project 重塑流中的每个文档，例如通过添加新字段或删除现有字段。对于每个输入文档，输出一个文档。另请参阅$unset删除现有字段。 $redact 通过基于文档本身中存储的信息限制每个文档的内容来重塑流中的每个文档。包含$project和$match的功能。可用于实现字段级编辑。对于每个输入文档，输出一个或零个文档。 $replaceRoot 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶部级别。$replaceWith是$replaceRoot阶段的别名 。 $replaceWith 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶部级别。$replaceWith是$replaceRoot阶段的别名 。 $sample 从输入中随机选择指定数量的文档。 $set 将新字段添加到文档。与$project相似，$set重塑流中的每个文档；具体而言，通过向输出文档添加新字段，该输出文档既包含输入文档中的现有字段，又包含新添加的字段。$set是$addFields阶段的别名。 $skip 跳过前 n 个文档，其中 n 是指定的跳过编号，并将未修改的其余文档传递给管道。对于每个输入文档，输出零文档(对于前 n 个文档)或一个文档(如果在前 n 个文档之后)。 $sort 按指定的排序 key 重新排序文档流。只有顺序改变;文档保持不变。对于每个输入文档，输出一个文档。 sortByCount 根据指定表达式的 value 对传入文档进行分组，然后计算每个不同 group 中的文档计数。 $unset 从文档中删除/排除字段。$unset是$project删除字段的阶段的别名。 $unwind 从输入文档解构 array 字段以输出每个元素的文档。每个输出文档都使用元素 value 替换 array。对于每个输入文档，输出 n 个文档，其中 n 是 array 元素的数量，对于空 array 可以为零。 对于要在管道阶段使用的聚合表达式运算符，请参阅聚合管道操作符。 db.aggregate()阶段 从 version 3.6 开始，MongoDB 还提供了db.aggregate方法： db.aggregate( [ { }, ... ] ) 以下阶段使用db.aggregate()方法而不是db.collection.aggregate()方法。 阶段 描述 $currentOp 返回有关 MongoDB 部署的活动 and/or 休眠操作的信息。 $listLocalSessions 列出最近在当前连接的mongos或mongod实例上使用的所有 active 会话。这些会话可能尚未传播到system.sessions集合。 阶段可用于更新 从MongoDB 4.2开始，您可以使用聚合管道在以下位置进行更新： 命令 mongo shell方法 findAndModify db.collection.findOneAndUpdate（）db.collection.findAndModify（） update db.collection.updateOne（）db.collection.updateMany（）db.collection.update（）Bulk.find.update（）Bulk.find.updateOne（）Bulk.find.upsert（） 对于更新，管道可以包括以下阶段： $addFields 及其别名 $set $project 及其别名 $unset $replaceRoot及其别名$replaceWith。 按字母顺序排列的阶段列表 阶段 描述 $addFields 向文档添加新字段。输出包含输入文档和新添加字段中所有现有字段的文档。 $bucket 根据指定的表达式和存储段边界将传入文档分类为称为存储段的组。 $bucketAuto 根据指定的表达式将传入的文档分类为特定数量的组(称为存储桶)。自动确定存储桶边界，以尝试将文档均匀地分配到指定数量的存储区中。 $collStats 返回有关集合或视图的统计信息。 $count 返回聚合管道此阶段的文档数量计数。 $currentOp 返回有关 MongoDB 部署的活动 and/or 休眠操作的信息。要运行，请使用db.aggregate()方法。 $facet 在同一组输入文档的单个阶段内处理多个聚合管道。允许创建能够在单个阶段中跨多个维度或方面表征数据的 多面聚合。 $geoNear 基于与地理空间点的接近度返回有序的文档流。将$match，$sort和$limit的功能合并到地理空间数据中。输出文档包括附加距离字段，并且可以包括位置标识符字段。 $graphLookup 对集合执行递归搜索。对于每个输出文档，添加一个新的 array 字段，该字段包含该文档的递归搜索的遍历结果。 $group 按指定的标识符表达式对文档进行分组，并将累加器表达式(如果指定)应用于每个 group。消耗所有输入文档，并为每个不同的 group 输出一个文档。输出文档仅包含标识符字段，如果指定，则包含累积字段。 $indexStats 返回有关集合的每个索引的使用的统计信息。 $limit 将未修改的前 n 个文档传递给管道，其中 n 是指定的限制。对于每个输入文档，输出一个文档(对于前 n 个文档)或零文档(在前 n 个文档之后)。 $listLocalSessions 列出最近在当前连接的mongos或mongod实例上使用的所有 active 会话。这些会话可能尚未传播到system.sessions集合。 $listSessions 列出所有活动时间已足够长以传播到system.sessions集合的会话。 $lookup 对同一数据库中的另一个集合执行左外连接，以从“已连接”集合中过滤文档以进行处理。 $match 过滤文档流以仅允许匹配的文档未经修改地传递到下一个管道阶段。 $match使用标准的 MongoDB 查询。对于每个输入文档，输出一个文档(匹配)或零文档(不匹配)。 $merge 将聚合管道的结果文档写入集合。该阶段可以将结果合并（插入新文档，合并文档，替换文档，保留现有文档，使操作失败，使用自定义更新管道处理文档）将结果合并到输出集合中。要使用该$merge阶段，它必须是管道中的最后一个阶段。4.2版中的新功能。 $out 将聚合管道的结果文档写入集合。要使用$out阶段，它必须是管道中的最后一个阶段。 $planCacheStats 返回集合的计划缓存信息。 $project 重新整形流中的每个文档，例如添加新字段或删除现有字段。对于每个输入文档，输出一个文档。 $redact 通过基于文档本身中存储的信息限制每个文档的内容来重塑流中的每个文档。包含$project和$match的功能。可用于实现字段级编辑。对于每个输入文档，输出一个或零个文档。 $replaceRoot 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶部级别。 $replaceWith 用指定的嵌入文档替换文档。该操作将替换输入文档中的所有现有字段，包括_id字段。指定嵌入在输入文档中的文档，以将嵌入的文档提升到顶部级别。别名$replaceRoot。 $sample 从输入中随机选择指定数量的文档。 $set 将新字段添加到文档。输出包含输入文档中所有现有字段和新添加的字段的文档。别名$addFields。 $skip 跳过前 n 个文档，其中 n 是指定的跳过编号，并将未修改的其余文档传递给管道。对于每个输入文档，输出零文档(对于前 n 个文档)或一个文档(如果在前 n 个文档之后)。 $sort 按指定的排序 key 重新排序文档流。只有顺序改变;文件保持不变。对于每个输入文档，输出一个文档。 $sortByCount 根据指定表达式的值对传入文档进行分组，然后计算每个不同组中的文档数。 $unwind 从输入文档解构 array 字段以输出每个元素的文档。每个输出文档都使用元素 value 替换 array。对于每个输入文档，输出 n 个文档，其中 n 是 array 元素的数量，对于空 array 可以为零。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command.html":{"url":"16-reference/02-command.html","title":"数据库命令","keywords":"","body":" 数据库命令 在本页面 用户命令 数据库操作 审核命令 下文概述的所有命令文档均描述了命令及其可用参数，并提供了每个命令的文档模板或原型。一些命令文档还包括相关的 mongoShell帮助器。 要针对当前数据库运行命令，请使用db.runCommand()： db.runCommand( { } ) 要对admin数据库运行管理命令，请使用db.adminCommand()： db.adminCommand( { } ) 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 用户命令 聚合命令 名称 描述 aggregate 使用聚合框架执行聚合任务，例如分组。 count 计算集合或视图中的文档数。 distinct 显示在集合或视图中为指定键找到的不同值。 mapReduce 对大型数据集执行map-reduce聚合。 地理空间命令 名称 描述 geoSearch 执行使用MongoDB的haystack索引功能的地理空间查询。 查询和写操作命令 名称 描述 delete 删除一个或多个文档。 find 返回集合或视图中的文档。 findAndModify 返回并修改单个文档。 getLastError 返回上一个操作的成功状态。 getMore 返回当前由游标指向的批处理文档。 insert 插入一个或多个文档。 resetError 不推荐使用。重置上一个错误状态。 update 更新一个或多个文档。 查询计划缓存命令 名称 描述 planCacheClear 删除集合的缓存查询计划。 planCacheClearFilters 清除集合的索引过滤器。 planCacheListFilters 列出集合的索引过滤器。 planCacheListPlans 显示指定查询模型的缓存查询计划。 planCacheListQueryShapes 显示存在其缓存的查询计划的查询模型。 planCacheSetFilter 为集合设置索引过滤器。 数据库操作 认证命令 名称 描述 authenticate 使用用户名和密码启动经过身份验证的会话。 getnonce 这是一个内部命令，用于生成用于身份验证的一次性密码。 logout 终止当前已认证的会话。 用户管理命令 名称 描述 createUser 创建一个新用户。 dropAllUsersFromDatabase 删除与数据库关联的所有用户。 dropUser 删除一个用户。 grantRolesToUser 向用户授予角色及其特权。 revokeRolesFromUser 从用户删除角色。 updateUser 更新用户的数据。 usersInfo 返回有关指定用户的信息。 角色管理命令 名称 描述 createRole 创建一个角色并指定其特权。 dropRole 删除用户定义的角色。 dropAllRolesFromDatabase 从数据库中删除所有用户定义的角色。 grantPrivilegesToRole 将特权分配给用户定义的角色。 grantRolesToRole 指定角色，用户定义的角色将从这些角色继承特权。 invalidateUserCache 刷新用户信息的内存缓存，包括凭据和角色。 revokePrivilegesFromRole 从用户定义的角色中删除指定的特权。 revokeRolesFromRole 从用户定义的角色中删除指定的继承角色。 rolesInfo 返回指定角色的信息。 updateRole 更新用户定义的角色。 复制命令 名称 描述 applyOps 应用于内部命令OPLOG条目到当前数据集。 isMaster 显示有关此成员在副本集中的角色的信息，包括它是否为主角色。 replSetAbortPrimaryCatchUp 强制选择的主数据库中止同步（追赶），然后完成到主数据库的过渡。 replSetFreeze 防止当前成员在一段时间内寻求选举为主。 replSetGetConfig 返回副本集的配置对象。 replSetGetStatus 返回报告副本集状态的文档。 replSetInitiate 初始化新的副本集。 replSetMaintenance 启用或禁用维护模式，该模式将辅助节点置于一种RECOVERING状态。 replSetReconfig 将新配置应用于现有副本集。 replSetResizeOplog 动态调整副本集成员的操作日志的大小。仅适用于WiredTiger存储引擎。 replSetStepDown 当前primary下台,成为一个secondary，迫使选举。 replSetSyncFrom 显式覆盖用于选择要复制的成员的默认逻辑。 也可以看看 有关复制的更多信息。 分片命令 名称 描述 addShard 添加一个分片到分片集群。 addShardToZone 将分片与zone关联。支持在分片群集中配置zone。 balancerStart 启动平衡器线程。 balancerStatus 返回有关平衡器状态的信息。 balancerStop 停止平衡器线程。 checkShardingIndex 验证分片键索引的内部命令。 clearJumboFlag 清除jumbo数据块的标志。 cleanupOrphaned 删除分片键值超出分片拥有的数据块范围之外的孤立数据。 enableSharding 在特定数据库上启用分片。 flushRouterConfig 强制mongod/ mongos实例更新其缓存的路由元数据。 getShardMap 报告分片群集状态的内部命令。 getShardVersion 返回配置服务器版本的内部命令。 isdbgrid 验证进程是否是mongos。 listShards 返回已配置的分片列表。 medianKey 不推荐使用的内部命令。请参阅splitVector。 moveChunk 在分片之间迁移块的内部命令。 movePrimary 从分片集群中删除分片时，重新分配主分片。 mergeChunks 提供在单个分片上组合块的功能。 removeShard 启动从分片群集中删除分片的进程。 removeShardFromZone 删除分片和zone之间的关联。支持在分片群集中配置zone。 setShardVersion 内部命令，用于设置配置服务器版本。 shardCollection 启用集合的分片功能，从而可以对集合进行分片。 shardingState 报告mongod 是否为分片群集的成员。 split 创建一个新的块。 splitChunk 拆分块的内部命令。而是使用方法sh.splitFind()和sh.splitAt()。 splitVector 确定分割点的内部命令。 unsetSharding 影响MongoDB部署中实例之间的连接的内部命令。 updateZoneKeyRange 添加或删除范围内的分片数据与zone之间的关联。支持在分片群集中配置zone。 也可以看看 有关MongoDB的分片功能的更多信息。 会话命令 指令 描述 abortTransaction 中止事务版本4.0中的新功能。 commitTransaction 提交事务版本4.0中的新功能。 endSessions 在会话超时期限之前终止会话。3.6版的新功能。 killAllSessions 杀死所有会话。3.6版的新功能。 killAllSessionsByPattern 杀死所有与指定模式匹配的会话3.6版的新功能。 killSessions 杀死指定的会话。3.6版的新功能。 refreshSessions 刷新空闲会话。3.6版的新功能。 startSession 开始新的会话。3.6版的新功能。 管理命令 名称 描述 clean 内部名称空间管理命令。 cloneCollection 将集合从远程主机复制到当前主机。 cloneCollectionAsCapped 将未设置上限的集合复制为新的设置上限的集合。 collMod 向集合添加选项或修改视图定义。 compact 对集合进行分片整理并重建索引。 connPoolSync 用于刷新连接池的内部命令。 convertToCapped 将无上限的集合转换为有上限的集合。 create 创建一个集合或视图。 createIndexes 为一个集合构建一个或多个索引。 currentOp 返回一个文档，该文档包含有关数据库实例正在进行的操作的信息。 drop 从数据库中删除指定的集合。 dropDatabase 删除当前数据库。 dropConnections 将外向连接删除到指定的主机列表。 dropIndexes 从集合中删除索引。 filemd5 返回使用GridFS存储的文件的md5哈希值。 fsync 将挂起的写入刷新到存储层，并锁定数据库以允许备份。 fsyncUnlock 解锁一个fsync锁。 getParameter 检索配置选项。 killCursors 杀死集合的指定游标。 killOp 终止操作ID指定的操作。 listCollections 返回当前数据库中的集合列表。 listDatabases 返回列出所有数据库的文档，并返回基本数据库统计信息。 listIndexes 列出集合的所有索引。 logRotate 循环MongoDB日志，以防止单个文件占用过多空间。 reIndex 重建集合上的所有索引。 renameCollection 更改现有集合的名称。 setFeatureCompatibilityVersion 启用或禁用保留向后不兼容的数据的功能。 setParameter 修改配置选项。 shutdown 关闭mongod或mongos进程。 诊断命令 名称 描述 availableQueryOptions 内部命令，报告当前MongoDB实例的功能。 buildInfo 显示有关MongoDB构建的统计信息。 collStats 报告指定集合的存储利用率静态信息。 connPoolStats 报告从此MongoDB实例到部署中其他MongoDB实例的传出连接的统计信息。 connectionStatus 报告当前连接的身份验证状态。 cursorInfo 在MongoDB 3.2中已删除。替换为metrics.cursor。 dataSize 返回数据范围的数据大小。供内部使用。 dbHash 返回数据库及其集合的哈希值。 dbStats 报告指定数据库的存储利用率统计信息。 diagLogging 在MongoDB 3.6中已删除。要捕获，重放和分析发送到您的MongoDB部署的命令，请使用mongoreplay。 driverOIDTest 将ObjectId转换为字符串以支持测试的内部命令。 explain 返回有关各种操作执行的信息。 features 报告当前MongoDB实例中可用的功能。 getCmdLineOpts 返回带有MongoDB实例及其解析选项的运行时参数的文档。 getLog 返回最近的日志消息。 hostInfo 返回反映基础主机系统的数据。 isSelf 内部命令支持测试。 listCommands 列出当前mongod实例提供的所有数据库命令。 lockInfo 内部命令，返回有关当前正在保留或挂起的锁的信息。仅适用于 mongod实例。 netstat 报告部署内连接性的内部命令。仅适用于mongos实例。 ping 测试部署内连接性的内部命令。 profile 数据库事件探查器的接口。 serverStatus 返回有关实例范围的资源利用率和状态的集合指标。 shardConnPoolStats 报告mongos连接池上的统计信息，以供客户端针对分片进行操作。 top 返回mongod实例中每个数据库的原始使用情况统计信息。 validate 内部命令，用于扫描集合的数据并为正确性编制索引。 whatsmyuri 返回有关当前客户端信息的内部命令。 免费监控命令 名称 描述 setFreeMonitoring 在运行时启用/禁用免费监视。 审核命令 名称 描述 logApplicationMessage 将自定义消息发布到审核日志。 译者：李冠飞 校对： 参见 原文 - Database Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/01-nav-aggregation.html":{"url":"16-reference/02-command/01-nav-aggregation.html","title":"Aggregation Commands","keywords":"","body":" Aggregation Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Aggregation Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/01-nav-aggregation/01-aggregate.html":{"url":"16-reference/02-command/01-nav-aggregation/01-aggregate.html","title":"aggregate","keywords":"","body":" aggregate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - aggregate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/01-nav-aggregation/02-count.html":{"url":"16-reference/02-command/01-nav-aggregation/02-count.html","title":"count","keywords":"","body":" count ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - count Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/01-nav-aggregation/03-distinct.html":{"url":"16-reference/02-command/01-nav-aggregation/03-distinct.html","title":"distinct","keywords":"","body":" distinct ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - distinct Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/01-nav-aggregation/04-mapReduce.html":{"url":"16-reference/02-command/01-nav-aggregation/04-mapReduce.html","title":"mapReduce","keywords":"","body":" mapReduce ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mapReduce Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/02-nav-geospatial.html":{"url":"16-reference/02-command/02-nav-geospatial.html","title":"Geospatial Commands","keywords":"","body":" Geospatial Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Geospatial Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/02-nav-geospatial/01-geoSearch.html":{"url":"16-reference/02-command/02-nav-geospatial/01-geoSearch.html","title":"geoSearch","keywords":"","body":" geoSearch ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - geoSearch Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud.html":{"url":"16-reference/02-command/03-nav-crud.html","title":"Query and Write Operation Commands","keywords":"","body":" Query and Write Operation Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Query and Write Operation Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/01-delete.html":{"url":"16-reference/02-command/03-nav-crud/01-delete.html","title":"delete","keywords":"","body":" delete ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - delete Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/02-find.html":{"url":"16-reference/02-command/03-nav-crud/02-find.html","title":"find","keywords":"","body":" find ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - find Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/03-findAndModify.html":{"url":"16-reference/02-command/03-nav-crud/03-findAndModify.html","title":"findAndModify","keywords":"","body":" findAndModify ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - findAndModify Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/04-getLastError.html":{"url":"16-reference/02-command/03-nav-crud/04-getLastError.html","title":"getLastError","keywords":"","body":" getLastError ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getLastError Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/05-getMore.html":{"url":"16-reference/02-command/03-nav-crud/05-getMore.html","title":"getMore","keywords":"","body":" getMore ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getMore Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/06-insert.html":{"url":"16-reference/02-command/03-nav-crud/06-insert.html","title":"insert","keywords":"","body":" insert ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - insert Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/07-resetError.html":{"url":"16-reference/02-command/03-nav-crud/07-resetError.html","title":"resetError","keywords":"","body":" resetError ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - resetError Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/03-nav-crud/08-update.html":{"url":"16-reference/02-command/03-nav-crud/08-update.html","title":"update","keywords":"","body":" update ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - update Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/04-nav-plan-cache.html":{"url":"16-reference/02-command/04-nav-plan-cache.html","title":"查询计划缓存命令","keywords":"","body":" 查询计划缓存命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 planCacheClear 删除集合的缓存查询计划。 planCacheClearFilters 清除集合的索引过滤器。 planCacheListFilters 列出集合的索引过滤器。 planCacheListPlans 显示指定查询模型的缓存查询计划。 planCacheListQueryShapes 显示存在其缓存的查询计划的查询模型。 planCacheSetFilter 为集合设置索引过滤器。 译者：李冠飞 校对： 参见 原文 - Query Plan Cache Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/04-nav-plan-cache/01-planCacheClear.html":{"url":"16-reference/02-command/04-nav-plan-cache/01-planCacheClear.html","title":"planCacheClear","keywords":"","body":" planCacheClear ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - planCacheClear Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/04-nav-plan-cache/02-planCacheClearFilters.html":{"url":"16-reference/02-command/04-nav-plan-cache/02-planCacheClearFilters.html","title":"planCacheClearFilters","keywords":"","body":" planCacheClearFilters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - planCacheClearFilters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/04-nav-plan-cache/03-planCacheListFilters.html":{"url":"16-reference/02-command/04-nav-plan-cache/03-planCacheListFilters.html","title":"planCacheListFilters","keywords":"","body":" planCacheListFilters ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - planCacheListFilters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/04-nav-plan-cache/04-planCacheSetFilter.html":{"url":"16-reference/02-command/04-nav-plan-cache/04-planCacheSetFilter.html","title":"planCacheSetFilter","keywords":"","body":" planCacheSetFilter ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - planCacheSetFilter Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/05-nav-authentication.html":{"url":"16-reference/02-command/05-nav-authentication.html","title":"认证命令","keywords":"","body":" 认证命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 authenticate 使用用户名和密码启动经过身份验证的会话。 getnonce 这是一个内部命令，用于生成用于身份验证的一次性密码。 logout 终止当前已认证的会话。 译者：李冠飞 校对： 参见 原文 - Authentication Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/05-nav-authentication/01-authenticate.html":{"url":"16-reference/02-command/05-nav-authentication/01-authenticate.html","title":"authenticate","keywords":"","body":" authenticate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - authenticate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/05-nav-authentication/02-getnonce.html":{"url":"16-reference/02-command/05-nav-authentication/02-getnonce.html","title":"getnonce","keywords":"","body":" getnonce ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getnonce Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/05-nav-authentication/03-logout.html":{"url":"16-reference/02-command/05-nav-authentication/03-logout.html","title":"logout","keywords":"","body":" logout ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - logout Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management.html":{"url":"16-reference/02-command/06-nav-user-management.html","title":"User Management Commands","keywords":"","body":" User Management Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - User Management Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/01-createUser.html":{"url":"16-reference/02-command/06-nav-user-management/01-createUser.html","title":"createUser","keywords":"","body":" createUser ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - createUser Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/02-dropAllUsersFromDatabase.html":{"url":"16-reference/02-command/06-nav-user-management/02-dropAllUsersFromDatabase.html","title":"dropAllUsersFromDatabase","keywords":"","body":" dropAllUsersFromDatabase ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropAllUsersFromDatabase Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/03-dropUser.html":{"url":"16-reference/02-command/06-nav-user-management/03-dropUser.html","title":"dropUser","keywords":"","body":" dropUser ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropUser Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/04-grantRolesToUser.html":{"url":"16-reference/02-command/06-nav-user-management/04-grantRolesToUser.html","title":"grantRolesToUser","keywords":"","body":" grantRolesToUser ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - grantRolesToUser Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/05-revokeRolesFromUser.html":{"url":"16-reference/02-command/06-nav-user-management/05-revokeRolesFromUser.html","title":"revokeRolesFromUser","keywords":"","body":" revokeRolesFromUser ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - revokeRolesFromUser Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/06-updateUser.html":{"url":"16-reference/02-command/06-nav-user-management/06-updateUser.html","title":"updateUser","keywords":"","body":" updateUser ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - updateUser Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/06-nav-user-management/07-usersInfo.html":{"url":"16-reference/02-command/06-nav-user-management/07-usersInfo.html","title":"usersInfo","keywords":"","body":" usersInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - usersInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management.html":{"url":"16-reference/02-command/07-nav-role-management.html","title":"Role Management Commands","keywords":"","body":" Role Management Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Role Management Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/01-createRole.html":{"url":"16-reference/02-command/07-nav-role-management/01-createRole.html","title":"createRole","keywords":"","body":" createRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - createRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/02-dropRole.html":{"url":"16-reference/02-command/07-nav-role-management/02-dropRole.html","title":"dropRole","keywords":"","body":" dropRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/03-dropAllRolesFromDatabase.html":{"url":"16-reference/02-command/07-nav-role-management/03-dropAllRolesFromDatabase.html","title":"dropAllRolesFromDatabase","keywords":"","body":" dropAllRolesFromDatabase ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropAllRolesFromDatabase Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/04-grantPrivilegesToRole.html":{"url":"16-reference/02-command/07-nav-role-management/04-grantPrivilegesToRole.html","title":"grantPrivilegesToRole","keywords":"","body":" grantPrivilegesToRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - grantPrivilegesToRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/05-grantRolesToRole.html":{"url":"16-reference/02-command/07-nav-role-management/05-grantRolesToRole.html","title":"grantRolesToRole","keywords":"","body":" grantRolesToRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - grantRolesToRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/06-invalidateUserCache.html":{"url":"16-reference/02-command/07-nav-role-management/06-invalidateUserCache.html","title":"invalidateUserCache","keywords":"","body":" invalidateUserCache ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - invalidateUserCache Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/07-revokePrivilegesFromRole.html":{"url":"16-reference/02-command/07-nav-role-management/07-revokePrivilegesFromRole.html","title":"revokePrivilegesFromRole","keywords":"","body":" revokePrivilegesFromRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - revokePrivilegesFromRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/08-revokeRolesFromRole.html":{"url":"16-reference/02-command/07-nav-role-management/08-revokeRolesFromRole.html","title":"revokeRolesFromRole","keywords":"","body":" revokeRolesFromRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - revokeRolesFromRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/09-rolesInfo.html":{"url":"16-reference/02-command/07-nav-role-management/09-rolesInfo.html","title":"rolesInfo","keywords":"","body":" rolesInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rolesInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/07-nav-role-management/10-updateRole.html":{"url":"16-reference/02-command/07-nav-role-management/10-updateRole.html","title":"updateRole","keywords":"","body":" updateRole ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - updateRole Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication.html":{"url":"16-reference/02-command/08-nav-replication.html","title":"Replication Commands","keywords":"","body":" Replication Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replication Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/01-applyOps.html":{"url":"16-reference/02-command/08-nav-replication/01-applyOps.html","title":"applyOps","keywords":"","body":" applyOps ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - applyOps Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/02-isMaster.html":{"url":"16-reference/02-command/08-nav-replication/02-isMaster.html","title":"isMaster","keywords":"","body":" isMaster ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - isMaster Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/03-replSetAbortPrimaryCatchUp.html":{"url":"16-reference/02-command/08-nav-replication/03-replSetAbortPrimaryCatchUp.html","title":"replSetAbortPrimaryCatchUp","keywords":"","body":" replSetAbortPrimaryCatchUp ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetAbortPrimaryCatchUp Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/04-replSetFreeze.html":{"url":"16-reference/02-command/08-nav-replication/04-replSetFreeze.html","title":"replSetFreeze","keywords":"","body":" replSetFreeze ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetFreeze Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/05-replSetGetConfig.html":{"url":"16-reference/02-command/08-nav-replication/05-replSetGetConfig.html","title":"replSetGetConfig","keywords":"","body":" replSetGetConfig ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetGetConfig Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/06-replSetGetStatus.html":{"url":"16-reference/02-command/08-nav-replication/06-replSetGetStatus.html","title":"replSetGetStatus","keywords":"","body":" replSetGetStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetGetStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/07-replSetInitiate.html":{"url":"16-reference/02-command/08-nav-replication/07-replSetInitiate.html","title":"replSetInitiate","keywords":"","body":" replSetInitiate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetInitiate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/08-replSetMaintenance.html":{"url":"16-reference/02-command/08-nav-replication/08-replSetMaintenance.html","title":"replSetMaintenance","keywords":"","body":" replSetMaintenance ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetMaintenance Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/09-replSetReconfig.html":{"url":"16-reference/02-command/08-nav-replication/09-replSetReconfig.html","title":"replSetReconfig","keywords":"","body":" replSetReconfig ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetReconfig Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/10-replSetResizeOplog.html":{"url":"16-reference/02-command/08-nav-replication/10-replSetResizeOplog.html","title":"replSetResizeOplog","keywords":"","body":" replSetResizeOplog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetResizeOplog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/11-replSetStepDown.html":{"url":"16-reference/02-command/08-nav-replication/11-replSetStepDown.html","title":"replSetStepDown","keywords":"","body":" replSetStepDown ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetStepDown Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/08-nav-replication/12-replSetSyncFrom.html":{"url":"16-reference/02-command/08-nav-replication/12-replSetSyncFrom.html","title":"replSetSyncFrom","keywords":"","body":" replSetSyncFrom ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - replSetSyncFrom Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding.html":{"url":"16-reference/02-command/09-nav-sharding.html","title":"Sharding Commands","keywords":"","body":" Sharding Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sharding Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/01-addShard.html":{"url":"16-reference/02-command/09-nav-sharding/01-addShard.html","title":"addShard","keywords":"","body":" addShard ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - addShard Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/02-addShardToZone.html":{"url":"16-reference/02-command/09-nav-sharding/02-addShardToZone.html","title":"addShardToZone","keywords":"","body":" addShardToZone ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - addShardToZone Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/03-balancerCollectionStatus.html":{"url":"16-reference/02-command/09-nav-sharding/03-balancerCollectionStatus.html","title":"balancerCollectionStatus","keywords":"","body":" balancerCollectionStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - balancerCollectionStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/04-balancerStart.html":{"url":"16-reference/02-command/09-nav-sharding/04-balancerStart.html","title":"balancerStart","keywords":"","body":" balancerStart ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - balancerStart Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/05-balancerStatus.html":{"url":"16-reference/02-command/09-nav-sharding/05-balancerStatus.html","title":"balancerStatus","keywords":"","body":" balancerStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - balancerStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/06-balancerStop.html":{"url":"16-reference/02-command/09-nav-sharding/06-balancerStop.html","title":"balancerStop","keywords":"","body":" balancerStop ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - balancerStop Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/07-checkShardingIndex.html":{"url":"16-reference/02-command/09-nav-sharding/07-checkShardingIndex.html","title":"checkShardingIndex","keywords":"","body":" checkShardingIndex ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - checkShardingIndex Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/08-clearJumboFlag.html":{"url":"16-reference/02-command/09-nav-sharding/08-clearJumboFlag.html","title":"clearJumboFlag","keywords":"","body":" clearJumboFlag ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - clearJumboFlag Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/09-cleanupOrphaned.html":{"url":"16-reference/02-command/09-nav-sharding/09-cleanupOrphaned.html","title":"cleanupOrphaned","keywords":"","body":" cleanupOrphaned ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cleanupOrphaned Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/10-enableSharding.html":{"url":"16-reference/02-command/09-nav-sharding/10-enableSharding.html","title":"enableSharding","keywords":"","body":" enableSharding ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - enableSharding Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/11-flushRouterConfig.html":{"url":"16-reference/02-command/09-nav-sharding/11-flushRouterConfig.html","title":"flushRouterConfig","keywords":"","body":" flushRouterConfig ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - flushRouterConfig Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/12-getShardMap.html":{"url":"16-reference/02-command/09-nav-sharding/12-getShardMap.html","title":"getShardMap","keywords":"","body":" getShardMap ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getShardMap Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/13-getShardVersion.html":{"url":"16-reference/02-command/09-nav-sharding/13-getShardVersion.html","title":"getShardVersion","keywords":"","body":" getShardVersion ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getShardVersion Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/14-isdbgrid.html":{"url":"16-reference/02-command/09-nav-sharding/14-isdbgrid.html","title":"isdbgrid","keywords":"","body":" isdbgrid ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - isdbgrid Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/15-listShards.html":{"url":"16-reference/02-command/09-nav-sharding/15-listShards.html","title":"listShards","keywords":"","body":" listShards ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listShards Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/16-medianKey.html":{"url":"16-reference/02-command/09-nav-sharding/16-medianKey.html","title":"medianKey","keywords":"","body":" medianKey ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - medianKey Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/17-moveChunk.html":{"url":"16-reference/02-command/09-nav-sharding/17-moveChunk.html","title":"moveChunk","keywords":"","body":" moveChunk ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - moveChunk Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/18-movePrimary.html":{"url":"16-reference/02-command/09-nav-sharding/18-movePrimary.html","title":"movePrimary","keywords":"","body":" movePrimary ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - movePrimary Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/19-mergeChunks.html":{"url":"16-reference/02-command/09-nav-sharding/19-mergeChunks.html","title":"mergeChunks","keywords":"","body":" mergeChunks ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mergeChunks Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/20-refineCollectionShardKey.html":{"url":"16-reference/02-command/09-nav-sharding/20-refineCollectionShardKey.html","title":"refineCollectionShardKey","keywords":"","body":" refineCollectionShardKey ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - refineCollectionShardKey Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/21-removeShard.html":{"url":"16-reference/02-command/09-nav-sharding/21-removeShard.html","title":"removeShard","keywords":"","body":" removeShard ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - removeShard Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/22-removeShardFromZone.html":{"url":"16-reference/02-command/09-nav-sharding/22-removeShardFromZone.html","title":"removeShardFromZone","keywords":"","body":" removeShardFromZone ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - removeShardFromZone Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/23-setShardVersion.html":{"url":"16-reference/02-command/09-nav-sharding/23-setShardVersion.html","title":"setShardVersion","keywords":"","body":" setShardVersion ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setShardVersion Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/24-shardCollection.html":{"url":"16-reference/02-command/09-nav-sharding/24-shardCollection.html","title":"shardCollection","keywords":"","body":" shardCollection ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - shardCollection Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/25-shardingState.html":{"url":"16-reference/02-command/09-nav-sharding/25-shardingState.html","title":"shardingState","keywords":"","body":" shardingState ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - shardingState Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/26-split.html":{"url":"16-reference/02-command/09-nav-sharding/26-split.html","title":"split","keywords":"","body":" split ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - split Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/27-splitChunk.html":{"url":"16-reference/02-command/09-nav-sharding/27-splitChunk.html","title":"splitChunk","keywords":"","body":" splitChunk ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - splitChunk Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/28-splitVector.html":{"url":"16-reference/02-command/09-nav-sharding/28-splitVector.html","title":"splitVector","keywords":"","body":" splitVector ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - splitVector Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/29-unsetSharding.html":{"url":"16-reference/02-command/09-nav-sharding/29-unsetSharding.html","title":"unsetSharding","keywords":"","body":" unsetSharding ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - unsetSharding Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/09-nav-sharding/30-updateZoneKeyRange.html":{"url":"16-reference/02-command/09-nav-sharding/30-updateZoneKeyRange.html","title":"updateZoneKeyRange","keywords":"","body":" updateZoneKeyRange ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - updateZoneKeyRange Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions.html":{"url":"16-reference/02-command/10-nav-sessions.html","title":"Sessions Commands","keywords":"","body":" Sessions Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sessions Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/01-abortTransaction.html":{"url":"16-reference/02-command/10-nav-sessions/01-abortTransaction.html","title":"abortTransaction","keywords":"","body":" abortTransaction ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - abortTransaction Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/02-commitTransaction.html":{"url":"16-reference/02-command/10-nav-sessions/02-commitTransaction.html","title":"commitTransaction","keywords":"","body":" commitTransaction ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - commitTransaction Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/03-endSessions.html":{"url":"16-reference/02-command/10-nav-sessions/03-endSessions.html","title":"endSessions","keywords":"","body":" endSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - endSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/04-killAllSessions.html":{"url":"16-reference/02-command/10-nav-sessions/04-killAllSessions.html","title":"killAllSessions","keywords":"","body":" killAllSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - killAllSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/05-killAllSessionsByPattern.html":{"url":"16-reference/02-command/10-nav-sessions/05-killAllSessionsByPattern.html","title":"killAllSessionsByPattern","keywords":"","body":" killAllSessionsByPattern ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - killAllSessionsByPattern Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/06-killSessions.html":{"url":"16-reference/02-command/10-nav-sessions/06-killSessions.html","title":"killSessions","keywords":"","body":" killSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - killSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/07-refreshSessions.html":{"url":"16-reference/02-command/10-nav-sessions/07-refreshSessions.html","title":"refreshSessions","keywords":"","body":" refreshSessions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - refreshSessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/10-nav-sessions/08-startSession.html":{"url":"16-reference/02-command/10-nav-sessions/08-startSession.html","title":"startSession","keywords":"","body":" startSession ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - startSession Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration.html":{"url":"16-reference/02-command/11-nav-administration.html","title":"Administration Commands","keywords":"","body":" Administration Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Administration Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/01-cloneCollectionAsCapped.html":{"url":"16-reference/02-command/11-nav-administration/01-cloneCollectionAsCapped.html","title":"cloneCollectionAsCapped","keywords":"","body":" cloneCollectionAsCapped ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cloneCollectionAsCapped Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/02-collMod.html":{"url":"16-reference/02-command/11-nav-administration/02-collMod.html","title":"collMod","keywords":"","body":" collMod ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - collMod Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/03-compact.html":{"url":"16-reference/02-command/11-nav-administration/03-compact.html","title":"compact","keywords":"","body":" compact ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - compact Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/04-connPoolSync.html":{"url":"16-reference/02-command/11-nav-administration/04-connPoolSync.html","title":"connPoolSync","keywords":"","body":" connPoolSync ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - connPoolSync Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/05-convertToCapped.html":{"url":"16-reference/02-command/11-nav-administration/05-convertToCapped.html","title":"convertToCapped","keywords":"","body":" convertToCapped ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - convertToCapped Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/06-create.html":{"url":"16-reference/02-command/11-nav-administration/06-create.html","title":"create","keywords":"","body":" create ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - create Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/07-createIndexes.html":{"url":"16-reference/02-command/11-nav-administration/07-createIndexes.html","title":"createIndexes","keywords":"","body":" createIndexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - createIndexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/08-currentOp.html":{"url":"16-reference/02-command/11-nav-administration/08-currentOp.html","title":"currentOp","keywords":"","body":" currentOp ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - currentOp Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/09-drop.html":{"url":"16-reference/02-command/11-nav-administration/09-drop.html","title":"drop","keywords":"","body":" drop ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - drop Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/10-dropDatabase.html":{"url":"16-reference/02-command/11-nav-administration/10-dropDatabase.html","title":"dropDatabase","keywords":"","body":" dropDatabase ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropDatabase Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/11-dropConnections.html":{"url":"16-reference/02-command/11-nav-administration/11-dropConnections.html","title":"dropConnections","keywords":"","body":" dropConnections ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropConnections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/12-dropIndexes.html":{"url":"16-reference/02-command/11-nav-administration/12-dropIndexes.html","title":"dropIndexes","keywords":"","body":" dropIndexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dropIndexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/13-filemd5.html":{"url":"16-reference/02-command/11-nav-administration/13-filemd5.html","title":"filemd5","keywords":"","body":" filemd5 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - filemd5 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/14-fsync.html":{"url":"16-reference/02-command/11-nav-administration/14-fsync.html","title":"fsync","keywords":"","body":" fsync ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - fsync Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/15-fsyncUnlock.html":{"url":"16-reference/02-command/11-nav-administration/15-fsyncUnlock.html","title":"fsyncUnlock","keywords":"","body":" fsyncUnlock ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - fsyncUnlock Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/16-getDefaultRWConcern.html":{"url":"16-reference/02-command/11-nav-administration/16-getDefaultRWConcern.html","title":"getDefaultRWConcern","keywords":"","body":" getDefaultRWConcern ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getDefaultRWConcern Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/17-getParameter.html":{"url":"16-reference/02-command/11-nav-administration/17-getParameter.html","title":"getParameter","keywords":"","body":" getParameter ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getParameter Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/18-killCursors.html":{"url":"16-reference/02-command/11-nav-administration/18-killCursors.html","title":"killCursors","keywords":"","body":" killCursors ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - killCursors Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/19-killOp.html":{"url":"16-reference/02-command/11-nav-administration/19-killOp.html","title":"killOp","keywords":"","body":" killOp ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - killOp Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/20-listCollections.html":{"url":"16-reference/02-command/11-nav-administration/20-listCollections.html","title":"listCollections","keywords":"","body":" listCollections ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listCollections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/21-listDatabases.html":{"url":"16-reference/02-command/11-nav-administration/21-listDatabases.html","title":"listDatabases","keywords":"","body":" listDatabases ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listDatabases Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/22-listIndexes.html":{"url":"16-reference/02-command/11-nav-administration/22-listIndexes.html","title":"listIndexes","keywords":"","body":" listIndexes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listIndexes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/23-logRotate.html":{"url":"16-reference/02-command/11-nav-administration/23-logRotate.html","title":"logRotate","keywords":"","body":" logRotate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - logRotate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/24-reIndex.html":{"url":"16-reference/02-command/11-nav-administration/24-reIndex.html","title":"reIndex","keywords":"","body":" reIndex ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - reIndex Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/25-renameCollection.html":{"url":"16-reference/02-command/11-nav-administration/25-renameCollection.html","title":"renameCollection","keywords":"","body":" renameCollection ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - renameCollection Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/26-setFeatureCompatibilityVersion.html":{"url":"16-reference/02-command/11-nav-administration/26-setFeatureCompatibilityVersion.html","title":"setFeatureCompatibilityVersion","keywords":"","body":" setFeatureCompatibilityVersion ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setFeatureCompatibilityVersion Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/27-setIndexCommitQuorum.html":{"url":"16-reference/02-command/11-nav-administration/27-setIndexCommitQuorum.html","title":"setIndexCommitQuorum","keywords":"","body":" setIndexCommitQuorum ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setIndexCommitQuorum Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/28-setParameter.html":{"url":"16-reference/02-command/11-nav-administration/28-setParameter.html","title":"setParameter","keywords":"","body":" setParameter ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setParameter Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/29-setDefaultRWConcern.html":{"url":"16-reference/02-command/11-nav-administration/29-setDefaultRWConcern.html","title":"setDefaultRWConcern","keywords":"","body":" setDefaultRWConcern ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setDefaultRWConcern Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/11-nav-administration/30-shutdown.html":{"url":"16-reference/02-command/11-nav-administration/30-shutdown.html","title":"shutdown","keywords":"","body":" shutdown ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - shutdown Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic.html":{"url":"16-reference/02-command/12-nav-diagnostic.html","title":"Diagnostic Commands","keywords":"","body":" Diagnostic Commands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Diagnostic Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/01-availableQueryOptions.html":{"url":"16-reference/02-command/12-nav-diagnostic/01-availableQueryOptions.html","title":"availableQueryOptions","keywords":"","body":" availableQueryOptions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - availableQueryOptions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/02-buildInfo.html":{"url":"16-reference/02-command/12-nav-diagnostic/02-buildInfo.html","title":"buildInfo","keywords":"","body":" buildInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - buildInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/03-collStats.html":{"url":"16-reference/02-command/12-nav-diagnostic/03-collStats.html","title":"collStats","keywords":"","body":" collStats ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - collStats Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/04-connPoolStats.html":{"url":"16-reference/02-command/12-nav-diagnostic/04-connPoolStats.html","title":"connPoolStats","keywords":"","body":" connPoolStats ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - connPoolStats Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/05-connectionStatus.html":{"url":"16-reference/02-command/12-nav-diagnostic/05-connectionStatus.html","title":"connectionStatus","keywords":"","body":" connectionStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - connectionStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/06-cursorInfo.html":{"url":"16-reference/02-command/12-nav-diagnostic/06-cursorInfo.html","title":"cursorInfo","keywords":"","body":" cursorInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursorInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/07-dataSize.html":{"url":"16-reference/02-command/12-nav-diagnostic/07-dataSize.html","title":"dataSize","keywords":"","body":" dataSize ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dataSize Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/08-dbHash.html":{"url":"16-reference/02-command/12-nav-diagnostic/08-dbHash.html","title":"dbHash","keywords":"","body":" dbHash ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dbHash Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/09-dbStats.html":{"url":"16-reference/02-command/12-nav-diagnostic/09-dbStats.html","title":"dbStats","keywords":"","body":" dbStats ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - dbStats Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/10-diagLogging.html":{"url":"16-reference/02-command/12-nav-diagnostic/10-diagLogging.html","title":"diagLogging","keywords":"","body":" diagLogging ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - diagLogging Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/11-driverOIDTest.html":{"url":"16-reference/02-command/12-nav-diagnostic/11-driverOIDTest.html","title":"driverOIDTest","keywords":"","body":" driverOIDTest ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - driverOIDTest Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/12-explain.html":{"url":"16-reference/02-command/12-nav-diagnostic/12-explain.html","title":"explain","keywords":"","body":" explain ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - explain Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/13-features.html":{"url":"16-reference/02-command/12-nav-diagnostic/13-features.html","title":"features","keywords":"","body":" features ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - features Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/14-getCmdLineOpts.html":{"url":"16-reference/02-command/12-nav-diagnostic/14-getCmdLineOpts.html","title":"getCmdLineOpts","keywords":"","body":" getCmdLineOpts ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getCmdLineOpts Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/15-getLog.html":{"url":"16-reference/02-command/12-nav-diagnostic/15-getLog.html","title":"getLog","keywords":"","body":" getLog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getLog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/16-hostInfo.html":{"url":"16-reference/02-command/12-nav-diagnostic/16-hostInfo.html","title":"hostInfo","keywords":"","body":" hostInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - hostInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/17-isSelf.html":{"url":"16-reference/02-command/12-nav-diagnostic/17-isSelf.html","title":"isSelf","keywords":"","body":" isSelf ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - isSelf Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/18-listCommands.html":{"url":"16-reference/02-command/12-nav-diagnostic/18-listCommands.html","title":"listCommands","keywords":"","body":" listCommands ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listCommands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/19-lockInfo.html":{"url":"16-reference/02-command/12-nav-diagnostic/19-lockInfo.html","title":"lockInfo","keywords":"","body":" lockInfo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - lockInfo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/20-netstat.html":{"url":"16-reference/02-command/12-nav-diagnostic/20-netstat.html","title":"netstat","keywords":"","body":" netstat ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - netstat Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/21-ping.html":{"url":"16-reference/02-command/12-nav-diagnostic/21-ping.html","title":"ping","keywords":"","body":" ping ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ping Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/22-profile.html":{"url":"16-reference/02-command/12-nav-diagnostic/22-profile.html","title":"profile","keywords":"","body":" profile ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - profile Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/23-serverStatus.html":{"url":"16-reference/02-command/12-nav-diagnostic/23-serverStatus.html","title":"serverStatus","keywords":"","body":" serverStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - serverStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/24-shardConnPoolStats.html":{"url":"16-reference/02-command/12-nav-diagnostic/24-shardConnPoolStats.html","title":"shardConnPoolStats","keywords":"","body":" shardConnPoolStats ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - shardConnPoolStats Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/25-top.html":{"url":"16-reference/02-command/12-nav-diagnostic/25-top.html","title":"top","keywords":"","body":" top ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - top Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/26-validate.html":{"url":"16-reference/02-command/12-nav-diagnostic/26-validate.html","title":"validate","keywords":"","body":" validate ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - validate Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/12-nav-diagnostic/27-whatsmyuri.html":{"url":"16-reference/02-command/12-nav-diagnostic/27-whatsmyuri.html","title":"whatsmyuri","keywords":"","body":" whatsmyuri ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - whatsmyuri Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/13-nav-free-monitoring.html":{"url":"16-reference/02-command/13-nav-free-monitoring.html","title":"免费监控命令","keywords":"","body":" 免费监控命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 getFreeMonitoringStatus 返回空闲监视状态。 setFreeMonitoring 在运行时启用/禁用免费监视。 译者：李冠飞 校对： 参见 原文 - Free Monitoring Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/13-nav-free-monitoring/01-getFreeMonitoringStatus.html":{"url":"16-reference/02-command/13-nav-free-monitoring/01-getFreeMonitoringStatus.html","title":"getFreeMonitoringStatus","keywords":"","body":" getFreeMonitoringStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getFreeMonitoringStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/13-nav-free-monitoring/02-setFreeMonitoring.html":{"url":"16-reference/02-command/13-nav-free-monitoring/02-setFreeMonitoring.html","title":"setFreeMonitoring","keywords":"","body":" setFreeMonitoring ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setFreeMonitoring Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/14-nav-auditing.html":{"url":"16-reference/02-command/14-nav-auditing.html","title":"数据库命令","keywords":"","body":" 数据库命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 logApplicationMessage 将自定义消息发布到审核日志。 译者：李冠飞 校对： 参见 原文 - System Events Auditing Commands Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/14-nav-auditing/01-logApplicationMessage.html":{"url":"16-reference/02-command/14-nav-auditing/01-logApplicationMessage.html","title":"logApplicationMessage","keywords":"","body":" logApplicationMessage ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - logApplicationMessage Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Administration-Commands.html":{"url":"16-reference/02-command/Administration-Commands.html","title":"管理命令","keywords":"","body":" 管理命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 clean 内部名称空间管理命令。 cloneCollection 将集合从远程主机复制到当前主机。 cloneCollectionAsCapped 将未设置上限的集合复制为新的设置上限的集合。 collMod 向集合添加选项或修改视图定义。 compact 对集合进行分片整理并重建索引。 connPoolSync 用于刷新连接池的内部命令。 convertToCapped 将无上限的集合转换为有上限的集合。 create 创建一个集合或视图。 createIndexes 为一个集合构建一个或多个索引。 currentOp 返回一个文档，该文档包含有关数据库实例正在进行的操作的信息。 drop 从数据库中删除指定的集合。 dropDatabase 删除当前数据库。 dropConnections 将外向连接删除到指定的主机列表。 dropIndexes 从集合中删除索引。 filemd5 返回使用GridFS存储的文件的md5哈希值。 fsync 将挂起的写入刷新到存储层，并锁定数据库以允许备份。 fsyncUnlock 解锁一个fsync锁。 getParameter 检索配置选项。 killCursors 杀死集合的指定游标。 killOp 终止操作ID指定的操作。 listCollections 返回当前数据库中的集合列表。 listDatabases 返回列出所有数据库的文档，并返回基本数据库统计信息。 listIndexes 列出集合的所有索引。 logRotate 循环MongoDB日志，以防止单个文件占用过多空间。 reIndex 重建集合上的所有索引。 renameCollection 更改现有集合的名称。 setFeatureCompatibilityVersion 启用或禁用保留向后不兼容的数据的功能。 setParameter 修改配置选项。 shutdown 关闭mongod或mongos进程。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Aggregation-Commands.html":{"url":"16-reference/02-command/Aggregation-Commands.html","title":"聚合命令","keywords":"","body":" 聚合命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 aggregate 使用聚合框架执行聚合任务，例如分组。 count 计算集合或视图中的文档数。 distinct 显示在集合或视图中为指定键找到的不同值。 mapReduce 对大型数据集执行map-reduce聚合。 有关不同方法的详细比较，请参阅“ 聚合命令比较”。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Diagnostic-Commands.html":{"url":"16-reference/02-command/Diagnostic-Commands.html","title":"诊断命令","keywords":"","body":" 诊断命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 availableQueryOptions 内部命令，报告当前MongoDB实例的功能。 buildInfo 显示有关MongoDB构建的统计信息。 collStats 报告指定集合的存储利用率静态信息。 connPoolStats 报告从此MongoDB实例到部署中其他MongoDB实例的传出连接的统计信息。 connectionStatus 报告当前连接的身份验证状态。 cursorInfo 在MongoDB 3.2中已删除。替换为metrics.cursor。 dataSize 返回数据范围的数据大小。供内部使用。 dbHash 返回数据库及其集合的哈希值。 dbStats 报告指定数据库的存储利用率统计信息。 diagLogging 在MongoDB 3.6中已删除。要捕获，重放和分析发送到您的MongoDB部署的命令，请使用mongoreplay。 driverOIDTest 将ObjectId转换为字符串以支持测试的内部命令。 explain 返回有关各种操作执行的信息。 features 报告当前MongoDB实例中可用的功能。 getCmdLineOpts 返回带有MongoDB实例及其解析选项的运行时参数的文档。 getLog 返回最近的日志消息。 hostInfo 返回反映基础主机系统的数据。 isSelf 内部命令支持测试。 listCommands 列出当前mongod实例提供的所有数据库命令。 lockInfo 内部命令，返回有关当前正在保留或挂起的锁的信息。仅适用于 mongod实例。 netstat 报告部署内连接性的内部命令。仅适用于mongos实例。 ping 测试部署内连接性的内部命令。 profile 数据库事件探查器的接口。 serverStatus 返回有关实例范围的资源利用率和状态的集合指标。 shardConnPoolStats 报告mongos连接池上的统计信息，以供客户端针对分片进行操作。 top 返回mongod实例中每个数据库的原始使用情况统计信息。 validate 内部命令，用于扫描集合的数据并为正确性编制索引。 whatsmyuri 返回有关当前客户端信息的内部命令。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Geospatial-Commands.html":{"url":"16-reference/02-command/Geospatial-Commands.html","title":"地理空间命令","keywords":"","body":" 地理空间命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 geoSearch 执行使用MongoDB的haystack索引功能的地理空间查询。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Query-and-Write-Operation-Commands.html":{"url":"16-reference/02-command/Query-and-Write-Operation-Commands.html","title":"查询和写操作命令","keywords":"","body":" 查询和写操作命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 delete 删除一个或多个文档。 find 返回集合或视图中的文档。 findAndModify 返回并修改单个文档。 getLastError 返回上一个操作的成功状态。 getMore 返回当前由游标指向的批处理文档。 insert 插入一个或多个文档。 resetError 不推荐使用。重置上一个错误状态。 update 更新一个或多个文档。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Replication-Commands.html":{"url":"16-reference/02-command/Replication-Commands.html","title":"复制命令","keywords":"","body":" 复制命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 applyOps 应用于内部命令OPLOG条目到当前数据集。 isMaster 显示有关此成员在副本集中的角色的信息，包括它是否为主角色。 replSetAbortPrimaryCatchUp 强制选择的主数据库中止同步（追赶），然后完成到主数据库的过渡。 replSetFreeze 防止当前成员在一段时间内寻求选举为主。 replSetGetConfig 返回副本集的配置对象。 replSetGetStatus 返回报告副本集状态的文档。 replSetInitiate 初始化新的副本集。 replSetMaintenance 启用或禁用维护模式，该模式将辅助节点置于一种RECOVERING状态。 replSetReconfig 将新配置应用于现有副本集。 replSetResizeOplog 动态调整副本集成员的操作日志的大小。仅适用于WiredTiger存储引擎。 replSetStepDown 当前primary下台,成为一个secondary，迫使选举。 replSetSyncFrom 显式覆盖用于选择要复制的成员的默认逻辑。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Role-Management-Commands.html":{"url":"16-reference/02-command/Role-Management-Commands.html","title":"角色管理命令","keywords":"","body":" 角色管理命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 createRole 创建一个角色并指定其特权。 dropRole 删除用户定义的角色。 dropAllRolesFromDatabase 从数据库中删除所有用户定义的角色。 grantPrivilegesToRole 将特权分配给用户定义的角色。 grantRolesToRole 指定角色，用户定义的角色将从这些角色继承特权。 invalidateUserCache 刷新用户信息的内存缓存，包括凭据和角色。 revokePrivilegesFromRole 从用户定义的角色中删除指定的特权。 revokeRolesFromRole 从用户定义的角色中删除指定的继承角色。 rolesInfo 返回指定角色的信息。 updateRole 更新用户定义的角色。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Sessions-Commands.html":{"url":"16-reference/02-command/Sessions-Commands.html","title":"会话命令","keywords":"","body":" 会话命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 指令 描述 abortTransaction 中止事务版本4.0中的新功能。 commitTransaction 提交事务版本4.0中的新功能。 endSessions 在会话超时期限之前终止会话。3.6版的新功能。 killAllSessions 杀死所有会话。3.6版的新功能。 killAllSessionsByPattern 杀死所有与指定模式匹配的会话3.6版的新功能。 killSessions 杀死指定的会话。3.6版的新功能。 refreshSessions 刷新空闲会话。3.6版的新功能。 startSession 开始新的会话。3.6版的新功能。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/Sharding-Commands.html":{"url":"16-reference/02-command/Sharding-Commands.html","title":"分片命令","keywords":"","body":" 分片命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 addShard 添加一个分片到分片集群。 addShardToZone 将分片与zone关联。支持在分片群集中配置zone。 balancerStart 启动平衡器线程。 balancerStatus 返回有关平衡器状态的信息。 balancerStop 停止平衡器线程。 checkShardingIndex 验证分片键索引的内部命令。 clearJumboFlag 清除jumbo数据块的标志。 cleanupOrphaned 删除分片键值超出分片拥有的数据块范围之外的孤立数据。 enableSharding 在特定数据库上启用分片。 flushRouterConfig 强制mongod/ mongos实例更新其缓存的路由元数据。 getShardMap 报告分片群集状态的内部命令。 getShardVersion 返回配置服务器版本的内部命令。 isdbgrid 验证进程是否是mongos。 listShards 返回已配置的分片列表。 medianKey 不推荐使用的内部命令。请参阅splitVector。 moveChunk 在分片之间迁移块的内部命令。 movePrimary 从分片集群中删除分片时，重新分配主分片。 mergeChunks 提供在单个分片上组合块的功能。 removeShard 启动从分片群集中删除分片的进程。 removeShardFromZone 删除分片和zone之间的关联。支持在分片群集中配置zone。 setShardVersion 内部命令，用于设置配置服务器版本。 shardCollection 启用集合的分片功能，从而可以对集合进行分片。 shardingState 报告mongod 是否为分片群集的成员。 split 创建一个新的块。 splitChunk 拆分块的内部命令。而是使用方法sh.splitFind()和sh.splitAt()。 splitVector 确定分割点的内部命令。 unsetSharding 影响MongoDB部署中实例之间的连接的内部命令。 updateZoneKeyRange 添加或删除范围内的分片数据与zone之间的关联。支持在分片群集中配置zone。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/02-command/User-Management-Commands.html":{"url":"16-reference/02-command/User-Management-Commands.html","title":"用户管理命令","keywords":"","body":" 用户管理命令 注意 有关特定命令的详细信息，包括语法和示例，请单击特定命令以转到其参考页面。 名称 描述 createUser 创建一个新用户。 dropAllUsersFromDatabase 删除与数据库关联的所有用户。 dropUser 删除一个用户。 grantRolesToUser 向用户授予角色及其特权。 revokeRolesFromUser 从用户删除角色。 updateUser 更新用户的数据。 usersInfo 返回有关指定用户的信息。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method.html":{"url":"16-reference/03-method.html","title":"mongo Shell 方法","keywords":"","body":" mongo Shell 方法 在本页面 集合 游标 数据库 查询计划缓存 批量写入操作 用户管理 角色管理 复制 分片 Free监控 构造函数 连接 本机 客户端字段级加密 MONGODB 中的 JAVASCRIPT 虽然这些方法使用 JavaScript，但大多数与 MongoDB 的交互都不使用 JavaScript，而是在交互 application 的语言中使用惯用的司机。 注意 有关特定方法(包括语法和示例)的详细信息，请单击特定方法以转到其 reference 页面。 集合 名称 描述 db.collection.aggregate() 提供对聚合管道的访问。 db.collection.bulkWrite() 提供批量写入操作功能。 db.collection.copyTo() 已过时。包装EVAL以在单个 MongoDB 实例中的集合之间复制数据。 db.collection.count() 包装计数以_return 计算集合或视图中的文档数。 db.collection.createIndex() 在集合上构建索引。 db.collection.createIndexes() 在集合上构建一个或多个索引。 db.collection.dataSize() 返回集合的大小。包装collStats输出中的尺寸字段。 db.collection.deleteOne() 删除集合中的单个文档。 db.collection.deleteMany() 删除集合中的多个文档。 db.collection.distinct() 返回具有指定字段的不同值的文档的 array。 db.collection.drop() 从数据库中删除指定的集合。 db.collection.dropIndex() 删除集合上的指定索引。 db.collection.dropIndexes() 删除集合上的所有索引。 db.collection.ensureIndex() 已过时。使用db.collection.createIndex()。 db.collection.explain() 返回有关各种方法的查询执行的信息。 db.collection.find() 对集合或视图执行查询并返回游标 object。 db.collection.findAndModify() 以原子方式修改并返回单个文档。 db.collection.findOne() 执行查询并返回单个文档。 db.collection.findOneAndDelete() 查找单个文档并将其删除。 db.collection.findOneAndReplace() 查找单个文档并替换它。 db.collection.findOneAndUpdate() 查找单个文档并进行更新。 db.collection.getIndexes() 返回描述集合上现有索引的文档的 array。 db.collection.getShardDistribution() 对于分片群集中的集合，db.collection.getShardDistribution()报告块分布的数据。 db.collection.getShardVersion() 分片 cluster 的内部诊断方法。 db.collection.group() 已过时。提供简单的数据聚合 function。通过 key 对集合中的文档进行分组，并处理结果。使用aggregate()进行更复杂的数据聚合。 db.collection.insert() 在集合中创建新文档。 db.collection.insertOne() 在集合中插入新文档。 db.collection.insertMany() 在集合中插入几个新文档。 db.collection.isCapped() 报告集合是否为上限集合。 db.collection.latencyStats() 返回集合的延迟统计信息。 db.collection.mapReduce() 执行 map-reduce 样式数据聚合。 db.collection.reIndex() 重建集合上的所有现有索引。 db.collection.remove() 从集合中删除文档。 db.collection.renameCollection() 更改集合的 name。 db.collection.replaceOne() 替换集合中的单个文档。 db.collection.save() 在insert()和update()周围提供 wrapper 以插入新文档。 db.collection.stats() 报告集合的 state。在collStats周围提供 wrapper。 db.collection.storageSize() 报告集合使用的总大小(以字节为单位)。在collStats输出的storageSize字段周围提供 wrapper。 db.collection.totalIndexSize() 报告集合上索引使用的总大小。在collStats输出的totalIndexSize字段周围提供 wrapper。 db.collection.totalSize() 报告集合的总大小，包括所有文档的大小和集合上的所有索引。 db.collection.update() 修改集合中的文档。 db.collection.updateOne() 修改集合中的单个文档。 db.collection.updateMany() 修改集合中的多个文档。 db.collection.watch() 在集合上建立变更流。 db.collection.validate() 对集合执行诊断操作。 游标 名称 描述 cursor.addOption() 添加特殊的线程协议标志，用于修改查询的行为。 cursor.batchSize() 控制 MongoDB 将在单个网络消息中 return 到 client 的文档数。 cursor.close() 关闭游标并释放相关的服务器资源。 cursor.isClosed() 如果光标关闭，则返回true。 cursor.collation() 指定db.collection.find()返回的游标的排序规则。 cursor.comment() 将 comment 附加到查询以允许日志和 system.profile 集合中的可跟踪性。 cursor.count() 修改光标以_return 结果集中的文档数而不是文档本身。 cursor.explain() 报告游标的查询执行计划。 cursor.forEach() 对游标中的每个文档应用 JavaScript function。 cursor.hasNext() 如果游标有文档并且可以迭代，则返回 true。 cursor.hint() 强制 MongoDB 为查询使用特定索引。 cursor.isExhausted() 如果光标关闭且批处理中没有剩余 object，则返回true。 cursor.itcount() 通过获取和迭代结果集来计算游标 client-side 中的文档总数。 cursor.limit() 约束游标结果集的大小。 cursor.map() 对函数中的每个文档应用 function，并在 array 中收集 return 值。 cursor.max() 指定游标的独占上限索引。用于cursor.hint()。 cursor.maxScan() 指定要扫描的最大项目数;收集扫描的文档，索引扫描的键。 cursor.maxTimeMS() 指定用于处理游标操作的累积 time 限制(以毫秒为单位)。 cursor.min() 指定游标的包含性较低索引范围。用于cursor.hint() cursor.next() 返回游标中的下一个文档。 cursor.noCursorTimeout() 指示服务器在一段时间不活动后自动关闭光标。 cursor.objsLeftInBatch() 返回当前游标批处理中剩余的文档数。 cursor.pretty() 配置光标以 easy-to-read 格式显示结果。 cursor.readConcern() 为find()操作指定阅读关注。 cursor.readPref() 指定阅读偏好到游标以控制 client 如何将查询定向到副本集。 cursor.returnKey() 将光标修改为 return 索引键而不是文档。 cursor.showRecordId() 向光标返回的每个文档添加内部存储引擎 ID 字段。 cursor.size() 应用skip()和limit()方法后，返回游标中文档的计数。 cursor.skip() 返回仅在传递或跳过多个文档后才开始返回结果的游标。 cursor.sort() 返回根据排序规范排序的结果。 cursor.tailable() 将光标标记为 tailable。仅适用于超过上限集合的游标。 cursor.toArray() 返回包含游标返回的所有文档的 array。 数据库 名称 描述 db.adminCommand() 对admin数据库运行命令。 db.aggregate() 运行不需要底层集合的 admin/diagnostic 管道。 db.cloneCollection() 在 MongoDB 实例之间直接复制数据。包裹cloneCollection。 db.cloneDatabase() 将数据库从 remote host 复制到当前 host。包裹克隆。 db.commandHelp() 返回数据库命令的帮助信息。 db.copyDatabase() 将数据库复制到当前 host 上的另一个数据库。包裹COPYDB。 db.createCollection() 创建新集合或视图。常用于创建上限集合。 db.createView() 创建一个视图。 db.currentOp() 报告当前的 in-progress 操作。 db.dropDatabase() 删除当前数据库。 db.eval() 已过时。将 JavaScript function 传递给mongod实例 server-side JavaScript evaluation。 db.fsyncLock() 刷新写入磁盘并锁定数据库以防止写入操作并协助备份操作。包裹FSYNC。 db.fsyncUnlock() 允许在使用db.fsyncLock()锁定的数据库上写入 continue。 db.getCollection() 返回集合或视图 object。用于访问名称在mongo shell 中无效的集合。 db.getCollectionInfos() 返回当前数据库中所有集合和视图的集合信息。 db.getCollectionNames() 列出当前数据库中的所有集合和视图。 db.getLastError() 检查并返回上一次操作的状态。包裹GetLastError 函数。 db.getLastErrorObj() 返回上一个操作的状态文档。包裹GetLastError 函数。 db.getLogComponents() 返回 log 消息详细级别。 db.getMongo() 返回当前连接的Mongo()连接 object。 db.getName() 返回当前数据库的 name。 db.getPrevError() 返回包含自上次错误重置以来的所有错误的状态文档。包裹getPrevError。 db.getProfilingLevel() 返回数据库操作的当前分析 level。 db.getProfilingStatus() 返回反映当前性能分析 level 和性能分析阈值的文档。 db.getReplicationInfo() 返回包含复制统计信息的文档。 db.getSiblingDB() 提供对指定数据库的访问。 db.help() 显示 common db object 方法的说明。 db.hostInfo() 返回一个文档，其中包含有关运行 MongoDB 的系统的信息。包裹Hostinfo 中。 db.isMaster() 返回报告副本集的 state 的文档。 db.killOp() 终止指定的操作。 db.listCommands() 显示 common 数据库命令的列表。 db.logout() 结束经过身份验证的 session。 db.printCollectionStats() 打印每个集合的统计信息。包裹db.collection.stats()。 db.printReplicationInfo() 从主数据库的角度打印副本集状态的报告。 db.printShardingStatus() 打印分片配置和块范围的报告。 db.printSlaveReplicationInfo() 从辅助节点的角度打印副本集状态的报告。 db.repairDatabase() 在当前数据库上运行修复例程。 db.resetError() 重置db.getPrevError()和getPrevError返回的错误消息。 db.runCommand() 运行数据库命令。 db.serverBuildInfo() 返回显示mongod实例的编译参数的文档。包装buildinfo。 db.serverCmdLineOpts() 返回一个文档，其中包含有关用于启动 MongoDB 实例的运行时的信息。包裹getCmdLineOpts。 db.serverStatus() 返回一个文档，该文档提供数据库 process 的 state 的概述。 db.setLogLevel() 设置单个 log 消息详细程度 level。 db.setProfilingLevel() 修改数据库概要分析的当前 level。 db.shutdownServer() 干净安全地关闭当前的mongod或mongos process。 db.stats() 返回报告当前数据库的 state 的文档。 db.version() 返回mongod实例的 version。 查询计划缓存 名称 描述 db.collection.getPlanCache() 返回一个接口，用于访问集合的查询计划缓存 object 和关联的 PlanCache 方法。 PlanCache.clear() 清除集合的所有缓存查询计划。可通过特定集合的计划缓存 object 访问，即：db.collection.getPlanCache().clear()。 PlanCache.clearPlansByQuery() 清除指定查询形状的缓存查询计划。可通过特定集合的计划缓存 object 访问，即：db.collection.getPlanCache().clearPlansByQuery() PlanCache.getPlansByQuery() 显示指定查询形状的缓存查询计划。可通过特定集合的计划缓存 object 访问，即：db.collection.getPlanCache().getPlansByQuery()。 PlanCache.help() 显示集合的查询计划缓存可用的方法。可通过特定集合的计划缓存 object 访问，即：db.collection.getPlanCache().help()。 PlanCache.listQueryShapes() 显示存在缓存查询计划的查询形状。可通过特定集合的计划缓存 object 访问，即：db.collection.getPlanCache().listQueryShapes()。 批量写入操作 名称 描述 db.collection.initializeOrderedBulkOp() 为有序的操作列表初始化Bulk()操作构建器。 db.collection.initializeUnorderedBulkOp() 为无序的操作列表初始化Bulk()操作构建器。 Bulk() 批量运营建设者。 Bulk.execute() 批量执行操作列表。 Bulk.find() 指定更新或删除操作的查询条件。 Bulk.find.arrayFilters() 指定用于确定要为update或updateOne操作更新 array 的哪些元素的过滤器。 Bulk.find.collation() 指定查询条件的整理。 Bulk.find.remove() 将多个文档删除操作添加到操作列表中。 Bulk.find.removeOne() 将单个文档删除操作添加到操作列表。 Bulk.find.replaceOne() 将单个文档替换操作添加到操作列表中。 Bulk.find.updateOne() 将单个文档更新操作添加到操作列表。 Bulk.find.update() 将multi更新操作添加到操作列表中。 Bulk.find.upsert() 为更新操作指定upsert: true。 Bulk.getOperations() 返回Bulk() operations object 中执行的写操作的 array。 Bulk.insert() 将 Insert 操作添加到操作列表中。 Bulk.tojson() 返回一个 JSON 文档，其中包含Bulk() operations object 中的操作数和批处理数。 Bulk.toString() 将Bulk.tojson()结果作为 string 返回。 用户管理 名称 描述 db.auth() 将用户验证到数据库。 db.changeUserPassword() 更改现有用户的密码。 db.createUser() 创建一个新用户。 db.dropUser() 删除单个用户。 db.dropAllUsers() 删除与数据库关联的所有用户。 db.getUser() 返回有关指定用户的信息。 db.getUsers() 返回有关与数据库关联的所有用户的信息。 db.grantRolesToUser() 向用户授予角色及其权限。 db.removeUser() 已过时。从数据库中删除用户。 db.revokeRolesFromUser() 从用户中删除角色。 db.updateUser() 更新用户数据。 角色管理 名称 描述 db.createRole() 创建角色并指定其权限。 db.dropRole() 删除 user-defined 角色。 db.dropAllRoles() 删除与数据库关联的所有 user-defined 角色。 db.getRole() 返回指定角色的信息。 db.getRoles() 返回数据库中所有 user-defined 角色的信息。 db.grantPrivilegesToRole() 为 user-defined 角色分配权限。 db.revokePrivilegesFromRole() 从 user-defined 角色中删除指定的权限。 db.grantRolesToRole() 指定 user-defined 角色从中继承权限的角色。 db.revokeRolesFromRole() 从角色中删除继承的角色。 db.updateRole() 更新 user-defined 角色。 复制 名称 描述 rs.add() 将成员添加到副本集。 rs.addArb() 将仲裁者添加到副本集。 rs.conf() 返回副本集 configuration 文档。 rs.freeze() 阻止当前成员在 time 期间寻求选举。 rs.help() 返回副本集函数的基本帮助文本。 rs.initiate() 初始化新的副本集。 rs.printReplicationInfo() 从主数据库的角度打印副本集状态的报告。 rs.printSlaveReplicationInfo() 从辅助节点的角度打印副本集状态的报告。 rs.reconfig() Re-configures 通过应用新副本集 configuration object 设置副本。 rs.remove() 从副本集中删除成员。 rs.slaveOk() 为当前连接设置slaveOk property。已过时。使用readPref()和Mongo.setReadPref()设置阅读偏好。 rs.status() 返回包含有关副本集的 state 的信息的文档。 rs.stepDown() 导致当前主成为强制选举的辅助。 rs.syncFrom() 设置此副本集成员将同步的成员，覆盖默认同步目标选择逻辑。 分片 名称 描述 sh.addShard() 将碎片添加到分片 cluster。 sh.addShardTag() 在 MongoDB 3.4 中，此方法别名为sh.addShardToZone()。 sh.addShardToZone() 将碎片与 zone 关联。支持在分片群集中配置zones。 sh.addTagRange() 在 MongoDB 3.4 中，此方法别名为sh.updateZoneKeyRange()。 sh.disableBalancing() 禁用分片数据库中单个集合的平衡。不影响分片 cluster 中其他集合的平衡。 sh.enableBalancing() 如果以前使用sh.disableBalancing()禁用，则激活分片收集平衡器 process。 sh.disableAutoSplit() 禁用分片 cluster 的 auto-splitting。 sh.enableAutoSplit() 为分片 cluster 启用 auto-splitting。 sh.enableSharding() 在特定数据库上启用分片。 sh.getBalancerHost() 从 MongoDB 3.4 开始不推荐使用 sh.getBalancerState() 返回 boolean 以报告当前是否启用了平衡器。 sh.removeTagRange() 在 MongoDB 3.4 中，此方法别名为sh.removeRangeFromZone()。 sh.removeRangeFromZone() 删除一系列分片键和 zone 之间的关联。支持在分片群集中配置zones。 sh.help() 返回sh方法的帮助文本。 sh.isBalancerRunning() 返回 boolean 以报告 balancer process 当前是否正在迁移块。 sh.moveChunk() 在分片 cluster中迁移块。 sh.removeShardTag() 在 MongoDB 3.4 中，此方法别名为sh.removeShardFromZone()。 sh.removeShardFromZone() 删除分片和 zone 之间的关联。用于管理zone 分片。 sh.setBalancerState() 启用或禁用在碎片之间迁移块的平衡器。 sh.shardCollection() 为集合启用分片。 sh.splitAt() 使用碎片 key的特定值作为分割点将现有的块分成两个块。 sh.splitFind() 将包含与查询匹配的文档的现有块划分为两个近似相等的块。 sh.startBalancer() 启用平衡器并等待平衡启动。 sh.status() 报告分片 cluster的状态，如db.printShardingStatus()。 sh.stopBalancer() 禁用平衡器并等待任何正在进行的平衡轮完成。 sh.waitForBalancer() 内部。等待平衡器 state 改变。 sh.waitForBalancerOff() 内部。等到平衡器停止运行。 sh.waitForPingChange() 内部。等待从分片 cluster 中的mongos之一更改 ping state。 sh.updateZoneKeyRange() 将一系列分片键与 zone 关联。支持在分片群集中配置zones。 Free监控 名称 描述 db.enableFreeMonitoring() 在运行时启用Free监控。 db.disableFreeMonitoring() 在运行时禁用Free监控。 db.getFreeMonitoringStatus() 返回空闲监视状态。 构造函数 名称 描述 BulkWriteResult() Wrapper 来自Bulk.execute()的结果集。 Date() 创建 date object。默认情况下，创建包含当前 date 的 date object。 ObjectId() 返回ObjectId。 ObjectId.getTimestamp() 返回ObjectId的时间戳部分。 ObjectId.toString() 显示ObjectId的 string 表示。 ObjectId.valueOf() 将 ObjectId 的str属性显示为十六进制 string。 UUID() 将 32-byte 十六进制 string 转换为 UUID BSON 子类型。 WriteResult() Wrapper 来自 write 方法的结果集。 WriteResult.hasWriteError() 返回一个 boolean，指定结果是否包含WriteResult.writeError。 WriteResult.hasWriteConcernError() 返回一个 boolean，指定结果是否包含WriteResult.writeConcernError。 连接 名称 描述 connect() 连接到 MongoDB 实例和该实例上的指定数据库。 Mongo() 创建一个新连接 object。 Mongo.getDB() 返回数据库 object。 Mongo.getReadPrefMode() 返回 MongoDB 连接的当前读取首选项模式。 Mongo.getReadPrefTagSet() 返回 MongoDB 连接的读取首选项标记集。 Mongo.isCausalConsistency() 指示是否在连接 object 上启用了因果一致性。 Mongo.setCausalConsistency() 启用或禁用连接 object 上的因果一致性。 Mongo.setReadPref() 为 MongoDB 连接设置阅读偏好。 Mongo.setSlaveOk() 允许当前连接上的操作从次要成员读取。 Mongo.startSession() 在连接 object 上启动 session。 session session object。 SessionOptions 选项 object 为 session。 本机 名称 描述 cat() 返回指定文件的内容。 cd() 将当前工作目录更改为指定的路径。 copyDbpath() 复制本地DBPATH。供内部使用。 fuzzFile() 供内部使用以支持测试。 getHostName() 返回系统的主机名运行mongo shell。 getMemInfo() 返回报告 shell 使用的 memory 数量的文档。 hostname() 返回系统的主机名运行 shell。 listFiles() 返回给出目录中每个 object 的 name 和大小的文档的 array。 load() 在 shell 中加载并运行 JavaScript 文件。 ls() 返回当前目录中 files 的列表。 md5sumFile() 指定文件的MD5哈希值。 mkdir() 在指定的路径创建目录。 pwd() 返回当前目录。 quit() 退出当前的 shell session。 removeFile() 从本地文件系统中删除指定的文件。 resetDbpath() 删除本地DBPATH。供内部使用。 sleep() 在给定的 time 期间暂停mongo shell。 setVerboseShell() 配置mongo shell 以报告操作时间。 version() 返回mongo shell 实例的当前 version。 _isWindows() 如果 shell 在 Windows 系统上运行，则返回true; false如果是 Unix 或 Linux 系统。 _rand() 返回0和1之间的随机数。 _srand() 供内部使用。 客户端字段级加密 注意 mongo客户端的字段级的加密方法需要与客户端的字段级加密的数据库连接启用。如果当前数据库连接不是在启用客户端字段级加密的情况下启动的，则可以： 使用shell程序中的Mongo()构造函数mongo与所需的客户端字段级加密选项建立连接。该Mongo()方法同时支持Amazon Web Services和本地密钥管理服务（KMS）提供程序以进行客户主密钥（CMK）管理。 要么 使用mongoshell 命令行选项与所需选项建立连接。命令行选项仅支持AWS KMS提供程序进行CMK管理。 名称 描述 getKeyVault() 返回当前MongoDB连接的密钥保险库对象。 KeyVault.createKey() 创建用于客户端字段级加密的数据加密密钥。 KeyVault.deleteKey() 从密钥库中删除指定的数据加密密钥。 KeyVault.getKey() 从密钥库中检索指定的数据加密密钥。 KeyVault.getKeys() 检索密钥库中的所有密钥。 KeyVault.addKeyAlternateName() 将密钥替代名称与指定的数据加密密钥相关联。 KeyVault.removeKeyAlternateName() 从指定的数据加密密钥中删除密钥替代名称。 KeyVault.getKeyByAltName() 检索具有指定键替代名称的键。 getClientEncryption() 返回用于支持字段的显式加密/解密的客户端加密对象。 ClientEncryption.encrypt() 使用指定的数据加密密钥和加密算法对字段进行加密。 ClientEncryption.decrypt() 使用关联的数据加密密钥和加密算法解密字段。 参见 原文 - mongo Shell Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection.html":{"url":"16-reference/03-method/01-js-collection.html","title":"Collection Methods","keywords":"","body":" Collection Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Collection Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/01-db.collection.aggregate.html":{"url":"16-reference/03-method/01-js-collection/01-db.collection.aggregate.html","title":"db.collection.aggregate（）","keywords":"","body":" db.collection.aggregate（） 在本页面 定义 行为 例子 定义 db.collection. aggregate(管道，选项) 计算集合中数据的聚合值或视图。 参数 类型 描述 pipeline array 一系列数据聚合操作或阶段。有关详细信息，请参阅聚合管道运算符。 在 version 2.6 中更改：该方法仍然可以接受管道阶段作为单独的 arguments 而不是 array 中的元素;但是，如果未将pipeline指定为 array，则无法指定options参数。 options document 可选的。 aggregate()传递给aggregate命令的其他选项。 version 2.6 中的新内容：仅当您将pipeline指定为 array 时才可用。 options文档可以包含以下字段和值： 字段 类型 描述 explain boolean 可选的。指定 return 有关管道处理的信息。有关 example，请参见返回有关聚合管道操作的信息。version 2.6 中的新内容。在多文档交易中不可用。 allowDiskUse boolean 可选的。允许写入临时文件。设置为时 true，大多数聚合操作可以将数据写入_tmp目录中的 dbPath子目录，但以下情况除外：$graphLookup]阶段$addToSet该$group阶段中使用的累加器表达式 （从4.2.3、4.0.14、3.6.17版本开始）$push该$group阶段中使用的累加器表达式 （从4.2.3、4.0.14、3.6.17版本开始）有关allowDiskUse的示例，请参见 使用外部排序执行大型排序操作。从MongoDB 4.2开始，事件探查器日志消息和诊断日志消息包括一个usedDisk 指示符，指示是否有任何聚合阶段由于内存限制而将数据写入临时文件。 cursor document 可选的。指定游标的初始批处理大小。 cursor字段的 value 是一个带有batchSize字段的文档。有关语法和 example，请参阅指定初始批量大小。 version 2.6 中的新内容。 maxTimeMS non-negative integer 可选的。指定处理游标操作的 time 限制(以毫秒为单位)。如果没有为 maxTimeMS 指定 value，则操作不会 timeout。 0的 value 显式指定默认的无界行为。 MongoDB 使用与db.killOp()相同的机制终止超出其分配的 time 限制的操作。 MongoDB 仅在其指定的中断点之一处终止操作。 bypassDocumentValidation boolean 可选的。仅在指定$out或$merge]聚合阶段时可用。 在操作期间启用db.collection.aggregate以绕过文档验证。这使您可以插入不符合验证要求的文档。 version 3.2 中的新内容。 readConcern document 可选的。指定读关注。 readConcern 选项具有以下语法：在 version 3.6 中更改。 readConcern: { level: } 可能的阅读关注级别为： “local”。这是 level 的默认读取问题。 “available”。当阅读操作和 Causally Consistent Sessions和“level”未指定时，这是对二级的读取的默认值。查询返回实例的最新数据。 “manority”。适用于使用WiredTiger 存储引擎的副本集。 “linerizable”。仅适用于主的读取操作。 有关读取关注级别的更多信息，请参阅读关注级别。 从MongoDB 4.2开始，该$out阶段不能与读取关注一起使用\"linearizable\"。也就是说，如果您为指定了\"linearizable\"读取关注 db.collection.aggregate()，则不能将$out阶段包括 在管道中。该$merge阶段不能与已关注的内容一起使用\"linearizable\"。也就是说，如果您为指定了 \"linearizable\"读取关注 db.collection.aggregate()，则不能将$merge阶段包括 在管道中。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection()，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 hint string or document 可选的。用于聚合的索引。索引位于初始 collection/view，聚合为 run。 通过索引 name 或索引规范文档指定索引。 注意 hint不适用于$lookup和$graphLookup阶段。 version 3.6 中的新内容。 comment string 可选的。用户可以指定任意 string 以帮助通过数据库探查器，currentOp 和日志跟踪操作。 version 3.6 中的新内容。 writeConcern document 可选的。表示 与or 阶段一起使用的[写关注点](的文档。$out $merge忽略对$outor $merge阶段使用默认的写关注。 返回值： 一个游标通过聚合管道操作的最后阶段产生的文件，或者包括 explain选项，提供了聚合操作的处理细节的文件。如果管道包含$out运算符，则 aggregate()返回一个空游标。请参阅 $out以获取更多信息。 行为 错误处理 如果发生错误，aggregate()帮助程序将抛出 exception。 游标行为 在mongo shell 中，如果从db.collection.aggregate()返回的游标未使用var关键字分配给变量，则mongo shell 会自动迭代光标 20 次。请参阅在 mongo Shell 中迭代一个 Cursor以处理mongo shell 中的游标。 从聚合返回的游标仅支持对已评估的游标(已检索其第一批的，即：游标)进行操作的游标方法，例如以下方法： cursor.hasNext()cursor.next()cursor.toArray()cursor.forEach() cursor.map()cursor.objsLeftInBatch()cursor.itcount()cursor.pretty() 也可以看看 有关更多信息，请参阅聚合管道，聚合参考，聚合管道限制和聚合。 会话 版本4.0中的新功能。 对于在会话内创建的游标，不能在getMore会话外调用 。 同样，对于在会话外部创建的游标，不能在getMore会话内部调用 。 会话空闲超时 从MongoDB 3.6开始，MongoDB驱动程序和mongoshell程序将所有操作与服务器会话相关联，但未确认的写操作除外。对于未与会话明确关联的操作（即使用Mongo.startSession()），MongoDB驱动程序和mongoshell程序会创建一个隐式会话并将其与该操作相关联。 如果会话空闲时间超过30分钟，则MongoDB服务器会将会话标记为已过期，并可以随时关闭它。当MongoDB服务器关闭会话时，它还会终止所有正在进行的操作并打开与该会话关联的游标。这包括配置了30分钟noCursorTimeout或maxTimeMS30分钟以上的光标。 对于返回游标的操作，如果游标可能闲置了30分钟以上，请在显式会话中使用发出操作，Session.startSession()并使用refreshSessions命令定期刷新该会话。请参阅 以获取更多信息。Session Idle Timeout 事务 db.collection.aggregate()可以在多文档事务中使用。 但是，事务中不允许以下阶段： $collStats $currentOp $indexStats $listLocalSessions $listSessions $out $merge $planCacheStats 您也不能指定该explain选项。 对于在事务外部创建的游标，不能getMore在事务内部调用 。 对于在事务中创建的游标，不能getMore在事务外部调用 。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 客户端断开 对于db.collection.aggregate()不包含$out或$merge阶段的操作： 从MongoDB 4.2开始，如果发出db.collection.aggregate()断开连接的客户端在操作完成之前断开连接，则MongoDB将标记db.collection.aggregate()为终止（即在操作上killOp）。 例子 以下示例使用包含以下文档的集合orders： { _id: 1, cust_id: \"abc1\", ord_date: ISODate(\"2012-11-02T17:04:11.102Z\"), status: \"A\", amount: 50 } { _id: 2, cust_id: \"xyz1\", ord_date: ISODate(\"2013-10-01T17:04:11.102Z\"), status: \"A\", amount: 100 } { _id: 3, cust_id: \"xyz1\", ord_date: ISODate(\"2013-10-12T17:04:11.102Z\"), status: \"D\", amount: 25 } { _id: 4, cust_id: \"xyz1\", ord_date: ISODate(\"2013-10-11T17:04:11.102Z\"), status: \"D\", amount: 125 } { _id: 5, cust_id: \"abc1\", ord_date: ISODate(\"2013-11-12T17:04:11.102Z\"), status: \"A\", amount: 25 } 分组和计算总和 以下聚合操作选择状态等于\"A\"的文档，按cust_id字段对匹配文档进行分组，并从amount字段的总和计算每个cust_id字段的total，并按降序 order 中的total字段对结果进行排序： db.orders.aggregate([ { $match: { status: \"A\" } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } }, { $sort: { total: -1 } } ]) 该操作返回带有以下文档的游标： { \"_id\" : \"xyz1\", \"total\" : 100 } { \"_id\" : \"abc1\", \"total\" : 75 } mongo shell 自动迭代返回的光标以打印结果。有关在mongo shell 中手动处理游标的信息，请参阅在 mongo Shell 中迭代一个 Cursor。 返回有关聚合管道操作的信息 以下聚合操作将选项explain设置为true以_return 有关聚合操作的信息。 db.orders.aggregate( [ { $match: { status: \"A\" } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } }, { $sort: { total: -1 } } ], { explain: true } ) 该操作返回带有文档的游标，该文档包含有关聚合管道处理的详细信息。例如，除了其他细节之外，文档可以显示所使用的操作的索引(如果有的话)。 [1]如果orders集合是分片集合，则文档还将显示分片和合并操作之间的分工，以及目标查询，目标分片。 注意 explain输出文档的预期 readers 是人类，而不是机器，输出格式可能会在不同版本之间发生变化。 mongo shell 自动迭代返回的光标以打印结果。有关在mongo shell 中手动处理游标的信息，请参阅在 mongo Shell 中迭代一个 Cursor。 [1]索引过滤器会影响所用索引的选择。有关详细信息，请参见索引过滤器。 使用外部排序执行大型排序操作 聚合管道阶段有最大 memory 使用限制。要处理大型数据集，请将allowDiskUse选项设置为true以启用将数据写入临时 files，如下面的示例所示： var results = db.stocks.aggregate( [ { $project : { cusip: 1, date: 1, price: 1, _id: 0 } }, { $sort : { cusip : 1, date: 1 } } ], { allowDiskUse: true } ) 从MongoDB 4.2开始，事件profiler log massages和diagnostic log massages包括一个usedDisk 指示符，指示是否有任何聚合阶段由于内存限制而将数据写入临时文件。 指定初始批量大小 要指定游标的初始批处理大小，请对cursor选项使用以下语法： cursor: { batchSize: } 对于 example，以下聚合操作指定游标的初始批处理大小0： db.orders.aggregate( [ { $match: { status: \"A\" } }, { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } }, { $sort: { total: -1 } }, { $limit: 2 } ], { cursor: { batchSize: 0 } } ) A batchSize 0表示空的第一批，对于快速返回游标或失败消息而不执行重要的 server-side 工作非常有用。与其他 MongoDB 游标一样，将后续批量大小指定为OP_GET_MORE操作。 mongo shell 自动迭代返回的光标以打印结果。有关在mongo shell 中手动处理游标的信息，请参阅在 mongo Shell 中迭代一个 Cursor。 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下聚合操作包括整理选项： db.myColl.aggregate( [ { $match: { status: \"A\" } }, { $group: { _id: \"$category\", count: { $sum: 1 } } } ], { collation: { locale: \"fr\", strength: 1 } } ); 注意 如果执行涉及多个视图的聚合(例如$lookup或$graphLookup)，则视图必须具有相同的整理。 有关归类字段的说明，请参阅整理文件。 提示索引 version 3.6 中的新内容。 使用以下文档创建集合foodColl： db.foodColl.insert([ { _id: 1, category: \"cake\", type: \"chocolate\", qty: 10 }, { _id: 2, category: \"cake\", type: \"ice cream\", qty: 25 }, { _id: 3, category: \"pie\", type: \"boston cream\", qty: 20 }, { _id: 4, category: \"pie\", type: \"blueberry\", qty: 15 } ]) 创建以下索引： db.foodColl.createIndex( { qty: 1, type: 1 } ); db.foodColl.createIndex( { qty: 1, category: 1 } ); 以下聚合操作包括强制使用指定索引的hint选项： db.foodColl.aggregate( [ { $sort: { qty: 1 }}, { $match: { category: \"cake\", qty: 10 } }, { $sort: { type: -1 } } ], { hint: { qty: 1, category: 1 } } ) 覆盖 readConcern 使用该readConcern选项可以指定操作的读取关注点。 您不能将$out或$merge阶段与阅读关注结合使用\"linearizable\"。也就是说，如果您为指定了\"linearizable\"读取关注 db.collection.aggregate()，则不能在管道中包括任何一个阶段。 对副本集的以下操作指定“ 读取关注点”，\"majority\"以读取已确认已写入大多数节点的数据的最新副本。 注意 要使用“多数”的阅读关注 level，replica sets 必须使用WiredTiger 存储引擎并选举protocol version 1。从 MongoDB 3.6 开始，默认情况下启用对读取问题“多数”的支持。对于 MongoDB 3.6.1 - 3.6.x，您可以禁用读取关注“多数”。有关更多信息，请参阅禁用阅读关注多数。 要确保单个线程可以读取自己的写入，请对副本集的主要使用“多数”读取关注和“多数”写入问题。 要使用“多数”的阅读关注 level，您不能包含$out阶段。 无论阅读关注 level 如何，节点上的最新数据可能无法反映系统中数据的最新 version。 db.restaurants.aggregate( [ { $match: { rating: { $lt: 5 } } } ], { readConcern: { level: \"majority\" } } ) 指定 Comment 名为movies的集合包含格式如下的文档： { \"_id\" : ObjectId(\"599b3b54b8ffff5d1cd323d8\"), \"title\" : \"Jaws\", \"year\" : 1975, \"imdb\" : \"tt0073195\" } 以下聚合操作查找在 1995 年创建的影片，并包含comment选项以在logs，db.system.profile集合和db.currentOp中提供跟踪信息。 db.movies.aggregate( [ { $match: { year : 1995 } } ], { comment : \"match_all_movies_from_1995\" } ).pretty() 在启用了性能分析的系统上，您可以查询system.profile集合以查看所有最近的类似聚合，如下所示： db.system.profile.find( { \"command.aggregate\": \"movies\", \"command.comment\" : \"match_all_movies_from_1995\" } ).sort( { ts : -1 } ).pretty() 这将以下列格式返回一组探查器结果： { \"op\" : \"command\", \"ns\" : \"video.movies\", \"command\" : { \"aggregate\" : \"movies\", \"pipeline\" : [ { \"$match\" : { \"year\" : 1995 } } ], \"comment\" : \"match_all_movies_from_1995\", \"cursor\" : { }, \"$db\" : \"video\" }, ... } 应用程序可以编码 order 中的任意信息，以便更轻松地跟踪或识别系统中的特定操作。例如，application 可能附加 string comment，其中包含 process ID，线程 ID，client 主机名和发出命令的用户。 译者：李冠飞 校对： 参见 原文 - db.collection.aggregate() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/02-db.collection.bulkWrite.html":{"url":"16-reference/03-method/01-js-collection/02-db.collection.bulkWrite.html","title":"db.collection.bulkWrite（）","keywords":"","body":" db.collection.bulkWrite（） 在本页面 定义 行为 例子 定义 db.collection. bulkWrite () version 3.2 中的新内容。 使用 order 执行控件执行多个写操作。 bulkWrite()具有以下语法： db.collection.bulkWrite( [ , , ... ], { writeConcern : , ordered : } ) 参数 类型 描述 operations array bulkWrite()写操作的 array。 有效操作为： insertOne updateOne updateMany deleteOne deleteMany replaceOne 有关每个操作的使用情况，请参阅写操作。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。 ordered boolean 可选的。一个 boolean，指定mongod实例是否应执行有序或无序操作执行。默认为true。 参阅执行操作 返回值： 一个布尔值acknowledged，true好像该操作在运行时带有 写关注点，或者false禁用了写关注点。 每个写入操作的计数。 一个数组，其中包含_id每个成功插入或插入的文档的。 行为 bulkWrite()采用 array 写操作并执行每个操作。默认情况下，操作在 order 中执行。请参阅执行操作以控制写操作执行的 order。 写操作 insertOne 将单个文档插入集合中。 见db.collection.insertOne()。 db.collection.bulkWrite( [ { insertOne : { \"document\" : } } ] ) updateOne 和 updateMany 更改 version 3.6：updateOne和updateMany操作添加了对arrayFilters参数的支持，该参数确定要在 array 字段中修改哪些元素。有关详细信息，请参阅db.collection.updateOne()和db.collection.updateMany()。 已更改 version 3.4：添加对整理的支持。有关详细信息，请参阅db.collection.updateOne()和db.collection.updateMany() updateOne更新集合中与过滤器匹配的单个文档。如果多个文档 match，updateOne将仅更新第一个匹配的文档。见db.collection.updateOne()。 db.collection.bulkWrite( [ { updateOne : { \"filter\" : , \"update\" : , \"upsert\" : , \"collation\": , \"arrayFilters\": [ , ... ] } } ] ) updateMany更新集合中匹配过滤器的所有文档。见db.collection.updateMany()。 db.collection.bulkWrite( [ { updateMany : { \"filter\" : , \"update\" : , \"upsert\" : , \"collation\": , \"arrayFilters\": [ , ... ] } } ] ) 字段 描述 filter 更新的选择标准。提供与 方法中相同的查询选择器db.collection.find()。 update 要执行的更新操作。可以指定：仅包含更新运算符表达式的文档。一个聚合管道 [ , , ... ]，指定要执行的修改。 upsert 可选的。一个布尔值，指示是否执行upsert。默认情况下upsert为false。 arrayFilters 可选的。筛选器文档数组，用于确定要对数组字段进行更新操作要修改的数组元素。 collation 可选的。指定用于操作的排序规则。 hint 可选的。用于支持更新的索引filter。如果指定的索引不存在，则操作错误。4.2.1版中的新功能。 有关详细信息，请参见db.collection.updateOne()和 db.collection.updateMany()。 replaceOne replaceOne替换与过滤器匹配的集合中的单个文档。如果多个文档 match，replaceOne将仅替换第一个匹配的文档。 db.collection.bulkWrite([ { replaceOne : { \"filter\" : , \"replacement\" : , \"upsert\" : } } ] ) 字段 描述 filter 替换操作的选择标准。提供与 方法中相同的 查询选择器db.collection.find()。 replacement 替换文件。该文档不能包含 更新运算符。 upsert 可选的。一个布尔值，指示是否执行upsert。默认情况下upsert为false。 collation 可选的。指定用于操作的排序规则。 hint 可选的。用于支持更新的索引filter。如果指定的索引不存在，则操作错误。4.2.1版中的新功能。 有关详细信息，请参见db.collection.replaceOne()。 deleteOne 和 deleteMany deleteOne删除集合中的一个文件 match 过滤器。如果多个文档 match，deleteOne将仅删除第一个匹配的文档。见db.collection.deleteOne()。 db.collection.bulkWrite([ { deleteOne : { \"filter\" : } } ] ) deleteMany删除集合中匹配过滤器的所有文档。见db.collection.deleteMany()。 db.collection.bulkWrite([ { deleteMany : { \"filter\" : } } ] ) 字段 描述 filter 删除操作的选择标准。提供与 方法中相同的 查询选择器db.collection.find()。 collation 可选的。指定用于操作的排序规则。 有关详细信息，请参见db.collection.deleteOne()和 db.collection.deleteMany()。 _id 字段 如果文档未指定_id字段，则mongod添加_id字段并在插入或插入文档之前为文档指定唯一的ObjectId。大多数驱动程序创建一个 ObjectId 并插入_id字段，但如果驱动程序或 application 没有，mongod将创建并填充_id。 如果文档包含_id字段，则_id value 在集合中必须是唯一的，以避免重复的 key 错误。 更新或替换操作不能指定与原始文档不同的_id value。 执行操作 ordered参数指定bulkWrite()是否将在 order 中执行操作。默认情况下，操作在 order 中执行。 以下 code 表示带有五个操作的bulkWrite()。 db.collection.bulkWrite( [ { insertOne : }, { updateOne : }, { updateMany : }, { replaceOne : }, { deleteOne : }, { deleteMany : } ] ) 在默认的ordered : true state 中，每个操作都将在 order 中执行，从第一个操作insertOne到最后一个操作deleteMany。 如果ordered设置为 false，则mongod可以重新排序操作以增加 performance。 Applications 不应该依赖于 order 操作执行。 以下 code 表示无序bulkWrite()，包含六个操作： db.collection.bulkWrite( [ { insertOne : }, { updateOne : }, { updateMany : }, { replaceOne : }, { deleteOne : }, { deleteMany : } ], { ordered : false } ) 使用ordered : false时，操作结果可能会有所不同。对于 example，deleteOne或deleteMany可能会删除更多或更少的文档，具体取决于insertOne，updateOne，updateMany或replaceOne操作之前或之后的 run。 每个 group 中的操作数不能超过数据库maxWriteBatchSize的 value。从 MongoDB 3.6 开始，这个 value 是100,000。此值显示在isMaster.maxWriteBatchSize字段中。 此限制可防止出现超大错误消息的问题。如果 group 超过此limit，则 client 驱动程序将 group 分成较小的组，其计数小于或等于限制的 value。例如，对于100,000的maxWriteBatchSize value，如果队列包含200,000操作，则驱动程序将创建 2 个组，每个组具有100,000个操作。 注意 使用 high-level API 时，驱动程序仅将 group 分为较小的组。如果直接使用db.runCommand()(对于 example，在编写驱动程序时)，MongoDB 在尝试执行超出限制的写入批处理时会抛出错误。 从 MongoDB 3.6 开始，一旦单个批处理的错误报告变得太大，MongoDB 会将所有剩余的错误消息截断为空的 string。目前，一旦至少有 2 个错误消息，总大小大于1MB，则开始。 尺寸和分组机械是内部性能细节，在将来的版本中可能会有所变化。 在分片集合上执行有序操作列表通常比执行无序列表慢，因为对于有序列表，每个操作必须等待上一个操作完成。 上限收藏 bulkWrite()写操作在上限集合上使用时有限制。 如果update条件增加了要修改的文档的大小，则updateOne和updateMany抛出WriteError。 如果replacement文档的大小比原始文档大，则replaceOne抛出WriteError。 如果在上限集合中使用deleteOne和deleteMany则抛出WriteError。 错误处理 bulkWrite()会在错误上抛出BulkWriteError exception。 排除写关注错误，有序操作在发生错误后停止，而无序操作继续处理队列中任何剩余的写操作。 写入关注错误显示在writeConcernErrors字段中，而所有其他错误显示在writeErrors字段中。如果遇到错误，则显示成功写入操作的数量而不是插入的_id值。有序操作显示遇到的单个错误，而无序操作显示 array 中的每个错误。 事务 db.collection.bulkWrite()可以在多文档事务中使用。 如果在事务中运行，则集合必须已经存在才能进行插入和操作。upsert: true 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 事务里面的错误处理 从MongoDB 4.2开始，如果db.collection.bulkWrite()操作在事务内部遇到错误，则该方法将引发BulkWriteException（与事务外部相同）。 在4.0中，如果bulkWrite操作在事务内部遇到错误，则抛出的错误不会包装为 BulkWriteException。 在事务内部，即使批量写入是无序的，批量写入中的第一个错误也会导致整个批量写入失败并中止事务。 例子 批量写操作 guidebook数据库中的characters集合包含以下文档： { \"_id\" : 1, \"char\" : \"Brisbane\", \"class\" : \"monk\", \"lvl\" : 4 }, { \"_id\" : 2, \"char\" : \"Eldon\", \"class\" : \"alchemist\", \"lvl\" : 3 }, { \"_id\" : 3, \"char\" : \"Meldane\", \"class\" : \"ranger\", \"lvl\" : 3 } 以下bulkWrite()对集合执行多个操作： try { db.characters.bulkWrite([ { insertOne: { \"document\": { \"_id\": 4, \"char\": \"Dithras\", \"class\": \"barbarian\", \"lvl\": 4 } } }, { insertOne: { \"document\": { \"_id\": 5, \"char\": \"Taeln\", \"class\": \"fighter\", \"lvl\": 3 } } }, { updateOne : { \"filter\" : { \"char\" : \"Eldon\" }, \"update\" : { $set : { \"status\" : \"Critical Injury\" } } } }, { deleteOne : { \"filter\" : { \"char\" : \"Brisbane\"} } }, { replaceOne : { \"filter\" : { \"char\" : \"Meldane\" }, \"replacement\" : { \"char\" : \"Tanys\", \"class\" : \"oracle\", \"lvl\": 4 } } } ]); } catch (e) { print(e); } 该操作返回以下内容： { \"acknowledged\" : true, \"deletedCount\" : 1, \"insertedCount\" : 2, \"matchedCount\" : 2, \"upsertedCount\" : 0, \"insertedIds\" : { \"0\" : 4, \"1\" : 5 }, \"upsertedIds\" : { } } 如果集合在执行批量写入之前包含带有\"_id\" : 5\"的文档，则在执行批量写入时，将为第二个 insertOne 抛出以下重复的 key exception： BulkWriteError({ \"writeErrors\" : [ { \"index\" : 1, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: guidebook.characters index: _id_ dup key: { : 5.0 }\", \"op\" : { \"_id\" : 5, \"char\" : \"Taeln\", \"class\" : \"fighter\", \"lvl\" : 3 } } ], \"writeConcernErrors\" : [ ], \"nInserted\" : 1, \"nUpserted\" : 0, \"nMatched\" : 0, \"nModified\" : 0, \"nRemoved\" : 0, \"upserted\" : [ ] }) 由于ordered默认为 true，因此只有第一个操作成功完成。 rest 未执行。 尽管出现错误，使用ordered : false运行bulkWrite()将允许剩余的操作完成。 无序批量写入 guidebook数据库中的characters集合包含以下文档： { \"_id\" : 1, \"char\" : \"Brisbane\", \"class\" : \"monk\", \"lvl\" : 4 }, { \"_id\" : 2, \"char\" : \"Eldon\", \"class\" : \"alchemist\", \"lvl\" : 3 }, { \"_id\" : 3, \"char\" : \"Meldane\", \"class\" : \"ranger\", \"lvl\" : 3 } 以下bulkWrite()对characters集合执行多个unordered操作。请注意，其中一个insertOne阶段具有重复的_id value： try { db.characters.bulkWrite([ { insertOne: { \"document\": { \"_id\": 4, \"char\": \"Dithras\", \"class\": \"barbarian\", \"lvl\": 4 } } }, { insertOne: { \"document\": { \"_id\": 4, \"char\": \"Taeln\", \"class\": \"fighter\", \"lvl\": 3 } } }, { updateOne : { \"filter\" : { \"char\" : \"Eldon\" }, \"update\" : { $set : { \"status\" : \"Critical Injury\" } } } }, { deleteOne : { \"filter\" : { \"char\" : \"Brisbane\"} } }, { replaceOne : { \"filter\" : { \"char\" : \"Meldane\" }, \"replacement\" : { \"char\" : \"Tanys\", \"class\" : \"oracle\", \"lvl\": 4 } } } ], { ordered : false } ); } catch (e) { print(e); } 该操作返回以下内容： BulkWriteError({ \"writeErrors\" : [ { \"index\" : 1, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: guidebook.characters index: _id_ dup key: { : 4.0 }\", \"op\" : { \"_id\" : 4, \"char\" : \"Taeln\", \"class\" : \"fighter\", \"lvl\" : 3 } } ], \"writeConcernErrors\" : [ ], \"nInserted\" : 1, \"nUpserted\" : 0, \"nMatched\" : 2, \"nModified\" : 2, \"nRemoved\" : 1, \"upserted\" : [ ] }) 由于这是unordered操作，因此尽管存在 exception，仍会处理队列中剩余的写入。 批量写与写关注 enemies集合包含以下文档： { \"_id\" : 1, \"char\" : \"goblin\", \"rating\" : 1, \"encounter\" : 0.24 }, { \"_id\" : 2, \"char\" : \"hobgoblin\", \"rating\" : 1.5, \"encounter\" : 0.30 }, { \"_id\" : 3, \"char\" : \"ogre\", \"rating\" : 3, \"encounter\" : 0.2 }, { \"_id\" : 4, \"char\" : \"ogre berserker\" , \"rating\" : 3.5, \"encounter\" : 0.12} 以下bulkWrite()使用100 毫秒写入关注值\"majority\"和超时值为对集合执行多个操作： try { db.enemies.bulkWrite( [ { updateMany : { \"filter\" : { \"rating\" : { $gte : 3} }, \"update\" : { $inc : { \"encounter\" : 0.1 } } }, }, { updateMany : { \"filter\" : { \"rating\" : { $lt : 2} }, \"update\" : { $inc : { \"encounter\" : -0.25 } } }, }, { deleteMany : { \"filter\" : { \"encounter\": { $lt : 0 } } } }, { insertOne : { \"document\" : { \"_id\" :5, \"char\" : \"ogrekin\" , \"rating\" : 2, \"encounter\" : 0.31 } } } ], { writeConcern : { w : \"majority\", wtimeout : 100 } } ); } catch (e) { print(e); } 如果副本集中所有必需节点确认写入操作所需的总 time 大于wtimeout，则在wtimeout期间过后将显示以下writeConcernError。 BulkWriteError({ \"writeErrors\" : [ ], \"writeConcernErrors\" : [ { \"code\" : 64, \"codeName\" : \"WriteConcernFailed\", \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }, { \"code\" : 64, \"codeName\" : \"WriteConcernFailed\", \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }, { \"code\" : 64, \"codeName\" : \"WriteConcernFailed\", \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" } ], \"nInserted\" : 1, \"nUpserted\" : 0, \"nMatched\" : 4, \"nModified\" : 4, \"nRemoved\" : 1, \"upserted\" : [ ] }) 结果集显示执行的操作，因为writeConcernErrors错误不是任何写操作失败的指示。 译者：李冠飞 校对： 参见 原文 - db.collection.bulkWrite() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/03-db.collection.copyTo.html":{"url":"16-reference/03-method/01-js-collection/03-db.collection.copyTo.html","title":"db.collection.copyTo（）","keywords":"","body":" db.collection.copyTo（） 在本页面 定义 行为 例子 定义 db.collection. copyTo(newCollection) 自 version 3.0 以来已弃用。 使用 server-side JavaScript 将collection中的所有文档复制到newCollection。如果newCollection不存在，MongoDB 会创建它。 如果启用了授权，则必须能够访问 order run db.collection.copyTo()中所有资源的所有操作。建议不要提供此类访问权限，但如果您的组织要求用户 run db.collection.copyTo()，请创建一个在anyResource上授予anyAction的角色。不要将此角色分配给任何其他用户。 参数 类型 描述 newCollection string 要将数据写入的集合的 name。 警告 使用 db.collection.copyTo()检查字段类型时，确保操作不会在从 BSON 转换为 JSON 期间从文档中删除类型信息。 db.collection.copyTo()方法在内部使用EVAL命令。因此，db.collection.copyTo()操作采用 global 锁定，阻止所有其他读取和写入操作，直到db.collection.copyTo()完成。 copyTo()返回复制的文档数。如果复制失败，则抛出 exception。 行为 因为copyTo()在内部使用EVAL，所以复制操作将阻止mongod实例上的所有其他操作。 例子 以下操作将source集合中的所有文档复制到target集合中。 db.source.copyTo(target) 译者：李冠飞 校对： 参见 原文 - db.collection.copyTo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/04-db.collection.count.html":{"url":"16-reference/03-method/01-js-collection/04-db.collection.count.html","title":"db.collection.count（）","keywords":"","body":" db.collection.count（） 在本页面 定义 行为 例子 定义 db.collection. count(查询，选项) 返回将_查询集合或视图的find()查询的文档计数。 db.collection.count()方法不执行find()操作，而是计算并返回匹配查询的结果数。 注意 与4.0功能兼容的MongoDB驱动程序弃用各自的游标和收集count()的API，取而代之的是新的API countDocuments()和estimatedDocumentCount()。有关给定驱动程序的特定API名称，请参阅驱动程序文档。 重要 避免使用 db.collection.count() 没有查询谓词的方法，因为如果没有查询谓词，该方法将基于集合的元数据返回结果，这可能会导致近似计数。特别是， 在分片群集上，结果计数将无法正确过滤出孤立的文档。 不正常关机后，计数可能不正确。 有关基于集合元数据的计数，另请参阅 带有count选项的collStats管道阶段。 参数 类型 描述 query document 查询选择标准。 options document 可选的。修改计数的额外选项。 options文档包含以下字段： 领域 类型 描述 limit integer 可选的。要计算的最大文档数。 skip integer 可选的。计数前要跳过的文档数。 hint string or document 可选的。查询的索引 name 提示或规范。 version 2.6 中的新内容。 maxTimeMS integer 可选的。允许查询 run 的最大 time 时间。 readConcern string 可选的。指定阅读关注。默认的 level 是“本地”。 要使用阅读关注的阅读关注 level，replica sets 必须使用WiredTiger 存储引擎并选举protocol version 1。 从 MongoDB 3.6 开始，默认情况下启用对读取关注“多数”的支持。对于 MongoDB 3.6.1 - 3.6.x，您可以禁用读取关注“多数”。有关更多信息，请参阅禁用阅读关注多数。 要确保单个线程可以读取自己的写入，请对副本集的主要使用“多数”读取关注和“多数”写入关注。 要使用“多数”的阅读关注 level，必须指定非空query条件。 version 中的新内容 3.2. collation document 可选的。指定 用于操作的排序规则。归类允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。排序规则选项具有以下语法：collation: { locale: , caseLevel: , caseFirst: , strength: , numericOrdering: , alternate: , maxVariable: , backwards: }指定排序规则时，该locale字段为必填字段；所有其他排序规则字段都是可选的。有关字段的说明，请参见整理文档。如果未指定排序规则，但是集合具有默认排序规则（请参阅参考资料db.createCollection()），则该操作将使用为集合指定的排序规则。如果没有为集合或操作指定排序规则，则MongoDB会将以前版本中使用的简单二进制比较用于字符串比较。您不能为一个操作指定多个排序规则。例如，您不能为每个字段指定不同的排序规则，或者如果对排序执行查找，则不能对查找使用一种排序规则，而对排序使用另一种排序规则。3.4版的新功能。 count()等同于db.collection.find(query).count()。 也可以看看 cursor.count() 行为 Sharded Clusters 在分片 cluster 上，如果孤儿文件存在或块迁移正在进行中，db.collection.count()可能导致计数不准确。 要避免这些情况，请在分片 cluster 上使用db.collection.aggregate()方法： 您可以使用$count阶段来计算文档。对于 example，以下操作计算集合中的文档： db.collection.aggregate([ { $count: \"myCount\" } ]) $count阶段等效于以下$group $project序列： db.collection.aggregate( [ { $group: { _id: null, myCount: { $sum: 1 } } }, { $project: { _id: 0 } } ] ) 要获取匹配查询条件的文档计数，还要包括$match阶段： db.collection.aggregate( [ { $match: }, { $count: \"myCount\" } ] ) 或者，如果使用$group + $project等效： db.collection.aggregate( [ { $match: }, { $count: \"myCount\" } ] ) 也可以看看 $collStats返回基于集合的元数据的近似计数。 索引使用 考虑具有以下索引的集合： { a: 1, b: 1 } 执行计数时，如果出现以下情况，MongoDB 可以仅使用索引返回计数： 查询可以使用索引， 查询只包含索引键的条件，和 查询谓词访问单个连续范围的索引键。 对于 example，以下操作可以仅使用索引_return 计数： db.collection.find( { a: 5, b: 5 } ).count() db.collection.find( { a: { $gt: 5 } } ).count() db.collection.find( { a: 5, b: { $gt: 10 } } ).count() 但是，如果查询可以使用索引但查询谓词不访问单个连续范围的索引键，或者查询还包含索引外部字段的条件，那么除了使用索引之外，MongoDB 还必须读取文档要_return 计数。 db.collection.find( { a: 5, b: { $in: [ 1, 2, 3 ] } } ).count() db.collection.find( { a: { $gt: 5 }, b: 5 } ).count() db.collection.find( { a: 5, b: 5, c: 5 } ).count() 在这种情况下，在初始读取文档期间，MongoDB 将文档分页到 memory，以便后续 calls 相同的计数操作将具有更好的 performance。 意外关机后的准确性 使用有线老虎存储引擎不正常关闭mongod后，count()报告的计数统计信息可能不准确。 漂移量取决于在最后检查站和不干净关闭之间执行的 insert，update 或 delete 操作的数量。检查点通常每 60 秒发生一次。但是，使用 non-default --syncdelay设置运行mongod实例可能会有更多或更少的检查点。 在mongod上的每个集合上运行验证以在不正常关闭后恢复正确的统计信息。 注意 这种精度损失仅适用于不包含查询谓词的count()操作。 例子 计算集合中的所有文档 要计算orders集合中所有文档的数量，请使用以下操作： db.orders.count() 此操作等效于以下内容： db.orders.find().count() 计算匹配查询的所有文档 使用大于new Date('01/01/2012')的字段ord_dt计算orders集合中的文档数： db.orders.count( { ord_dt: { $gt: new Date('01/01/2012') } } ) 该查询等效于以下内容： db.orders.find( { ord_dt: { $gt: new Date('01/01/2012') } } ).count() 译者：李冠飞 校对： 参见 原文 - db.collection.count() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/05-db.collection.countDocuments.html":{"url":"16-reference/03-method/01-js-collection/05-db.collection.countDocuments.html","title":"db.collection.countDocuments（）","keywords":"","body":" db.collection.countDocuments（） 在本页面 定义 行为 例子 定义 db.collection.countDocuments(query, options) 版本4.0.3中的新功能。 参数 类型 描述 query document 查询选择条件。要计算所有文档，请指定一个空文档。另请参阅查询限制。 options document 可选的。影响计数行为的其他选项。 该options文档可以包含以下内容： 字段 类型 描述 limit integer 可选的。要计算的最大文件数。 skip integer 可选的。计数前要跳过的文档数。 hint string or document 可选的。用于查询的索引名称或索引规范。 maxTimeMS integer 可选的。允许计数运行的最长时间。 行为 结构 与db.collection.count()， db.collection.countDocuments()不使用元数据返回计数不同。相反，它会执行文档的聚合以返回准确的计数，即使是在异常关闭后或分片群集中存在孤立的文档之后。 db.collection.countDocuments()包装以下聚合操作并仅返回的值n： db.collection.aggregate([ { $match: }, { $group: { _id: null, n: { $sum: 1 } } } ]) 空或不存在的集合和视图 从版本4.2.1（和版本4.0.13中的4.0系列）开始， db.collection.countDocuments()返回0在一个空的或不存在的集合或视图。 在MongoDB的早期版本中，db.collection.countDocuments()查询空或不存在的集合或视图会报错。 查询限制 您不能在db.collection.countDocuments()中将以下查询运算符用作以下查询表达式的一部分： 限制操作符 替代 $where 使用$expr代替 $near $geoWithin与$center一起使用。即：{ $geoWithin: { $center: [ [ , ], ] } } $nearSphere $geoWithin与$centerSphere一起使用。即：{ $geoWithin: { $centerSphere: [ [ , ], ] } } 事务 db.collection.countDocuments()可以在多文档事务中使用。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档事务的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 客户端断开 从MongoDB 4.2开始，如果发出db.collection.countDocuments()断开连接的客户端 在操作完成之前断开连接，则MongoDB将标记为终止db.collection.countDocuments()（即在操作上killOp）。 例子 计算集合中的所有文档 要计算orders集合中所有文档的数量，请使用以下操作： db.orders.countDocuments({}) 计算与查询匹配的所有文档 计算orders 集合中具有ord_dt大于的字段的文档数：new Date('01/01/2012')： db.orders.countDocuments( { ord_dt: { $gt: new Date('01/01/2012') } }, { limit: 100 } ) 也可以看看 db.collection.estimatedDocumentCount() $group 和 $sum count 带有count选项的collStats pipeline stage。 译者：李冠飞 校对： 参见 原文 - db.collection.countDocuments() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/06-db.collection.estimatedDocumentCount.html":{"url":"16-reference/03-method/01-js-collection/06-db.collection.estimatedDocumentCount.html","title":"db.collection.estimatedDocumentCount（）","keywords":"","body":" db.collection.estimatedDocumentCount（） 在本页面 定义 行为 例子 定义 db.collection.estimatedDocumentCount（options） 版本4.0.3中的新功能。 返回集合或视图中所有文档的计数。该方法包装count命令。 db.collection.estimatedDocumentCount( ) 参数 类型 描述 options document 可选的。影响计数行为的其他选项。 该options文档可以包含以下内容： 字段 类型 描述 maxTimeMS integer 可选的。允许计数运行的最长时间。 行为 结构 db.collection.estimatedDocumentCount()不使用查询过滤器，而是使用元数据返回集合的计数。 分片集群 在分片群集上，结果计数将无法正确过滤出 orphaned document。 不正常关机 不正常关机后，计数可能不正确。 mongod使用Wired Tiger存储引擎不正常关闭后，所报告的计数统计信息 db.collection.estimatedDocumentCount()可能不准确。 偏移量取决于在最后一个checkpoint与异常关闭之间执行的插入，更新或删除操作的数量。检查点通常每60秒出现一次。但是，mongod使用非默认--syncdelay设置运行的实例可能具有或多或少的频繁检查点。 validate在mongod异常关闭后，对上的每个集合运行以恢复正确的统计信息。 客户端断开 从MongoDB 4.2开始，如果发出db.collection.estimatedDocumentCount()断开连接的客户端在操作完成之前断开连接，则MongoDB将标记为终止db.collection.estimatedDocumentCount()（即在操作上killOp）。 例子 以下示例用于 db.collection.estimatedDocumentCount检索orders集合中所有文档的计数： db.orders.estimatedDocumentCount({}) 也可以看看 db.collection.countDocuments() count 带有count选项的collStats pipeline stage。 译者：李冠飞 校对： 参见 原文 - db.collection.estimatedDocumentCount() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/07-db.collection.createIndex.html":{"url":"16-reference/03-method/01-js-collection/07-db.collection.createIndex.html","title":"db.collection.createIndex（）","keywords":"","body":" db.collection.createIndex（） 在本页面 定义 选项 行为 例子 附加信息 定义 db.collection. createIndex(键，选项) 在集合上创建索引。 在 version 3.2 中更改：MongoDB 禁止创建version 0索引。要升级现有的 version 0 索引，请参阅Version 0 索引。 参数 类型 描述 keys document 包含字段和 value 对的文档，其中字段是索引 key，value 描述该字段的索引类型。对于字段的升序索引，请指定的 value;对于降序索引，请指定-1的 value。 MongoDB 支持几种不同的索引类型，包括文本，地理空间和哈希索引。有关更多信息，请参见索引类型。 从 3.6 开始，您不能将*指定为索引 name。MongoDB支持几种不同的索引类型，包括 text，geospatial和hashed索引。有关 更多信息，请参见索引类型。在版本4.2中进行了更改： MongoDB 4.2 通配符索引 支持工作负载，用户可以在其中查询自定义字段或集合中各种字段：要在文档中的所有字段和子字段上创建通配符索引，请指定为索引键。创建通配符索引时，不能指定降序索引键。{ \"$**\" : 1 }，您还可以使用可选参数在索引中包括或排除特定字段及其子字段 wildcardProjection。_id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它：{ “ wildcardProjection”：{ “ _id”：1 “ ”：0 &124; 1 } }除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。您可以在特定字段及其子路径上创建通配符索引，方法是将该字段的完整路径指定为索引键并附\"$**\"加到该路径：{ \"path.to.field.$**\" : 1 }特定于路径的通配符索引语法与该wildcardProjection选项不兼容 。您不能在指定的路径上指定其他包含或排除。通配符索引键必须使用上面列出的语法之一。例如，您不能指定 复合索引键。有关通配符索引的更完整文档（包括对其创建的限制），请参阅通配符索引限制。该featureCompatibilityVersion必须创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.2部署上设置功能兼容版本。mongod 4.2 options document 可选的。包含一组控制索引创建的选项的文档。有关详细信息，请参阅选项。 db.collection.createIndex()是createIndexes命令周围的 wrapper。 要最小化 building 索引对复制集和分片群集的影响，请使用在复制集上建立索引中所述的滚动索引 build 过程。 选项 options文档包含一组控制索引创建的选项。不同的索引类型可以具有特定于该类型的附加选项。 更改了 version 3.4：添加了对整理选项的支持。 所有索引类型的选项 除非另有说明，否则以下选项适用于所有索引类型： 更改 version 3.0：dropDups选项不再可用。 参数 类型 描述 background boolean 可选的。在MongoDB 4.2中已弃用。对于功能兼容版本（fcv）\"4.0\"，指定可指示MongoDB在后台构建索引。后台构建 不会阻止对集合的操作。默认值为 。background: true/false在版本4.2中进行了更改。对于功能兼容版本（fcv）\"4.2\"，所有索引构建都使用优化的 构建过程，该过程仅在构建过程的开始和结束时才持有排他锁。其余的构建过程将产生交错的读写操作。background如果指定，MongoDB将忽略该选项。 unique boolean 可选的。创建唯一索引，以便集合不接受索引 key value 与索引中现有 value 匹配的文档的插入或更新。 指定true以创建唯一索引。默认的 value 是false。 该选项不适用于哈希索引。 name String 可选的。索引的 name。如果未指定，MongoDB 通过连接索引字段和 sort order 的名称来生成索引 name。 从4.2版开始，对于featureCompatibilityVersion设置为\"4.2\"或更大的版本，MongoDB删除了 最大127个字节的限制。在早期版本或将featureCompatibilityVersion（fCV）设置为MongoDB的版本 中 ，索引名称必须位于内 。Index Name Length \"4.0\" limit partialFilterExpression document 可选的。如果指定，则索引仅 references 与匹配过滤器表达式的文档。有关更多信息，请参见部分索引。 过滤器表达式可以包括：等式表达式(即：field: value或使用$eq operator)， $exists：true表达式， $gt，$gte，$lt，$lte表达式， $type表达式， $and operator 仅 top-level 您可以指定所有 MongoDB 索引类型的partialFilterExpression选项。 version 3.2 中的新内容。 sparse boolean 可选的。如果true，则索引仅使用指定字段 references 文档。这些索引使用较少的空间，但在某些情况下(特别是排序)表现不同。默认的 value 是false。有关更多信息，请参见稀疏索引。 在 version 3.2 中更改：从 MongoDB 3.2 开始，MongoDB 提供了创建部分索引的选项。部分索引提供了稀疏索引功能的超集。如果您使用 MongoDB 3.2 或更高版本，则部分索引应优先于稀疏索引。 version 2.6 中更改：2 dsphere索引默认为稀疏，并忽略此选项。对于包含2dsphere index key(s)的复合索引以及其他类型的键，只有2dsphere索引字段确定索引是否引用文档。 2 d，geoHaystack和文本索引的行为与2 dsphere索引类似。 expireAfterSeconds integer 可选的。将 value(以秒为单位)指定为TTL，以控制 long MongoDB 如何保留此集合中的文档。有关此功能的更多信息，请参见通过设置 TTL 使集合中的数据过期。这仅适用于TTL索引。 storageEngine document 可选的。允许用户在_创建索引时以 per-index 为基础配置存储引擎。 storageEngine选项应采用以下形式： storageEngine: { : } 在验证 creating 索引时指定的存储引擎 configuration 选项，并在复制期间记录到OPLOG以支持具有使用不同存储引擎的成员的副本_set。 version 3.0 中的新内容。 整理选项 version 3.4 中的新内容。 警告 MongoDB 3.2 和早期版本不支持排序规则。在 MongoDB 3.2 及更早版本中，不要使用不受支持的排序规则选项创建索引，因为这会阻止升级到 3.4，这将强制执行更严格的索引选项验证。 参数 类型 描述 collation document 可选的。指定索引的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 如果已在集合 level 中指定了排序规则，则：如果在创建索引时未指定排序规则，MongoDB 将使用集合的默认排序规则创建索引。 如果在创建索引时指定了排序规则，MongoDB 将使用指定的排序规则创建索引。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 version 3.4 中的新内容。 以下索引仅支持简单的二进制比较，不支持整理： 文本索引， 2 d索引和 geoHaystack索引。 建议 要在具有 non-simple 归类的集合上创建text，2d或geoHaystack索引，必须在创建索引时显式指定{collation: {locale: \"simple\"} }。 整理和索引使用 如果已在集合 level 中指定了排序规则，则： 如果在创建索引时未指定排序规则，MongoDB 将使用集合的默认排序规则创建索引。 如果在创建索引时指定了排序规则，MongoDB 将使用指定的排序规则创建索引。 建议 通过指定1或2的归类strength，可以创建不区分大小写的索引。排序规则strength的索引是 1的不区分字母也不区分大小写。 与其他索引选项不同，您可以使用不同的排序规则在同一 key(s) 上创建多个索引。要使用相同的 key pattern 但不同的排序规则创建索引，必须提供唯一的索引名称。 要使用索引进行 string 比较，操作还必须指定相同的排序规则。也就是说，如果操作指定了不同的排序规则，则具有排序规则的索引不能支持对索引字段执行 string 比较的操作。 对于 example，集合myColl在 string 字段category上有一个索引，其中包含整理 locale \"fr\"。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 以下查询操作(指定与索引相同的排序规则)可以使用索引： db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作(默认情况下使用“简单”二进制文件夹)无法使用索引： db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是 strings，数组和嵌入文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 对于 example，集合myColl在数字字段score和price以及 string 字段category上具有复合索引;使用用于 string 比较的排序规则 locale \"fr\"创建索引： db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 以下操作(使用\"simple\"二进制排序规则进行 string 比较)可以使用索引： db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 以下操作在索引的category字段上使用\"simple\"二进制排序规则进行 string 比较，可以使用索引仅满足查询的score: 5部分： db.myColl.find( { score: 5, category: \"cafe\" } ) 文本索引的选项 以下选项仅适用于文本索引： 参数 类型 描述 weights document 可选的。对于文本索引，包含字段和权重对的文档。权重是 1 到 99,999 之间的整数，并且表示该字段相对于其他索引字段在分数方面的重要性。您可以为部分或全部索引字段指定权重。请参阅使用权重控制搜索结果以调整分数。默认的 value 是1。 default_language String 可选的。对于文本索引，确定停用词列表的语言以及词干分析器和标记生成器的规则。有关可用语言，请参阅文本搜索语言;有关详细信息和示例，请参阅指定文本索引的语言。默认的 value 是english。 language_override String 可选的。对于文本索引，集合文档中字段的 name 包含文档的覆盖语言。默认的 value 是language。有关 example，请参阅使用任何字段指定文档的语言。 textIndexVersion integer 可选的。 text索引 version number。用户可以使用此选项覆盖默认的 version number。 有关可用版本，请参阅版本。 version 2.6 中的新内容。 2dsphere 索引的选项 以下选项仅适用于2 dsphere索引： 参数 类型 描述 2dsphereIndexVersion integer 可选的。 2dsphere索引 version number。用户可以使用此选项覆盖默认的 version number。 有关可用版本，请参阅版本。 version 2.6 中的新内容。 2d 索引的选项 以下选项仅适用于2 d索引： 参数 类型 描述 bits integer 可选的。对于2 d索引，存储位置数据的地理散列 value 的精度数。 bits value 的范围是 1 到 32(含)。默认的 value 是26。 min number 可选的。对于2 d索引，经度和纬度值的下包含边界。默认的 value 是-180.0。 max number 可选的。对于2 d索引，经度和纬度值的上包含边界。默认的 value 是180.0。 geoHaystack 索引的选项 以下选项仅适用于geoHaystack索引： 参数 类型 描述 bucketSize number 对于geoHaystack索引，请指定要对位置值进行分组的单位数; 即： group 在同一个存储桶中的那些位置值在指定的单位数内。 value 必须大于 0。 wildcard索引的选项 以下选项仅适用于 通配符索引： 参数 类型 描述 wildcardProjection document 可选的。允许用户使用 键模式在通配符索引中包括或排除特定字段路径。仅当在所有文档字段上创建通配符索引时，此选项才有效。如果在特定字段路径及其子字段上创建通配符索引，则无法指定此选项，例如 { \"$**\" : 1} { \"path.to.field.$**\" : 1 }该wildcardProjection选项采用以下形式：wildcardProjection: { \"path.to.field.a\" : , \"path.to.field.b\" : }该可以是以下几点：1. 1或true将该字段包括在通配符索引中。2. 0或false从通配符索引中排除该字段。_id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它：{ \"wildcardProjection\" : { \"_id\" : 1, \"\" : 01}}除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。 行为 并发 在版本4.2中进行了更改。 对于featureCompatibilityVersion \"4.2\"，db.collection.createIndex()使用优化的构建过程，该过程在索引构建的开始和结束时获取并持有对指定集合的排他锁。集合上的所有后续操作必须等到db.collection.createIndex()释放排他锁。db.collection.createIndex()允许在大多数索引构建期间交错进行读写操作。 对于featureCompatibilityVersion \"4.0\"，db.collection.createIndex()使用4.2之前的索引构建过程，默认情况下会在构建过程的整个过程中获取父数据库的互斥锁。4.2之前的构建过程将阻止对数据库及其所有集合的所有操作，直到操作完成。background索引不使用排他锁。 有关的锁定行为的更多信息db.collection.createIndex()，请参见 填充集合的索引构建。 重塑现有的索引 如果您要求db.collection.createIndex()已经存在的索引，则MongoDB不会重新创建该索引。 指数设置 非归类选项 除排序规则选项外，如果您创建具有一组索引选项的索引，然后尝试重新创建相同的索引但具有不同的索引选项，则MongoDB不会更改选项，也不会重新创建索引。 要更改这些索引选项，请db.collection.dropIndex()在db.collection.createIndex()使用新选项运行之前 删除现有索引 。 排序规则选项 与其他索引选项不同，您可以在具有不同排序规则的同一键上创建多个索引。要创建具有相同键模式但排序规则不同的索引，必须提供唯一的索引名称。 索引键长度限制 对于将featureCompatibilityVersion（fCV）设置为\"4.0\"或更早版本的MongoDB 2.6至MongoDB版本， 如果现有文档的索引条目超过，则MongoDB 不会在集合上创建索引。Maximum Index Key Length 例子 在单个字段上创建升序索引 以下 example 在字段orderDate上创建升序索引。 db.collection.createIndex( { orderDate: 1 } ) 如果keys文档指定了多个字段，则createIndex()创建复合指数。 在多个字段上创建索引 以下 example 在orderDate字段(在升序 order 中)和zipcode字段(在降序 order.)中)创建复合索引 db.collection.createIndex( { orderDate: 1, zipcode: -1 } ) 复合索引不能包含哈希指数 component。 注意 索引的 order 对于使用索引支持sort()操作很重要。 使用指定的排序规则创建索引 version 3.4 中的新内容。 以下 example 创建名为category_fr的索引。 example 使用整理创建索引，指定 locale fr和比较强度2： db.collection.createIndex( { category: 1 }, { name: \"category_fr\", collation: { locale: \"fr\", strength: 2 } } ) 以下 example 使用整理创建名为date_category_fr的复合索引。排序规则仅适用于具有 string 值的索引键。 db.collection.createIndex( { orderDate: 1, category: 1 }, { name: \"date_category_fr\", collation: { locale: \"fr\", strength: 2 } } ) 排序规则适用于值为 string 的索引键。 对于使用相同排序规则的索引键的查询或排序操作，MongoDB 可以使用索引。有关详细信息，请参阅整理和索引使用。 创建一个通配符指数 4.2版中的新功能。 mongodfeatureCompatibilityVersion必须4.2创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.2部署上设置功能兼容版本。 _id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它： { \"wildcardProjection\" : { \"_id\" : 1, \"\" : 0|1 } } 除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。 通配符索引不支持以下索引类型或属性： Compound TTL Text 2d (Geospatial) 2dsphere (Geospatial) Hashed Unique 注意 通配符索引与通配符文本索引不同并且不兼容 。通配符索引不能支持使用$text运算符的查询。 有关通配符索引限制的完整文档，请参见 通配符索引限制。 有关通配符索引的完整文档，请参见 通配符索引。 以下列出了创建通配符索引的示例： 在单个字段路径上创建通配符索引 在所有字段路径上创建通配符索引 在通配符索引覆盖率中包括特定字段 从通配符索引覆盖率中忽略特定字段 在单个字段路径上创建通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作在product_attributes字段上创建通配符索引 ： use inventory db.products_catalog.createIndex( { \"product_attributes.$**\" : 1 } ) 使用此通配符索引，MongoDB索引的所有标量值 product_attributes。如果字段是嵌套的文档或数组，则通配符索引将递归到文档/数组中，并为文档/数组中的所有标量字段建立索引。 通配符索引可以支持product_attributes对其嵌套字段之一或其嵌套字段进行任意单字段查询 ： db.products_catalog.find( { \"product_attributes.superFlight\" : true } ) db.products_catalog.find( { \"product_attributes.maxSpeed\" : { $gt : 20 } } ) db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"water\" } } ) 注意 特定于路径的通配符索引语法与该wildcardProjection选项不兼容 。有关更多信息，请参见参数文档。 在所有字段路径上创建通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作在所有标量字段（不包括_id字段）上创建通配符索引： use inventory db.products_catalog.createIndex( { \"$**\" : 1 } ) 使用此通配符索引，MongoDB可以索引集合中每个文档的所有标量字段。如果给定字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并为文档/数组中的所有标量字段建立索引。 创建的索引可以支持对集合中文档中任意字段的查询： db.products_catalog.find( { \"product_price\" : { $lt : 25 } } ) db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"water\" } } ) 注意 _id默认情况下，通配符索引会忽略该字段。要将_id字段包括 在通配符索引中，必须在wildcardProjection文档中明确包含它。有关更多信息，请参见参数文档。 在通配符索引覆盖率中包括特定字段 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作将创建一个通配符索引，并使用该wildcardProjection选项在索引中仅包含product_attributes.elements和product_attributes.resistance 字段的标量值 。 use inventory db.products_catalog.createIndex( { \"$**\" : 1 }, { \"wildcardProjection\" : { \"product_attributes.elements\" : 1, \"product_attributes.resistance\" : 1 } } ) 尽管键模式\"$**\"涵盖了文档中的所有字段，但该 wildcardProjection字段将索引限制为仅包含的字段。有关的完整文档wildcardProjection，请参阅 通配符索引的选项。 如果字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并索引文档/数组中的所有标量字段。 创建的索引可以支持对以下内容中包含的任何标量字段的查询wildcardProjection： db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"Water\" } } ) db.products_catalog.find( { \"product_attributes.resistance\" : \"Bludgeoning\" } ) 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关更多信息 wildcardProjection，请参见参数文档。 从通配符索引覆盖率中忽略特定字段 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作创建一个通配符指数，并使用wildcardProjection文件索引的所有标量场的每个文档的集合中，排除了 product_attributes.elements和product_attributes.resistance 字段： use inventory db.products_catalog.createIndex( { \"$**\" : 1 }, { \"wildcardProjection\" : { \"product_attributes.elements\" : 0, \"product_attributes.resistance\" : 0 } } ) 尽管键模式\"$**\"涵盖了文档中的所有字段，但 wildcardProjection该字段从索引中排除了指定的字段。有关的完整文档wildcardProjection，请参阅 通配符索引的选项。 如果字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并索引文档/数组中的所有标量字段。 创建的索引可以支持对任何标量字段的查询，但 以下项除外wildcardProjection： db.products_catalog.find( { \"product_attributes.maxSpeed\" : { $gt: 25 } } ) db.products_catalog.find( { \"product_attributes.superStrength\" : true } ) 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关更多信息 wildcardProjection，请参见参数文档。 附加信息 本手册的索引部分用于 MongoDB 中索引和索引的完整文档。 db.collection.getIndexes()查看集合的现有索引的规范。 文字索引有关 creating text索引的详细信息。 地理空间索引和geoHaystack 索引用于地理空间查询。 TTL 指数表示数据到期。 译者：李冠飞 校对： 参见 原文 - db.collection.createIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/08-db.collection.createIndexes.html":{"url":"16-reference/03-method/01-js-collection/08-db.collection.createIndexes.html","title":"db.collection.createIndexes（）","keywords":"","body":" db.collection.createIndexes（） 在本页面 定义 选项 行为 例子 附加信息 定义 db.collection. createIndexes([*keyPatterns,]options) version 3.2 中的新内容。 在集合上创建一个或多个索引。 参数 类型 描述 keyPatterns document 包含字段和 value 对的文档，其中字段是索引 key，value 描述该字段的索引类型。对于字段的升序索引，请指定的 value;对于降序索引，请指定-1的 value。 MongoDB 支持几种不同的索引类型，包括文本，地理空间和哈希索引。有关更多信息，请参见索引类型。 从 3.6 开始，您不能将*指定为索引 name。MongoDB支持几种不同的索引类型，包括 text，geospatial和hashed索引。有关 更多信息，请参见索引类型。在版本4.2中进行了更改： MongoDB 4.2 通配符索引 支持工作负载，用户可以在其中查询自定义字段或集合中各种字段：要在文档中的所有字段和子字段上创建通配符索引，请指定为索引键。创建通配符索引时，不能指定降序索引键。{ \"$**\" : 1 }，您还可以使用可选参数在索引中包括或排除特定字段及其子字段 wildcardProjection。_id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它：{ “ wildcardProjection”：{ “ _id”：1 “ ”：0 &124; 1 } }除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。您可以在特定字段及其子路径上创建通配符索引，方法是将该字段的完整路径指定为索引键并附\"$**\"加到该路径：{ \"path.to.field.$**\" : 1 }特定于路径的通配符索引语法与该wildcardProjection选项不兼容 。您不能在指定的路径上指定其他包含或排除。通配符索引键必须使用上面列出的语法之一。例如，您不能指定 复合索引键。有关通配符索引的更完整文档（包括对其创建的限制），请参阅通配符索引限制。该featureCompatibilityVersion必须创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.2部署上设置功能兼容版本。mongod 4.2 options document 可选的。包含一组控制索引创建的选项的文档。有关详细信息，请参阅选项。 db.collection.createIndexes()是createIndexes命令周围的 wrapper。 要最小化 building 索引对副本_set 和分片群集的影响，请使用在副本_Set 上建立索引中所述的滚动索引 build 过程。 选项 options文档包含一组控制索引创建的选项。不同的索引类型可以具有特定于该类型的附加选项。 重要 为 db.collection.createIndexes()指定选项时，这些选项适用于所有指定的索引。对于 example，如果指定了排序规则选项，则所有创建的索引都将包含该排序规则。 如果尝试使用不兼容的选项创建索引，db.collection.createIndexes()将_return 错误。有关更多信息，请参阅选项说明。 更改了 version 3.4：添加了对整理的支持。 所有索引类型的选项 除非另有说明，否则以下选项适用于所有索引类型： 更改 version 3.0：dropDups选项不再可用。 参数 类型 描述 background boolean 可选的。在后台构建索引，以便操作不会阻止其他数据库活动。在后台指定true到 build。默认的 value 是false。 unique boolean 可选的。指定keyPatterns array 中指定的每个索引都是独特的指数。唯一索引不接受索引 key value 与索引中现有 value 匹配的文档的插入或更新。 指定true以创建唯一索引。默认的 value 是false。 该选项不适用于哈希索引。 name string 可选的。索引的 name。如果未指定，MongoDB 通过连接索引字段和 sort order 的名称来生成索引 name。 无论是用户指定还是生成 MongoDB，索引名称(包括其完整命名空间(即：database.collection))都不能超过索引名称限制。 为db.collection.createIndexes指定的选项适用于 key pattern array 中包含的所有索引规范。由于索引名称必须是唯一的，因此如果使用db.collection.createIndexes创建单个索引，则只能指定 name。 partialFilterExpression document 可选的。如果指定，则仅索引 reference 文档匹配过滤器表达式。有关更多信息，请参见部分索引。 过滤器表达式可以包括：等式表达式(即.field: value或使用$eq operator)， $exists：true表达式， $gt，$gte，$lt，$lte表达式， $type表达式， $and operator 仅 top-level 您可以指定所有 MongoDB 索引类型的partialFilterExpression选项。 version 3.2 中的新内容。 sparse boolean 可选的。如果是true，索引只有 reference 文件带有指定的字段。这些索引使用较少的空间，但在某些情况下(特别是排序)表现不同。默认的 value 是false。有关更多信息，请参见稀疏索引。 在 version 3.2 中更改：从 MongoDB 3.2 开始，MongoDB 提供了创建部分索引的选项。部分索引提供了稀疏索引功能的超集。如果您使用 MongoDB 3.2 或更高版本，则部分索引应优先于稀疏索引。 version 2.6 中更改：2 dsphere索引默认为稀疏，并忽略此选项。对于包含2dsphere index key(s)的复合索引以及其他类型的键，只有2dsphere索引字段确定索引是否引用文档。 2 d，geoHaystack和文本索引的行为与2 dsphere索引类似。 expireAfterSeconds integer 可选的。将 value(以秒为单位)指定为TTL，以控制 long MongoDB 如何保留此集合中的文档。有关此功能的更多信息，请参见通过设置 TTL 使集合中的数据过期。这仅适用于TTL索引。 storageEngine document 可选的。允许用户为创建的索引配置存储引擎。 storageEngine选项应采用以下形式： storageEngine: { : } 在验证 creating 索引时指定的存储引擎 configuration 选项，并在复制期间记录到OPLOG以支持具有使用不同存储引擎的成员的副本_set。 version 3.0 中的新内容。 整理选项 参数 类型 描述 collation document 可选的。指定索引的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 如果已在集合 level 中指定了排序规则，则：如果在创建索引时未指定排序规则，MongoDB 将使用集合的默认排序规则创建索引。 如果在创建索引时指定了排序规则，MongoDB 将使用指定的排序规则创建索引。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 version 3.4 中的新内容。 以下索引仅支持简单的二进制比较，不支持整理： 文本索引， 2 d索引和 geoHaystack索引。 建议 要在具有 non-simple 归类的集合上创建text，2d或geoHaystack索引，必须在创建索引时显式指定{collation: {locale: \"simple\"} }。 整理和索引使用 如果已在集合 level 中指定了排序规则，则： 如果在创建索引时未指定排序规则，MongoDB 将使用集合的默认排序规则创建索引。 如果在创建索引时指定了排序规则，MongoDB 将使用指定的排序规则创建索引。 建议 通过指定1或2的归类strength，可以创建 case-insensitive 索引。 1的整理strength的索引是变音符号和 case-insensitive。 与其他索引选项不同，您可以使用不同的排序规则在同一 key(s) 上创建多个索引。要使用相同的 key pattern 但不同的排序规则创建索引，必须提供唯一的索引名称。 要使用索引进行 string 比较，操作还必须指定相同的排序规则。也就是说，如果操作指定了不同的排序规则，则具有排序规则的索引不能支持对索引字段执行 string 比较的操作。 对于 example，集合myColl在 string 字段category上有一个索引，其中包含整理 locale \"fr\"。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 以下查询操作(指定与索引相同的排序规则)可以使用索引： db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作(默认情况下使用“简单”二进制文件夹)无法使用索引： db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是 strings，数组和嵌入文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 对于 example，集合myColl在数字字段score和price以及 string 字段category上具有复合索引;使用用于 string 比较的排序规则 locale \"fr\"创建索引： db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 以下操作(使用\"simple\"二进制排序规则进行 string 比较)可以使用索引： db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 以下操作在索引的category字段上使用\"simple\"二进制排序规则进行 string 比较，可以使用索引仅满足查询的score: 5部分： db.myColl.find( { score: 5, category: \"cafe\" } ) 文本索引的选项 以下选项仅适用于文本索引： 参数 类型 描述 weights document 可选的。对于文本索引，包含字段和权重对的文档。权重是 1 到 99,999 之间的整数，并且表示该字段相对于其他索引字段在分数方面的重要性。您可以为部分或全部索引字段指定权重。请参阅使用权重控制搜索结果以调整分数。默认的 value 是1。 default_language string 可选的。对于文本索引，确定停用词列表的语言以及词干分析器和标记生成器的规则。有关可用语言，请参阅文本搜索语言;有关详细信息和示例，请参阅指定文本索引的语言。默认的 value 是english。 language_override string 可选的。对于文本索引，集合文档中字段的 name 包含文档的覆盖语言。默认的 value 是language。有关 example，请参阅使用任何字段指定文档的语言。 textIndexVersion integer 可选的。 text索引 version number。用户可以使用此选项覆盖默认的 version number。 有关可用版本，请参阅版本。 version 2.6 中的新内容。 2dsphere 索引的选项 以下选项仅适用于2 dsphere索引： 参数 类型 描述 2dsphereIndexVersion integer 可选的。 2dsphere索引 version number。用户可以使用此选项覆盖默认的 version number。 有关可用版本，请参阅版本。 version 2.6 中的新内容。 2d 索引的选项 以下选项仅适用于2 d索引： 参数 类型 描述 bits integer 可选的。对于2 d索引，存储位置数据的地理散列 value 的精度数。 bits value 的范围是 1 到 32(含)。默认的 value 是26。 min number 可选的。对于2 d索引，经度和纬度值的下包含边界。默认的 value 是-180.0 max number 可选的。对于2 d索引，经度和纬度值的上包含边界。默认的 value 是180.0。 geoHaystack 索引的选项 以下选项仅适用于geoHaystack索引： 参数 类型 描述 bucketSize number 对于geoHaystack索引，请指定要对位置值进行分组的单位数; 即：group 在同一个存储桶中的那些位置值在指定的单位数内。 value 必须大于 0。 wildcard索引的选项 以下选项仅适用于 通配符索引： 参数 类型 描述 wildcardProjection document 可选的。允许用户从通配符索引中包括或排除特定的字段路径 。仅当创建通配符索引时，此选项才有效。该wildcardProjection选项采用以下形式：wildcardProjection: { \"path.to.field.a\" : , \"path.to.field.b\" : }该可以是以下几点：1. 1或true将该字段包括在通配符索引中。2. 0或false从通配符索引中排除该字段。_id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它{ \"wildcardProjection\" : { \"_id\" : 1, \"\" : 0 &124; 1}}除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。指定的选项db.collection.createIndexes适用于键模式数组中包括的所有索引规范。wildcardProjection仅在使用创建单个通配符索引时 指定 db.collection.createIndexes 行为 并发 在版本4.2中进行了更改。 对于featureCompatibilityVersion \"4.2\"，db.collection.createIndexes() 使用优化的构建过程，该过程在索引构建的开始和结束时获取并持有对指定集合的排他锁。集合上的所有后续操作必须等到db.collection.createIndexes()释放排他锁。db.collection.createIndexes()允许在大多数索引构建期间交错进行读写操作。 对于featureCompatibilityVersion \"4.0\"，db.collection.createIndexes()使用4.2之前的索引构建过程，默认情况下会在构建过程的整个过程中获取父数据库的互斥锁。4.2之前的构建过程将阻止对数据库及其所有集合的所有操作，直到操作完成。background索引不使用排他锁。 有关的锁定行为的更多信息db.collection.createIndexes()，请参见 填充集合的索引构建。 重塑现有的索引 如果您要求db.collection.createIndexes()一个或多个已经存在的索引，MongoDB不会重新创建现有的一个或多个索引。 指数期权 非归类选项 除排序规则选项外，如果您创建具有一组索引选项的索引，然后尝试重新创建相同的索引但具有不同的索引选项，则MongoDB不会更改选项，也不会重新创建索引。 要更改这些索引选项，请db.collection.dropIndex()在db.collection.createIndexes()使用新选项运行之前 删除现有索引 。 排序规则选项 与其他索引选项不同，您可以在具有不同排序规则的同一键上创建多个索引。要创建具有相同键模式但排序规则不同的索引，必须提供唯一的索引名称。 索引键长度限制 对于将featureCompatibilityVersion（fCV）设置为\"4.0\"或更早版本的MongoDB 2.6至MongoDB版本， 如果现有文档的索引条目超过，则MongoDB 不会在集合上创建索引。Maximum Index Key Length 通配符索引 4.2版中的新功能。 _id默认情况下，通配符索引会忽略该字段。要将_id字段包含 在通配符索引中，必须在wildcardProjection文档中明确包含它： { \"wildcardProjection\" : { \"_id\" : 1, \"\" : 0|1 } } 除了显式包含 _id字段外，您无法在wildcardProjection文档中组合包含和排除语句 。 该featureCompatibilityVersion必须创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.2部署上设置功能兼容版本。mongod 4.2 通配符索引不支持以下索引类型或属性： Compound TTL Text 2d (Geospatial) 2dsphere (Geospatial) Hashed Unique 注意 通配符索引与通配符文本索引不同并且不兼容 。通配符索引不能支持使用$text运算符的查询。 有关通配符索引限制的完整文档，请参见 通配符索引限制。 有关创建通配符索引的示例，请参见 创建通配符索引。有关通配符索引的完整文档，请参见通配符索引。 例子 也可以看看 db.collection.createIndex()用于各种索引规范的示例。 创建没有选项的索引 考虑包含类似于以下内容的文档的restaurants集合： { location: { type: \"Point\", coordinates: [-73.856077, 40.848447] }, name: \"Morris Park Bake Shop\", cuisine: \"Cafe\", borough: \"Bronx\", } 以下 example 在restaurants集合上创建两个索引：borough字段上的升序索引和location字段上的2 dsphere索引。 db.restaurants.createIndexes([{\"borough\": 1}, {\"location\": \"2dsphere\"}]) 使用指定的排序规则创建索引 以下 example 在products集合上创建两个索引：manufacturer字段上的升序索引和category字段上的升序索引。两个索引都使用整理指定 locale fr和比较强度2： db.products.createIndexes( [ { \"manufacturer\": 1}, { \"category\": 1 } ], { collation: { locale: \"fr\", strength: 2 } }) 对于使用相同排序规则的索引键的查询或排序操作，MongoDB 可以使用索引。有关详细信息，请参阅整理和索引使用。 创建一个通配符指数 新的4.2版：mongodfeatureCompatibilityVersion必须是4.2创建通配符索引。有关设置fCV的说明，请参阅 在MongoDB 4.2部署上设置功能兼容版本。 有关通配符索引的完整文档，请参见 通配符索引。 以下列出了创建通配符索引的示例： 在单个字段路径上创建通配符索引 在所有字段路径上创建通配符索引 在多个特定字段路径上创建通配符索引 创建排除多个特定字段路径的通配符索引 在单个字段路径上创建通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作在product_attributes字段上创建通配符索引 ： use inventory db.products_catalog.createIndexes( [ { \"product_attributes.$**\" : 1 } ] ) 使用此通配符索引，MongoDB索引的所有标量值 product_attributes。如果字段是嵌套的文档或数组，则通配符索引将递归到文档/数组中，并为文档/数组中的所有标量字段建立索引。 通配符索引可以支持product_attributes对其嵌套字段之一或其嵌套字段进行任意单字段查询 ： db.products_catalog.find( { \"product_attributes.superFlight\" : true } ) db.products_catalog.find( { \"product_attributes.maxSpeed\" : { $gt : 20 } } ) db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"water\" } } ) 注意 特定于路径的通配符索引语法与该wildcardProjection选项不兼容 。有关更多信息，请参见参数文档。 在所有字段路径上创建通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作在所有标量字段（不包括_id字段）上创建通配符索引： use inventory db.products_catalog.createIndexes( [ { \"$**\" : 1 } ] ) 使用此通配符索引，MongoDB可以索引集合中每个文档的所有标量字段。如果给定字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并为文档/数组中的所有标量字段建立索引。 创建的索引可以支持对集合中文档中任意字段的查询： db.products_catalog.find( { \"product_price\" : { $lt : 25 } } ) db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"water\" } } ) 注意 _id默认情况下，通配符索引会忽略该字段。要将_id字段包括 在通配符索引中，必须在wildcardProjection`文档中明确包含它。有关更多信息，请参见参数文档。 在多个特定字段路径上创建通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作将创建一个通配符索引，并使用该wildcardProjection选项在索引中仅包含product_attributes.elements和product_attributes.resistance 字段的标量值 。 use inventory db.products_catalog.createIndexes( [ { \"$**\" : 1 } ], { \"wildcardProjection\" : { \"product_attributes.elements\" : 1, \"product_attributes.resistance\" : 1 } } ) 尽管键模式\"$**\"涵盖了文档中的所有字段，但该 wildcardProjection字段将索引限制为仅包含的字段。有关的完整文档wildcardProjection，请参阅 通配符索引的选项。 如果字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并索引文档/数组中的所有标量字段。 创建的索引可以支持对以下内容中包含的任何标量字段的查询wildcardProjection： db.products_catalog.find( { \"product_attributes.elements\" : { $eq: \"Water\" } } ) db.products_catalog.find( { \"product_attributes.resistance\" : \"Bludgeoning\" } ) 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关更多信息 wildcardProjection，请参见参数文档。 创建一个排除多个特定字段路径的通配符索引 考虑一个集合products_catalog，其中文档可能包含一个 product_attributes字段。该product_attributes字段可以包含任意嵌套的字段，包括嵌入式文档和数组： { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0b\"), \"product_name\" : \"Blaster Gauntlet\", \"product_attributes\" : { \"price\" : { \"cost\" : 299.99 \"currency\" : USD } ... } }, { \"_id\" : ObjectId(\"5c1d358bf383fbee028aea0c\"), \"product_name\" : \"Super Suit\", \"product_attributes\" : { \"superFlight\" : true, \"resistance\" : [ \"Bludgeoning\", \"Piercing\", \"Slashing\" ] ... }, } 以下操作创建一个通配符指数，并使用wildcardProjection文件索引的所有标量场的每个文档的集合中，排除了 product_attributes.elements和product_attributes.resistance 字段： use inventory db.products_catalog.createIndexes( [ { \"$**\" : 1 } ], { \"wildcardProjection\" : { \"product_attributes.elements\" : 0, \"product_attributes.resistance\" : 0 } } ) 尽管键模式\"$**\"涵盖了文档中的所有字段，但 wildcardProjection该字段从索引中排除了指定的字段。有关的完整文档wildcardProjection，请参阅 通配符索引的选项。 如果字段是嵌套文档或数组，则通配符索引将递归到文档/数组中，并索引文档/数组中的所有标量字段。 创建的索引可以支持对任何标量字段的查询，但 以下项除外wildcardProjection： db.products_catalog.find( { \"product_attributes.maxSpeed\" : { $gt: 25 } } ) db.products_catalog.find( { \"product_attributes.superStrength\" : true } ) 注意 通配符索引不支持在wildcardProjection文档中混合包含和排除语句，除非明确包含该_id字段。有关更多信息 wildcardProjection，请参见参数文档。 附加信息 有关索引的其他信息，请参阅： 本手册的索引部分用于 MongoDB 中索引和索引的完整文档。 db.collection.getIndexes()查看集合的现有索引的规范。 文字索引有关 creating text索引的详细信息。 地理空间索引和geoHaystack 索引用于地理空间查询。 TTL 指数表示数据到期。 译者：李冠飞 校对： 参见 原文 - db.collection.createIndexes() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/09-db.collection.dataSize.html":{"url":"16-reference/03-method/01-js-collection/09-db.collection.dataSize.html","title":"db.collection.dataSize（）","keywords":"","body":" db.collection.dataSize（） db.collection.dataSize() 返回： 集合的大小(以字节为单位)。 数据压缩不会影响此 value。 此方法在collStats(即：db.collection.stats())命令的尺寸输出周围提供 wrapper。 译者：李冠飞 校对： 参见 原文 - db.collection.dataSize() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/10-db.collection.deleteOne.html":{"url":"16-reference/03-method/01-js-collection/10-db.collection.deleteOne.html","title":"db.collection.deleteOne（）","keywords":"","body":" db.collection.deleteOne（） 在本页面 定义 行为 例子 定义 db.collection. deleteOne () 从集合中删除单个文档。 db.collection.deleteOne( , { writeConcern: , collation: } ) 参数 类型 描述 filter document 使用query operators指定删除条件。 指定空文档{ }以删除集合中返回的第一个文档。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法： 排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 返回： 包含以下内容的文档： boolean acknowledged as true如果操作使用写关注或false运行，如果写入关注被禁用 deletedCount包含已删除文档的数量 行为 删除 Order deleteOne删除与过滤器匹配的第一个文档。使用属于独特的指数的字段(如_id)进行精确删除。 上限收藏 如果在上限集合上使用，deleteOne()会抛出WriteError exception。要从上限集合中删除文档，请改用db.collection.drop()。 事务 db.collection.deleteOne()可以在多文档事务中使用。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 删除单个文档 orders集合包含具有以下结构的文档： { _id: ObjectId(\"563237a41a4d68582c2509da\"), stock: \"Brent Crude Futures\", qty: 250, type: \"buy-limit\", limit: 48.90, creationts: ISODate(\"2015-11-01T12:30:15Z\"), expiryts: ISODate(\"2015-11-01T12:35:15Z\"), client: \"Crude Traders Inc.\" } 以下操作使用_id: ObjectId(\"563237a41a4d68582c2509da\")删除 order： try { db.orders.deleteOne( { \"_id\" : ObjectId(\"563237a41a4d68582c2509da\") } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"deletedCount\" : 1 } 以下操作删除expiryts大于ISODate(\"2015-11-01T12:40:15Z\")的第一个文档 try { db.orders.deleteOne( { \"expiryts\" : { $lt: ISODate(\"2015-11-01T12:40:15Z\") } } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"deletedCount\" : 1 } 写作关注 deleteOne() 给定三个成员副本集，以下操作指定majority wtimeout，wtimeout 100： try { db.orders.deleteOne( { \"_id\" : ObjectId(\"563237a41a4d68582c2509da\") }, { w : \"majority\", wtimeout : 100 } ); } catch (e) { print (e); } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.deleteOne( { category: \"cafe\", status: \"A\" }, { collation: { locale: \"fr\", strength: 1 } } ) 也可以看看 要删除多个文档，请参阅db.collection.deleteMany() 译者：李冠飞 校对： 参见 原文 - db.collection.deleteOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/11-db.collection.deleteMany.html":{"url":"16-reference/03-method/01-js-collection/11-db.collection.deleteMany.html","title":"db.collection.deleteMany（）","keywords":"","body":" db.collection.deleteMany（） 在本页面 定义 行为 例子 定义 db.collection. deleteMany () 从集合中删除匹配filter的所有文档。 db.collection.deleteMany( , { writeConcern: , collation: } ) 参数 类型 描述 filter document 使用query operators指定删除条件。 要删除集合中的所有文档，请传入一个空文档({ })。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法： 排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 返回： 包含以下内容的文档： boolean acknowledged as true如果操作使用写关注或false运行，如果写入关注被禁用 deletedCount包含已删除文档的数量 行为 上限集合 如果在上限集合上使用，deleteMany()会抛出WriteError exception。要从上限集合中删除所有文档，请改用db.collection.drop()。 删除单个文档 要删除单个文档，请改用db.collection.deleteOne()。 或者，使用独特的指数的一部分字段，例如_id。 事务 db.collection.deleteMany()可以在多文档事务中使用。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 删除多个文档 orders集合包含具有以下结构的文档： { _id: ObjectId(\"563237a41a4d68582c2509da\"), stock: \"Brent Crude Futures\", qty: 250, type: \"buy-limit\", limit: 48.90, creationts: ISODate(\"2015-11-01T12:30:15Z\"), expiryts: ISODate(\"2015-11-01T12:35:15Z\"), client: \"Crude Traders Inc.\" } 以下操作将删除client : \"Crude Traders Inc.\"所有文档： try { db.orders.deleteMany( { \"client\" : \"Crude Traders Inc.\" } ); } catch (e) { print (e); } 操作返回： { \"acknowledged\" : true, \"deletedCount\" : 10 } 以下操作将删除stock : \"Brent Crude Futures\"和limit大于48.88的所有文档： try { db.orders.deleteMany( { \"stock\" : \"Brent Crude Futures\", \"limit\" : { $gt : 48.88 } } ); } catch (e) { print (e); } 操作返回： { \"acknowledged\" : true, \"deletedCount\" : 8 } 写作关注 deleteMany() 给定三个成员副本集，以下操作指定majority majority和wtimeout 100： try { db.orders.deleteMany( { \"client\" : \"Crude Traders Inc.\" }, { w : \"majority\", wtimeout : 100 } ); } catch (e) { print (e); } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.deleteMany( { category: \"cafe\", status: \"A\" }, { collation: { locale: \"fr\", strength: 1 } } ) 译者：李冠飞 校对： 参见 原文 - db.collection.deleteMany() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/12-db.collection.distinct.html":{"url":"16-reference/03-method/01-js-collection/12-db.collection.distinct.html","title":"db.collection.distinct（）","keywords":"","body":" db.collection.distinct（） 在本页面 定义 选项 行为 例子 定义 db.collection. distinct(字段，查询，选项) 在单个集合或视图中查找指定字段的不同值，并在 array 中返回结果。 参数 类型 描述 field string 要为其返回不同值的字段。 query document 一个查询，指定从中检索不同值的文档。 options document 可选的。指定选项的文档。见选项。 db.collection.distinct()方法在不同命令周围提供 wrapper。 注意 结果不得大于最大BSON 大小。如果结果超过最大 BSON 大小，请使用聚合管道使用$group operator 检索不同的值，如使用聚合管道检索不同的值中所述。 选项 { collation: } 领域 类型 描述 collation document 可选的。指定要用于操作的整理。整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。排序规则选项具有以下语法：collation: { locale: , caseLevel: , caseFirst: , strength: , numericOrdering: , alternate: , maxVariable: , backwards: }指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 行为 在分片集群中，不同命令可能返回孤立文档。 数组字段 如果指定的field的 value 是 array，则db.collection.distinct()将 array 的每个元素视为单独的 value。 例如，如果某个字段的 value 为[ 1, [1], 1 ]，则db.collection.distinct()将1，[1]和1视为单独的值。 对于 example，请参阅返回 Array 字段的不同值。 索引使用 如果可能，db.collection.distinct()操作可以使用索引。 索引也可以覆盖 db.collection.distinct()操作。有关索引涵盖的查询的详细信息，请参阅涵盖查询。 事务 在事务中执行不同的操作： 对于未分片的集合，您可以在舞台上使用 db.collection.distinct()方法/ distinct命令以及聚合管道$group。 对于分片集合，不能使用 db.collection.distinct()方法或 distinct命令。 要查找分片集合的不同值，请在$group阶段使用聚合管道。有关详细信息，请参见“ 区别操作 ”。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 客户端断开 从MongoDB 4.2开始，如果发出db.collection.distinct()断开连接的客户端在操作完成之前断开连接，则MongoDB将标记db.collection.distinct()为终止（即killOp在操作上）。 例子 这些示例使用包含以下文档的inventory集合： { \"_id\": 1, \"dept\": \"A\", \"item\": { \"sku\": \"111\", \"color\": \"red\" }, \"sizes\": [ \"S\", \"M\" ] } { \"_id\": 2, \"dept\": \"A\", \"item\": { \"sku\": \"111\", \"color\": \"blue\" }, \"sizes\": [ \"M\", \"L\" ] } { \"_id\": 3, \"dept\": \"B\", \"item\": { \"sku\": \"222\", \"color\": \"blue\" }, \"sizes\": \"S\" } { \"_id\": 4, \"dept\": \"A\", \"item\": { \"sku\": \"333\", \"color\": \"black\" }, \"sizes\": [ \"S\" ] } 返回字段的不同值 以下 example 从inventory集合中的所有文档返回字段dept的不同值： db.inventory.distinct( \"dept\" ) 该方法返回以下 array 不同的dept值： [ \"A\", \"B\" ] 返回嵌入字段的不同值 以下 example 从inventory集合中的所有文档返回嵌入在item字段中的字段sku的不同值： db.inventory.distinct( \"item.sku\" ) 该方法返回以下 array 不同的sku值： [ \"111\", \"222\", \"333\" ] 也可以看看 点符号有关访问嵌入文档中的字段的信息 返回 Array 字段的不同值 以下 example 从inventory集合中的所有文档返回字段sizes的不同值： db.inventory.distinct( \"sizes\" ) 该方法返回以下 array 不同的sizes值： [ \"M\", \"S\", \"L\" ] 有关distinct()和 array 字段的信息，请参阅行为部分。 使用 distinct 指定 Query 以下 example 从dept等于\"A\"的文档中返回嵌入在item字段中的字段sku的不同值： db.inventory.distinct( \"item.sku\", { dept: \"A\" } ) 该方法返回以下 array 不同的sku值： [ \"111\", \"333\" ] 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下聚合操作包括整理选项： db.myColl.distinct( \"category\", {}, { collation: { locale: \"fr\", strength: 1 } } ) 有关归类字段的说明，请参阅整理文件。 译者：李冠飞 校对： 参见 原文 - db.collection.distinct() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/13-db.collection.drop.html":{"url":"16-reference/03-method/01-js-collection/13-db.collection.drop.html","title":"db.collection.drop（）","keywords":"","body":" db.collection.drop（） 在本页面 定义 行为 例子 定义 db.collection.drop() 从数据库中删除集合或视图。该方法还会删除与已删除集合关联的所有索引。该方法在下降命令周围提供 wrapper。 db.collection.drop()的形式如下： 在版本4.0中更改：db.collection.drop()接受选项文档。 db.collection.drop() db.collection.drop()接受具有以下字段的可选文档： 字段 描述 writeConcern 可选的。表示操作的写关注点的 文档db.collection.drop()。省略使用默认的写关注。当分片群集上发出，mongos转换 写入关注的的 drop命令及其助手 db.collection.drop()来\"majority\"。版本4.0中的新功能。 返回： true成功删除集合时。 false当不存在要收集的集合时。 行为 该db.collection.drop()方法和drop命令为在删除的集合上打开的任何 变更流创建一个无效事件。 从MongoDB 4.0.2开始，删除集合将删除其关联的区域/标签范围。 资源锁定 在版本4.2中进行了更改。 db.collection.drop()在操作期间获得对指定集合的排他锁。集合上的所有后续操作都必须等到db.collection.drop()释放锁为止。 在MongoDB 4.2之前的版本中，db.collection.drop()获得了对父数据库的排他锁，阻止了对数据库及其所有集合的所有操作，直到操作完成。 例子 使用默认写入问题删除集合 以下操作将students集合拖放到当前数据库中。 db.students.drop() 使用Write Concern 删除一个集合w: \"majority\" 在版本4.0中更改：db.collection.drop()接受选项文档。 以下操作将students集合拖放到当前数据库中。该操作使用\"majority\"写关注点： db.students.drop( { writeConcern: { w: \"majority\" } } ) 译者：李冠飞 校对： 参见 原文 - db.collection.drop() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/14-db.collection.dropIndex.html":{"url":"16-reference/03-method/01-js-collection/14-db.collection.dropIndex.html","title":"db.collection.dropIndex（）","keywords":"","body":" db.collection.dropIndex（） 在本页面 定义 例子 定义 db.collection.dropIndex(索引) 从集合中删除或删除指定的索引。 db.collection.dropIndex()方法在dropIndexes命令周围提供包装。 注意 您不能删除_id字段上的默认索引。 从MongoDB 4.2开始，您不能指定 db.collection.dropIndex(\"*\")删除所有非_id索引。使用 db.collection.dropIndexes()代替。 db.collection.dropIndex()方法采用以下参数： 参数 类型 描述 index string or document 指定要删除的索引。您可以通过索引 name 或索引规范文档指定索引。 [1] 要删除文本索引，请指定索引 name。从MongoDB 4.2开始，您不能指定\"*\"删除所有非_id索引。使用 db.collection.dropIndexes()代替。 要获取db.collection.dropIndex()方法的索引 name 或索引规范文档，请使用db.collection.getIndexes()方法。 警告 此命令在受影响的数据库上获取写锁定，并将阻止其他操作，直到完成为止。 行为 从MongoDB 4.2开始，该dropIndex()操作只会终止使用正在删除的索引的查询。这可能包括将索引视为查询计划一部分的 查询。 在MongoDB 4.2之前，在集合上删除索引将杀死该集合上所有打开的查询。 资源锁定 在版本4.2中进行了更改。 db.collection.dropIndex()在操作期间获得对指定集合的排他锁。集合上的所有后续操作都必须等到db.collection.dropIndex()释放锁为止。 在MongoDB 4.2之前的版本中，db.collection.dropIndex()获得了对父数据库的排他锁，阻止了对数据库及其所有集合的所有操作，直到操作完成。 例子 考虑一个pets集合。在pets集合上调用getIndexes()方法将返回以下索引： [ { “v“ : 1, “key“ : { “_id“ : 1 }, “ns“ : “test.pets“, “name“ : “_id_“ }, { “v“ : 1, “key“ : { “cat“ : -1 }, “ns“ : “test.pets“, “name“ : “catIdx“ }, { “v“ : 1, “key“ : { “cat“ : 1, “dog“ : -1 }, “ns“ : “test.pets“, “name“ : “cat_1_dog_-1“ } ] 字段上的单个字段索引cat具有用户指定的名称catIdx [2]和索引指定文档为 。{ \"cat\" : -1 } 要删除索引catIdx，可以使用索引 name： db.pets.dropIndex( “catIdx“ ) 或者您可以使用索引规范文档{ “cat“ : -1 }： db.pets.dropIndex( { “cat“ : -1 } ) [1] (1，2)在 2.2.2 之前使用mongo shell version 时，如果在创建索引期间指定了 name，则必须使用 name 删除索引。 [2] 在创建索引期间，如果用户不**指定索引 name，则系统通过将索引 key 字段和 value 与下划线如：连接来生成 name。 cat_1。 译者：李冠飞 校对： 参见 原文 - db.collection.dropIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/15-db.collection.dropIndexes.html":{"url":"16-reference/03-method/01-js-collection/15-db.collection.dropIndexes.html","title":"db.collection.dropIndexes（）","keywords":"","body":" db.collection.dropIndexes（） 在本页面 定义 行为 定义 db.collection. dropIndexes () _id从集合中删除指定的一个或多个索引（字段中的索引除外 ）。 您可以使用该方法执行以下操作： _id从集合中删除除索引之外的所有内容。 db.collection.dropIndexes() 从集合中删除指定的索引。要指定索引，可以通过以下方法之一： 索引规范文档（除非索引是 文本索引，在这种情况下，请使用索引名称删除）： db.collection.dropIndexes( { a: 1, b: 1 } ) 索引名称： db.collection.dropIndexes( \"a_1_b_1\" ) 建议 若要获取索引的名称，请使用 db.collection.getIndexes()方法。 从集合中删除指定的索引。（从MongoDB 4.2开始可用）。要指定要删除的多个索引，请向该方法传递一个索引名称数组： db.collection.dropIndexes( [ \"a_1_b_1\", \"a_1\", \"a_1__id_-1\" ] ) 如果索引名称数组包含不存在的索引，则该方法将出错，而不会删除任何指定的索引。 建议 若要获取索引的名称，请使用 db.collection.getIndexes()方法。 db.collection.dropIndexes()方法采用以下可选参数： 参数 类型 描述 indexes string 或 document 或 array of strings 可选的。指定要删除的一个或多个索引。要删除集合中除_id索引以外的所有索引，请省略参数。要删除单个索引，请指定索引名称，索引规范文档（除非索引是 文本索引）或索引名称的数组。要删除文本索引，请指定索引名称或索引名称的数组，而不是索引规范文档。要删除多个索引（从MongoDB 4.2开始可用），请指定一个索引名称数组。 db.collection.dropIndexes()是围绕着一个包装 dropIndexes命令。 行为 只kill相关查询 从MongoDB 4.2开始，该dropIndexes()操作只会终止使用正在删除的索引的查询。这可能包括将索引视为查询计划一部分的 查询。 在MongoDB 4.2之前，在集合上删除索引将杀死该集合上所有打开的查询。 资源锁定 在版本4.2中进行了更改。 db.collection.dropIndexes()在操作期间获得对指定集合的排他锁。集合上的所有后续操作都必须等到db.collection.dropIndexes()释放锁为止。 在MongoDB 4.2之前的版本中，db.collection.dropIndexes()获得了对父数据库的排他锁，阻止了对数据库及其所有集合的所有操作，直到操作完成。 索引名称 如果给该方法传递了一个包含不存在的索引的索引名数组，则该方法将出错，而不会删除任何指定的索引。 _id索引 您不能在_id字段上删除默认索引。 文本索引 要删除文本索引，请指定索引名称而不是索引规范文档。 译者：李冠飞 校对： 参见 原文 - db.collection.dropIndexes() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/16-db.collection.ensureIndex.html":{"url":"16-reference/03-method/01-js-collection/16-db.collection.ensureIndex.html","title":"db.collection.ensureIndex（）","keywords":"","body":" db.collection.ensureIndex（） 在本页面 定义 附加信息 定义 db.collection. ensureIndex(键，选项) 从3.0.0版开始不推荐使用：db.collection.ensureIndex()现在是的别名 db.collection.createIndex()。 如果索引尚不存在，则在指定字段上创建索引。 附加信息 使用db.collection.createIndex()而不是db.collection.ensureIndex()来创建新索引。 本手册的索引部分用于 MongoDB 中索引和索引的完整文档。 db.collection.getIndexes()查看集合的现有索引的规范。 译者：李冠飞 校对： 参见 原文 - db.collection.ensureIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/17-db.collection.explain.html":{"url":"16-reference/03-method/01-js-collection/17-db.collection.explain.html","title":"db.collection.explain（）","keywords":"","body":" db.collection.explain（） 在本页面 定义 行为 例子 输出 定义 db.collection. explain () 返回有关以下方法的查询计划的信息： 从MongoDB 3.0开始 从MongoDB 3.2开始 aggregate()count() find()remove() update() distinct()findAndModify() 若要使用db.collection.explain()，请将上述方法之一附加到db.collection.explain()： db.collection.explain(). 例如， db.products.explain().remove( { category: \"apparel\" }, { justOne: true } ) 有关更多示例，请参阅例子。有关可用于db.collection.explain()的方法列表，请参阅db.collection.explain().help()。 db.collection.explain()方法具有以下参数： 参数 类型 描述 verbosity string 可选的。指定解释输出的详细模式。该模式会影响explain()的行为并确定要 return 的信息量。可能的模式是：\"queryPlanner\"，\"executionStats\"和\"allPlansExecution\"。 默认模式为\"queryPlanner\"。 为了向后兼容早期版本的cursor.explain()，MongoDB 将true解释为\"allPlansExecution\"，将false解释为\"queryPlanner\"。 有关模式的更多信息，请参阅详细模式。 行为 详细模式 db.collection.explain()的行为和返回的信息量取决于verbosity模式。 queryPlanner 模式 默认情况下，db.collection.explain()在queryPlanner详细模式下运行。 MongoDB 运行查询优化器来为 evaluation 下的操作选择获胜计划。 db.collection.explain()返回已评估方法的queryPlanner信息。 executionStats 模式 MongoDB 运行查询优化器来选择获胜计划，执行获胜计划以完成，并返回描述获胜计划执行的统计数据。 对于写入操作，db.collection.explain()返回有关将执行的更新或删除操作的信息，但不会将修改应用于数据库。 db.collection.explain()返回已评估方法的queryPlanner和executionStats信息。但是，executionStats不提供被拒绝计划的查询执行信息。 allPlansExecution 模式 MongoDB 运行查询优化器来选择获胜计划并执行获胜计划以完成。在\"allPlansExecution\"模式中，MongoDB 返回描述获胜计划执行情况的统计信息以及计划选择期间捕获的其他候选计划的统计信息。 对于写入操作，db.collection.explain()返回有关将执行的更新或删除操作的信息，但不会将修改应用于数据库。 db.collection.explain()返回已评估方法的queryPlanner和executionStats信息。 executionStats包括获胜计划的完整查询执行信息。 如果查询优化器考虑了多个计划，executionStats信息还包括在计划选择阶段期间为获胜和被拒绝的候选计划捕获的部分执行信息。 Explain and Write Operations 对于写操作，db.collection.explain()返回有关将要执行但实际上并未修改数据库的写操作的信息。 Restrictions 在MongoDB中4.2开始，你不能运行explain命令/ db.collection.explain()在executionStats模式或allPlansExecution一个模式包含阶段。相反，您可以：aggregation pipeline $out 以queryPlanner方式运行说明 在executionStats模式或allPlansExecution 模式下运行说明，但没有该$out阶段以返回该阶段之前的$out阶段的信息。 explain() Mechanics db.collection.explain()方法包装说明命令，是 run 说明的首选方法。 db.collection.explain().find()类似于db.collection.find().explain()，以下 key 差异： db.collection.explain().find()结构允许额外链接查询修饰符。有关查询修饰符的列表，请参见db.collection.explain().find().help()。 db.collection.explain().find()返回一个游标，它需要调用.next()或其别名.finish()来_return explain()结果。如果在mongo shell 中以交互方式 run，mongo shell 会自动 calls .finish()来_return 结果。但是，对于脚本，必须显式调用.next()或.finish()来_return 结果。有关 cursor-related 方法的列表，请参阅db.collection.explain().find().help()。 db.collection.explain().aggregate()相当于将说明选项传递给db.collection.aggregate()方法。 help() 要查看db.collection.explain()，run 支持的操作列表： db.collection.explain().help() db.collection.explain().find()返回一个游标，允许链接查询修饰符。要查看db.collection.explain().find()以及 cursor-related 方法支持的查询修饰符列表，润： db.collection.explain().find().help() 您可以将多个修改器链接到db.collection.explain().find()。对于 example，请参阅用修饰符解释 find()。 例子 queryPlanner 模式 默认情况下，db.collection.explain()在\"queryPlanner\"详细模式下运行。 以下 example 在“queryPlanner” 详细模式下运行db.collection.explain()以返回指定count()操作的查询计划信息： db.products.explain().count( { quantity: { $gt: 50 } } ) executionStats 模式 以下 example 在“executionStats” verbosity 模式下运行db.collection.explain()以_return 指定find()操作的查询计划和执行信息： db.products.explain(\"executionStats\").find( { quantity: { $gt: 50 }, category: \"apparel\" } ) allPlansExecution 模式 以下 example 在“allPlansExecution” verbosity 模式下运行db.collection.explain()。对于指定的update()操作，db.collection.explain()为所有考虑的计划返回queryPlanner和executionStats： 注意 执行此解释不会修改数据，而是运行更新操作的查询谓词。对于候选计划，MongoDB 返回计划选择阶段期间捕获的执行信息。 db.products.explain(\"allPlansExecution\").update( { quantity: { $lt: 1000}, category: \"apparel\" }, { $set: { reorder: true } } ) 用修饰符解释 find() db.collection.explain().find() construct 允许链接查询修饰符。对于 example，以下操作使用sort()和hint()查询修饰符提供有关find()方法的信息。 db.products.explain(\"executionStats\").find( { quantity: { $gt: 50 }, category: \"apparel\" } ).sort( { quantity: -1 } ).hint( { category: 1, quantity: -1 } ) 有关可用的查询修饰符列表，shell 中的 run： db.collection.explain().find().help() 迭代 explain().find() Return 游标 db.collection.explain().find()将光标返回到解释结果。如果在mongo shell 中以交互方式 run，mongo shell 将使用.next()方法自动迭代游标。但是，对于脚本，必须显式调用.next()(或其别名.finish())来_return 结果： var explainResult = db.products.explain().find( { category: \"apparel\" } ).next(); 输出 db.collection.explain()操作可以 return 以下信息： queryPlanner，详细说明查询优化器选择的计划，列出被拒绝的计划; executionStats，详细说明获胜计划的执行情况和被拒绝的计划;和 serverInfo，提供有关 MongoDB 实例的信息。 详细程度模式(即：queryPlanner，executionStats，allPlansExecution)确定结果是否包含executionStats以及executionStats是否包含计划选择期间捕获的数据。 有关输出的详细信息，请参阅解释结果。 对于具有 version 3.0 mongos和至少一个 2.6 mongod分片的混合 version 分片 cluster，当您在 version 3.0 mongo shell 中 run db.collection.explain()时，db.collection.explain()将使用$explain operator 重试_ret以 2.6 格式返回结果。 译者：李冠飞 校对： 参见 原文 - db.collection.explain() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/18-db.collection.find.html":{"url":"16-reference/03-method/01-js-collection/18-db.collection.find.html","title":"db.collection.find（）","keywords":"","body":" db.collection.find（） 在本页面 定义 行为 例子 定义 db.collection. find(查询，投影) 选择集合或视图中的文档，并将光标返回到所选文档。 参数 类型 描述 query document 可选的。使用query operators指定选择过滤器。要 return 集合中的所有文档，请省略此参数或传递空文档({})。 projection document 可选的。指定_retch 查询过滤器的文档中的 return 字段。要_retret 匹配文档中的所有字段，请省略此参数。有关详细信息，请参阅投影。 返回： 与匹配query标准的文档。当find()方法“返回文档”时，该方法实际上是将光标返回到文档。 行为 投影 projection参数确定匹配文档中返回的字段。 projection参数采用以下形式的文档： { field1: , field2: ... } 可以是以下任何一种： 1或true在 return 文档中包含该字段。 0或false排除该字段。 表达式使用投影操作员。 find()视图操作不支持以下投影 operators： $ $elemMatch $slice $meta 注意 对于_id字段，您不必明确指定_id: 1来_return _id字段。除非指定_id: 0以禁止字段，否则find()方法始终返回_id字段。 除了排除_id字段外，projection不能同时包含 include 和 exclude 规范。在明确包含字段的投影中，_id字段是您可以显式排除的唯一字段。 游标处理 在mongo shell 中执行db.collection.find()会自动迭代光标以显示前 20 个文档。键入it以继续迭代。 要使用驱动程序访问返回的文档，请使用适当的司机语言光标处理机制。 也可以看看 迭代返回的游标 修改光标行为 可用的mongo Shell游标方法 阅读关注 要为db.collection.find()指定阅读关注，请使用cursor.readConcern()方法。 包装类型 MongoDB 将某些数据类型视为等效用于比较目的。例如，数字类型在比较之前进行转换。但是，对于大多数数据类型，比较 operators仅对目标字段的BSON 类型与查询操作数的类型匹配的文档执行比较。考虑以下集合： { \"_id\": \"apples\", \"qty\": 5 } { \"_id\": \"bananas\", \"qty\": 7 } { \"_id\": \"oranges\", \"qty\": { \"in stock\": 8, \"ordered\": 12 } } { \"_id\": \"avocados\", \"qty\": \"fourteen\" } 以下查询使用$gt来 return qty的 value 大于4的文档。 db.collection.find( { qty: { $gt: 4 } } ) 该查询返回以下文档： { \"_id\": \"apples\", \"qty\": 5 } { \"_id\": \"bananas\", \"qty\": 7 } 不返回_id等于\"avocados\"的文档，因为qty value 的类型为string而$gt操作数的类型为integer。 不返回_id等于\"oranges\"的文档，因为其qty value 的类型为object。 注意 要在集合中强制执行数据类型，请使用Schema 验证。 会话 版本4.0中的新功能。 对于在会话内创建的游标，不能getMore在会话外调用 。 同样，对于在会话外部创建的游标，不能getMore在会话内部调用 。 会话空闲超时 从MongoDB 3.6开始，MongoDB驱动程序和mongoshell程序将所有操作与服务器会话相关联，但未确认的写操作除外。对于未与会话明确关联的操作（即使用Mongo.startSession()），MongoDB驱动程序和mongo外壳程序会创建一个隐式会话并将其与该操作相关联。 如果会话空闲时间超过30分钟，则MongoDB服务器会将会话标记为已过期，并可以随时关闭它。当MongoDB服务器关闭会话时，它还会终止所有正在进行的操作并打开与该会话关联的游标。这包括配置了30分钟noCursorTimeout或maxTimeMS30分钟以上的光标。 对于可能闲置超过30分钟的操作，请使用将该操作与显式会话相关联， Session.startSession()并使用该refreshSessions命令定期刷新该会话。请参阅以获取更多信息。Session Idle Timeout 交易 db.collection.find()可以在多文档交易中使用。 对于在事务外部创建的游标，不能getMore在事务内部调用 。 对于在事务中创建的游标，不能getMore在事务外部调用 。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 客户端断开 从MongoDB 4.2开始，如果发出db.collection.find() 断开连接的客户端在操作完成之前断开连接，则MongoDB将标记db.collection.find()为终止（即killOp在操作上）。 例子 本节中的示例使用bios 集合中的文档，其中文档通常具有以下形式： { \"_id\" : , \"name\" : { \"first\" : , \"last\" : }, // embedded document \"birth\" : , \"death\" : , \"contribs\" : [ , ... ], // Array of Strings \"awards\" : [ { \"award\" : , year: , by: } // Array of embedded documents ... ] } 要创建和填充bios集合，请参阅bios Example Collection。 查找集合中的所有文档 没有参数的find()方法返回集合中的所有文档，并返回文档的所有字段。对于 example，以下操作返回bios 系列中的所有文档： db.bios.find() 查找 Match 查询条件的文档 查询平等 以下操作返回bios 系列中_id等于5的文档： db.bios.find( { _id: 5 } ) 以下操作返回bios 系列中的文档，其中name嵌入文档中的字段last等于\"Hopper\"： db.bios.find( { \"name.last\": \"Hopper\" } ) 注意 要访问嵌入文档中的字段，请使用点符号(\".\")。 使用 Operators 进行查询 要查找匹配一组选择条件的文档，请使用参数调用find()。 MongoDB 提供各种query operators来指定标准。 以下操作使用$in operator return bios 系列中的文档，其中_id等于5或ObjectId(\"507c35dd8fada716c89d0013\")： db.bios.find( { _id: { $in: [ 5, ObjectId(\"507c35dd8fada716c89d0013\") ] } } ) 以下操作使用$gt operator 返回bios集合中birth大于new Date('1950-01-01')的所有文档： db.bios.find( { birth: { $gt: new Date('1950-01-01') } } ) 以下操作使用$regex operator return bios 系列中的文档，其中name.last字段以字母N(或\"LIKE N%\")开头 db.bios.find( { \"name.last\": { $regex: /^N/ } } ) 有关查询 operators 的列表，请参阅查询 Selectors。 查询范围 组合比较 operators 以指定字段的范围。以下操作从bios 系列文档返回，其中birth介于new Date('1940-01-01')和new Date('1960-01-01')之间(独占)： db.bios.find( { birth: { $gt: new Date('1940-01-01'), $lt: new Date('1960-01-01') } } ) 有关查询 operators 的列表，请参阅查询 Selectors。 查询多个条件 以下操作返回bios 系列中的所有文档，其中birth字段为比...更棒 new Date('1950-01-01')且death字段不存在： db.bios.find( { birth: { $gt: new Date('1920-01-01') }, death: { $exists: false } } ) 有关查询 operators 的列表，请参阅查询 Selectors。 查询嵌入式文档 以下示例查询bios 系列中的name嵌入字段。 查询嵌入式文档的精确匹配 以下操作返回bios 系列中的文档，其中嵌入的文档name正好是{ first: \"Yukihiro\", last: \"Matsumoto\" }，包括 order： db.bios.find( { name: { first: \"Yukihiro\", last: \"Matsumoto\" } } ) name字段必须完全匹配嵌入文档。查询将使文档与具有name以下任一值的字段进行匹配： { first: \"Yukihiro\", aka: \"Matz\", last: \"Matsumoto\" } { last: \"Matsumoto\", first: \"Yukihiro\" } 查询嵌入文档的字段 以下操作返回bios 系列中的文档，其中嵌入文档name包含带有 value \"Yukihiro\"的字段first和带有 value \"Matsumoto\"的字段last。该查询使用点符号访问嵌入文档中的字段： db.bios.find( { \"name.first\": \"Yukihiro\", \"name.last\": \"Matsumoto\" } ) 该查询匹配name字段包含嵌入文档的文档，其中first字段包含 value \"Yukihiro\"，字段last包含 value \"Matsumoto\"。例如，查询将使用包含以下任一值的name字段匹配文档： { first: \"Yukihiro\", aka: \"Matz\", last: \"Matsumoto\" } { last: \"Matsumoto\", first: \"Yukihiro\" } 有关更多信息和示例，另请参阅查询 Embedded/Nested 文档。 查询数组 查询 Array 元素 以下示例查询bios 系列中的contribs array。 以下操作返回bios 系列中的文档，其中 array 字段contribs包含元素\"UNIX\"： db.bios.find( { contribs: \"UNIX\" } ) 以下操作返回bios 系列中的文档，其中 array 字段contribs包含元素\"ALGOL\"或\"Lisp\"： db.bios.find( { contribs: { $in: [ \"ALGOL\", \"Lisp\" ]} } ) 以下操作使用$all query operator return bios 系列中的文档，其中 array 字段contribs包含元素\"ALGOL\"和\"Lisp\"： db.bios.find( { contribs: { $all: [ \"ALGOL\", \"Lisp\" ] } } ) 有关更多示例，请参阅$all。另见$elemMatch。 以下操作使用$size operator return bios 系列中contribs的 array 大小为 4 的文档：db.bios.find( { contribs: { $size: 4 } } ) 有关查询 array 的更多信息和示例，请参阅： 查询 Array 查询嵌入式文档的 Array 有关 array 特定查询 operators 的列表，请参阅Array。 查询 Array of Documents 以下示例查询bios 系列中的awards array。 以下操作返回bios 系列中的文档，其中awards array 包含award字段等于\"Turing的元素： db.bios.find( { \"awards.award\": \"Turing Award\" } ) 以下操作返回bios 系列中的文档，其中awards array 包含至少一个元素，其中award字段等于\"Turing Award\"且year字段大于 1980： db.bios.find( { awards: { $elemMatch: { award: \"Turing Award\", year: { $gt: 1980 } } } } ) 使用$elemMatch operator 在 array 元素上指定多个条件。 有关查询 array 的更多信息和示例，请参阅： 查询 Array 查询嵌入式文档的 Array 有关 array 特定查询 operators 的列表，请参阅Array。 预测 projection参数指定 return 的哪些字段。除非排除属于_id字段，否则该参数包含 include 或 exclude 规范，而不是两者。 注意 除非在投影文档_id: 0中明确排除_id字段，否则返回_id字段。 指定 Return 的字段 以下操作查找bios 系列中的所有文档，并仅返回name字段，contribs字段和_id字段： db.bios.find( { }, { name: 1, contribs: 1 } ) 注意 除非在投影文档_id: 0中明确排除_id字段，否则返回_id字段。 明确排除的字段 以下操作查询bios 系列并返回除name嵌入文档和birth字段中的first字段之外的所有字段： db.bios.find( { contribs: 'OOP' }, { 'name.first': 0, birth: 0 } ) 明确排除_id 字段 注意 除非在投影文档_id: 0中明确排除_id字段，否则返回_id字段。 以下操作在bios 系列中查找文档，并仅返回name字段和contribs字段： db.bios.find( { }, { name: 1, contribs: 1, _id: 0 } ) 关于数组和嵌入式文档 以下操作查询bios 系列并返回name嵌入文档中的last字段和contribs array 中的前两个元素： db.bios.find( { }, { _id: 0, 'name.last': 1, contribs: { $slice: 2 } } ) 也可以看看 从查询返回的项目字段 迭代返回的光标 find()方法返回光标到结果。 在mongo shell 中，如果未使用var关键字将返回的游标分配给变量，则会自动迭代游标以访问最匹配查询的前 20 个文档。您可以设置DBQuery.shellBatchSize变量以更改自动迭代文档的数量。 要手动迭代结果，请将返回的光标分配给带有var关键字的变量，如以下部分所示。 使用 Variable Name 以下 example 使用变量myCursor迭代游标并打印匹配的文档： var myCursor = db.bios.find( ); myCursor 使用 next()方法 以下 example 使用游标方法next()来访问文档： var myCursor = db.bios.find( ); var myDocument = myCursor.hasNext() ? myCursor.next() : null; if (myDocument) { var myName = myDocument.name; print (tojson(myName)); } 要打印，您还可以使用printjson()方法而不是print(tojson())： if (myDocument) { var myName = myDocument.name; printjson(myName); } 使用 forEach()方法 以下 example 使用游标方法forEach()来迭代游标并访问文档： var myCursor = db.bios.find( ); myCursor.forEach(printjson); 修改游标行为 mongo shell 和司机提供了几个游标方法，这些方法调用find()方法返回的游标来修改其行为。 Order 结果集中的文档 sort()方法对结果集中的文档进行排序。以下操作返回name中按name字段按升序排序的文档中的文档： db.bios.find().sort( { name: 1 } ) sort()对应于 SQL 中的ORDER BY语句。 将文档数限制为 Return limit()方法限制结果集中的文档数。以下操作最多返回bios 系列中的5个文档： db.bios.find().limit( 5 ) limit()对应于 SQL 中的LIMIT语句。 设置结果集的起始点 skip()方法控制结果集的起始点。以下操作会跳过bios 系列中的第一个5文档并返回所有剩余文档： db.bios.find().skip( 5 ) 指定排序规则 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 collation()方法为db.collection.find()操作指定整理。 db.bios.find( { \"name.last\": \"hopper\" } ).collation( { locale: \"en_US\", strength: 1 } ) 结合光标方法 以下 statements 链游标方法limit()和sort()： db.bios.find().sort( { name: 1 } ).limit( 5 ) db.bios.find().limit( 5 ).sort( { name: 1 } ) 这两个语句是等价的; 即：你链接limit()和sort()方法的 order 并不重要。两个 statements return 前五个文档，由'name'上的升序排序 order 确定。 可用的mongoShell游标方法 cursor.allowDiskUse() cursor.allowPartialResults() cursor.batchSize() cursor.close() cursor.isClosed() cursor.collation() cursor.comment() cursor.count() cursor.explain() cursor.forEach() cursor.hasNext() cursor.hint() cursor.isExhausted() cursor.itcount() cursor.limit() cursor.map() cursor.max() cursor.maxTimeMS() cursor.min() cursor.next() cursor.noCursorTimeout() cursor.objsLeftInBatch() cursor.pretty() cursor.readConcern() cursor.readPref() cursor.returnKey() cursor.showRecordId() cursor.size() cursor.skip() cursor.sort() cursor.tailable() cursor.toArray() 译者：李冠飞 校对： 参见 原文 - db.collection.find() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/19-db.collection.findAndModify.html":{"url":"16-reference/03-method/01-js-collection/19-db.collection.findAndModify.html","title":"db.collection.findAndModify（）","keywords":"","body":" db.collection.findAndModify（） 在本页面 定义 Return 数据 行为 例子 定义 db.collection. findAndModify(文件) 修改并返回单个文档。默认情况下，返回的文档不包括对更新所做的修改。要通过对更新进行的修改来回显文档，请使用new选项。 findAndModify()方法是findAndModify命令周围的 shell 助手。 findAndModify()方法具有以下形式： 更改了 version 3.6. db.collection.findAndModify({ query: , sort: , remove: , update: , new: , fields: , upsert: , bypassDocumentValidation: , writeConcern: , collation: , arrayFilters: [ , ... ] }); db.collection.findAndModify()方法采用带有以下嵌入文档字段的文档参数： 参数 类型 描述 query document 可选的。修改的选择标准。 query字段使用与db.collection.find()方法中使用的query selectors相同的query selectors。虽然查询可能匹配多个文档，但findAndModify() 只会选择一个文档来修改。 如果未指定，则默认为空文档。 从 MongoDB 3.6.14(和 3.4.23)开始，如果查询参数不是文档，则操作错误。 sort document 可选的。如果查询选择多个文档，则确定操作修改的文档。 findAndModify()修改此参数指定的 sort order 中的第一个文档。 从 MongoDB 3.6.14(和 3.4.23)开始，如果 sort 参数不是文档，则操作错误。 remove boolean 必须指定remove或update字段。删除query字段中指定的文档。将其设置为true以删除所选文档。默认值为false。 update document 必须指定remove或update字段。执行所选文档的更新。 update字段使用相同的更新 operators或field: value规范来修改所选文档。 new boolean 可选的。当true时，返回修改后的文档而不是原始文档。 findAndModify()方法忽略remove操作的new选项。默认值为false。 fields document 可选的。 return 的字段子集。 fields文档指定包含1的字段，如：fields: { : 1, : 1, ... }。见投影。 从 MongoDB 3.6.14(和 3.4.23)开始，如果 fields 参数不是文档，则操作错误。 upsert boolean 可选的。与update字段结合使用。 当true，findAndModify()时：如果没有文件匹配query，则创建一个新文档。有关详细信息，请参阅upsert 行为。 更新与query匹配的单个文档。 要避免多次 upsert，请确保query字段为唯一索引。 默认为false。 bypassDocumentValidation boolean 可选的。允许db.collection.findAndModify在操作期间绕过文档验证。这使您可以更新不符合验证要求的文档。 version 3.2 中的新内容。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。 version 3.2 中的新内容。 maxTimeMS integer 可选的。指定处理操作的 time 限制(以毫秒为单位)。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 arrayFilters array 可选的。过滤器文档的 array，用于确定要在 array 字段上为更新操作修改哪些 array 元素。 在更新文档中，使用$ []过滤后的位置 operator 来定义标识符，然后在 array 过滤器文档中进行 reference。如果标识符未包含在更新文档中，则不能为标识符提供 array 过滤器文档。 注意 必须以小写字母开头，并且只包含字母数字字符。 您可以在更新文档中多次包含相同的标识符;但是，对于更新文档中的每个不同标识符($[identifier])，您必须指定恰好一个对应的 array 过滤器文档。也就是说，您不能为同一标识符指定多个 array 过滤器文档。对于 example，如果 update 语句包含标识符x(可能多次)，则不能为arrayFilters指定以下内容，其中包含 2 个单独的x过滤器文档：[ { \"x.a\": { $gt: 85 } }, { \"x.b\": { $gt: 80 } } ] 但是，您可以在同一标识符上指定复合条件单个过滤器文档，例如以下示例：// Example 1 [ { $or: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 2 [ { $and: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 3 [ { \"x.a\": { $gt: 85 }, \"x.b\": { $gt: 80 } } ]例如，请参阅为 Array Update Operations 指定 arrayFilters。 version 3.6 中的新内容。 Return 数据 对于删除操作，如果查询与文档匹配，findAndModify()将返回已删除的文档。如果查询未匹配要删除的文档，findAndModify()将返回null。 对于更新操作，findAndModify()返回以下之一： 如果未设置new参数或false： 如果查询与文档匹配，则为 pre-modification 文档; 否则，null。 如果new是true： 修改后的文档，如果查询返回 match; 插入的文档，如果upsert: true，没有文档与查询匹配; 否则，null。 更改 version 3.0：在以前的版本中，如果更新，sort已指定，upsert: true，new选项未设置或new: false，db.collection.findAndModify()将返回空文档{}而不是null。 行为 Upsert 和 Unique Index 当findAndModify()包含upsert: true选项并且查询 field(s)没有唯一索引时，该方法可以在某些情况下多次插入文档。 在下面的示例中，不存在 name Andy的文档，并且多个 clients 发出以下命令： db.people.findAndModify({ query: { name: \"Andy\" }, sort: { rating: 1 }, update: { $inc: { score: 1 } }, upsert: true }) 然后，如果这些 clients 的findAndModify()方法在任何命令启动modify阶段之前完成query阶段，和在name字段上没有唯一索引，则命令可以全部执行 upsert，创建多个重复文档。 要防止使用相同的 name 创建多个重复文档，请在name字段上创建独特的指数。有了这个唯一索引，多个方法将表现出以下行为之一： 正好一个findAndModify()成功插入一个新文档。 零个或多个findAndModify()方法更新新插入的文档。 零个或多个findAndModify()方法在尝试 Insert 具有相同 name 的文档时失败。如果由于name字段上的唯一索引约束违规而导致方法失败，则可以重试该方法。如果没有删除文档，则重试不应失败。 Sharded Collections 在分片环境中使用findAndModify时，query 必须包含针对分片集合的分片 cluster 的所有操作的碎片 key。 findAndModify针对非分片集合的mongos实例发出的操作正常运行。 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 文件验证 db.collection.findAndModify()方法添加了对bypassDocumentValidation选项的支持，该选项允许您在使用验证规则插入或更新集合中的文档时绕过文件验证。 与update方法的比较 更新文档时，findAndModify()和update()方法的操作方式不同： 默认情况下，两个操作都会修改单个文档。但是，带有multi选项的update()方法可以修改多个文档。 如果多个文档匹配更新条件，对于findAndModify()，您可以指定sort以提供对要更新的文档的某种控制措施。 使用update()方法的默认行为，您无法在多个文档 match 时指定要更新的单个文档。 默认情况下，findAndModify()返回文档的 pre-modified version。要获取更新的文档，请使用new选项。 update()方法返回包含操作状态的写结果 object。要 return 更新的文档，请使用find()方法。但是，其他更新可能已在您的更新和文档检索之间修改了文档。此外，如果更新仅修改了单个文档但匹配了多个文档，则需要使用其他逻辑来标识更新的文档。 修改单个文档时，findAndModify()和update()方法都会自动更新文档。有关这些方法的操作的交互和顺序的更多详细信息，请参阅原子性和 Transactions。 事务 db.collection.findAndModify()可以在多文档交易中使用。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 现有的收藏和交易 在事务内部，您可以指定对现有集合的读/写操作。如果db.collection.findAndModify()导致upsert，则该集合必须已经存在。 写的担忧和事务 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 例子 更新和 Return 以下方法更新并返回文档与查询条件匹配的人员集合中的现有文档： db.people.findAndModify({ query: { name: \"Tom\", state: \"active\", rating: { $gt: 10 } }, sort: { rating: 1 }, update: { $inc: { score: 1 } } }) 此方法执行以下操作： query在people集合中查找name字段具有 value Tom，state字段具有 value active且rating字段具有 value greater than 10 的文档。 sort以升序 order 命令查询结果。如果多个文档符合query条件，则该方法将选择修改此sort所订购的第一个文档。 更新increments score字段的 value 为 1。 该方法返回为此更新选择的原始(i.e.pre-modification)文档： { \"_id\" : ObjectId(\"50f1e2c99beb36a0f45c6453\"), \"name\" : \"Tom\", \"state\" : \"active\", \"rating\" : 100, \"score\" : 5 } 要 return 修改的文档，请将new:true选项添加到方法中。 如果没有文档与query条件匹配，则该方法返回null。 UPSERT 以下方法包括update选项的upsert: true选项，用于更新匹配的文档;如果不存在匹配的文档，则创建新文档： db.people.findAndModify({ query: { name: \"Gus\", state: \"active\", rating: 100 }, sort: { rating: 1 }, update: { $inc: { score: 1 } }, upsert: true }) 如果方法找到匹配的文档，则该方法执行更新。 如果方法不找到匹配的文档，则该方法创建一个新文档。因为该方法包含sort选项，所以它返回一个空文档{ }作为原始(pre-modification)文档： { } 如果方法确实**不包含sort选项，则该方法返回null。 null 返回新文档 以下方法包括upsert: true选项和new:true选项。该方法更新匹配的文档并返回更新的文档，或者，如果不存在匹配的文档，则插入文档并在value字段中返回新插入的文档。 在以下 example 中，people集合中的任何文档都不匹配query条件： db.people.findAndModify({ query: { name: \"Pascal\", state: \"active\", rating: 25 }, sort: { rating: 1 }, update: { $inc: { score: 1 } }, upsert: true, new: true }) 该方法返回新插入的文档： { \"_id\" : ObjectId(\"50f49ad6444c11ac2448a5d6\"), \"name\" : \"Pascal\", \"rating\" : 25, \"score\" : 1, \"state\" : \"active\" } 排序和删除 通过在rating字段上包含sort规范，以下 example 将从people集合中删除state value 为active且匹配文档中最低rating的单个文档： db.people.findAndModify( { query: { state: \"active\" }, sort: { rating: 1 }, remove: true } ) 该方法返回已删除的文档： { \"_id\" : ObjectId(\"52fba867ab5fdca1299674ad\"), \"name\" : \"XYZ123\", \"score\" : 1, \"state\" : \"active\", \"rating\" : 3 } 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.findAndModify({ query: { category: \"cafe\", status: \"a\" }, sort: { category: 1 }, update: { $set: { status: \"Updated\" } }, collation: { locale: \"fr\", strength: 1 } }); 该操作返回以下文档： { \"_id\" : 1, \"category\" : \"café\", \"status\" : \"A\" } 为 Array Update Operations 指定 arrayFilters 注意 arrayFilters 不适用于使用聚合管道的更新。 version 3.6 中的新内容。 从 MongoDB 3.6 开始，在更新 array 字段时，您可以指定arrayFilters来确定要更新的 array 元素。 更新元素 Match arrayFilters Criteria 使用以下文档创建集合students： db.students.insert([ { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] }, { \"_id\" : 2, \"grades\" : [ 98, 100, 102 ] }, { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } ]) 要修改grades array 中大于或等于100的所有元素，请使用过滤后的位置 operator $ [ ]和db.collection.findAndModify方法中的arrayFilters选项： db.students.findAndModify({ query: { grades: { $gte: 100 } }, update: { $set: { \"grades.$[element]\" : 100 } }, arrayFilters: [ { \"element\": { $gte: 100 } } ] }) 该操作更新单个文档的grades字段，在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } 更新 Array 文档的特定元素 使用以下文档创建集合students2： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 要修改grades array 中等级大于或等于85的所有元素的mean字段的 value，请使用过滤后的位置 operator $ [ ]和db.collection.findAndModify方法中的arrayFilters： db.students2.findAndModify({ query: { }, update: { $set: { \"grades.$[elem].mean\" : 100 } }, arrayFilters: [ { \"elem.grade\": { $gte: 85 } } ] }) 该操作更新单个文档的grades字段，在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } 使用聚合管道进行更新 从MongoDB 4.2开始，db.collection.findAndModify()可以接受聚合管道进行更新。管道可以包括以下阶段： $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 例如，students2使用以下文档创建一个集合： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 以下操作将查找一个_id字段等于 的文档，1并使用聚合管道total从该grades字段中计算一个新 字段： db.students2.findAndModify( { query: { \"_id\" : 1 }, update: [ { $set: { \"total\" : { $sum: \"$grades.grade\" } } } ], // The $set stage is an alias for ``$addFields`` stage new: true } ) 注意 $set管道中的使用是指聚集阶段 $set，而不是更新操作$set。 该操作返回更新的文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ], \"total\" : 250 } 也可以看看 可线性化通过 findAndModify 读取 译者：李冠飞 校对： 参见 原文 - db.collection.findAndModify() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/20-db.collection.findOne.html":{"url":"16-reference/03-method/01-js-collection/20-db.collection.findOne.html","title":"db.collection.findOne（）","keywords":"","body":" db.collection.findOne（） 在本页面 定义 行为 例子 定义 db.collection. findOne(查询，投影) 返回一个满足集合或视图上指定查询条件的文档。如果多个文档满足查询，则此方法根据自然订单返回第一个文档，该文档反映磁盘上文档的 order。在上限集合中，natural order 与 insert order 相同。如果没有文档满足查询，则该方法返回 null。 参数 类型 描述 query document 可选的。使用query operators指定查询选择条件。 projection document 可选的。使用投影操作员指定要 return 的字段。省略此参数以 return 匹配文档中的所有字段。 projection参数采用以下形式的文档： { field1: , field2: ... } 可以是以下包含或排除值之一： 1或true包括。即使未在投影参数中明确指定字段，findOne()方法也始终包含_id字段。 0或false排除。 projection 参数不能混合 include 和 exclude 规则，而 exception 则排除_id字段。 返回： 一个文档满足指定为此方法的第一个参数的条件。如果指定projection参数，findOne()将返回仅包含projection字段的文档。除非您明确排除，否则始终包含_id字段。 虽然类似于find()方法，findOne()方法返回文档而不是游标。 行为 客户端断开 从MongoDB 4.2开始，如果发出db.collection.findOne()断开连接的客户端在操作完成之前断开连接，则MongoDB将标记db.collection.findOne()为终止（即killOp在操作上）。 例子 使用空查询规范 以下操作从bios 系列返回单个文档： db.bios.findOne() 使用查询规范 以下操作返回bios 系列中的第一个匹配文档，其中嵌入文档name中的字段first以字母G 开头，或字段birth小于new Date('01/01/1945')： db.bios.findOne( { $or: [ { 'name.first' : /^G/ }, { birth: { $lt: new Date('01/01/1945') } } ] } ) 用投影 projection参数指定 return 的哪些字段。除非排除属于_id字段，否则该参数包含 include 或 exclude 规范，而不是两者。 指定 Return 的字段 以下操作在bios 系列中查找文档，并仅返回name，contribs和_id字段： db.bios.findOne( { }, { name: 1, contribs: 1 } ) 除了排除的字段外返回所有内容 以下操作返回bios 系列中的文档，其中contribs字段包含元素OOP，并返回除_id字段，name嵌入文档中的first字段和birth字段之外的所有字段： db.bios.findOne( { contribs: 'OOP' }, { _id: 0, 'name.first': 0, birth: 0 } ) findOne 结果文档 您不能将游标方法应用于findOne()的结果，因为返回单个文档。您可以直接访问该文档： var myDocument = db.bios.findOne(); if (myDocument) { var myName = myDocument.name; print (tojson(myName)); } 译者：李冠飞 校对： 参见 原文 - db.collection.findOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/21-db.collection.findOneAndDelete.html":{"url":"16-reference/03-method/01-js-collection/21-db.collection.findOneAndDelete.html","title":"db.collection.findOneAndDelete（）","keywords":"","body":" db.collection.findOneAndDelete（） 在本页面 定义 行为 定义 db.collection. findOneAndDelete(过滤器，选项) version 3.2 中的新内容。 根据filter和sort条件删除单个文档，返回已删除的文档。 findOneAndDelete()方法具有以下形式： db.collection.findOneAndDelete( , { projection: , sort: , maxTimeMS: , collation: } ) findOneAndDelete()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定空文档{ }以删除集合中返回的第一个文档。 如果未指定，则默认为空文档。 从 MongoDB 3.6.14(和 3.4.23)开始，如果查询参数不是文档，则操作错误。 projection document 可选的。 return 的字段子集。 要_返回返回文档中的所有字段，请省略此参数。 从 MongoDB 3.6.14(和 3.4.23)开始，如果投影参数不是文档，则操作错误。 sort document 可选的。为filter匹配的文档指定排序 order。 从 MongoDB 3.6.14(和 3.4.23)开始，如果 sort 参数不是文档，则操作错误。 见cursor.sort()。 maxTimeMS number 可选的。指定操作必须在其中完成的 time 限制(以毫秒为单位)。如果超出限制则引发错误。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 返回： 返回已删除的文档。 行为 findOneAndDelete()删除集合中与filter匹配的第一个匹配文档。 sort参数可用于影响更新的文档。 投影 projection参数采用以下形式的文档： { field1 : , field2 : ... } value 可以是以下任何一种： 1或true包括该字段。即使未在投影参数中明确说明，该方法也会返回_id字段。 0或false排除该字段。这可以在任何字段上使用，包括_id。 事务 db.collection.findOneAndDelete()可以在多文档交易中使用。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 删除文档 grades集合包含类似于以下内容的文档： { _id: 6305, name : \"A. MacDyver\", \"assignment\" : 5, \"points\" : 24 }, { _id: 6308, name : \"B. Batlock\", \"assignment\" : 3, \"points\" : 22 }, { _id: 6312, name : \"M. Tagnum\", \"assignment\" : 5, \"points\" : 30 }, { _id: 6319, name : \"R. Stiles\", \"assignment\" : 2, \"points\" : 12 }, { _id: 6322, name : \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 }, { _id: 6234, name : \"R. Stiles\", \"assignment\" : 1, \"points\" : 10 } 以下操作查找name : M. Tagnum并删除它的第一个文档： db.scores.findOneAndDelete( { \"name\" : \"M. Tagnum\" } ) 该操作返回已删除的原始文档： { _id: 6312, name: \"M. Tagnum\", \"assignment\" : 5, \"points\" : 30 } 排序和删除文档 grades集合包含类似于以下内容的文档： { _id: 6305, name : \"A. MacDyver\", \"assignment\" : 5, \"points\" : 24 }, { _id: 6308, name : \"B. Batlock\", \"assignment\" : 3, \"points\" : 22 }, { _id: 6312, name : \"M. Tagnum\", \"assignment\" : 5, \"points\" : 30 }, { _id: 6319, name : \"R. Stiles\", \"assignment\" : 2, \"points\" : 12 }, { _id: 6322, name : \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 }, { _id: 6234, name : \"R. Stiles\", \"assignment\" : 1, \"points\" : 10 } 以下操作首先查找name : \"A. MacDyver\"所有文档。然后在删除具有最低点 value 的文档之前按points升序排序： db.scores.findOneAndDelete( { \"name\" : \"A. MacDyver\" }, { sort : { \"points\" : 1 } } ) 该操作返回已删除的原始文档： { _id: 6322, name: \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 } 投影已删除的文档 以下操作使用 projection 仅返回返回文档中的_id和assignment字段： db.scores.findOneAndDelete( { \"name\" : \"A. MacDyver\" }, { sort : { \"points\" : 1 }, projection: { \"assignment\" : 1 } } ) 该操作返回包含assignment和_id字段的原始文档： { _id: 6322, \"assignment\" : 2 } 使用 Time 限制更新文档 以下操作设置 5ms time 限制以完成删除： try { db.scores.findOneAndDelete( { \"name\" : \"A. MacDyver\" }, { sort : { \"points\" : 1 }, maxTimeMS : 5 }; ); } catch(e){ print(e); } 如果操作超过 time 限制，则返回： Error: findAndModifyFailed failed: { \"ok\" : 0, \"errmsg\" : \"operation exceeded time limit\", \"code\" : 50 } 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.findOneAndDelete( { category: \"cafe\", status: \"a\" }, { collation: { locale: \"fr\", strength: 1 } } ); 该操作返回以下文档： { \"_id\" : 1, \"category\" : \"café\", \"status\" : \"A\" } 译者：李冠飞 校对： 参见 原文 - db.collection.findOneAndDelete() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/22-db.collection.findOneAndReplace.html":{"url":"16-reference/03-method/01-js-collection/22-db.collection.findOneAndReplace.html","title":"db.collection.findOneAndReplace（）","keywords":"","body":" db.collection.findOneAndReplace（） 在本页面 定义 行为 例子 定义 db.collection. findOneAndReplace(过滤，替换，选项) version 3.2 中的新内容。 根据filter和sort条件修改和替换单个文档。 findOneAndReplace()方法具有以下形式： db.collection.findOneAndReplace( , , { projection: , sort: , maxTimeMS: , upsert: , returnNewDocument: , collation: } ) findOneAndReplace()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定一个空文档{ }以替换集合中返回的第一个文档。 如果未指定，则默认为空文档。 从 MongoDB 3.6.14(和 3.4.23)开始，如果查询参数不是文档，则操作错误。 replacement document 替换文件。 不能包含更新 operators。 文档无法指定与替换文档不同的_id value。 projection document 可选的。 return 的字段子集。 要_return 匹配文档中的所有字段，请省略此参数。 从 MongoDB 3.6.14(和 3.4.23)开始，如果投影参数不是文档，则操作错误。 sort document 可选的。为filter匹配的文档指定排序 order。 从 MongoDB 3.6.14(和 3.4.23)开始，如果 sort 参数不是文档，则操作错误。 见cursor.sort()。 maxTimeMS number 可选的。指定操作必须在其中完成的 time 限制(以毫秒为单位)。如果超出限制则引发错误。 upsert boolean 可选的。当true，findOneAndReplace()时：如果没有文档与filter匹配，则从replacement参数插入文档。插入新文档后返回null，除非returnNewDocument是true。 用replacement文档替换与filter匹配的文档。 MongoDB 将_id字段添加到替换文档中，如果未在filter或replacement文档中指定。如果两者都存在_id，则值必须相等。 要避免多次 upsert，请确保query字段为唯一索引。 默认为false。 returnNewDocument boolean 可选的。当true时，返回替换文档而不是原始文档。 默认为false。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 返回： 返回原始文档，如果是returnNewDocument: true，则返回替换文档。 行为 findOneAndReplace()替换集合中与filter匹配的第一个匹配文档。 sort参数可用于影响修改哪个文档。 投影 projection参数采用以下形式的文档： { field1 : , field2 : ... } value 可以是以下任何一种： 1或true包括该字段。即使未在投影参数中明确说明，该方法也会返回_id字段。 0或false排除该字段。这可以在任何字段上使用，包括_id。 分片集合 要db.collection.findOneAndReplace()在分片集合上使用，查询过滤器必须在分片键上包含相等条件。 碎片键修改 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 事务 db.collection.findOneAndReplace()可以在多文档交易中使用。 如果该操作导致upsert，则该集合必须已经存在。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 替换文档 scores集合包含类似于以下内容的文档： { \"_id\" : 1521, \"team\" : \"Fearful Mallards\", \"score\" : 25000 }, { \"_id\" : 2231, \"team\" : \"Tactful Mooses\", \"score\" : 23500 }, { \"_id\" : 4511, \"team\" : \"Aquatic Ponies\", \"score\" : 19250 }, { \"_id\" : 5331, \"team\" : \"Cuddly Zebras\", \"score\" : 15235 }, { \"_id\" : 3412, \"team\" : \"Garrulous Bears\", \"score\" : 22300 } 以下操作查找score小于20000的第一个文档并替换它： db.scores.findOneAndReplace( { \"score\" : { $lt : 20000 } }, { \"team\" : \"Observant Badgers\", \"score\" : 20000 } ) 该操作返回已替换的原始文档： { \"_id\" : 2512, \"team\" : \"Aquatic Ponies\", \"score\" : 19250 } 如果returnNewDocument是 true，则操作将_return 替换文档。 排序和替换文档 scores集合包含类似于以下内容的文档： { \"_id\" : 1521, \"team\" : \"Fearful Mallards\", \"score\" : 25000 }, { \"_id\" : 2231, \"team\" : \"Tactful Mooses\", \"score\" : 23500 }, { \"_id\" : 4511, \"team\" : \"Aquatic Ponies\", \"score\" : 19250 }, { \"_id\" : 5331, \"team\" : \"Cuddly Zebras\", \"score\" : 15235 }, { \"_id\" : 3412, \"team\" : \"Garrulous Bears\", \"score\" : 22300 } 按score排序会更改操作的结果。以下操作按score升序对filter的结果进行排序，并替换最低得分文档： db.scores.findOneAndReplace( { \"score\" : { $lt : 20000 } }, { \"team\" : \"Observant Badgers\", \"score\" : 20000 }, { sort: { \"score\" : 1 } } ) 该操作返回已替换的原始文档： { \"_id\" : 5112, \"team\" : \"Cuddly Zebras\", \"score\" : 15235 } 有关此命令的 non-sorted 结果，请参见替换文档。 投射退回文件 scores集合包含类似于以下内容的文档： { \"_id\" : 1521, \"team\" : \"Fearful Mallards\", \"score\" : 25000 }, { \"_id\" : 2231, \"team\" : \"Tactful Mooses\", \"score\" : 23500 }, { \"_id\" : 4511, \"team\" : \"Aquatic Ponies\", \"score\" : 19250 }, { \"_id\" : 5331, \"team\" : \"Cuddly Zebras\", \"score\" : 15235 }, { \"_id\" : 3412, \"team\" : \"Garrulous Bears\", \"score\" : 22300 } 以下操作使用 projection 仅显示返回文档中的team字段： db.scores.findOneAndReplace( { \"score\" : { $lt : 22250 } }, { \"team\" : \"Therapeutic Hamsters\", \"score\" : 22250 }, { sort : { \"score\" : 1 }, project: { \"_id\" : 0, \"team\" : 1 } } ) 该操作返回仅包含team字段的原始文档： { \"team\" : \"Aquatic Ponies\"} 用 Time Limit 替换 Document 以下操作设置完成的 5ms time 限制： try { db.scores.findOneAndReplace( { \"score\" : { $gt : 25000 } }, { \"team\" : \"Emphatic Rhinos\", \"score\" : 25010 }, { maxTimeMS: 5 } ); } catch(e){ print(e); } 如果操作超过 time 限制，则返回： Error: findAndModifyFailed failed: { \"ok\" : 0, \"errmsg\" : \"operation exceeded time limit\", \"code\" : 50 } 用 Upsert 替换文档 如果没有匹配的filter，则以下操作使用upsert字段来插入替换文档： try { db.scores.findOneAndReplace( { \"team\" : \"Fortified Lobsters\" }, { \"_id\" : 6019, \"team\" : \"Fortified Lobsters\" , \"score\" : 32000}, { upsert : true, returnNewDocument: true } ); } catch (e){ print(e); } 该操作返回以下内容： { \"_id\" : 6019, \"team\" : \"Fortified Lobsters\", \"score\" : 32000 } 如果returnNewDocument是 false，则操作将返回null，因为 return 没有原始文档。 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.findOneAndReplace( { category: \"cafe\", status: \"a\" }, { category: \"cafÉ\", status: \"Replaced\" }, { collation: { locale: \"fr\", strength: 1 } } ); 该操作返回以下文档： { \"_id\" : 1, \"category\" : \"café\", \"status\" : \"A\" } 译者：李冠飞 校对： 参见 原文 - db.collection.findOneAndReplace() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/23-db.collection.findOneAndUpdate.html":{"url":"16-reference/03-method/01-js-collection/23-db.collection.findOneAndUpdate.html","title":"db.collection.findOneAndUpdate（）","keywords":"","body":" db.collection.findOneAndUpdate（） 在本页面 定义 行为 例子 定义 db.collection. findOneAndUpdate(过滤，更新，选项) version 3.2 中的新内容。 根据filter和sort条件更新单个文档。 findOneAndUpdate()方法具有以下形式： 更改了 version 3.6. db.collection.findOneAndUpdate( , , { projection: , sort: , maxTimeMS: , upsert: , returnNewDocument: , collation: , arrayFilters: [ , ... ] } ) findOneAndUpdate()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定一个空文档{ }以更新集合中返回的第一个文档。 如果未指定，则默认为空文档。 从 MongoDB 3.6.14(和 3.4.23)开始，如果查询参数不是文档，则操作错误。 update document 更新文件。 必须仅包含更新 operators。 projection document 可选的。 return 的字段子集。 要_返回返回文档中的所有字段，请省略此参数。 从 MongoDB 3.6.14(和 3.4.23)开始，如果投影参数不是文档，则操作错误。 sort document 可选的。为filter匹配的文档指定排序 order。 从 MongoDB 3.6.14(和 3.4.23)开始，如果 sort 参数不是文档，则操作错误。 见cursor.sort()。 maxTimeMS number 可选的。指定操作必须在其中完成的 time 限制(以毫秒为单位)。如果超出限制则引发错误。 upsert boolean 可选的。当true，findOneAndUpdate()时：如果没有文件匹配filter，则创建一个新文档。有关详细信息，请参阅upsert 行为。插入新文档后返回null，除非returnNewDocument是true。 更新与filter匹配的单个文档。 要避免多次 upsert，请确保filter字段为唯一索引。 默认为false。 returnNewDocument boolean 可选的。当true时，返回更新的文档而不是原始文档。 默认为false。 collation document 可选的。 指定要用于操作的整理。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 arrayFilters array 可选的。过滤器文档的 array，用于确定要在 array 字段上为更新操作修改哪些 array 元素。 在更新文档中，使用$ []过滤后的位置 operator 来定义标识符，然后在 array 过滤器文档中进行 reference。如果标识符未包含在更新文档中，则不能为标识符提供 array 过滤器文档。 注意 必须以小写字母开头，并且只包含字母数字字符。 您可以在更新文档中多次包含相同的标识符;但是，对于更新文档中的每个不同标识符($[identifier])，您必须指定恰好一个对应的 array 过滤器文档。也就是说，您不能为同一标识符指定多个 array 过滤器文档。对于 example，如果 update 语句包含标识符x(可能多次)，则不能为arrayFilters指定以下内容，其中包含 2 个单独的x过滤器文档： // INVALID [ { \"x.a\": { $gt: 85 } }, { \"x.b\": { $gt: 80 } } ] 但是，您可以在同一标识符上指定复合条件单个过滤器文档，例如以下示例： // Example 1 [ { $or: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 2 [ { $and: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 3 [ { \"x.a\": { $gt: 85 }, \"x.b\": { $gt: 80 } } ]例如，请参阅为 Array Update Operations 指定 arrayFilters。 version 3.6 中的新内容。 返回： 返回原始文档，如果是returnNewDocument: true，则返回更新的文档。 行为 findOneAndUpdate()更新集合中与filter匹配的第一个匹配文档。 sort参数可用于影响更新的文档。 投影 projection参数采用以下形式的文档： { field1 : , field2 : ... } value 可以是以下任何一种： 1或true包括该字段。即使未在投影参数中明确说明，该方法也会返回_id字段。 0或false排除该字段。这可以在任何字段上使用，包括_id。 分片集合 要db.collection.findOneAndUpdate()在分片集合上使用，查询过滤器必须在分片键上包含相等条件。 碎片键修改 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 要用于 db.collection.findOneAndUpdate()更新分片键： 您必须在运行mongos无论是在 事务或作为重试写。千万不能直接在碎片颁发运行。 您必须在查询过滤器的完整分片键上包含相等条件。例如，如果一个集合messages 使用的片键，更新为一个文件的碎片关键，你必须包括在查询过滤器。您可以根据需要在查询中包括其他字段。{ country : 1, userid : 1 }``country: , userid: 事务 db.collection.findOneAndUpdate()可以在多文档交易中使用。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 现有的收藏和交易 在事务内部，您可以指定对现有集合的读/写操作。如果db.collection.findOneAndUpdate()导致upsert，则该集合必须已经存在。 如果该操作导致upsert，则该集合必须已经存在。 写的担忧和事务 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 例子 更新文档 grades集合包含类似于以下内容的文档： { _id: 6305, name : \"A. MacDyver\", \"assignment\" : 5, \"points\" : 24 }, { _id: 6308, name : \"B. Batlock\", \"assignment\" : 3, \"points\" : 22 }, { _id: 6312, name : \"M. Tagnum\", \"assignment\" : 5, \"points\" : 30 }, { _id: 6319, name : \"R. Stiles\", \"assignment\" : 2, \"points\" : 12 }, { _id: 6322, name : \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 }, { _id: 6234, name : \"R. Stiles\", \"assignment\" : 1, \"points\" : 10 } 以下操作查找name : R. Stiles的第一个文档，并按5递增得分： db.grades.findOneAndUpdate( { \"name\" : \"R. Stiles\" }, { $inc: { \"points\" : 5 } } ) 该操作在更新之前返回原始文档： { _id: 6319, name: \"R. Stiles\", \"assignment\" : 2, \"points\" : 12 } 如果returnNewDocument是 true，则操作将_return 更新文档。 排序和更新文档 grades集合包含类似于以下内容的文档： { _id: 6305, name : \"A. MacDyver\", \"assignment\" : 5, \"points\" : 24 }, { _id: 6308, name : \"B. Batlock\", \"assignment\" : 3, \"points\" : 22 }, { _id: 6312, name : \"M. Tagnum\", \"assignment\" : 5, \"points\" : 30 }, { _id: 6319, name : \"R. Stiles\", \"assignment\" : 2, \"points\" : 12 }, { _id: 6322, name : \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 }, { _id: 6234, name : \"R. Stiles\", \"assignment\" : 1, \"points\" : 10 } 以下操作更新name : \"A. MacDyver\"的文档。操作通过points升序对匹配文档进行排序，以更新具有最少点的匹配文档。 db.grades.findOneAndUpdate( { \"name\" : \"A. MacDyver\" }, { $inc : { \"points\" : 5 } }, { sort : { \"points\" : 1 } } ) 该操作在更新之前返回原始文档： { _id: 6322, name: \"A. MacDyver\", \"assignment\" : 2, \"points\" : 14 } 投射退回文件 以下操作使用 projection 仅显示返回文档中的_id，points和assignment字段： db.grades.findOneAndUpdate( { \"name\" : \"A. MacDyver\" }, { $inc : { \"points\" : 5 } }, { sort : { \"points\" : 1 }, projection: { \"assignment\" : 1, \"points\" : 1 } } ) 该操作仅返回原始文档，其中仅包含projection文档和_id字段中指定的字段，因为它未在投影文件中明确禁止(_id: 0)。 { \"_id\" : 6322, \"assignment\" : 2, \"points\" : 14 } 使用 Time 限制更新文档 以下操作设置 5ms time 限制以完成更新： try { db.grades.findOneAndUpdate( { \"name\" : \"A. MacDyver\" }, { $inc : { \"points\" : 5 } }, { sort: { \"points\" : 1 }, maxTimeMS : 5 }; ); } catch(e){ print(e); } 如果操作超过 time 限制，则返回： Error: findAndModifyFailed failed: { \"ok\" : 0, \"errmsg\" : \"operation exceeded time limit\", \"code\" : 50 } 使用 Upsert 更新文档 如果没有匹配filter，则以下操作使用upsert字段来插入更新文档： try { db.grades.findOneAndUpdate( { \"name\" : \"A.B. Abracus\" }, { $set: { \"name\" : \"A.B. Abracus\", \"assignment\" : 5}, $inc : { \"points\" : 5 } }, { sort: { \"points\" : 1 }, upsert:true, returnNewDocument : true } ); } catch (e){ print(e); } 该操作返回以下内容： { \"_id\" : ObjectId(\"5789249f1c49e39a8adc479a\"), \"name\" : \"A.B. Abracus\", \"assignment\" : 5, \"points\" : 5 } 如果returnNewDocument是 false，则操作将返回null，因为 return 没有原始文档。 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.findOneAndUpdate( { category: \"cafe\" }, { $set: { status: \"Updated\" } }, { collation: { locale: \"fr\", strength: 1 } } ); 该操作返回以下文档： { \"_id\" : 1, \"category\" : \"café\", \"status\" : \"A\" } 为 Array Update Operations 指定 arrayFilters version 3.6 中的新内容。 从 MongoDB 3.6 开始，在更新 array 字段时，您可以指定arrayFilters来确定要更新的 array 元素。 更新元素 Match arrayFilters Criteria 使用以下文档创建集合students： db.students.insert([ { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] }, { \"_id\" : 2, \"grades\" : [ 98, 100, 102 ] }, { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } ]) 要修改grades array 中大于或等于100的所有元素，请使用过滤后的位置 operator $ []和db.collection.findOneAndUpdate方法中的arrayFilters选项： db.students.findOneAndUpdate( { grades: { $gte: 100 } }, { $set: { \"grades.$[element]\" : 100 } }, { arrayFilters: [ { \"element\": { $gte: 100 } } ] } ) 该操作更新单个文档的grades字段，在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } 更新 Array 文档的特定元素 使用以下文档创建集合students2： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 要修改grades array 中等级大于或等于85的所有元素的mean字段的 value，请使用过滤后的位置 operator $ []和db.collection.findOneAndUpdate方法中的arrayFilters： db.students2.findOneAndUpdate( { }, { $set: { \"grades.$[elem].mean\" : 100 } }, { arrayFilters: [ { \"elem.grade\": { $gte: 85 } } ] } ) 该操作更新单个文档的grades字段，在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } 使用聚合管道进行更新 从MongoDB 4.2开始，db.collection.findOneAndUpdate()可以接受聚合管道进行更新。管道可以包括以下阶段： $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 例如，students2使用以下文档创建一个集合： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 以下操作将查找一个_id字段等于 的文档，1并使用聚合管道total从该grades字段中计算一个新 字段： db.students2.findOneAndUpdate( { _id : 1 }, [ { $set: { \"total\" : { $sum: \"$grades.grade\" } } } ], // The $set stage is an alias for ``$addFields`` stage { returnNewDocument: true } ) 注意 该$set管道中的使用是指聚集阶段 $set，而不是更新操作$set。 该操作返回更新的文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" :85, \"std\" : 6 } ], \"total\" : 250 } 译者：李冠飞 校对： 参见 原文 - db.collection.findOneAndUpdate() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/24-db.collection.getIndexes.html":{"url":"16-reference/03-method/01-js-collection/24-db.collection.getIndexes.html","title":"db.collection.getIndexes（）","keywords":"","body":" db.collection.getIndexes（） 在本页面 定义 行为 必需的访问权 输出 定义 db.collection. getIndexes () 返回一个 array，其中包含用于标识和描述集合上现有索引的文档列表。您必须在集合上调用db.collection.getIndexes()。例如： db.collection.getIndexes() 将collection更改为要为其返回索引信息的集合的 name。 行为 从MongoDB 4.2开始，如果发出db.collection.getIndexes()断开连接的客户端在操作完成之前断开连接，则MongoDB将标记db.collection.getIndexes()为终止（即killOp在操作上）。 必需的访问权 要db.collection.getIndexes()在强制执行访问控制时运行，使用者必须listIndexes对该集合具有访问权限。 内置角色read提供了db.collection.getIndexes()为数据库中的集合运行所需的特权。 输出 db.collection.getIndexes()返回包含集合索引信息的 array 文档。索引信息包括用于创建索引的键和选项。有关键和索引选项的信息，请参阅db.collection.createIndex()。 译者：李冠飞 校对： 参见 原文 - db.collection.getIndexes() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/25-db.collection.getShardDistribution.html":{"url":"16-reference/03-method/01-js-collection/25-db.collection.getShardDistribution.html","title":"db.collection.getShardDistribution（）","keywords":"","body":" db.collection.getShardDistribution（） 在本页面 定义 输出 定义 db.collection. getShardDistribution () 打印分片集合的数据分布统计信息。 建议 在运行方法之前，使用flushRouterConfig命令刷新缓存的路由 table，以避免返回集合的陈旧分发信息。刷新后，run db.collection.getShardDistribution()为您希望 build 索引的集合。 例如： db.adminCommand( { flushRouterConfig: \"test.myShardedCollection\" } ); db.getSiblingDB(\"test\").myShardedCollection.getShardDistribution(); 也可以看看 分片 输出 Sample 输出 以下是分片集合分布的 sample 输出： Shard shard-a at shard-a/MyMachine.local:30000,MyMachine.local:30001,MyMachine.local:30002 data : 38.14Mb docs : 1000003 chunks : 2 estimated data per chunk : 19.07Mb estimated docs per chunk : 500001 Shard shard-b at shard-b/MyMachine.local:30100,MyMachine.local:30101,MyMachine.local:30102 data : 38.14Mb docs : 999999 chunks : 3 estimated data per chunk : 12.71Mb estimated docs per chunk : 333333 Totals data : 76.29Mb docs : 2000002 chunks : 5 Shard shard-a contains 50% data, 50% docs in cluster, avg obj size on shard : 40b Shard shard-b contains 49.99% data, 49.99% docs in cluster, avg obj size on shard : 40b 输出字段 Shard at data : docs : chunks : estimated data per chunk : / estimated docs per chunk : / Shard at data : docs : chunks : estimated data per chunk : / estimated docs per chunk : / Totals data : docs : chunks : Shard contains % data, % docs in cluster, avg obj size on shard : stats.shards[ ].avgObjSize Shard contains % data, % docs in cluster, avg obj size on shard : stats.shards[ ].avgObjSize 输出信息显示： 是一个包含分片 name 的 string。 是一个包含 host name(s 的 string。 是一个包含数据大小的数字，包括度量单位(如： b，Mb)。 是一个报告分片中文档数量的数字。 是一个报告分片中块数的数字。 /是计算的 value，它反映了分片的每个块的估计数据大小，包括度量单位(如： b，Mb)。 /是计算出的 value，它反映了碎片每个块的估计文档数。 是一个 value，用于报告分片集合中数据的总大小，包括度量单位。 是一个 value，用于报告分片集合中的文档总数。 是一个计算出的数字，用于报告所有分片的块数，例如： = + 是一个计算的 value，对于每个分片，数据大小反映为集合总数据大小的百分比，对于 example： = / 是一个计算的 value，对于每个分片，它反映了文档的数量，作为集合的文档总数的百分比，对于 example： = / stats.shards[ ].avgObjSize是反映分片的平均 object 大小(包括度量单位)的数字。 译者：李冠飞 校对： 参见 原文 - db.collection.getShardDistribution() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/26-db.collection.getShardVersion.html":{"url":"16-reference/03-method/01-js-collection/26-db.collection.getShardVersion.html","title":"db.collection.getShardVersion（）","keywords":"","body":" db.collection.getShardVersion（） db.collection. getShardVersion () 此方法返回有关分片集群中数据的 state 的信息，该信息在诊断分片 cluster 的基础问题时很有用。 仅供内部和诊断使用。 译者：李冠飞 校对： 参见 原文 - db.collection.getShardVersion() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/27-db.collection.hideIndex.html":{"url":"16-reference/03-method/01-js-collection/27-db.collection.hideIndex.html","title":"db.collection.hideIndex()","keywords":"","body":" db.collection.hideIndex() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.collection.hideIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/28-db.collection.insert.html":{"url":"16-reference/03-method/01-js-collection/28-db.collection.insert.html","title":"db.collection.insert（）","keywords":"","body":" db.collection.insert（） 在本页面 定义 行为 例子 写结果 BulkWriteResult 定义 db.collection. insert () 将一个或多个文档插入集合中。 insert()方法具有以下语法： db.collection.insert( , { writeConcern: , ordered: } ) 参数 类型 描述 document 文件或 array 要插入集合的文档或 array 文档。 writeConcern writeConcern 可选的。表示写关注的文件。省略使用默认写入问题。见写关注。 version 2.6 中的新内容。 ordered boolean 可选的。如果true，则在 array 中执行文档的有序插入，如果其中一个文档发生错误，MongoDB 将 return 而不处理 array 中的其余文档。 如果false，执行无序的 insert，如果其中一个文档发生错误，继续处理 array 中的其余文档。 默认为true。 更改 version 2.6：insert()返回包含操作状态的 object。 返回： 单个插入的写结果 object。 ABulkWriteResult object 用于批量插入。 行为 写关注 insert()方法使用插入命令，该命令使用默认的写关注。要指定其他写入问题，请在 options 参数中包含写入关注点。 创建集合 如果集合不存在，则insert()方法将创建集合。 _id 字段 如果文档未指定_id字段，则 MongoDB 将添加_id字段，并在插入之前为文档指定唯一的ObjectId。大多数驱动程序创建一个 ObjectId 并插入_id字段，但如果驱动程序或 application 没有，则mongod将创建并填充_id。 如果文档包含_id字段，则_id value 在集合中必须是唯一的，以避免重复的 key 错误。 事务 db.collection.insert()可以在多文档交易中使用。 集合必须已经存在。事务中不允许执行会导致创建新集合的插入操作。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 以下示例将文档插入products集合。如果集合不存在，insert()方法将创建集合。 插入文档而不指定_id 字段 在以下 example 中，传递给insert()方法的文档不包含_id字段： db.products.insert( { item: \"card\", qty: 15 } ) 在 insert 期间，mongod将创建_id字段并为其分配唯一的ObjectId value，由插入的文档验证： { \"_id\" : ObjectId(\"5063114bd386d8fadbd6b004\"), \"item\" : \"card\", \"qty\" : 15 } 当操作为 run 时，ObjectId值特定于机器和 time。因此，您的值可能与 example 中的值不同。 插入指定_id 字段的文档 在下面的示例中，传递给insert()方法的文档包含_id字段。 _id的 value 在集合中必须是唯一的，以避免重复的 key 错误。 db.products.insert( { _id: 10, item: \"box\", qty: 20 } ) 该操作在products集合中插入以下文档： { \"_id\" : 10, \"item\" : \"box\", \"qty\" : 20 } 插入多个文档 以下 example 通过将 array 文档传递给insert()方法来执行三个文档的批量插入。默认情况下，MongoDB 执行有序的 insert。对于有序插入，如果在其中一个文档的 insert 期间发生错误，MongoDB 将返回错误而不处理 array 中的其余文档。 array 中的文档不需要具有相同的字段。例如，array 中的第一个文档有一个_id字段和一个type字段。由于第二个和第三个文档不包含_id字段，mongod将在 insert 期间为第二个和第三个文档创建_id字段： db.products.insert( [ { _id: 11, item: \"pencil\", qty: 50, type: \"no.2\" }, { item: \"pen\", qty: 20 }, { item: \"eraser\", qty: 25 } ] ) 该操作插入了以下三个文件： { \"_id\" : 11, \"item\" : \"pencil\", \"qty\" : 50, \"type\" : \"no.2\" } { \"_id\" : ObjectId(\"51e0373c6f35bd826f47e9a0\"), \"item\" : \"pen\", \"qty\" : 20 } { \"_id\" : ObjectId(\"51e0373c6f35bd826f47e9a1\"), \"item\" : \"eraser\", \"qty\" : 25 } 执行无序 Insert 以下 example 执行三个文档的无序插入。对于无序插入，如果在其中一个文档的 insert 期间发生错误，MongoDB 将继续插入 array 中的其余文档。 db.products.insert( [ { _id: 20, item: \"lamp\", qty: 50, type: \"desk\" }, { _id: 21, item: \"lamp\", qty: 20, type: \"floor\" }, { _id: 22, item: \"bulk\", qty: 100 } ], { ordered: false } ) 覆盖默认写入关注 对副本集的以下操作指定\"w: majority\"的\"w: majority\"，其wtimeout为 5000 毫秒，以便该方法在写入传播到大多数表决副本集成员后返回，或者该方法在 5 秒后超时。 在 version 3.0 中更改：在以前的版本中，majority指的是副本集的大多数成员而不是大多数投票成员。 db.products.insert( { item: \"envelopes\", qty : 100, type: \"Clasp\" }, { writeConcern: { w: \"majority\", wtimeout: 5000 } } ) 写结果 传递单个文档时，insert()返回WriteResult object。 成功的结果 insert()返回包含操作状态的写结果 object。成功后，写结果 object 包含有关插入文档数量的信息： WriteResult({ \"nInserted\" : 1 }) 写关注错误 如果insert()方法遇到写入关注错误，则结果包括WriteResult.writeConcernError字段： WriteResult({ \"nInserted\" : 1, \"writeConcernError\" : { \"code\" : 64, \"errmsg\" : \"waiting for replication timed out at shard-a\" } }) 与写关注无关的错误 如果insert()方法遇到 non-write 关注错误，则结果包括WriteResult.writeError字段： WriteResult({ \"nInserted\" : 0, \"writeError\" : { \"code\" : 11000, \"errmsg\" : \"insertDocument :: caused by :: 11000 E11000 duplicate key error index: test.foo.$_id_ dup key: { : 1.0 }\" } }) BulkWriteResult 传递 array 文档时，insert()返回BulkWriteResult() object。有关详细信息，请参阅BulkWriteResult()。 译者：李冠飞 校对： 参见 原文 - db.collection.insert() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/29-db.collection.insertOne.html":{"url":"16-reference/03-method/01-js-collection/29-db.collection.insertOne.html","title":"db.collection.insertOne（）","keywords":"","body":" db.collection.insertOne（） 在本页面 定义 行为 例子 定义 db.collection. insertOne () version 3.2 中的新内容。 将文档插入集合中。 insertOne()方法具有以下语法： db.collection.insertOne( , { writeConcern: } ) 参数 类型 描述 document document 要插入集合的文档。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 返回： 包含以下内容的文档：一个布尔值acknowledged，true好像该操作在运行时带有 写关注点，或者false禁用了写关注点。insertedId具有_id插入文档的值的字段。 行为 集合创建 如果集合不存在，则insertOne()方法将创建集合。 _id 字段 如果文档未指定_id字段，则mongod将添加_id字段，并在插入之前为文档指定唯一的ObjectId。大多数驱动程序创建一个 ObjectId 并插入_id字段，但如果驱动程序或 application 没有，mongod将创建并填充_id。 如果文档包含_id字段，则_id value 在集合中必须是唯一的，以避免重复的 key 错误。 Explainability insertOne()与db.collection.explain()不兼容。 请改用insert()。 错误处理 出错时，insertOne()抛出writeError或writeConcernError exception。 事务 db.collection.insertOne()可以在多文档交易中使用。 集合必须已经存在。事务中不允许执行会导致创建新集合的插入操作。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 插入文档而不指定_id 字段 在以下 example 中，传递给insertOne()方法的文档不包含_id字段： try { db.products.insertOne( { item: \"card\", qty: 15 } ); } catch (e) { print (e); }; 该操作返回以下文档： { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"56fc40f9d735c28df206d078\") } 由于文档不包含_id，mongod创建并添加_id字段并为其分配唯一的ObjectId value。 当操作为 run 时，ObjectId值特定于机器和 time。因此，您的值可能与 example 中的值不同。 插入指定_id 字段的文档 在下面的示例中，传递给insertOne()方法的文档包含_id字段。 _id的 value 在集合中必须是唯一的，以避免重复的 key 错误。 try { db.products.insertOne( { _id: 10, item: \"box\", qty: 20 } ); } catch (e) { print (e); } 该操作返回以下内容： { \"acknowledged\" : true, \"insertedId\" : 10 } 为的任何 key 插入重复的 value，例如_id，会抛出 exception。以下尝试使用已存在的_id value 插入文档： try { db.products.insertOne( { _id: 10, \"item\" : \"packing peanuts\", \"qty\" : 200 } ); } catch (e) { print (e); } 由于_id: 10已存在，因此抛出以下 exception： WriteError({ \"index\" : 0, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: inventory.products index: _id_ dup key: { : 10.0 }\", \"op\" : { \"_id\" : 10, \"item\" : \"packing peanuts\", \"qty\" : 200 } }) 增加写作关注 给定三个成员副本集，以下操作指定majority wtimeout，wtimeout 100： try { db.products.insertOne( { \"item\": \"envelopes\", \"qty\": 100, type: \"Self-Sealing\" }, { writeConcern: { w : \"majority\", wtimeout : 100 } } ); } catch (e) { print (e); } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) 也可以看看 要插入多个文档，请参阅db.collection.insertMany() 译者：李冠飞 校对： 参见 原文 - db.collection.insertOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/30-db.collection.insertMany.html":{"url":"16-reference/03-method/01-js-collection/30-db.collection.insertMany.html","title":"db.collection.insertMany（）","keywords":"","body":" db.collection.insertMany（） 在本页面 定义 行为 例子 定义 db.collection. insertMany () version 3.2 中的新内容。 将多个文档插入集合中。 insertMany()方法具有以下语法： db.collection.insertMany( [ , , ... ], { writeConcern: , ordered: } ) 参数 类型 描述 document document 要插入集合的 array 文档。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 ordered boolean 可选的。一个 boolean，指定mongod实例是否应该执行有序或无序的 insert。默认为true。 返回： 一个文档包含： boolean acknowledged as true如果操作使用写关注或false运行如果写入关注被禁用 为_id每个成功插入的文档 行为 给定 array 文档，insertMany()将 array 中的每个文档插入到集合中。 执行操作 默认情况下，文档插入 order。 如果ordered设置为 false，则文档以无序格式插入，并且可以通过mongod重新排序以增加 performance。如果使用无序insertMany()，Applications 不应该依赖于插入的排序。 每个 group 中的操作数不能超过数据库maxWriteBatchSize的 value。从 MongoDB 3.6 开始，这个 value 是100,000。此值显示在isMaster.maxWriteBatchSize字段中。 此限制可防止出现超大错误消息的问题。如果 group 超过此limit，则 client 驱动程序将 group 分成较小的组，其计数小于或等于限制的 value。例如，对于100,000的maxWriteBatchSize value，如果队列包含200,000操作，则驱动程序将创建 2 个组，每个组具有100,000个操作。 注意 使用 high-level API 时，驱动程序仅将 group 分为较小的组。如果直接使用db.runCommand()(对于 example，在编写驱动程序时)，MongoDB 在尝试执行超出限制的写入批处理时会抛出错误。 从 MongoDB 3.6 开始，一旦单个批处理的错误报告变得太大，MongoDB 会将所有剩余的错误消息截断为空的 string。目前，一旦至少有 2 个错误消息，总大小大于1MB，则开始。 尺寸和分组机制是内部性能细节，在将来的版本中可能会有所变化。 在分片集合上执行有序操作列表通常比执行无序列表慢，因为对于有序列表，每个操作必须等待上一个操作完成。 集合创建 如果集合不存在，则insertMany()在成功写入时创建集合。 _id 字段 如果文档未指定_id字段，则mongod添加_id字段并为文档指定唯一的ObjectId。大多数驱动程序创建一个 ObjectId 并插入_id字段，但如果驱动程序或 application 没有创建，mongod将创建并填充_id。 如果文档包含_id字段，则_id value 在集合中必须是唯一的，以避免重复的 key 错误。 Explainability insertMany()与db.collection.explain()不兼容。 请改用insert()。 错误处理 插入抛出BulkWriteError exception。 排除写关注错误，有序操作在发生错误后停止，而无序操作继续处理队列中任何剩余的写操作。 写入关注错误显示在writeConcernErrors字段中，而所有其他错误显示在writeErrors字段中。如果遇到错误，则显示成功写入操作的数量，而不是插入的_id 列表。有序操作显示遇到的单个错误，而无序操作显示 array 中的每个错误。 事务 db.collection.insertMany()可以在多文档交易中使用。 集合必须已经存在。事务中不允许执行会导致创建新集合的插入操作。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 以下示例将文档插入products集合。 插入多个文档而不指定_id 字段 以下 example 使用db.collection.insertMany()来插入不包含_id字段的文档： try { db.products.insertMany( [ { item: \"card\", qty: 15 }, { item: \"envelope\", qty: 20 }, { item: \"stamps\" , qty: 30 } ] ); } catch (e) { print (e); } 该操作返回以下文档： { \"acknowledged\" : true, \"insertedIds\" : [ ObjectId(\"562a94d381cb9f1cd6eb0e1a\"), ObjectId(\"562a94d381cb9f1cd6eb0e1b\"), ObjectId(\"562a94d381cb9f1cd6eb0e1c\") ] } 由于文档不包含_id，mongod为每个文档创建并添加_id字段，并为其分配唯一的ObjectId value。 当操作为 run 时，ObjectId值特定于机器和 time。因此，您的值可能与 example 中的值不同。 Insert 若干文档指定_id 字段 以下 example/operation 使用insertMany()来插入包含_id字段的文档。 _id的 value 在集合中必须是唯一的，以避免重复的 key 错误。 try { db.products.insertMany( [ { _id: 10, item: \"large box\", qty: 20 }, { _id: 11, item: \"small box\", qty: 55 }, { _id: 12, item: \"medium box\", qty: 30 } ] ); } catch (e) { print (e); } 该操作返回以下文档： { \"acknowledged\" : true, \"insertedIds\" : [ 10, 11, 12 ] } 为的任何 key(例如_id)插入重复的 value 会抛出 exception。以下尝试使用已存在的_id value 插入文档： try { db.products.insertMany( [ { _id: 13, item: \"envelopes\", qty: 60 }, { _id: 13, item: \"stamps\", qty: 110 }, { _id: 14, item: \"packing tape\", qty: 38 } ] ); } catch (e) { print (e); } 由于_id: 13已存在，因此抛出以下 exception： BulkWriteError({ \"writeErrors\" : [ { \"index\" : 0, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: inventory.products index: _id_ dup key: { : 13.0 }\", \"op\" : { \"_id\" : 13, \"item\" : \"stamps\", \"qty\" : 110 } } ], \"writeConcernErrors\" : [ ], \"nInserted\" : 1, \"nUpserted\" : 0, \"nMatched\" : 0, \"nModified\" : 0, \"nRemoved\" : 0, \"upserted\" : [ ] }) 请注意，插入了一个文档：_id: 13的第一个文档将成功插入，但第二个 insert 将失败。这也将阻止插入队列中剩余的其他文档。 使用ordered到false时，insert 操作将继续使用任何剩余文档。 无序插入 以下尝试使用_id字段和ordered: false插入多个文档。 array 文档包含两个具有重复_id字段的文档。 try { db.products.insertMany( [ { _id: 10, item: \"large box\", qty: 20 }, { _id: 11, item: \"small box\", qty: 55 }, { _id: 11, item: \"medium box\", qty: 30 }, { _id: 12, item: \"envelope\", qty: 100}, { _id: 13, item: \"stamps\", qty: 125 }, { _id: 13, item: \"tape\", qty: 20}, { _id: 14, item: \"bubble wrap\", qty: 30} ], { ordered: false } ); } catch (e) { print (e); } 该操作抛出以下 exception： BulkWriteError({ \"writeErrors\" : [ { \"index\" : 2, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: inventory.products index: _id_ dup key: { : 11.0 }\", \"op\" : { \"_id\" : 11, \"item\" : \"medium box\", \"qty\" : 30 } }, { \"index\" : 5, \"code\" : 11000, \"errmsg\" : \"E11000 duplicate key error collection: inventory.products index: _id_ dup key: { : 13.0 }\", \"op\" : { \"_id\" : 13, \"item\" : \"tape\", \"qty\" : 20 } } ], \"writeConcernErrors\" : [ ], \"nInserted\" : 5, \"nUpserted\" : 0, \"nMatched\" : 0, \"nModified\" : 0, \"nRemoved\" : 0, \"upserted\" : [ ] }) 由于重复的_id值，item: \"medium box\"和item: \"tape\"的文档无法插入nInserted表示插入了剩余的 5 个文档。 使用写关注 给定三个成员副本集，以下操作指定majority majority和wtimeout 100： try { db.products.insertMany( [ { _id: 10, item: \"large box\", qty: 20 }, { _id: 11, item: \"small box\", qty: 55 }, { _id: 12, item: \"medium box\", qty: 30 } ], { w: \"majority\", wtimeout: 100 } ); } catch (e) { print (e); } 如果主要和至少一个辅助设备在 100 毫秒内确认每个写入操作，则返回： { \"acknowledged\" : true, \"insertedIds\" : [ ObjectId(\"562a94d381cb9f1cd6eb0e1a\"), ObjectId(\"562a94d381cb9f1cd6eb0e1b\"), ObjectId(\"562a94d381cb9f1cd6eb0e1c\") ] } 如果副本集中所有必需节点确认写入操作所需的总 time 大于wtimeout，则在wtimeout期间过后将显示以下writeConcernError。 此操作返回： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) 译者：李冠飞 校对： 参见 原文 - db.collection.insertMany() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/31-db.collection.isCapped.html":{"url":"16-reference/03-method/01-js-collection/31-db.collection.isCapped.html","title":"db.collection.isCapped（）","keywords":"","body":" db.collection.isCapped（） db.collection. isCapped () 返回： 如果集合是上限集合则返回true，否则返回false。 也可以看看 上限集合 译者：李冠飞 校对： 参见 原文 - db.collection.isCapped() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/32-db.collection.latencyStats.html":{"url":"16-reference/03-method/01-js-collection/32-db.collection.latencyStats.html","title":"db.collection.latencyStats（）","keywords":"","body":" db.collection.latencyStats（） 在本页面 定义 输出 例子 定义 db.collection. latencyStats(选项) db.collection.latencyStats()返回给定集合的延迟统计信息。它是一个包装 $collStats。 此方法具有以下形式： db.collection.latencyStats( { histograms: } ) histograms参数是可选的 boolean。如果histograms: true则latencyStats()将延迟直方图添加到 return 文档。 也可以看看 $collStats 输出 latencyStats()返回包含字段latencyStats的文档，其中包含以下字段： 字段 描述 reads 读取请求的延迟统计信息。 writes 写请求的延迟统计信息。 commands 数据库命令的延迟统计信息。 每个字段都包含一个包含以下字段的嵌入式文档： 字段 描述 latency 一个64位整数，以毫秒为单位给出总的组合延迟。 ops 一个64位整数，给出自启动以来对集合执行的操作总数。 histogram 嵌入式文档的 array，每个都代表一个延迟范围。每个文档涵盖以前文档范围的两倍。对于介于 2048 微秒和大约 1 秒之间的上限值，直方图包括 half-steps。 此字段仅在latencyStats: { histograms: true }选项的情况下存在。输出中省略了具有零count的空范围。 每个文档都包含以下字段：字段 :描述 micros :一个64位整数，以毫秒为单位给出当前等待时间范围的上限时间。该文档的范围介于上一个文档的 micros值（不包括此值）和该文档的 值（包括不包括在内）之间。 count :一个64位整数，给出延迟小于或等于的操作数micros。 例如，如果collStats返回以下直方图：histogram: [ { micros: NumberLong(1), count: NumberLong(10) }, { micros: NumberLong(2), count: NumberLong(1) }, { micros: NumberLong(4096), count: NumberLong(1) }, { micros: NumberLong(16384), count: NumberLong(1000) }, { micros: NumberLong(49152), count: NumberLong(100) } ] 这表示： 10 次操作占用 1 微秒或更少， 1 操作范围(1,2)微秒， 1 操作范围内的范围(3072,4096)微秒， 1000 次操作(12288,16384)和范围内的 100 次操作(32768,49152)。 例子 您可以在mongo shell 中运行latencyStats()，如下所示： db.data.latencyStats( { histograms: true } ).pretty() latencyStats()返回如下文档： { \"ns\" : \"test.data\", \"localTime\" : ISODate(\"2016-11-01T21:56:28.962Z\"), \"latencyStats\" : { \"reads\" : { \"histogram\" : [ { \"micros\" : NumberLong(16), \"count\" : NumberLong(6) }, { \"micros\" : NumberLong(512), \"count\" : NumberLong(1) } ], \"latency\" : NumberLong(747), \"ops\" : NumberLong(7) }, \"writes\" : { \"histogram\" : [ { \"micros\" : NumberLong(64), \"count\" : NumberLong(1) }, { \"micros\" : NumberLong(24576), \"count\" : NumberLong(1) } ], \"latency\" : NumberLong(26845), \"ops\" : NumberLong(2) }, \"commands\" : { \"histogram\" : [ ], \"latency\" : NumberLong(0), \"ops\" : NumberLong(0) } } } 译者：李冠飞 校对： 参见 原文 - db.collection.latencyStats() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/33-db.collection.mapReduce.html":{"url":"16-reference/03-method/01-js-collection/33-db.collection.mapReduce.html","title":"db.collection.mapReduce（）","keywords":"","body":" db.collection.mapReduce（） 在本页面 map功能要求 reduce功能要求 选项 finalize功能要求 Map-Reduce 例子 输出 附加信息 db.collection. mapReduce( map，reduce，{，，，，，，，}) 注意 从4.2版开始，MongoDB弃用： 地图-reduce选项来创建一个新的分片集合以及使用的分片供选择的map-reduce。要输出到分片集合，请首先创建分片集合。MongoDB 4.2还不建议替换现有分片集合。 nonAtomic：false选项的显式规范。 db.collection.mapReduce()方法为MapReduce命令提供了包装。 注意 视图不支持 map-reduce 操作。 db.collection.mapReduce()具有以下语法： db.collection.mapReduce( , , { out: , query: , sort: , limit: , finalize: , scope: , jsMode: , verbose: , bypassDocumentValidation: } ) db.collection.mapReduce()采用以下参数： 参数 类型 描述 map function 一个 JavaScript function 将与key关联或“maps”并发出key和 value pair。 有关详细信息，请参阅map Function 的要求。 reduce function 一个 JavaScript function，它“减少”到一个 object 所有与特定key关联的values。 有关详细信息，请参阅reduce Function 的要求。 options document 为db.collection.mapReduce()指定其他参数的文档。 bypassDocumentValidation boolean 可选的。允许MapReduce在操作期间绕过文档验证。这使您可以插入不符合验证要求的文档。 version 3.2 中的新内容。 下表描述了db.collection.mapReduce()可以接受的其他参数。 领域 类型 描述 out string or document 指定 map-reduce 操作结果的位置。您可以输出到集合，输出到具有操作的集合，或输出内联。在对集合的主要成员执行 map-reduce 操作时，您可以输出到集合;在次要成员上，您只能使用inline输出。 有关详细信息，请参阅选项。 query document 使用query operators指定选择条件，以确定输入到map function 的文档。 sort document 对输入文档进行排序。此选项对优化很有用。对于 example，请将 sort key 指定为与 emit key 相同，以便减少 reduce 操作。 sort key 必须位于此集合的现有索引中。 limit number 指定输入map function 的最大文档数。 finalize function 可选的。遵循reduce方法并修改输出。 有关详细信息，请参阅finalize Function 的要求。 scope document 指定map，reduce和finalize函数中可访问的 global 变量。 jsMode boolean 指定是否在执行map和reduce函数之间将中间数据转换为 BSON 格式。 默认为false。 如果false：1. 在内部，MongoDB 将map function 发出的 JavaScript objects 转换为 BSON objects。然后在调用reduce function 时将这些 BSON objects 转换回 JavaScript objects。 2. map-reduce 操作将中间 BSON object 放置在临时的 on-disk 存储中。这允许 map-reduce 操作在任意大的数据集上执行。 如果true：1. 在内部，map function 期间发出的 JavaScript objects 仍然是 JavaScript objects。无需为reduce function 转换 objects，这可以加快执行速度。 2. 您只能将jsMode用于映射器emit() function 中少于 500,000 个不同key arguments 的结果_set。 verbose boolean 指定是否在结果信息中包含timing信息。将verbose设置为true以包含timing信息。 默认为false。 collation document 可选的。 指定要用于操作的排序规则。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：排序规则：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 注意 map-reduce operations， group 命令和$where 运算表达式无法访问 mongo shell 中可用的某些 global 函数或 properties，例如 db。 可用的 PropertiesAvailable 函数 以下JavaScript函数和属性可用于 和 运算符表达式：map-reduce operations、$where 可用属性 可用功能 argsMaxKeyMinKey assert()BinData()DBPointer()DBRef()doassert()emit()gc()HexData()hex_md5()isNumber()isObject()ISODate()isString()Map()MD5()NumberInt()NumberLong()ObjectId()print()printjson()printjsononeline()sleep()Timestamp()tojson()tojsononeline()tojsonObject()UUID()version() map功能要求 map function 负责将每个输入文档转换为零个或多个文档。它可以访问scope参数中定义的变量，并具有以下原型： function() { ... emit(key, value); } map function 具有以下要求： 在map function 中，在 function 中将当前文档作为this引用。 map function 不应出于任何原因访问数据库。 map function 应该是纯的，或者在 function 之外没有影响(即：side effects.) 单个发射只能容纳 MongoDB 的最大 BSON 文件大小的一半。 map function 可以选择多次调用emit(key,value)来创建一个将key与value相关联的输出文档。 在MongoDB 4.2和更早版本中，单个发射只能容纳MongoDB 最大BSON文档大小的一半。从版本4.4开始，MongoDB删除了此限制。 从MongoDB 4.4开始，它的功能mapReduce不再支持范围（即BSON类型15）的已弃用JavaScript 。该map 函数必须是BSON类型的String（即BSON类型2）或BSON类型的JavaScript（即BSON类型13）。要确定变量的范围，请使用 scope参数。 map自版本4.2.1起，该功能不建议在范围内使用JavaScript 以下map function 将调用emit(key,value) 0 或 1 次，具体取决于输入文档的status字段的 value： function() { if (this.status == 'A') emit(this.cust_id, 1); } 以下map function 可能会多次调用emit(key,value)，具体取决于输入文档的items字段中的元素数： function() { this.items.forEach(function(item){ emit(item.sku, 1); }); } reduce功能要求 reduce function 具有以下原型： function(key, values) { ... return result; } reduce function 表现出以下行为： reduce function 不应该访问数据库，甚至不应该执行读操作。 reduce function 不应影响外部系统。 MongoDB 不会为只有一个 value 的 key 调用reduce function。 values参数是一个 array，其元素是value objects，它们被“映射”到key。 MongoDB 可以为同一个 key 多次调用reduce function。在这种情况下，该 key 的reduce function 的前一个输出将成为该 key 的下一个reduce function 调用的输入值之一。 reduce function 可以访问scope参数中定义的变量。 reduce的输入不得大于 MongoDB 的最大 BSON 文件大小的一半。返回大型文档然后在后续的reduce步骤中将其连接在一起时，可能会违反此要求。 从版本4.2.1开始，MongoDB在该功能的作用域（即BSON类型15）中弃用JavaScript reduce。要确定变量的范围，请改用scope 参数。 因为可以为同一个 key 多次调用reduce function，所以以下 properties 需要 true： return object 的类型必须与map function 发出的value的类型相同。 reduce function 必须是关联的。以下语句必须是 true： reduce(key, [ C, reduce(key, [ A, B ]) ] ) == reduce( key, [ C, A, B ] ) reduce function 必须是幂等的。确保以下语句是 true： reduce( key, [ reduce(key, valuesArray) ] ) == reduce( key, valuesArray ) reduce function 应该是可交换的：也就是说，valuesArray中元素的 order 不应该影响reduce function 的输出，因此以下语句是 true： reduce( key, [ A, B ] ) == reduce( key, [ B, A ] ) 选项 您可以为out参数指定以下选项： 输出到集合 此选项输出到新集合，并且在副本集的辅助成员上不可用。 out: 输出到带有 Action 的 Collection 注意 从4.2版开始，MongoDB弃用： 地图-reduce选项来创建一个新的分片集合以及使用的分片供选择的map-reduce。要输出到分片集合，请首先创建分片集合。MongoDB 4.2还不建议替换现有分片集合。 nonAtomic：false选项的显式规范。 此选项仅在将已存在的集合传递给out时可用。它不适用于副本集 的辅助成员。 out: { : [, db: ] [, sharded: ] [, nonAtomic: ] } 当您输出带有操作的集合时，out具有以下参数： ：指定以下操作之一： replace 如果具有的集合存在，则替换的内容。 merge 如果输出集合已存在，则将新结果与现有结果合并。如果现有文档与新结果具有相同的 key，则覆盖该现有文档。 reduce 如果输出集合已存在，则将新结果与现有结果合并。如果现有文档与新结果具有相同的 key，则将reduce function 应用于新文档和现有文档，并使用结果覆盖现有文档。 db : 可选的。您希望 map-reduce 操作写入其输出的数据库的 name。默认情况下，这将是与输入集合相同的数据库。 sharded : 可选的。如果true并且您已在输出数据库上启用了分片，则 map-reduce 操作将使用_id字段分割输出集合作为分片 key。 如果true和collectionName是现有的未整数集合，map-reduce 将失败。 nonAtomic : 注意 开始在MongoDB中4.2，明确设置nonAtomic到false已被弃用。 可选的。将输出操作指定为 non-atomic。这仅对merge和reduce输出模式应用，这可能需要几分钟才能执行。 默认情况下nonAtomic是false，map-reduce 操作在 post-processing 期间锁定数据库。 如果nonAtomic是true，则 post-processing step 会阻止 MongoDB 锁定数据库：在此 time 期间，其他 clients 将能够读取输出集合的中间状态。 输出内联 在 memory 中执行 map-reduce 操作并 return 结果。此选项是副本集的辅助成员上out的唯一可用选项。 out: { inline: 1 } 结果必须符合BSON 文档的最大大小。 finalize功能要求 finalize function 具有以下原型： function(key, reducedValue) { ... return modifiedObject; } finalize function 接收value 作为其 arguments 和reduce function 的reducedValue。意识到： finalize function 不应出于任何原因访问数据库。 finalize function 应该是纯的，或者在 function 之外没有影响(即：side effects.) finalize function 可以访问scope参数中定义的变量。 从版本4.2.1开始，MongoDB在该功能的作用域（即BSON类型15）中弃用JavaScript finalize。要确定变量的范围，请改用scope 参数。 Map-Reduce 例子 聚合管道作为替代 聚合管道比map-reduce提供更好的性能和更一致的接口。 各种map-reduce表达式可以使用被重写聚合管道运算符，诸如$group， $merge等 下面的示例包括聚合管道备选方案。 orders使用以下文档创建样本集合： db.orders.insertMany([ { _id: 1, cust_id: \"Ant O. Knee\", ord_date: new Date(\"2020-03-01\"), price: 25, items: [ { sku: \"oranges\", qty: 5, price: 2.5 }, { sku: \"apples\", qty: 5, price: 2.5 } ], status: \"A\" }, { _id: 2, cust_id: \"Ant O. Knee\", ord_date: new Date(\"2020-03-08\"), price: 70, items: [ { sku: \"oranges\", qty: 8, price: 2.5 }, { sku: \"chocolates\", qty: 5, price: 10 } ], status: \"A\" }, { _id: 3, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-08\"), price: 50, items: [ { sku: \"oranges\", qty: 10, price: 2.5 }, { sku: \"pears\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 4, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-18\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 5, cust_id: \"Busby Bee\", ord_date: new Date(\"2020-03-19\"), price: 50, items: [ { sku: \"chocolates\", qty: 5, price: 10 } ], status: \"A\"}, { _id: 6, cust_id: \"Cam Elot\", ord_date: new Date(\"2020-03-19\"), price: 35, items: [ { sku: \"carrots\", qty: 10, price: 1.0 }, { sku: \"apples\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 7, cust_id: \"Cam Elot\", ord_date: new Date(\"2020-03-20\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 8, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-20\"), price: 75, items: [ { sku: \"chocolates\", qty: 5, price: 10 }, { sku: \"apples\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 9, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-20\"), price: 55, items: [ { sku: \"carrots\", qty: 5, price: 1.0 }, { sku: \"apples\", qty: 10, price: 2.5 }, { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" }, { _id: 10, cust_id: \"Don Quis\", ord_date: new Date(\"2020-03-23\"), price: 25, items: [ { sku: \"oranges\", qty: 10, price: 2.5 } ], status: \"A\" } ]) 返回每位客户的总价格 通过cust_id对orders集合执行 map-reduce 操作到 group，并为每个cust_id计算price的总和： 定义map功能来处理每个输入文档： 在 function 中，this指的是 map-reduce 操作正在处理的文档。 function maps 为每个文档的cust_id并发出cust_id和price键值对。 var mapFunction1 = function() { emit(this.cust_id, this.price); }; 使用两个参数 keyCustId和valuesPrices定义相应的 reduce function： valuesPrices是一个数组，其元素是 map function 发出的price值，并按keyCustId分组。 function 将valuesPrice array 缩减为其元素的总和。 var reduceFunction1 = function(keyCustId, valuesPrices) { return Array.sum(valuesPrices); }; 使用mapFunction1 map function 和reduceFunction1 reduce function 对orders集合中的所有文档执行 map-reduce。 db.orders.mapReduce( mapFunction1, reduceFunction1, { out: \"map_reduce_example\" } ) 此操作将结果输出到名为map_reduce_example的集合。如果map_reduce_example集合已存在，则操作将使用此 map-reduce 操作的结果替换内容。 查询map_reduce_example集合以验证结果： db.map_reduce_example.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Don Quis\", \"value\" : 155 } 聚合替代 使用可用的聚合管道运算符，您可以重写map-reduce操作，而无需定义自定义函数： db.orders.aggregate([ { $group: { _id: \"$cust_id\", value: { $sum: \"$price\" } } }, { $out: \"agg_alternative_1\" } ]) $group由平台组cust_id并计算value字段（参见$sum）。该 value字段包含price每个的总计cust_id。 该阶段将以下文档输出到下一阶段： { \"_id\" : \"Don Quis\", \"value\" : 155 } { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } 然后，$out将输出写入collection agg_alternative_1。或者，您可以使用 $merge代替$out。 查询agg_alternative_1集合以验证结果： db.agg_alternative_1.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"Ant O. Knee\", \"value\" : 95 } { \"_id\" : \"Busby Bee\", \"value\" : 125 } { \"_id\" : \"Cam Elot\", \"value\" : 60 } { \"_id\" : \"Don Quis\", \"value\" : 155 } 使用 Item 的平均数量计算 Order 和总数量 在此事例中，您将对orders集合执行 map-reduce 操作，以处理ord_date value 大于01/01/2012的所有文档。操作按item.sku字段分组，并计算每个sku的订单数量和订购总数量。然后，该操作将为每个值计算每个订单的平均数量，并将结果合并到输出集合中。合并结果时，如果现有文档的密钥与新结果相同，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 定义map功能来处理每个输入文档： 在 function 中，this指的是 map-reduce 操作正在处理的文档。 对于每个 item，函数将sku与一个新的 object value相关联，该对象 value包含订单的count和_ite用于 order 并发出sku和value对。 var mapFunction2 = function() { for (var idx = 0; idx 使用两个 arguments keySKU和countObjVals定义相应的 reduce function： countObjVals是一个 array，其元素是映射到 map function 传递给 reducer function 的分组keySKU值的 objects。 function 将countObjVals array 缩减为包含count和qty字段的单个 object reducedValue。 在reducedVal中，count字段包含来自各个 array 元素的count字段的总和，qty字段包含来自各个 array 元素的qty字段的总和。 var reduceFunction2 = function(keySKU, countObjVals) { reducedVal = { count: 0, qty: 0 }; for (var idx = 0; idx 使用两个 arguments key和reducedVal定义 finalize function。 function 修改reducedVal object 以添加名为avg的计算字段并返回修改后的 object： var finalizeFunction2 = function (key, reducedVal) { reducedVal.avg = reducedVal.qty/reducedVal.count; return reducedVal; }; 使用mapFunction2，reduceFunction2和finalizeFunction2函数对orders集合执行 map-reduce 操作。 db.orders.mapReduce( mapFunction2, reduceFunction2, { out: { merge: \"map_reduce_example\" }, query: { ord_date: { $gt: new Date('01/01/2012') } }, finalize: finalizeFunction2 } ) 此操作使用query字段仅选择ord_date大于new Date(01/01/2012)的文档。然后它将结果输出到集合map_reduce_example。如果map_reduce_example集合已存在，则操作将现有内容与此 map-reduce 操作的结果合并。也就是说，如果现有文档具有与新结果相同的密钥，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 查询map_reduce_example2集合以验证结果： db.map_reduce_example2.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"apples\", \"value\" : { \"count\" : 3, \"qty\" : 30, \"avg\" : 10 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 6, \"qty\" : 58, \"avg\" : 9.666666666666666 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } 聚合替代 使用可用的聚合管道运算符，您可以重写map-reduce操作，而无需定义自定义函数： db.orders.aggregate( [ { $match: { ord_date: { $gte: new Date(\"2020-03-01\") } } }, { $unwind: \"$items\" }, { $group: { _id: \"$items.sku\", qty: { $sum: \"$items.qty\" }, orders_ids: { $addToSet: \"$_id\" } } }, { $project: { value: { count: { $size: \"$orders_ids\" }, qty: \"$qty\", avg: { $divide: [ \"$qty\", { $size: \"$orders_ids\" } ] } } } }, { $merge: { into: \"agg_alternative_3\", on: \"_id\", whenMatched: \"replace\", whenNotMatched: \"insert\" } } ] ) 该$match阶段仅选择ord_date大于或等于的那些文档。new Date(\"2020-03-01\") 该$unwinds阶段按items数组字段细分文档，以输出每个数组元素的文档。例如： { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 1, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-01T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"apples\", \"qty\" : 5, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 8, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 2, \"cust_id\" : \"Ant O. Knee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 70, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 3, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-08T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"pears\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 4, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-18T00:00:00Z\"), \"price\" : 25, \"items\" : { \"sku\" : \"oranges\", \"qty\" : 10, \"price\" : 2.5 }, \"status\" : \"A\" } { \"_id\" : 5, \"cust_id\" : \"Busby Bee\", \"ord_date\" : ISODate(\"2020-03-19T00:00:00Z\"), \"price\" : 50, \"items\" : { \"sku\" : \"chocolates\", \"qty\" : 5, \"price\" : 10 }, \"status\" : \"A\" } ... $group由平台组items.sku，计算每个SKU： qty字段。该qty字段包含qty每个订单的总数items.sku（请参阅参考资料$sum）。 orders_ids阵列。该orders_ids字段包含不同顺序的阵列_id的对items.sku（参见 $addToSet）。 { \"_id\" : \"chocolates\", \"qty\" : 15, \"orders_ids\" : [ 2, 5, 8 ] } { \"_id\" : \"oranges\", \"qty\" : 63, \"orders_ids\" : [ 4, 7, 3, 2, 9, 1, 10 ] } { \"_id\" : \"carrots\", \"qty\" : 15, \"orders_ids\" : [ 6, 9 ] } { \"_id\" : \"apples\", \"qty\" : 35, \"orders_ids\" : [ 9, 8, 1, 6 ] } { \"_id\" : \"pears\", \"qty\" : 10, \"orders_ids\" : [ 3 ] } $project阶段调整输出文档的形状以反映map-reduce的输出，该输出具有两个字段_id和 value。该$projectsets： value.count的尺寸在orders_ids数组中。（请参阅$size。） value.qty在qty输入文档的字段。 value.avg每订购数量的平均数目。（请参阅$divide和$size。） { \"_id\" : \"apples\", \"value\" : { \"count\" : 4, \"qty\" : 35, \"avg\" : 8.75 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 7, \"qty\" : 63, \"avg\" : 9 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } 最后，$merge将输出写入collection agg_alternative_3。如果现有文档的密钥_id与新结果相同，则该操作将覆盖现有文档。如果不存在具有相同密钥的文档，则该操作将插入该文档。 查询agg_alternative_3集合以验证结果： db.agg_alternative_3.find().sort( { _id: 1 } ) 该操作返回以下文档： { \"_id\" : \"apples\", \"value\" : { \"count\" : 4, \"qty\" : 35, \"avg\" : 8.75 } } { \"_id\" : \"carrots\", \"value\" : { \"count\" : 2, \"qty\" : 15, \"avg\" : 7.5 } } { \"_id\" : \"chocolates\", \"value\" : { \"count\" : 3, \"qty\" : 15, \"avg\" : 5 } } { \"_id\" : \"oranges\", \"value\" : { \"count\" : 7, \"qty\" : 63, \"avg\" : 9 } } { \"_id\" : \"pears\", \"value\" : { \"count\" : 1, \"qty\" : 10, \"avg\" : 10 } } 输出 db.collection.mapReduce()方法的输出与MapReduce命令的输出相同。有关db.collection.mapReduce()输出的信息，请参阅MapReduce命令的产量部分。 限制 MongoDB驱动程序会自动将afterClusterTime设置为与因果一致的会话相关联的操作。从MongoDB 4.2开始， db.collection.mapReduce()不再支持 afterClusterTime。因此， db.collection.mapReduce()不能与因果一致的会话相关联 。 附加信息 对 Map Function 进行故障排除 排除 Reduce Function 问题 MapReduce命令 聚合 Map-Reduce 执行增量 Map-Reduce 译者：李冠飞 校对： 参见 原文 - db.collection.mapReduce() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/34-db.collection.reIndex.html":{"url":"16-reference/03-method/01-js-collection/34-db.collection.reIndex.html","title":"db.collection.reIndex（）","keywords":"","body":" db.collection.reIndex（） 在本页面 行为 db.collection. reIndex () db.collection.reIndex()删除集合上的所有索引并重新创建它们。对于具有大量数据 and/or 大量索引的集合，此操作可能很费时。 警告 对于大多数用户，不需要db.collection.reIndex()操作。 避免对副本集中的集合 running db.collection.reIndex()。 不要对分片 cluster 中的集合运行db.collection.reIndex()。 在版本4.2中进行了更改： MongoDB不允许db.collection.reIndex()在上运行mongos，对分片db.collection.reIndex()群集中的集合实施了更严格的限制 。 行为 注意 对于副本_set，db.collection.reIndex()不会从主节点传播到从节点。 db.collection.reIndex()只会影响单个mongod实例。 重要 由于多索引构建中描述的逻辑，db.collection.reIndex()始终在前台构建索引。 对于将featureCompatibilityVersion（fCV）设置为\"4.0\" 或更早版本的MongoDB 2.6至MongoDB版本， 如果现有文档的索引条目超过，则MongoDB 不会在集合上创建索引。Maximum Index Key Length 资源锁定 在版本4.2.2中更改。 对于MongoDB 4.2.2及更高版本，请db.collection.reIndex()在集合上获得排他（W）锁，并阻止对该集合进行其他操作，直到完成。 对于MongoDB 4.0.0到4.2.1，db.collection.reIndex() 获得全局排他（W）锁并在上阻止其他操作， mongod直到完成。 对于MongoDB 3.6及更早版本，这些操作 db.collection.reIndex()在数据库上获得排他（W）锁，并阻塞数据库上的其他操作，直到完成。 有关锁定MongoDB的更多信息，请参阅FAQ：并发。 也可以看看 索引 译者：李冠飞 校对： 参见 原文 - db.collection.reIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/35-db.collection.remove.html":{"url":"16-reference/03-method/01-js-collection/35-db.collection.remove.html","title":"db.collection.remove（）","keywords":"","body":" db.collection.remove（） 在本页面 定义 行为 例子 写结果 定义 db.collection. remove () 从集合中删除文档。 db.collection.remove()方法可以具有两种语法之一。 remove()方法可以采用查询文档和可选的justOne boolean： db.collection.remove( , ) 或者该方法可以采用查询文档和可选的删除选项文档： version 2.6 中的新内容。 db.collection.remove( , { justOne: , writeConcern: , collation: } ) 参数 类型 描述 query document 使用query operators指定删除条件。要删除集合中的所有文档，请传递空文档({})。 justOne boolean 可选的。要将删除限制为仅一个文档，请设置为true。省略使用false的默认 value 并删除符合删除条件的所有文档。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。见写关注。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 collation document 可选的。 指定要用于操作的排序规则。 排序规则允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：collation：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 remove()返回包含操作状态的 object。 返回： 包含操作状态的写结果 object。 行为 写关注 remove()方法使用删除命令，该命令使用默认的写关注。要指定其他写入问题，请在 options 参数中包含写入关注点。 查询注意事项 默认情况下，remove()删除 match query表达式的所有文档。指定justOne选项以限制删除单个文档的操作。要删除按指定 order 排序的单个文档，请使用findAndModify()方法。 删除多个文档时，删除操作可能与对集合的其他读 and/or 写操作交错。 上限集合 您不能将remove()方法与上限集合一起使用。 分片集合 指定justOne选项的分片集合的所有remove()操作必须包含查询规范中的碎片 key或_id字段。 remove()操作在分片集合中指定justOne，不包含碎片 key或_id字段返回错误。 事务 db.collection.remove()可以在多文档事务中使用。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 以下是remove()方法的示例。 从集合中删除所有文档 要删除集合中的所有文档，请使用空查询文档{}调用去掉方法。以下操作将删除bios 系列中的所有文档： db.bios.remove( { } ) 此操作不等同于drop()方法。 要从集合中删除所有文档，使用drop()方法删除整个集合(包括索引)，然后重新创建集合并重建索引可能更有效。 删除符合的所有文档 要删除匹配删除条件的文档，请使用参数调用remove()方法： 以下操作将从集合products中删除qty大于20的所有文档： db.products.remove( { qty: { $gt: 20 } } ) 覆盖默认写入关注 对副本集的以下操作将删除集合products中qty大于20的所有文档，并指定\"w: majority\"的\"w: majority\"，其wtimeout为 5000 毫秒，以便该方法在写入传播到大多数表决副本集后返回成员或方法在 5 秒后超时。 db.products.remove( { qty: { $gt: 20 } }, { writeConcern: { w: \"majority\", wtimeout: 5000 } } ) 删除匹配条件的单个文档 要删除匹配删除条件的第一个文档，请使用query条件调用去掉方法，并将justOne参数设置为true或1。 以下操作从集合products中删除第一个文档，其中qty大于20： db.products.remove( { qty: { $gt: 20 } }, true ) 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"cafe\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.remove( { category: \"cafe\", status: \"A\" }, { collation: { locale: \"fr\", strength: 1 } } ) 写结果 更改了 version 2.6. 成功的结果 remove()返回包含操作状态的写结果 object。成功后，写结果 object 包含有关删除的文档数量的信息： WriteResult({ \"nRemoved\" : 4 }) 也可以看看 WriteResult.nRemoved 写下关注错误 如果remove()方法遇到写入关注错误，则结果包括WriteResult.writeConcernError字段： WriteResult({ \"nRemoved\" : 21, \"writeConcernError\" : { \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" } }) 也可以看看 WriteResult.hasWriteConcernError() 与写关注无关的错误 如果remove()方法遇到 non-write 关注错误，则结果包括WriteResult.writeError字段： WriteResult({ \"nRemoved\" : 0, \"writeError\" : { \"code\" : 2, \"errmsg\" : \"unknown top level operator: $invalidFieldName\" } }) 也可以看看 WriteResult.hasWriteError() 译者：李冠飞 校对： 参见 原文 - db.collection.remove() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/36-db.collection.renameCollection.html":{"url":"16-reference/03-method/01-js-collection/36-db.collection.renameCollection.html","title":"db.collection.renameCollection（）","keywords":"","body":" db.collection.renameCollection（） 在本页面 定义 行为 例子 定义 db.collection. renameCollection(target，dropTarget) 重命名集合。为renameCollection 数据库命令提供包装。 参数 类型 描述 target string 集合的新 name。将 string 括在引号中。 dropTarget boolean 可选的。如果true，mongod在重命名集合之前删除了renameCollection的目标。默认的 value 是false。 行为 db.collection.renameCollection()方法通过更改与给定集合关联的元数据在集合中运行。 有关其他警告和消息，请参阅文档renameCollection。 警告 db.collection.renameCollection()方法和renameCollection命令将使打开的游标无效，这会中断当前返回数据的查询。 对于Change Streams，该 db.collection.renameCollection()方法和 renameCollection命令为在源或目标集合上打开的任何现有 Change Streams创建一个 无效事件。 该方法具有以下限制： db.collection.renameCollection()无法在数据库之间移动集合。使用renameCollection进行这些重命名操作。 分片集合不支持db.collection.renameCollection()。 您无法重命名意见。 资源锁定 在版本4.2中进行了更改。 renameCollection()在操作期间获得对源集合和目标集合的排他锁。集合上的所有后续操作都必须等到 renameCollection()完成。在MongoDB 4.2之前的版本中，renameCollection需要获得独占数据库锁才能重命名同一数据库内的集合 。 与mongodump交互 如果客户端在转储过程中发出db.collection.renameCollection()，则mongodump以--oplog失败开始。看到mongodump.--oplog获取更多信息。 例子 在集合 object 上调用db.collection.renameCollection()方法。例如： db.rrecord.renameCollection(\"record\") 此操作会将rrecord集合重命名为record。如果目标 name(i.e.record)是现有集合的 name，则操作将失败。 译者：李冠飞 校对： 参见 原文 - db.collection.renameCollection() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/37-db.collection.replaceOne.html":{"url":"16-reference/03-method/01-js-collection/37-db.collection.replaceOne.html","title":"db.collection.replaceOne（）","keywords":"","body":" db.collection.replaceOne（） 在本页面 定义 行为 例子 定义 db.collection. replaceOne(过滤，替换，选项) version 3.2 中的新内容。 根据过滤器替换集合中的单个文档。 replaceOne()方法具有以下形式： db.collection.replaceOne( , , { upsert: , writeConcern: , collation: } ) replaceOne()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定一个空文档{ }以替换集合中返回的第一个文档。 replacement document 替换文件。 不能包含更新 operators。 upsert boolean 可选的。当true，replaceOne()时：如果没有文档与filter匹配，则从replacement参数插入文档。 将与filter匹配的文档替换为replacement文档。如果未在filter或replacement文档中指定_id如果filter或replacement文档中未指定。 MongoDB，则会将_id字段添加到替换文档中。如果两者都存在_id，则值必须相等。 要避免多次 upsert，请确保query字段为唯一索引。 默认为false。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 collation document 可选的。 指定要用于操作的排序规则。 排序规则允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 排序规则选项具有以下语法：collation：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他校对字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，MongoDB 使用先前版本中用于 string 比较的简单二进制比较。 您无法为操作指定多个排序规则。对于 example，您不能为每个字段指定不同的排序规则，或者如果使用排序执行查找，则不能对查找使用一个排序规则，而对排序使用另一个排序规则。 version 3.4 中的新内容。 hint document 可选的。指定用于支持过滤器的索引的文档或字符串。该选项可以采用索引规范文档或索引名称字符串。如果指定的索引不存在，则操作错误。有关示例，请参阅为replaceOne指定提示。4.2.1版中的新功能。 返回： 包含以下内容的文档：一个布尔值acknowledged，就true好像该操作在运行时带有 写关注关系或false是否禁用了写关注关系 matchedCount包含匹配文档数 modifiedCount包含已修改文档数 upsertedId包含_id for upserted 文档 行为 replaceOne()使用replacement文档替换集合中与filter匹配的第一个匹配文档。 upsert 如果upsert: true和filter没有文档匹配，则 db.collection.replaceOne()根据replacement文档创建一个新文档。 如果在分片集合上指定upsert: true，则必须在filter 中包含完整的分片键。有关分片集合的其他 db.collection.replaceOne()行为，请参见分片集合。 请参阅用Upsert替换。 上限收藏 如果替换操作更改了文档大小，则操作将失败。 分片集合 从MongoDB 4.2开始，首先db.collection.replaceOne()尝试使用查询过滤器定位单个分片。如果该操作无法通过查询过滤器定位到单个分片，则它将尝试以替换文档定位。 在早期版本中，该操作尝试使用替换文档作为目标。 如果替换分片集合中的文档，则替换文档必须包含分片键。附加要求适用于分片集合和分片 密钥修改上的更新。 upsert在分片集合上 从MongoDB 4.2开始，对于db.collection.replaceOne() 包含upsert: true分片集合并在分片集合上的操作，您必须在filter中包含完整的分片键。 碎片键修改 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 要用于db.collection.replaceOne()更新分片键： 您必须在运行mongos无论是在 事务或作为重试写。千万不能直接在碎片颁发运行。 您必须在查询过滤器的完整分片键上包含相等条件。例如，如果一个集合messages 使用{ country : 1, userid : 1 }的片键，更新为一个文件的碎片关键，你必须包括country: , userid: 在查询过滤器。您可以根据需要在查询中包括其他字段。 事务 db.collection.replaceOne()可以在多文档交易中使用。 如果该操作导致upsert，则该集合必须已经存在。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 替换 restaurant集合包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\" }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 0 } 以下操作替换name: \"Central Perk Cafe\"所在的单个文档： try { db.restaurant.replaceOne( { \"name\" : \"Central Perk Cafe\" }, { \"name\" : \"Central Pork Cafe\", \"Borough\" : \"Manhattan\" } ); } catch (e){ print(e); } 操作返回： { \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } 如果未找到匹配项，则操作将返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0 } 如果未找到 match，则设置upsert: true将插入文档。见替换为 Upsert 替换为 Upsert restaurant集合包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 0 } 以下操作尝试使用upsert : true替换文档，使用upsert : true： try { db.restaurant.replaceOne( { \"name\" : \"Pizza Rat's Pizzaria\" }, { \"_id\": 4, \"name\" : \"Pizza Rat's Pizzaria\", \"Borough\" : \"Manhattan\", \"violations\" : 8 }, { upsert: true } ); } catch (e){ print(e); } 从upsert : true开始，文档是根据replacement文档插入的。操作返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0, \"upsertedId\" : 4 } 该集合现在包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 0 }, { \"_id\" : 4, \"name\" : \"Pizza Rat's Pizzaria\", \"Borough\" : \"Manhattan\", \"violations\" : 8 } 替换为写关注 给定三个成员副本集，以下操作指定majority majority和wtimeout 100： try { db.restaurant.replaceOne( { \"name\" : \"Pizza Rat's Pizzaria\" }, { \"name\" : \"Pizza Rat's Pub\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { w: \"majority\", wtimeout: 100 } ); } catch (e) { print(e); } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"café\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.replaceOne( { category: \"cafe\", status: \"a\" }, { category: \"cafÉ\", status: \"Replaced\" }, { collation: { locale: \"fr\", strength: 1 } } ); 指定hint用于replaceOne 4.2.1版中的新功能。 members使用以下文档创建样本集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" }, { \"_id\" : 3, \"member\" : \"lmn123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 4, \"member\" : \"pqr123\", \"status\" : \"D\", \"points\" : 20, \"misc1\" : \"Deactivated\", \"misc2\" : null }, { \"_id\" : 5, \"member\" : \"ijk123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 6, \"member\" : \"cde123\", \"status\" : \"A\", \"points\" : 86, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" } ]) 在集合上创建以下索引： db.members.createIndex( { status: 1 } ) db.members.createIndex( { points: 1 } ) 以下更新操作明确暗示要使用索引：{ status: 1 } 注意 如果指定的索引不存在，则操作错误。 db.members.replaceOne( { \"points\": { $lte: 20 }, \"status\": \"P\" }, { \"misc1\": \"using index on status\", status: \"P\", member: \"replacement\", points: \"20\"}, { hint: { status: 1 } } ) 该操作返回以下内容： { \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } 要查看使用的索引，可以使用$indexStats管道： db.members.aggregate( [ { $indexStats: { } }, { $sort: { name: 1 } } ] ) 译者：李冠飞 校对： 参见 原文 - db.collection.replaceOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/38-db.collection.save.html":{"url":"16-reference/03-method/01-js-collection/38-db.collection.save.html","title":"db.collection.save（）","keywords":"","body":" db.collection.save（） 在本页面 定义 行为 例子 写结果 定义 db.collection. save () 更新现有的文献或插入新文档，具体取决于其document参数。 注意 MongoDB弃用该db.collection.save()方法。而是使用db.collection.insertOne()或 db.collection.replaceOne()代替。 save()方法具有以下形式： db.collection.save( , { writeConcern: } ) 参数 类型 描述 document document 要保存到集合的文档。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。见写关注。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 该save()返回包含操作的状态的对象。 返回： 包含操作状态的写结果 object。 行为 写关注 save()方法使用插入或更新命令，它使用默认的写关注。要指定其他写关注点，请在 options 参数中包含写入关注点。 插入 如果文档不包含_id字段，则save()方法 calls insert()方法。在操作期间，mongo shell 将创建ObjectId并将其分配给_id字段。 注意 大多数 MongoDB 驱动程序 clients 将包含_id字段并在将 insert 操作发送到 MongoDB 之前生成ObjectId;但是，如果 client 发送没有_id字段的文档，则mongod将添加_id字段并生成ObjectId。 更新 如果文档包含_id字段，则save()方法等效于upsert 选项设置为true且_id字段上的查询谓词的更新。 事务 db.collection.save()可以在多文档交易中使用。 如果该操作导致插入，则该集合必须已经存在。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 保存新文档而不指定_id 字段 在下面的示例中，save()方法执行 insert，因为传递给该方法的文档不包含_id字段： db.products.save( { item: \"book\", qty: 40 } ) 在 insert 期间，shell 将创建具有唯一ObjectId value 的_id字段，由插入的文档验证： { \"_id\" : ObjectId(\"50691737d386d8fadbd6b01d\"), \"item\" : \"book\", \"qty\" : 40 } 当操作为 run 时，ObjectId值特定于机器和 time。因此，您的值可能与 example 中的值不同。 保存新文档指定_id 字段 在下面的示例中，save()使用upsert:true执行更新，因为文档包含_id字段： db.products.save( { _id: 100, item: \"water\", qty: 30 } ) 由于_id字段包含集合中不存在的 value，因此更新操作会导致插入文档。这些操作的结果与带有 upsert 选项的 update()方法设置为true相同。 该操作导致products集合中的以下新文档： { \"_id\" : 100, \"item\" : \"water\", \"qty\" : 30 } 替换现有文档 products集合包含以下文档： { \"_id\" : 100, \"item\" : \"water\", \"qty\" : 30 } save()方法使用upsert:true执行更新，因为文档包含_id字段： db.products.save( { _id : 100, item : \"juice\" } ) 由于_id字段包含集合中存在的 value，因此操作会执行更新以替换文档并生成以下文档： { \"_id\" : 100, \"item\" : \"juice\" } 覆盖默认写入关注 对副本集的以下操作指定\"w: majority\"的\"w: majority\"，其wtimeout为 5000 毫秒，以便该方法在写入传播到大多数表决副本集成员后返回，或者该方法在 5 秒后超时。 db.products.save( { item: \"envelopes\", qty : 100, type: \"Clasp\" }, { writeConcern: { w: \"majority\", wtimeout: 5000 } } ) 写结果 将save()返回一个WriteResult包含插入或更新操作的状态对象。有关详细信息，请参见WriteResult以获得插入信息，并 参见 WriteResult以获得更新信息。 译者：李冠飞 校对： 参见 原文 - db.collection.save() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/39-db.collection.stats.html":{"url":"16-reference/03-method/01-js-collection/39-db.collection.stats.html","title":"db.collection.stats（）","keywords":"","body":" db.collection.stats（） 在本页面 定义 行为 例子 定义 db.collection. stats(选项) 返回有关集合的统计信息。 该方法包括以下参数： 参数 类型 描述 scale number 可选的。输出中使用的比例显示项目的大小。默认情况下，输出显示bytes中的大小。要显示千字节而不是字节，请指定1024 value 1024。 如果您指定非整数比例因子，则MongoDB将使用指定因子的整数部分。例如，如果将比例因子指定为1023.999，则MongoDB将使用1023该比例因子。从4.2版开始，输出包括scaleFactor 用于缩放大小值的输出。 indexDetails boolean 可选的。如果为true，则db.collection.stats()除收集统计信息外，还返回 index details仅适用于WiredTiger存储引擎。默认为false。 indexDetailsKey document 可选的。如果indexDetails是true，则可以使用indexDetailsKey通过指定索引 key 规范来过滤索引详细信息。只返回与indexDetailsKey完全匹配的索引。 如果找不到匹配项，indexDetails将显示所有索引的统计信息。 使用getIndexes()发现索引键。你不能将indexDetailsKey与indexDetailsName一起使用。 indexDetailsName string 可选的。如果indexDetails是true，则可以使用indexDetailsName通过指定索引name来过滤索引详细信息。只返回与indexDetailsName完全匹配的索引名称。 如果找不到匹配项，indexDetails将显示所有索引的统计信息。 使用getIndexes()来发现索引名称。你不能将indexDetailsName与indexDetailsField一起使用。 仅指定scale因素，MongoDB支持旧格式： db.collection.stats() 返回值： 包含有关指定集合的统计信息的文档。请参阅collStats以获取返回统计信息的细分。 该db.collection.stats()方法提供了围绕数据库命令的包装collStats。 行为 缩放大小 除非度量标准名称（例如\"bytes currently in the cache\" ）另外指定，与大小相关的值以字节为单位显示，可以按比例覆盖。 比例因子将受影响的大小值四舍五入为整数。 存储引擎 根据存储引擎，返回的数据可能不同。有关字段的详细信息，请参阅输出详细信息。 意外关机后的准确性 使用Wired Tiger存储引擎不正常关闭mongod后，db.collection.stats()报告的计数和大小统计信息可能不准确。 偏移量取决于在最后检查站和不干净关闭之间执行的 insert，update 或 delete 操作的数量。检查点通常每 60 秒发生一次。但是，使用 non-default --syncdelay设置运行mongod实例可能会有更多或更少的检查点。 在mongod上的每个集合上运行验证以在不正常关闭后恢复正确的统计信息。 索引过滤器行为 使用indexDetailsKey或indexDetailsName过滤indexDetails将仅_return 单个匹配的索引。如果未找到确切的 match，indexDetails将显示有关集合的所有索引的信息。 indexDetailsKey字段采用以下形式的文档： { '' : , '' : , ... } 其中是索引的字段，是索引的方向，或特殊索引类型，如text或2dsphere。有关索引类型的完整列表，请参见索引类型。 意外停机和计数 对于使用WiredTiger存储引擎的 MongoDB 实例，在不正常关闭后，大小和计数的统计信息可能会被collStats，dbStats，计数报告最多 1000 个文档。要恢复集合的正确统计信息，请在集合上运行 run 验证。 进行中索引 从MongoDB 4.2开始，db.collection.stats包括有关当前正在构建的索引的信息。有关详细信息，请参见： collStats.nindexes collStats.indexDetails collStats.indexBuilds collStats.totalIndexSize collStats.indexSizes 例子 注意 您可以在入门指南中找到用于这些示例的集合数据 基本统计查询 以下操作返回restaurants集合上的统计信息： db.restaurants.stats() 操作返回： { \"ns\" : \"guidebook.restaurants\", \"count\" : 25359, \"size\" : 10630398, \"avgObjSize\" : 419, \"storageSize\" : 4104192 \"capped\" : false, \"wiredTiger\" : { \"metadata\" : { \"formatVersion\" : 1 }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=1),block_allocation=best,block_compressor=snappy,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=4KB,key_format=q,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=32KB,leaf_value_max=64MB,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=10m,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=0,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:collection-2-7253336746667145592\", \"LSM\" : { \"bloom filters in the LSM tree\" : 0, \"bloom filter false positives\" : 0, \"bloom filter hits\" : 0, \"bloom filter misses\" : 0, \"bloom filter pages evicted from cache\" : 0, \"bloom filter pages read into cache\" : 0, \"total size of bloom filters\" : 0, \"sleep for LSM checkpoint throttle\" : 0, \"chunks in the LSM tree\" : 0, \"highest merge generation in the LSM tree\" : 0, \"queries that could have benefited from a Bloom filter that did not exist\" : 0, \"sleep for LSM merge throttle\" : 0 }, \"block-manager\" : { \"file allocation unit size\" : 4096, \"blocks allocated\" : 338, \"checkpoint size\" : 4096000, \"allocations requiring file extension\" : 338, \"blocks freed\" : 0, \"file magic number\" : 120897, \"file major version number\" : 1, \"minor version number\" : 0, \"file bytes available for reuse\" : 0, \"file size in bytes\" : 4104192 }, \"btree\" : { \"btree checkpoint generation\" : 15, \"column-store variable-size deleted values\" : 0, \"column-store fixed-size leaf pages\" : 0, \"column-store internal pages\" : 0, \"column-store variable-size leaf pages\" : 0, \"pages rewritten by compaction\" : 0, \"number of key/value pairs\" : 0, \"fixed-record size\" : 0, \"maximum tree depth\" : 3, \"maximum internal page key size\" : 368, \"maximum internal page size\" : 4096, \"maximum leaf page key size\" : 3276, \"maximum leaf page size\" : 32768, \"maximum leaf page value size\" : 67108864, \"overflow pages\" : 0, \"row-store internal pages\" : 0, \"row-store leaf pages\" : 0 }, \"cache\" : { \"bytes read into cache\" : 9309503, \"bytes written from cache\" : 10817368, \"checkpoint blocked page eviction\" : 0, \"unmodified pages evicted\" : 0, \"page split during eviction deepened the tree\" : 0, \"modified pages evicted\" : 1, \"data source pages selected for eviction unable to be evicted\" : 0, \"hazard pointer blocked page eviction\" : 0, \"internal pages evicted\" : 0, \"pages split during eviction\" : 1, \"in-memory page splits\" : 1, \"overflow values cached in memory\" : 0, \"pages read into cache\" : 287, \"overflow pages read into cache\" : 0, \"pages written from cache\" : 337 }, \"compression\" : { \"raw compression call failed, no additional data available\" : 0, \"raw compression call failed, additional data available\" : 0, \"raw compression call succeeded\" : 0, \"compressed pages read\" : 287, \"compressed pages written\" : 333, \"page written failed to compress\" : 0, \"page written was too small to compress\" : 4 }, \"cursor\" : { \"create calls\" : 1, \"insert calls\" : 25359, \"bulk-loaded cursor-insert calls\" : 0, \"cursor-insert key and value bytes inserted\" : 10697901, \"next calls\" : 76085, \"prev calls\" : 1, \"remove calls\" : 0, \"cursor-remove key bytes removed\" : 0, \"reset calls\" : 25959, \"restarted searches\" : 0, \"search calls\" : 0, \"search near calls\" : 594, \"update calls\" : 0, \"cursor-update value bytes updated\" : 0 }, \"reconciliation\" : { \"dictionary matches\" : 0, \"internal page multi-block writes\" : 1, \"leaf page multi-block writes\" : 2, \"maximum blocks required for a page\" : 47, \"internal-page overflow keys\" : 0, \"leaf-page overflow keys\" : 0, \"overflow values written\" : 0, \"pages deleted\" : 0, \"page checksum matches\" : 0, \"page reconciliation calls\" : 4, \"page reconciliation calls for eviction\" : 1, \"leaf page key bytes discarded using prefix compression\" : 0, \"internal page key bytes discarded using suffix compression\" : 333 }, \"session\" : { \"object compaction\" : 0, \"open cursor count\" : 1 }, \"transaction\" : { \"update conflicts\" : 0 } }, \"nindexes\" : 4, \"totalIndexSize\" : 626688, \"indexSizes\" : { \"_id_\" : 217088, \"borough_1_cuisine_1\" : 139264, \"cuisine_1\" : 131072, \"borough_1_address.zipcode_1\" : 139264 }, \"ok\" : 1 } 由于统计数据未给出比例参数，因此所有大小值都在bytes中。 带有比例的统计查询 以下操作通过指定scale的scale来更改从bytes到kilobytes的数据比例： db.restaurants.stats( { scale : 1024 } ) 操作返回： { \"ns\" : \"guidebook.restaurants\", \"count\" : 25359, \"size\" : 10381, \"avgObjSize\" : 419, \"storageSize\" : 4008, \"capped\" : false, \"wiredTiger\" : { ... }, \"nindexes\" : 4, \"totalIndexSize\" : 612, \"indexSizes\" : { \"_id_\" : 212, \"borough_1_cuisine_1\" : 136, \"cuisine_1\" : 128, \"borough_1_address.zipcode_1\" : 136 }, \"ok\" : 1 } 带索引详细信息的统计查找 以下操作将创建一个indexDetails文档，其中包含与集合中每个索引相关的信息： db.restaurant.stats( { indexDetails : true } ) 操作返回： { \"ns\" : \"guidebook.restaurants\", \"count\" : 25359, \"size\" : 10630398, \"avgObjSize\" : 419, \"storageSize\" : 4104192, \"capped\" : false, \"wiredTiger\" : { ... }, \"nindexes\" : 4, \"indexDetails\" : { \"_id_\" : { \"metadata\" : { \"formatVersion\" : 6, \"infoObj\" : \"{ \"v\" : 1, \"key\" : { \"_id\" : 1 }, \"name\" : \"_id_\", \"ns\" : \"blogs.posts\" }\" }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=6,infoObj={ \"v\" : 1, \"key\" : { \"_id\" : 1 }, \"name\" : \"_id_\", \"ns\" : \"blogs.posts\" }),block_allocation=best,block_compressor=,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=75,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:index-3-7253336746667145592\", \"LSM\" : { ... }, \"block-manager\" : { ... }, \"btree\" : { ... }, \"cache\" : { ... }, \"compression\" : { ... }, \"cursor\" : { ... }, \"reconciliation\" : { ... }, \"session\" : { ... }, \"transaction\" : { ... } }, \"borough_1_cuisine_1\" : { \"metadata\" : { \"formatVersion\" : 6, \"infoObj\" : \"{ \"v\" : 1, \"key\" : { \"borough\" : 1, \"cuisine\" : 1 }, \"name\" : \"borough_1_cuisine_1\", \"ns\" : \"blogs.posts\" }\" }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=6,infoObj={ \"v\" : 1, \"key\" : { \"borough\" : 1, \"cuisine\" : 1 }, \"name\" : \"borough_1_cuisine_1\", \"ns\" : \"blogs.posts\" }),block_allocation=best,block_compressor=,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=75,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:index-4-7253336746667145592\", \"LSM\" : { ... }, \"block-manager\" : { ... }, \"btree\" : { ... }, \"cache\" : { ... }, \"compression\" : { ... }, \"cursor\" : { ... }, \"reconciliation\" : { ... }, \"session\" : { \"object compaction\" : 0, \"open cursor count\" : 0 }, \"transaction\" : { \"update conflicts\" : 0 } }, \"cuisine_1\" : { \"metadata\" : { \"formatVersion\" : 6, \"infoObj\" : \"{ \"v\" : 1, \"key\" : { \"cuisine\" : 1 }, \"name\" : \"cuisine_1\", \"ns\" : \"blogs.posts\" }\" }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=6,infoObj={ \"v\" : 1, \"key\" : { \"cuisine\" : 1 }, \"name\" : \"cuisine_1\", \"ns\" : \"blogs.posts\" }),block_allocation=best,block_compressor=,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=75,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:index-5-7253336746667145592\", \"LSM\" : { ... }, \"block-manager\" : { ... }, \"btree\" : { ... }, \"cache\" : { ... }, \"compression\" : { ... }, \"cursor\" : { ... }, \"reconciliation\" : { ... }, \"session\" : { ... }, \"transaction\" : { ... } }, \"borough_1_address.zipcode_1\" : { \"metadata\" : { \"formatVersion\" : 6, \"infoObj\" : \"{ \"v\" : 1, \"key\" : { \"borough\" : 1, \"address.zipcode\" : 1 }, \"name\" : \"borough_1_address.zipcode_1\", \"ns\" : \"blogs.posts\" }\" }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=6,infoObj={ \"v\" : 1, \"key\" : { \"borough\" : 1, \"address.zipcode\" : 1 }, \"name\" : \"borough_1_address.zipcode_1\", \"ns\" : \"blogs.posts\" }),block_allocation=best,block_compressor=,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=75,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:index-6-7253336746667145592\", \"LSM\" : { ... }, \"block-manager\" : { ... }, \"btree\" : { ... }, \"cache\" : { ... }, \"compression\" : { ... }, \"cursor\" : { ... }, \"reconciliation\" : { ... }, \"session\" : { ... }, \"transaction\" : { ... } } }, \"totalIndexSize\" : 626688, \"indexSizes\" : { \"_id_\" : 217088, \"borough_1_cuisine_1\" : 139264, \"cuisine_1\" : 131072, \"borough_1_address.zipcode_1\" : 139264 }, \"ok\" : 1 } 带有过滤索引详细信息的统计信息查找 要过滤indexDetails字段中的索引，可以使用indexDetailsKey选项指定索引键，也可以使用indexDetailsName指定索引 name。要发现集合的索引键和名称，请使用db.collection.getIndexes()。 给定以下索引： { \"ns\" : \"guidebook.restaurants\", \"v\" : 1, \"key\" : { \"borough\" : 1, \"cuisine\" : 1 }, \"name\" : \"borough_1_cuisine_1\" } 以下操作将indexDetails文档过滤为indexDetailsKey文档定义的单个索引。 db.restaurants.stats( { 'indexDetails' : true, 'indexDetailsKey' : { 'borough' : 1, 'cuisine' : 1 } } ) 以下操作将indexDetails文档过滤为indexDetailsName文档定义的单个索引。 db.restaurants.stats( { 'indexDetails' : true, 'indexDetailsName' : 'borough_1_cuisine_1' } ) 两个操作都会 return 相同的输出： { \"ns\" : \"blogs.restaurants\", \"count\" : 25359, \"size\" : 10630398, \"avgObjSize\" : 419, \"storageSize\" : 4104192, \"capped\" : false, \"wiredTiger\" : { ... }, \"nindexes\" : 4, \"indexDetails\" : { \"borough_1_cuisine_1\" : { \"metadata\" : { \"formatVersion\" : 6, \"infoObj\" : \"{ \"v\" : 1, \"key\" : { \"borough\" : 1, \"cuisine\" : 1 }, \"name\" : \"borough_1_cuisine_1\", \"ns\" : \"blogs.posts\" }\" }, \"creationString\" : \"allocation_size=4KB,app_metadata=(formatVersion=6,infoObj={ \"v\" : 1, \"key\" : { \"borough\" : 1, \"cuisine\" : 1 }, \"name\" : \"borough_1_cuisine_1\", \"ns\" : \"blogs.posts\" }),block_allocation=best,block_compressor=,cache_resident=0,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=0,extractor=,format=btree,huffman_key=,huffman_value=,immutable=0,internal_item_max=0,internal_key_max=0,internal_key_truncate=,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=),lsm=(auto_throttle=,bloom=,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=0,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_max=15,merge_min=0),memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=75,type=file,value_format=u\", \"type\" : \"file\", \"uri\" : \"statistics:table:index-4-7253336746667145592\", \"LSM\" : { ... }, \"block-manager\" : { ... }, \"btree\" : { ... }, \"cache\" : { ... }, \"compression\" : { ... }, \"cursor\" : { ... }, \"reconciliation\" : { ... }, \"session\" : { ... }, \"transaction\" : { ... } } }, \"totalIndexSize\" : 626688, \"indexSizes\" : { \"_id_\" : 217088, \"borough_1_cuisine_1\" : 139264, \"cuisine_1\" : 131072, \"borough_1_address.zipcode_1\" : 139264 }, \"ok\" : 1 } 有关输出的说明，请参阅输出细节。 也可以看看 $collStats 译者：李冠飞 校对： 参见 原文 - db.collection.stats() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/40-db.collection.storageSize.html":{"url":"16-reference/03-method/01-js-collection/40-db.collection.storageSize.html","title":"db.collection.storageSize（）","keywords":"","body":" db.collection.storageSize（） db.collection. storageSize () 返回： 分配给此集合以进行文档存储的总存储量。如果压缩了集合数据(即WiredTiger 的默认值)，则存储大小反映压缩大小，可能小于db.collection.dataSize()返回的 value。 在collStats(即：db.collection.stats())输出的storageSize字段周围提供 wrapper。 译者：李冠飞 校对： 参见 原文 - db.collection.storageSize() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/41-db.collection.totalIndexSize.html":{"url":"16-reference/03-method/01-js-collection/41-db.collection.totalIndexSize.html","title":"db.collection.totalIndexSize（）","keywords":"","body":" db.collection.totalIndexSize（） db.collection. totalIndexSize () 返回： 集合的所有索引的总大小。如果索引使用前缀压缩(即WiredTiger 的默认值)，则返回的大小反映压缩大小。 此方法在collStats(即：db.collection.stats())操作的totalIndexSize输出周围提供包装。 译者：李冠飞 校对： 参见 原文 - db.collection.totalIndexSize() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/42-db.collection.totalSize.html":{"url":"16-reference/03-method/01-js-collection/42-db.collection.totalSize.html","title":"db.collection.totalSize（）","keywords":"","body":" db.collection.totalSize（） db.collection. totalSize () 返回： 集合中数据的总大小(以字节为单位)加上集合中每个索引的大小。如果压缩了集合数据(即WiredTiger 的默认值)，则返回的大小反映了集合数据的压缩大小。如果索引使用前缀压缩(即WiredTiger 的默认值)，则返回的大小反映索引的压缩大小。 返回的 value 是db.collection.storageSize()和db.collection.totalIndexSize()的总和(以字节为单位)。 译者：李冠飞 校对： 参见 原文 - db.collection.totalSize() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/43-db.collection.unhideIndex.html":{"url":"16-reference/03-method/01-js-collection/43-db.collection.unhideIndex.html","title":"db.collection.unhideIndex()","keywords":"","body":" db.collection.unhideIndex() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.collection.unhideIndex() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/44-db.collection.update.html":{"url":"16-reference/03-method/01-js-collection/44-db.collection.update.html","title":"db.collection.update（）","keywords":"","body":" db.collection.update（） 在本页面 定义 语法 访问控制 行为 例子 写结果 定义 db.collection. update(查询，更新，选项) 修改集合中的现有文档。该方法可以修改现有文档的特定字段或完全替换现有文档，具体取决于更新参数。 默认情况下，update()方法更新单文档。设置多参数multi：true以更新 match 查询条件的所有文档。 语法 db.collection.update()方法具有以下形式： db.collection.update( , , { upsert: , multi: , writeConcern: , collation: , arrayFilters: [ , ... ] } ) 参数 db.collection.update()方法采用以下参数： 参数 类型 描述 query document 更新的选择标准。提供与方法中相同的查询选择器find()。 当执行update()with 且查询不匹配任何现有文档时，如果查询使用点表示法在字段上指定条件，则MongoDB将拒绝插入新文档 。upsert: true _id update document or pipeline 要应用的修改。可以是以下之一：更新文件：仅包含更新运算符表达式更新文件：仅包含键值对: 聚合管道 （从MongoDB 4.2开始）：仅包含以下聚合阶段：a. $addFields及其别名 $setb. $project及其别名 $unsetc. $replaceRoot及其别名$replaceWith有关详细信息和示例，请参见示例。 upsert boolean 可选的。如果设置为true，则在没有文档与查询条件匹配时创建新文档。默认的 value 是false，当没有找到 match 时，它不会插入新文档。 multi boolean 可选的。如果设置为true，则更新符合query条件的多个文档。如果设置为false，则更新一个文档。默认的 value 是false。有关其他信息，请参阅多参数。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。w: 1 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。有关使用的示例writeConcern，请参见 覆盖默认写问题。 collation document 可选的。 排序规则允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。 有关使用的示例collation，请参见 指定排序规则。version 3.4 中的新内容。 arrayFilters array 可选的。过滤器文档数组，用于确定要在数组 字段上为更新操作修改的数组元素。 在更新文档中，使用$ []来定义标识符，仅更新那些与arrayFilters中相应的filter文档相匹配的数组元素。 注意 如果更新文档中未包含标识符，则不能具有数组过滤器文档作为标识符。 有关示例，请参阅为数组更新操作指定arrayFilters。version 3.6 中的新内容。 hint document or string 可选的。一个文档或字符串，它指定用于支持查询谓词的索引。该选项可以采用索引规范文档或索引名称字符串。如果指定的索引不存在，则操作错误。有关示例，请参见为更新操作指定提示。4.2版中的新功能。 返回： 该方法返回包含操作状态的WriteResult文档。 访问控制 在运行时authorization，用户必须具有包括以下特权的访问权限： update对指定集合的操作。 find对指定集合的操作。 insert如果操作导致更新，则对指定的集合执行操作。 内置角色readWrite提供所需的特权。 行为 分片集合 db.collection.update()要与分片集合一起使用，必须在 字段上包括完全匹配项或将目标设为单个分片（例如：通过包含分片键）。multi: false_id 当db.collection.update()执行更新操作（而不是文档替换操作）时， db.collection.update()可以针对多个分片。 也可以看看 findAndModify() 替换分片集合上的文档操作 从MongoDB 4.2开始，替换文档操作首先尝试使用查询过滤器来针对单个分片。如果该操作无法通过查询过滤器定位到单个分片，则它将尝试以替换文档定位。 在早期版本中，该操作尝试使用替换文档作为目标。 upsert在分片集合上 对于db.collection.update()包含 upsert：true且位于分片集合上的操作，您必须在中包含完整的分片键filter： 用于更新操作。 用于替换文档操作（从MongoDB 4.2开始）。 碎片键修改 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 要用于db.collection.update()更新分片键： 您必须指定。multi: false 您必须在运行mongos无论是在 事务或作为重试写。千万不能直接在碎片发布运行。 您必须在查询过滤器的完整分片键上包含相等条件。例如，如果一个集合messages 使用{ country : 1, userid : 1 }的片键，更新为一个文件的碎片关键，你必须包括country: , userid: 在查询过滤器。您可以根据需要在查询中包括其他字段。 事务 db.collection.update()可以在多文档交易中使用。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如：运行时限制和操作日志大小限制），另请参见 生产注意事项。 现有的集合和事务 在事务内部，您可以指定对现有集合的读/写操作。如果db.collection.update()导致upsert，则该集合必须已经存在。 如果该操作导致upsert，则该集合必须已经存在。 写关注和事务 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 例子 使用更新运算符表达式（$ inc，$ set） 在mongoshell中，创建一个books包含以下文档的集合。此命令首先从books集合中删除所有先前存在的文档： db.books.remove({}); db.books.insertMany([ { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"tags\" : [ \"technology\", \"computer\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false }, { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 } ], \"reorder\" : false } ]); 如果文档包含更新运算符修饰符（例如使用 $set修饰符的修饰符），则： 该文档必须仅 包含更新运算符表达式。 该db.collection.update()方法仅更新文档中的相应字段。 要整体更新嵌入式文档或数组，请为该字段指定替换值。 要更新嵌入式文档或数组中的特定字段，请使用点表示法 指定该字段。 您可以使用下面的Web Shell插入示例文档并执行示例更新操作： db.books.update( { _id: 1 }, { $inc: { stock: 5 }, $set: { item: \"ABC123\", \"info.publisher\": \"2222\", tags: [ \"software\" ], \"ratings.1\": { by: \"xyz\", rating: 3 } } } ) 在此操作中： 该参数指定更新哪个文档，{ _id: 1 } 在$inc操作递增stock字段， 在$set运算符替换值： item 字段， publisher info嵌入文档中的字段， tags 字段 ratings数组中的第二个元素。 更新后的文档如下： { \"_id\" : 1, \"item\" : \"ABC123\", \"stock\" : 5, \"info\" : { \"publisher\" : \"2222\", \"pages\" : 430 }, \"tags\" : [ \"software\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"xyz\", \"rating\" : 3 } ], \"reorder\" : false } 此操作对应于以下SQL语句： UPDATE books SET stock = stock + 5 item = \"ABC123\" publisher = 2222 pages = 430 tags = \"software\" rating_authors = \"ijk,xyz\" rating_values = \"4,3\" WHERE _id = 1 注意 如果query参数已匹配多个文档，则此操作将仅更新一个匹配的文档。要更新多个文档，必须将multi选项设置为true。 也可以看看 $set, $inc, Update运算符, 点符号 将元素添加到现有数组 在mongoshell中，创建一个books包含以下文档的集合。此命令首先从books集合中删除所有先前存在的文档： db.books.remove({}); db.books.insertMany([ { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"tags\" : [ \"technology\", \"computer\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false }, { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 } ], \"reorder\" : false } ]); 以下操作使用$pushupdate运算符将新对象附加到ratings数组。 您可以使用下面的Web Shell插入示例文档并执行示例更新操作： db.books.update( { _id: 2 }, { $push: { ratings: { \"by\" : \"jkl\", \"rating\" : 2 } } } ) 更新后的文档如下： { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 }, { \"by\" : \"jkl\", \"rating\" : 2 } ], \"reorder\" : false } 也可以看看 $push 删除字段（$ unset） 在mongoshell中，创建一个books包含以下文档的集合。此命令首先从books集合中删除所有先前存在的文档： db.books.remove({}); db.books.insertMany([ { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"tags\" : [ \"technology\", \"computer\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false }, { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 } ], \"reorder\" : false } ]); 以下操作使用$unset操作符通过删除tags文档中的字段。{ _id: 1 } 您可以使用下面的Web Shell插入示例文档并执行示例更新操作： db.books.update( { _id: 1 }, { $unset: { tags: 1 } } ) 更新后的文档如下： { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false } 没有直接等效于$unset的SQL ，但是$unset类似于以下SQL命令，该命令tags从books 表中删除了该字段： ALTER TABLE books DROP COLUMN tags 也可以看看 $unset，$rename，update运算符 替换整个文件 在mongoshell中，创建一个books包含以下文档的集合。此命令首先从books集合中删除所有先前存在的文档： db.books.remove({}); db.books.insertMany([ { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"tags\" : [ \"technology\", \"computer\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false }, { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 } ], \"reorder\" : false } ]); 如果文档仅 包含field:value 表达式，则： 该db.collection.update()方法将匹配的文档替换为文档。该 db.collection.update()方法不会替换该 _id值。 db.collection.update()无法更新多个文档。 以下操作将传递仅包含字段和值对的文档。该文档将完全替换原始文档（_id字段除外）。 您可以使用下面的Web Shell插入示例文档并执行示例更新操作： db.books.update( { _id: 2 }, { item: \"XYZ123\", stock: 10, info: { publisher: \"2255\", pages: 150 }, tags: [ \"baking\", \"cooking\" ] } ) 更新的文档仅包含替换文档中的_id字段和该字段。这样，这些字段 ratings和reorder不再存在于更新的文档中，因为这些字段不在替换文档中。 { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 10, \"info\" : { \"publisher\" : \"2255\", \"pages\" : 150 }, \"tags\" : [ \"baking\", \"cooking\" ] } 此操作对应于以下SQL语句： DELETE from books WHERE _id = 2 INSERT INTO books (_id, item, stock, publisher, pages, tags) VALUES (2, \"xyz123\", 10, \"2255\", 150, \"baking,cooking\") 更新多个文件 在mongoshell中，创建一个books包含以下文档的集合。此命令首先从books集合中删除所有先前存在的文档： db.books.remove({}); db.books.insertMany([ { \"_id\" : 1, \"item\" : \"TBD\", \"stock\" : 0, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 430 }, \"tags\" : [ \"technology\", \"computer\" ], \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"lmn\", \"rating\" : 5 } ], \"reorder\" : false }, { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 15, \"info\" : { \"publisher\" : \"5555\", \"pages\" : 150 }, \"tags\" : [ ], \"ratings\" : [ { \"by\" : \"xyz\", \"rating\" : 5 } ], \"reorder\" : false } ]); 如果multi设置为true，则该 db.collection.update()方法将更新所有符合条件的文档。该multi更新操作可以与其他的读/写操作交错。 以下操作将 所有小于或等于10的 文档的reorder字段设置true为。如果匹配的文档中不存在该字段，则运算符将使用指定的值添加该字段。 您可以使用下面的Web Shell插入示例文档并执行示例更新操作： db.books.update( { stock: { $lte: 10 } }, { $set: { reorder: true } }, { multi: true } ) 集合中的结果文档如下： [ { \"_id\" : 1, \"item\" : \"ABC123\", \"stock\" : 5, \"info\" : { \"publisher\" : \"2222\", \"pages\" : 430 }, \"ratings\" : [ { \"by\" : \"ijk\", \"rating\" : 4 }, { \"by\" : \"xyz\", \"rating\" : 3 } ], \"reorder\" : true } { \"_id\" : 2, \"item\" : \"XYZ123\", \"stock\" : 10, \"info\" : { \"publisher\" : \"2255\", \"pages\" : 150 }, \"tags\" : [ \"baking\", \"cooking\" ], \"reorder\" : true } ] 此操作对应于以下SQL语句： UPDATE books SET reorder=true WHERE stock 注意 您无法指定何时执行替换，即文档何时仅包含表达式：multi: true field:value 也可以看看 $set` 如果不存在匹配项，则插入新文档（Upsert） 当您指定选项upsert：true时： 如果文档符合查询条件，请 db.collection.update()执行更新。 如果没有文件的查询条件匹配， db.collection.update()插入一个单一的文件。 如果在分片集合上指定upsert: true，则必须在filter 中包含完整的分片键。有关分片集合的其他 行为，请参见分片集合。 db.collection.update() 替换文件更新 如果没有文档符合查询条件，并且 参数是替换文档（即：仅包含字段和值的键值对），则更新将插入带有替换文档的字段和值的新文档。 如果您_id在查询参数或替换文档中指定字段，则MongoDB将_id在插入的文档中使用该字段。 如果您未_id在查询参数或替换文档中指定字段，则MongoDB生成的_id字段会添加带有随机生成的ObjectId值的 字段。 注意 您不能_id在查询参数和替换文档中指定其他字段值。如果这样做，则操作错误。 例如，以下更新将upsert选项设置为true： db.books.update( { item: \"ZZZ135\" }, // Query parameter { // Replacement document item: \"ZZZ135\", stock: 5, tags: [ \"database\" ] }, { upsert: true } // Options ) 如果没有文档与该参数匹配，则更新操作将插入仅包含替换文档的文档。由于_id在替换文档或查询文档中未指定任何字段，因此该操作ObjectId将为新文档的_id字段创建一个新的唯一性。您可以看到upsert反映在操作的WriteResult中： WriteResult({ \"nMatched\" : 0, \"nUpserted\" : 1, \"nModified\" : 0, \"_id\" : ObjectId(\"5da78973835b2f1c75347a83\") }) 该操作将以下文档插入books 集合中（您的ObjectId值将有所不同）： { \"_id\" : ObjectId(\"5da78973835b2f1c75347a83\"), \"item\" : \"ZZZ135\", \"stock\" : 5, \"tags\" : [ \"database\" ] } 带运算符表达式的Upsert 如果没有文档符合查询条件，并且 参数是带有update运算符expression的文档，则该操作根据参数中的equals子句创建基本文档，并应用参数中的表达式。 来自的比较操作将不会包含在新文档中。如果新文档不包含该_id字段，则MongoDB将_id使用ObjectId值添加该字段。 例如，以下更新将upsert选项设置为true： db.books.update( { item: \"BLP921\" }, // Query parameter { // Update document $set: { reorder: false }, $setOnInsert: { stock: 10 } }, { upsert: true } // Options ) 如果没有文档符合查询条件，则该操作将插入以下文档（您的ObjectId值将有所不同）： { \"_id\" : ObjectId(\"5da79019835b2f1c75348a0a\"), \"item\" : \"BLP921\", \"reorder\" : false, \"stock\" : 10 } 也可以看看 $setOnInsert 使用Upsert的聚合管道 如果参数是聚合管道，则更新将从 参数中的equals子句创建基础文档，然后将管道应用于文档以创建要插入的文档。如果新文档不包含该_id字段，则MongoDB将_id使用ObjectId值添加该字段。 例如，以下upsert：true操作指定使用以下内容的聚合管道 该$replaceRoot阶段可以提供与$setOnInsert更新运算符表达式类似的行为， $set可以提供与$set更新操作符表达式相似的行为的阶段， 聚合变量NOW，它解析为当前日期时间，并且可以提供与$currentDate更新运算符表达式类似的行为 。 db.books.update( { item: \"MRQ014\", ratings: [2, 5, 3] }, // Query parameter [ // Aggregation pipeline { $replaceRoot: { newRoot: { $mergeObjects: [ { stock: 0 }, \"$$ROOT\" ] } } }, { $set: { avgRating: { $avg: \"$ratings\" }, tags: [ \"fiction\", \"murder\" ], lastModified: \"$$NOW\" } } ], { upsert: true } // Options ) 如果没有文档与该参数匹配，则该操作会将以下文档插入到books 集合中（您的ObjectId值将有所不同）： { \"_id\" : ObjectId(\"5e2921e0b4c550aad59d1ba9\"), \"stock\" : 0, \"item\" : \"MRQ014\", \"ratings\" : [ 2, 5, 3 ], \"avgRating\" : 3.3333333333333335, \"tags\" : [ \"fiction\", \"murder\" ], \"lastModified\" : ISODate(\"2020-01-23T04:32:32.951Z\") } 也可以看看 有关使用聚合管道进行更新的其他示例，请参见使用聚合管道进行更新。 结合Upsert和多选项 结合使用Upsert和多选项（匹配） 在mongoshell中，将以下文档插入books集合中： db.books.insertMany([ { _id: 5, item: \"RQM909\", stock: 18, info: { publisher: \"0000\", pages: 170 }, reorder: true }, { _id: 6, item: \"EFG222\", stock: 15, info: { publisher: \"1111\", pages: 72 }, reorder: true } ]) 以下操作同时指定了multi选项和upsert选项。如果存在匹配的文档，则该操作将更新所有匹配的文档。如果不存在匹配的文档，则该操作将插入一个新文档。 db.books.update( { stock: { $gte: 10 } }, // Query parameter { // Update document $set: { reorder: false, tags: [ \"literature\", \"translated\" ] } }, { upsert: true, multi: true } // Options ) 该操作将更新所有匹配的文档，并产生以下结果： { \"_id\" : 5, \"item\" : \"RQM909\", \"stock\" : 18, \"info\" : { \"publisher\" : \"0000\", \"pages\" : 170 }, \"reorder\" : false, \"tags\" : [ \"literature\", \"translated\" ] } { \"_id\" : 6, \"item\" : \"EFG222\", \"stock\" : 15, \"info\" : { \"publisher\" : \"1111\", \"pages\" : 72 }, \"reorder\" : false, \"tags\" : [ \"literature\", \"translated\" ] } 结合使用Upsert和多选项（无匹配项） 如果集合中没有匹配的文档，则该操作将导致使用和 规范中的字段插入单个文档。例如，考虑以下操作： db.books.update( { \"info.publisher\": \"Self-Published\" }, // Query parameter { // Update document $set: { reorder: false, tags: [ \"literature\", \"hardcover\" ], stock: 25 } }, { upsert: true, multi: true } // Options ) 该操作将以下文档插入books 集合中（您的ObjectId值将有所不同）： { \"_id\" : ObjectId(\"5db337934f670d584b6ca8e0\"), \"info\" : { \"publisher\" : \"Self-Published\" }, \"reorder\" : false, \"stock\" : 25, \"tags\" : [ \"literature\", \"hardcover\" ] } 带Dotted_id查询的Upsert 当执行update()with 且查询不匹配任何现有文档时，如果查询使用点表示法在字段上指定条件，则MongoDB将拒绝插入新文档 。upsert: true _id 此限制可确保_id文档中嵌入的字段的顺序 定义明确，并且不与查询中指定的顺序绑定。 如果您尝试以这种方式插入文档，MongoDB将引发错误。例如，考虑以下更新操作。由于更新操作指定upsert:true了_id字段并且查询使用点符号指定了字段上的条件，因此在构建要插入的文档时，更新将导致错误。 db.collection.update( { \"_id.name\": \"Robert Frost\", \"_id.uid\": 0 }, { \"categories\": [\"poet\", \"playwright\"] }, { upsert: true } ) 该WriteResult操作将返回以下错误： WriteResult({ \"nMatched\" : 0, \"nUpserted\" : 0, \"nModified\" : 0, \"writeError\" : { \"code\" : 111, \"errmsg\" : \"field at '_id' must be exactly specified, field at sub-path '_id.name'found\" } }) 也可以看看 WriteResult() 使用唯一索引 警告 为避免多次插入同一文档，请仅在query字段是唯一索引时使用upsert: true 。 给定一个名为集合people，其中没有包含Andy值的name字段，考虑当多个客户端在同一时间使用upsert: true发出以下db.collection.update()时： db.people.update( { name: \"Andy\" }, // Query parameter { // Update document name: \"Andy\", rating: 1, score: 1 }, { upsert: true } // Options ) 如果所有db.collection.update()操作query在任何客户端成功插入数据之前完成了该 部分，并且 该name字段上没有唯一索引，则每个更新操作都可能导致插入。 为防止MongoDB多次插入同一文档，请在字段上创建唯一索引name。使用唯一索引，如果多个应用程序使用upsert: true发出相同的更新，则恰好一个db.collection.update()将成功插入新文档。 其余操作将是： 更新新插入的文档， 当他们尝试插入重复项时失败。 如果操作由于重复的索引键错误而失败，则应用程序可以重试该操作，该操作将作为更新操作成功。 也可以看看 $setOnInsert 使用聚合管道更新 从MongoDB 4.2开始，db.collection.update()方法可以接受指定要执行的修改的聚合管道。管道可以包括以下阶段：[ , , ... ] $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 使用文档中其他字段的值修改字段 members使用以下文档创建一个集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"A\", \"points\" : 2, \"misc1\" : \"note to self: confirm status\", \"misc2\" : \"Need to activate\", \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\", \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]) 假设您希望将这些字段收集到一个新字段中，而不是使用单独的misc1和misc2字段comments。以下更新操作使用聚合管道执行以下操作： 添加新comments字段并设置该lastUpdate字段。 删除集合中所有文档的misc1和misc2字段。 db.members.update( { }, [ { $set: { status: \"Modified\", comments: [ \"$misc1\", \"$misc2\" ], lastUpdate: \"$$NOW\" } }, { $unset: [ \"misc1\", \"misc2\" ] } ], { multi: true } ) 注意 $set和$unset在管道中是指聚合阶段$set，并$unset 分别，而不是更新的运营商$set和 $unset。 第一阶段 $set阶段： 创建一个新的数组字段，comments其元素是misc1和misc2字段的当前内容， 并且将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 $unset阶段将删除misc1和misc2字段。 命令后，集合包含以下文档： { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"Modified\", \"points\" : 2, \"lastUpdate\" : ISODate(\"2020-01-23T05:11:45.784Z\"), \"comments\" : [ \"note to self: confirm status\", \"Need to activate\" ] } { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"Modified\", \"points\" : 60, \"lastUpdate\" : ISODate(\"2020-01-23T05:11:45.784Z\"), \"comments\" : [ \"reminder: ping me at 100pts\", \"Some random comment\" ] } 也可以看看 Updates with Aggregation Pipeline 根据当前字段值执行条件更新 使用以下文档创建一个students3集合： db.students3.insert([ { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]); 使用聚合管道，可以使用计算出的平均成绩和字母成绩更新文档。 db.students3.update( { }, [ { $set: { average : { $trunc: [ { $avg: \"$tests\" }, 0 ] }, lastUpdate: \"$$NOW\" } }, { $set: { grade: { $switch: { branches: [ { case: { $gte: [ \"$average\", 90 ] }, then: \"A\" }, { case: { $gte: [ \"$average\", 80 ] }, then: \"B\" }, { case: { $gte: [ \"$average\", 70 ] }, then: \"C\" }, { case: { $gte: [ \"$average\", 60 ] }, then: \"D\" } ], default: \"F\" } } } } ], { multi: true } ) 注意 $set管道中的使用是指聚合阶段 $set，而不是更新运算符$set。 第一阶段 $set阶段： 根据字段average的平均值 计算一个新tests字段。请参阅$avg有关 $avg聚合运算符$trunc的更多信息和有关$trunc截取聚合运算符的更多信息 。 将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 $set阶段根据前一阶段计算的平均成绩计算新的成绩等级。参见 $switch以获取有关$switch 聚合运算符的更多信息。 命令后，集合包含以下文档： { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:29:35.340Z\"), \"average\" : 92, \"grade\" : \"A\" } { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:29:35.340Z\"), \"average\" : 90, \"grade\" : \"A\" } { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:29:35.340Z\"), \"average\" : 75, \"grade\" : \"C\" } 也可以看看 Updates with Aggregation Pipeline 指定arrayFilters数组更新操作 在更新文档中，使用$[]过滤后的位置运算符定义一个标识符，然后在数组过滤器文档中引用该标识符。如果更新文档中未包含标识符，则不能具有数组过滤器文档作为标识符。 注意 在必须以小写字母开头，并且只包含字母数字字符。 您可以在更新文档中多次包含相同的标识符；但是，对于$[identifier]更新文档中的每个不同的标识符，必须精确地指定一个 对应的数组过滤器文档。即：您不能为同一标识符指定多个数组过滤器文档。例如：如果update语句包含标识符x （可能多次），则不能为以下内容指定以下内容 arrayFilters：包括2个单独的过滤器文档x： // INVALID [ { \"x.a\": { $gt: 85 } }, { \"x.b\": { $gt: 80 } } ] 但是，可以在单个过滤器文档中的相同标识符上指定复合条件，例如以下示例： // Example 1 [ { $or: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 2 [ { $and: [{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}] } ] // Example 3 [ { \"x.a\": { $gt: 85 }, \"x.b\": { $gt: 80 } } ] arrayFilters 不适用于使用聚合管道的更新。 更新元素匹配arrayFilters条件 要更新所有符合指定条件的数组元素，请使用 arrayFilters参数。 在mongoshell程序中，students 使用以下文档创建一个集合： db.students.insertMany([ { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] }, { \"_id\" : 2, \"grades\" : [ 98, 100, 102 ] }, { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } ]) 要更新grades阵列中大于或等于100的所有元素 ，使用过滤的位置操作符 $[]与所述arrayFilters选项： db.students.update( { grades: { $gte: 100 } }, { $set: { \"grades.$[element]\" : 100 } }, { multi: true, arrayFilters: [ { \"element\": { $gte: 100 } } ] } ) 操作后，集合包含以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 100, 100 ] } 更新文档数组的特定元素 您还可以使用arrayFilters参数更新文档数组中的特定文档字段。 在mongoshell程序中，students2 使用以下文档创建一个集合： db.students2.insertMany([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 要修改mean的grades数组中grade大于或等于85的所有元素的字段 值，请使用$[]带有过滤条件的位置运算符和arrayFilters： db.students2.update( { }, { $set: { \"grades.$[elem].mean\" : 100 } }, { multi: true, arrayFilters: [ { \"elem.grade\": { $gte: 85 } } ] } ) 操作后，集合具有以下文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 100, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 100, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 } ] } 指定hint更新操作 4.2版中的新功能。 mongoshell程序中，members 使用以下文档创建一个集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" }, { \"_id\" : 3, \"member\" : \"lmn123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 4, \"member\" : \"pqr123\", \"status\" : \"D\", \"points\" : 20, \"misc1\" : \"Deactivated\", \"misc2\" : null }, { \"_id\" : 5, \"member\" : \"ijk123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 6, \"member\" : \"cde123\", \"status\" : \"A\", \"points\" : 86, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" } ]) 在集合上创建以下索引： db.members.createIndex( { status: 1 } ) db.members.createIndex( { points: 1 } ) 以下更新操作hints明确指出要使用索引：{status: 1 } 注意 如果指定的索引不存在，则操作错误。 db.members.update( { points: { $lte: 20 }, status: \"P\" }, // Query parameter { $set: { misc1: \"Need to activate\" } }, // Update document { multi: true, hint: { status: 1 } } // Options ) update命令返回以下内容： WriteResult({ \"nMatched\" : 3, \"nUpserted\" : 0, \"nModified\" : 3 }) 要查看使用的索引，请运行explain以下操作： db.members.explain().update( { \"points\": { $lte: 20 }, \"status\": \"P\" }, { $set: { \"misc1\": \"Need to activate\" } }, { multi: true, hint: { status: 1 } } ) db.collection.explain().update()不修改文件。 覆盖默认写问题 对副本集的以下操作指定5,000毫秒的写关注时间\"w: majority\"，以 使该方法在写传送到大多数有表决权的副本集成员之后返回，或者该方法在5秒钟后超时。 db.books.update( { stock: { $lte: 10 } }, { $set: { reorder: true } }, { multi: true, writeConcern: { w: \"majority\", wtimeout: 5000 } } ) 指定排序规则 指定 用于操作的排序规则。 排序规则允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。 排序规则选项具有以下语法： collation: { locale: , caseLevel: , caseFirst: , strength: , numericOrdering: , alternate: , maxVariable: , backwards: } 指定排序规则时，该locale字段为必填字段；所有其他排序规则字段都是可选的。有关字段的说明，请参见整理文档。 如果未指定排序规则，但是集合具有默认排序规则（请参阅参考资料db.createCollection()），则该操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，则MongoDB会将以前版本中使用的简单二进制比较用于字符串比较。 您不能为一个操作指定多个排序规则。例如，您不能为每个字段指定不同的排序规则，或者如果对排序执行查找，则不能对查找使用一种排序规则，而对排序使用另一种排序规则。 3.4版的新功能。 在mongoshell程序中，创建一个myColl包含以下文档的集合 ： db.myColl.insertMany( [ { _id: 1, category: \"café\", status: \"A\" }, { _id: 2, category: \"cafe\", status: \"a\" }, { _id: 3, category: \"cafE\", status: \"a\" } ]) 下面的操作包括排序选项和设置multi，以true更新所有匹配的文档： db.myColl.update( { category: \"cafe\" }, { $set: { status: \"Updated\" } }, { collation: { locale: \"fr\", strength: 1 }, multi: true } ); 该操作的写入结果返回以下文档，指示集合中的所有三个文档均已更新： WriteResult({ \"nMatched\" : 3, \"nUpserted\" : 0, \"nModified\" : 3 }) 操作后，集合包含以下文档： { \"_id\" : 1, \"category\" : \"café\", \"status\" : \"Updated\" } { \"_id\" : 2, \"category\" : \"cafe\", \"status\" : \"Updated\" } { \"_id\" : 3, \"category\" : \"cafE\", \"status\" : \"Updated\" } 写结果 成功的结果 db.collection.update()方法返回一个 WriteResult包含操作状态的对象。成功后，WriteResult对象包含符合查询条件的文档数，更新插入的文档数以及修改的文档数： WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 }) 注意 WriteResult.nMatched，WriteResult.nUpserted，WriteResult.nModified 写关注错误 如果该db.collection.update()方法遇到写关注错误，则结果包括以下 WriteResult.writeConcernError字段： WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1, \"writeConcernError\" : { \"code\" : 64, \"errmsg\" : \"waiting for replication timed out at shard-a\" } }) 也可以看看 WriteResult.hasWriteConcernError() 与写关注无关的错误 如果db.collection.update()方法遇到非写关注错误，则结果包括以下WriteResult.writeError字段： WriteResult({ \"nMatched\" : 0, \"nUpserted\" : 0, \"nModified\" : 0, \"writeError\" : { \"code\" : 7, \"errmsg\" : \"could not contact primary for replica set shard-a\" } }) 也可以看看 WriteResult.hasWriteError() 译者：李冠飞 校对： 参见 原文 - db.collection.update() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/45-db.collection.updateOne.html":{"url":"16-reference/03-method/01-js-collection/45-db.collection.updateOne.html","title":"db.collection.updateOne（）","keywords":"","body":" db.collection.updateOne（） 在本页面 定义 语法 访问控制 行为 例子 定义 db.collection. updateOne(过滤，更新，选项) version 3.2 中的新内容。 根据过滤器更新集合中的单个文档。 语法 updateOne()方法具有以下形式： db.collection.updateOne( , , { upsert: , writeConcern: , collation: , arrayFilters: [ , ... ] } ) 参数 db.collection.updateOne()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定一个空文档{ }以更新集合中的所有文档。 update document 要应用的修改。可以是以下之一： 1. 更新文件：仅包含更新运算符表达式。有关更多信息，请参见 使用更新运算符表达式文档进行更新。2. 聚合管道（从MongoDB 4.2开始）：仅包含以下聚合阶段：a. $addFields及其别名 $setb. $project及其别名 $unsetc. replaceRoot及其别名$replaceWith。有关更多信息，请参见 使用聚合管道更新。要使用替换文档进行更新，请参阅 db.collection.replaceOne()。 upsert boolean 可选的。当true，updateOne()时：1. 如果没有文档匹配filter，则创建一个新文档。有关详细信息，请参阅upsert 行为。 2. 更新匹配filter的文档。 要避免多次 upsert，请确保filter字段为唯一索引。 默认为false。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 collation document 可选的。 指定要用于操作的排序规则。 排序规则允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。排序规则选项具有以下语法：collation：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他排序规则字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，则MongoDB会将以前版本中使用的简单二进制比较用于字符串比较。 您不能为一个操作指定多个排序规则。例如，您不能为每个字段指定不同的排序规则，或者如果对排序执行查找，则不能对查找使用一种排序规则，而对排序使用另一种排序规则。 3.4版的新功能。 arrayFilters array 可选的。过滤器文档的 array，用于确定要在 array 字段上为更新操作修改哪些 array 元素。 在更新文档中，使用$[]过滤后的位置运算符定义一个标识符，然后在数组过滤器文档中引用该标识符。如果更新文档中未包含标识符，则不能具有数组过滤器文档作为标识符。 注意必须以小写字母开头，并且只包含字母数字字符。 您可以在更新文档中多次包含相同的标识符;但是，对于更新文档中的每个不同标识符($[identifier])，您必须指定恰好一个对应的 array 过滤器文档。也就是说，您不能为同一标识符指定多个 array 过滤器文档。对于 example，如果 update 语句包含标识符x(可能多次)，则不能为arrayFilters指定以下内容，其中包含 2 个单独的x过滤器文档：[ { \"x.a\": { $gt: 85 } }, { \"x.b\": { $gt: 80 } } ]但是，您可以在同一标识符上指定复合条件单个过滤器文档，例如以下示例：[ {$or：[{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}]} ] [ {$and：[{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}]} ] [ { \"x.a\": { $gt: 85 }, \"x.b\": { $gt: 80 } }] 有关示例，请参阅为数组更新操作指定arrayFilters。 version 3.6 中的新内容。 hint Document or string 可选的。一个文档或字符串，它指定用于支持查询谓词的索引。该选项可以采用索引规范文档或索引名称字符串。如果指定的索引不存在，则操作错误。有关示例，请参见为更新操作指定提示。4.2.1版中的新功能。 返回： 包含以下内容的文档：一个布尔值acknowledged，就好像该操作在运行时带有 写关注关系true或是否禁用了写关注关系false matchedCount包含匹配文档数 modifiedCount包含已修改文档数 upsertedId包含_id 要提交的文档 访问控制 在运行authorization时，用户必须具有包括以下特权的访问权限： update 对指定集合的操作。 find对指定集合的操作。 insert如果操作导致更新，则对指定的集合执行操作。 内置角色readWrite提供所需的特权。 行为 更新单个文件 db.collection.updateOne()查找与过滤器匹配的第一个文档，并应用指定的 更新修改。 使用更新运算符表达式文档进行更新 对于更新规范，db.collection.updateOne()方法可以接受仅包含更新运算符表达式的文档。 例如： db.collection.updateOne( , { $set: { status: \"D\" }, $inc: { quantity: 2 } }, ... ) 使用聚合管道进行更新 从MongoDB 4.2开始，db.collection.updateOne()方法可以接受指定要执行的修改的聚合管道 。管道可以包括以下阶段：[ , , ... ] $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 例如： db.collection.updateOne( , [ { $set: { status: \"Modified\", comments: [ \"$misc1\", \"$misc2\" ] } }, { $unset: [ \"misc1\", \"misc2\" ] } ] ... ) 注意 $set和$unset在管道中是指聚集阶段$set，并$unset分别，而不是更新的运算符$set和$unset。 有关示例，请参见使用聚合管道更新。 UPSERT 如果upsert: true和filter没有文档匹配，则 db.collection.updateOne()根据条件filter和update修改创建一个新文档。请参阅 使用Upsert更新。 如果在分片集合上指定upsert: true，则必须在filter中包括完整的分片键。有关分片集合db.collection.updateOne()的其他行为，请参见分片集合。 固定集合 如果更新操作更改了文档大小，则该操作将失败。 分片集合 要db.collection.updateOne()在分片集合上使用： 如果未指定upsert: true，则必须在字段_id上包含完全匹配项或将目标指定为单个分片（例如，通过在过滤器中包含分片键）。 如果指定upsert: true，则过滤器 必须包含分片键。 碎片键修改 从MongoDB 4.2开始，您可以更新文档的分片键值，除非分片键字段是不可变_id字段。有关更新分片键的详细信息，请参见更改文档的分片键值。 在MongoDB 4.2之前，文档的分片键字段值是不可变的。 要用于db.collection.updateOne()更新分片键： 您必须在运行mongos无论是在事务或作为重试写。千万不能直接在碎片颁发运行。 您必须在查询过滤器的完整分片键上包含相等条件。例如，如果一个集合messages 使用{ country : 1, userid : 1 }的片键，更新为一个文件的碎片关键，你必须包括在country: , userid: 查询过滤器。您可以根据需要在查询中包括其他字段。 可解释性 updateOne()与不兼容 db.collection.explain()。 使用update()代替。 事务 db.collection.updateOne()可以在多文档事务中使用。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 现有的集合和事务 在事务内部，您可以指定对现有集合的读/写操作。如果db.collection.updateOne()导致upsert，则该集合必须已经存在。 写关注和事务 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 例子 更新 restaurant集合包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\" }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 0 } 以下操作使用violations字段更新name: \"Central Perk Cafe\"的单个文档： try { db.restaurant.updateOne( { \"name\" : \"Central Perk Cafe\" }, { $set: { \"violations\" : 3 } } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } 如果未找到匹配项，则操作将返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0 } 如果未找到 match，则设置upsert: true将插入文档。见使用 Upsert 更新 使用聚合管道更新 从MongoDB 4.2开始，db.collection.updateOne()可以使用聚合管道进行更新。管道可以包括以下阶段： $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 实施例1 以下示例使用聚合管道文档中其他字段的值来修改字段。 members使用以下文档创建一个集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"A\", \"points\" : 2, \"misc1\" : \"note to self: confirm status\", \"misc2\" : \"Need to activate\", \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, comments: [ \"reminder: ping me at 100pts\", \"Some random comment\" ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]) 假设您希望将这些字段收集到一个新字段中，而不是使用单独的misc1和misc2字段comments。以下更新操作使用聚合管道执行以下操作： 添加新comments字段并设置该lastUpdate字段。 删除集合中所有文档的misc1和misc2字段。 db.members.updateOne( { _id: 1 }, [ { $set: { status: \"Modified\", comments: [ \"$misc1\", \"$misc2\" ], lastUpdate: \"$$NOW\" } }, { $unset: [ \"misc1\", \"misc2\" ] } ] ) 注意 $set和$unset在管道中是指聚合阶段$set，并$unset分别，而不是更新的运营商$set和$unset。 第一阶段 $set阶段： 创建一个新的数组字段，comments其元素是misc1和misc2字段的当前内容 将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 该$unset阶段将删除misc1和misc2字段。 命令后，集合包含以下文档： { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"Modified\", \"points\" : 2, \"lastUpdate\" : ISODate(\"2020-01-23T05:21:59.321Z\"), \"comments\" : [ \"note to self: confirm status\", \"Need to activate\" ] } { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"comments\" : [ \"reminder: ping me at 100pts\", \"Some random comment\" ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } 示例 聚合管道允许基于当前字段值执行条件更新，以及使用当前字段值来计算单独的字段值。 例如，students3使用以下文档创建一个集合： db.students3.insert([ { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"average\" : 92, \"grade\" : \"A\", \"lastUpdate\" : ISODate(\"2020-01-23T05:18:40.013Z\") }, { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"average\" : 91, \"grade\" : \"A\", \"lastUpdate\" : ISODate(\"2020-01-23T05:18:40.013Z\") }, { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]); 第三个文档_id: 3缺少average和 grade 字段。使用聚合管道，可以使用计算出的平均成绩和字母成绩更新文档。 db.students3.updateOne( { _id: 3 }, [ { $set: { average: { $trunc: [ { $avg: \"$tests\" }, 0 ] }, lastUpdate: \"$$NOW\" } }, { $set: { grade: { $switch: { branches: [ { case: { $gte: [ \"$average\", 90 ] }, then: \"A\" }, { case: { $gte: [ \"$average\", 80 ] }, then: \"B\" }, { case: { $gte: [ \"$average\", 70 ] }, then: \"C\" }, { case: { $gte: [ \"$average\", 60 ] }, then: \"D\" } ], default: \"F\" } } } } ] ) 注意 $set管道中的使用是指聚合阶段 $set，而不是更新运算符$set。 第一阶段 $set阶段： 根据字段average的平均值 计算一个新tests字段。请参阅$avg有关 $avg聚合运算符$trunc的更多信息和有关$trunc截断聚合运算符的更多信息。 将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 $set阶段计算新字段grade基础上，average在前一阶段计算。参见 $switch以获取有关$switch 聚合运算符的更多信息。 命令后，集合包含以下文档： { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"average\" : 92, \"grade\" : \"A\", \"lastUpdate\" : ISODate(\"2020-01-23T05:18:40.013Z\") } { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"average\" : 91, \"grade\" : \"A\", \"lastUpdate\" : ISODate(\"2020-01-23T05:18:40.013Z\") } { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:33:30.674Z\"), \"average\" : 75, \"grade\" : \"C\" } 也可以看看 聚合管道更新 使用 Upsert 更新 restaurant集合包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : \"0\" } 以下操作尝试使用name : \"Pizza Rat's Pizzaria\"更新文档，而upsert: true： try { db.restaurant.updateOne( { \"name\" : \"Pizza Rat's Pizzaria\" }, { $set: {\"_id\" : 4, \"violations\" : 7, \"borough\" : \"Manhattan\" } }, { upsert: true } ); } catch (e) { print(e); } 从upsert:true开始，文档基于filter和update标准inserted。操作返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0, \"upsertedId\" : 4 } 该集合现在包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 4 }, { \"_id\" : 4, \"name\" : \"Pizza Rat's Pizzaria\", \"Borough\" : \"Manhattan\", \"violations\" : 7 } name字段使用filter条件填充，而update operators 用于创建文档的 rest。 以下操作使用violations更新大于10的第一个文档： try { db.restaurant.updateOne( { \"violations\" : { $gt: 10} }, { $set: { \"Closed\" : true } }, { upsert: true } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0, \"upsertedId\" : ObjectId(\"56310c3c0c5cbb6031cafaea\") } 该集合现在包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"Borough\" : \"Manhattan\", \"violations\" : 3 }, { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"Borough\" : \"Queens\", \"violations\" : 2 }, { \"_id\" : 3, \"name\" : \"Empire State Pub\", \"Borough\" : \"Brooklyn\", \"violations\" : 4 }, { \"_id\" : 4, \"name\" : \"Pizza Rat's Pizzaria\", \"Borough\" : \"Manhattan\", \"grade\" : 7 } { \"_id\" : ObjectId(\"56310c3c0c5cbb6031cafaea\"), \"Closed\" : true } 由于没有文档与过滤器匹配，并且upsert是true，updateOne仅使用生成的_id和update条件插入文档。 写关注更新 给定三个成员副本集，以下操作指定majority wtimeout，wtimeout 100： try { db.restaurant.updateOne( { \"name\" : \"Pizza Rat's Pizzaria\" }, { $inc: { \"violations\" : 3}, $set: { \"Closed\" : true } }, { w: \"majority\", wtimeout: 100 } ); } catch (e) { print(e); } 如果主要和至少一个辅助设备在 100 毫秒内确认每个写入操作，则返回： { \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }): 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"cafe\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.updateOne( { category: \"cafe\" }, { $set: { status: \"Updated\" } }, { collation: { locale: \"fr\", strength: 1 } } ); 为 Array Update Operations 指定 arrayFilters version 3.6 中的新内容。 从 MongoDB 3.6 开始，在更新 array 字段时，您可以指定arrayFilters来确定要更新的 array 元素。 更新元素 Match arrayFilters Criteria 使用以下文档创建集合students： db.students.insert([ { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] }, { \"_id\" : 2, \"grades\" : [ 98, 100, 102 ] }, { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } ]) 要修改grades array 中大于或等于100的所有元素，请使用过滤后的位置 operator $ []和db.collection.updateOne方法中的arrayFilters选项： db.students.updateOne( { grades: { $gte: 100 } }, { $set: { \"grades.$[element]\" : 100 } }, { arrayFilters: [ { \"element\": { $gte: 100 } } ] } ) 该操作更新单个文档的grades字段，在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } 要修改是大于或等于所有元素100中 grades阵列中，使用过滤的位置操作者 $[]与arrayFilters在选项 db.collection.updateOne方法： db.students.updateOne( { grades: { $gte: 100 } }, { $set: { \"grades.$[element]\" : 100 } }, { arrayFilters: [ { \"element\": { $gte: 100 } } ] } ) 该操作将更新grades单个文档的字段，并且在操作之后，集合具有以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } 更新 Array 文档的特定元素 使用以下文档创建集合students2： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 要修改grades array 中等级大于或等于85的所有元素的mean字段的 value，请使用过滤后的位置 operator $ []和db.collection.updateOne方法中的arrayFilters： db.students2.updateOne( { }, { $set: { \"grades.$[elem].mean\" : 100 } }, { arrayFilters: [ { \"elem.grade\": { $gte: 85 } } ] } ) 该操作更新单个文档的 array，并且在操作之后，该集合具有以下文档： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } 也可以看看 要更新多个文档，请参阅db.collection.updateMany()。 指定hint更新操作 4.2.1版中的新功能。 members使用以下文档创建样本集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" }, { \"_id\" : 3, \"member\" : \"lmn123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 4, \"member\" : \"pqr123\", \"status\" : \"D\", \"points\" : 20, \"misc1\" : \"Deactivated\", \"misc2\" : null }, { \"_id\" : 5, \"member\" : \"ijk123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 6, \"member\" : \"cde123\", \"status\" : \"A\", \"points\" : 86, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" } ]) 在集合上创建以下索引： db.members.createIndex( { status: 1 } ) db.members.createIndex( { points: 1 } ) 以下更新操作明确暗示要使用索引：{ status: 1 } 注意 如果指定的索引不存在，则操作错误。 db.members.updateOne( { \"points\": { $lte: 20 }, \"status\": \"P\" }, { $set: { \"misc1\": \"Need to activate\" } }, { hint: { status: 1 } } ) update命令返回以下内容： { \"acknowledged\" : true, \"matchedCount\" : 1, \"modifiedCount\" : 1 } 要查看使用的索引，可以使用$indexStats管道： db.members.aggregate( [ { $indexStats: { } }, { $sort: { name: 1 } } ] ) 译者：李冠飞 校对： 参见 原文 - db.collection.updateOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/46-db.collection.updateMany.html":{"url":"16-reference/03-method/01-js-collection/46-db.collection.updateMany.html","title":"db.collection.updateMany（）","keywords":"","body":" db.collection.updateMany（） 在本页面 定义 语法 访问控制 行为 例子 定义 db.collection. updateMany(过滤，更新，选项) version 3.2 中的新内容。 更新与集合的指定过滤器匹配的所有文档。 语法 updateMany()方法具有以下形式： db.collection.updateMany( , , { upsert: , writeConcern: , collation: , arrayFilters: [ , ... ], hint: // Available starting in MongoDB 4.2.1 } ) 参数 updateMany()方法采用以下参数： 参数 类型 描述 filter document 更新的选择标准。可以使用与find()方法相同的query selectors。 指定一个空文档{ }以更新集合中的所有文档。 update document 要应用的修改。可以是以下之一： 1. 更新文件：仅包含更新运算符表达式。有关更多信息，请参见 使用更新运算符表达式文档进行更新。2. 聚合管道（从MongoDB 4.2开始）：仅包含以下聚合阶段：a. $addFields及其别名 $setb. $project及其别名 $unsetc. replaceRoot及其别名$replaceWith。有关更多信息，请参见 使用聚合管道更新。要使用替换文档进行更新，请参阅 db.collection.replaceOne()。 upsert boolean 可选的。当true，updateMany()时：1. 如果没有文档匹配filter，则创建一个新文档。有关详细信息，请参阅upsert 行为。 2. 更新匹配filter的文档。 要避免多次 upsert，请确保filter字段为唯一索引。 默认为false。 writeConcern document 可选的。表示写关注的文件。省略使用默认写入问题。如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 collation document 可选的。 指定要用于操作的排序规则。 排序规则允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。排序规则选项具有以下语法：collation：{ locale：， caseLevel：， caseFirst：， strength：， numericOrdering：， alternate：， maxVariable：， backwards ： } 指定排序规则时，locale字段是必填字段;所有其他排序规则字段都是可选的。有关字段的说明，请参阅整理文件。 如果未指定排序规则但集合具有默认排序规则(请参阅db.createCollection())，则操作将使用为集合指定的排序规则。 如果没有为集合或操作指定排序规则，则MongoDB会将以前版本中使用的简单二进制比较用于字符串比较。 您不能为一个操作指定多个排序规则。例如，您不能为每个字段指定不同的排序规则，或者如果对排序执行查找，则不能对查找使用一种排序规则，而对排序使用另一种排序规则。 3.4版的新功能。 arrayFilters array 可选的。过滤器文档的 array，用于确定要在 array 字段上为更新操作修改哪些 array 元素。 在更新文档中，使用$[]过滤后的位置运算符定义一个标识符，然后在数组过滤器文档中引用该标识符。如果更新文档中未包含标识符，则不能具有数组过滤器文档作为标识符。 注意必须以小写字母开头，并且只包含字母数字字符。 您可以在更新文档中多次包含相同的标识符;但是，对于更新文档中的每个不同标识符($[identifier])，您必须指定恰好一个对应的 array 过滤器文档。也就是说，您不能为同一标识符指定多个 array 过滤器文档。对于 example，如果 update 语句包含标识符x(可能多次)，则不能为arrayFilters指定以下内容，其中包含 2 个单独的x过滤器文档：[ { \"x.a\": { $gt: 85 } }, { \"x.b\": { $gt: 80 } } ]但是，您可以在同一标识符上指定复合条件单个过滤器文档，例如以下示例：[ {$or：[{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}]} ] [ {$and：[{\"x.a\": {$gt: 85}}, {\"x.b\": {$gt: 80}}]} ] [ { \"x.a\": { $gt: 85 }, \"x.b\": { $gt: 80 } }] 有关示例，请参阅为数组更新操作指定arrayFilters。 version 3.6 中的新内容。 hint Document or string 可选的。一个文档或字符串，它指定用于支持查询谓词的索引。该选项可以采用索引规范文档或索引名称字符串。如果指定的索引不存在，则操作错误。有关示例，请参见为更新操作指定提示。4.2.1版中的新功能。 返回： 包含以下内容的文档：一个布尔值acknowledged，就好像该操作在运行时带有 写关注关系true或是否禁用了写关注关系false matchedCount包含匹配文档数 modifiedCount包含已修改文档数 upsertedId包含_id 要提交的文档 访问控制 在运行authorization时，用户必须具有包括以下特权的访问权限： update 对指定集合的操作。 find对指定集合的操作。 insert如果操作导致更新，则对指定的集合执行操作。 内置角色readWrite提供所需的特权。 行为 updateMany()使用update条件应用修改更新匹配filter的集合中的所有匹配文档。 UPSERT 如果upsert: true和没有与filter文档匹配，则db.collection.updateMany()根据filter和update参数创建一个新文档。 如果在分片集合上指定upsert: true，则必须在 filter 中包含完整的分片键。有关其他db.collection.updateMany()行为，请参见分片集合。 请参阅 使用Upsert更新多个文档。 使用更新运算符表达式文档进行更新 对于修改规范，该 db.collection.updateMany()方法可以接受仅包含要执行的更新操作符表达式的文档。 例如： db.collection.updateMany( , { $set: { status: \"D\" }, $inc: { quantity: 2 } }, ... ) 使用聚合管道进行更新 从MongoDB 4.2开始，db.collection.updateMany()方法可以接受指定要执行修改的聚合管道 。管道可以包括以下阶段：[ , , ... ] $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 例如： db.collection.updateMany( , [ { $set: { status: \"Modified\", comments: [ \"$misc1\", \"$misc2\" ] } }, { $unset: [ \"misc1\", \"misc2\" ] } ] ... ) 注意 管道中使用的$set和$unset分别指向聚合阶段$set和$unset，而不是更新操作符$set和$unset。 有关示例，请参见使用聚合管道更新。 固定集合 如果更新操作更改了文档大小，则该操作将失败。 分片集合 对于db.collection.updateMany()包含分片集合并包含upsert: true在分片集合中的操作，必须在filter中包含完整的分片键。 可解释性 updateMany()与 db.collection.explain()不兼容。 使用update()代替。 事务 db.collection.updateMany()可以在多文档事务中使用。 如果该操作导致upsert，则该集合必须已经存在。 如果在事务中运行，请不要为操作明确设置写关注点。要对事务使用写关注，请参见 事务和写关注。 重要 在大多数情况下，与单文档写入相比，多文档事务产生的性能成本更高，并且多文档事务的可用性不应替代有效的架构设计。在许多情况下， 非规范化数据模型（嵌入式文档和数组）将继续是您的数据和用例的最佳选择。也就是说，在许多情况下，适当地对数据建模将最大程度地减少对多文档交易的需求。 有关其他事务使用方面的注意事项（例如运行时限制和操作日志大小限制），另请参见 生产注意事项。 例子 更新多个文档 restaurant集合包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"violations\" : 3 } { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"violations\" : 2 } { \"_id\" : 3, \"name\" : \"Empire State Sub\", \"violations\" : 5 } { \"_id\" : 4, \"name\" : \"Pizza Rat's Pizzaria\", \"violations\" : 8 } 下面的操作更新，所有文件violations都大于4和$set审核标志： try { db.restaurant.updateMany( { violations: { $gt: 4 } }, { $set: { \"Review\" : true } } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"matchedCount\" : 2, \"modifiedCount\" : 2 } 该集合现在包含以下文档： { \"_id\" : 1, \"name\" : \"Central Perk Cafe\", \"violations\" : 3 } { \"_id\" : 2, \"name\" : \"Rock A Feller Bar and Grill\", \"violations\" : 2 } { \"_id\" : 3, \"name\" : \"Empire State Sub\", \"violations\" : 5, \"Review\" : true } { \"_id\" : 4, \"name\" : \"Pizza Rat's Pizzaria\", \"violations\" : 8, \"Review\" : true } 如果未找到匹配项，则操作将返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0 } 如果未找到匹配项，则设置upsert: true将插入文档。 使用聚合管道更新 从MongoDB 4.2开始，db.collection.updateMany()可以使用聚合管道进行更新。管道可以包括以下阶段： $addFields及其别名 $set $project及其别名 $unset $replaceRoot及其别名$replaceWith。 使用聚合管道可以实现更具表达力的更新语句，例如根据当前字段值表达条件更新，或使用另一个字段的值更新一个字段。 实施例1 以下示例使用聚合管道文档中其他字段的值来修改字段。 members使用以下文档创建一个集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"A\", \"points\" : 2, \"misc1\" : \"note to self: confirm status\", \"misc2\" : \"Need to activate\", \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\", \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]) 假设您希望将这些字段收集到一个新字段中，而不是使用单独的misc1和misc2字段comments。以下更新操作使用聚合管道执行以下操作： 添加新comments字段并设置该lastUpdate字段。 删除集合中所有文档的misc1和misc2字段。 db.members.updateMany( { }, [ { $set: { status: \"Modified\", comments: [ \"$misc1\", \"$misc2\" ], lastUpdate: \"$$NOW\" } }, { $unset: [ \"misc1\", \"misc2\" ] } ] ) 注意 $set和$unset在管道中是指聚合阶段$set，并$unset分别，而不是更新的运营商$set和$unset。 第一阶段 $set阶段： 创建一个新的数组字段，comments其元素是misc1和misc2字段的当前内容 将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 $unset阶段将删除misc1和misc2字段。 命令后，集合包含以下文档： { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"Modified\", \"points\" : 2, \"lastUpdate\" : ISODate(\"2020-01-23T05:50:49.247Z\"), \"comments\" : [ \"note to self: confirm status\", \"Need to activate\" ] } { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"Modified\", \"points\" : 60, \"lastUpdate\" : ISODate(\"2020-01-23T05:50:49.247Z\"), \"comments\" : [ \"reminder: ping me at 100pts\", \"Some random comment\" ] } 示例 聚合管道允许基于当前字段值执行条件更新，以及使用当前字段值来计算单独的字段值。 例如，students3使用以下文档创建一个集合： db.students3.insert([ { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") }, { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2019-01-01T00:00:00Z\") } ]); 使用聚合管道，可以使用计算出的平均成绩和字母成绩更新文档。 db.students3.updateMany( { }, [ { $set: { average : { $trunc: [ { $avg: \"$tests\" }, 0 ] } , lastUpdate: \"$$NOW\" } }, { $set: { grade: { $switch: { branches: [ { case: { $gte: [ \"$average\", 90 ] }, then: \"A\" }, { case: { $gte: [ \"$average\", 80 ] }, then: \"B\" }, { case: { $gte: [ \"$average\", 70 ] }, then: \"C\" }, { case: { $gte: [ \"$average\", 60 ] }, then: \"D\" } ], default: \"F\" } } } } ] ) 注意 $set管道中的使用是指聚合阶段 $set，而不是更新运算符$set。 第一阶段 $set阶段： 根据字段average的平均值 计算一个新tests字段。请参阅$avg有关 $avg聚合运算符$trunc的更多信息和有关$trunc截断聚合运算符的更多信息。 将字段设置为lastUpdate聚合变量的值NOW。聚合变量 NOW解析为当前日期时间值，并且在整个管道中保持不变。要访问聚合变量，请在变量前加双美元符号$$ 并用引号引起来。 第二阶段 $set阶段计算新字段grade基础上，average在前一阶段计算。参见 $switch以获取有关$switch 聚合运算符的更多信息。 命令后，集合包含以下文档： { \"_id\" : 1, \"tests\" : [ 95, 92, 90 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:31:01.670Z\"), \"average\" : 92, \"grade\" : \"A\" } { \"_id\" : 2, \"tests\" : [ 94, 88, 90 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:31:01.670Z\"), \"average\" : 90, \"grade\" : \"A\" } { \"_id\" : 3, \"tests\" : [ 70, 75, 82 ], \"lastUpdate\" : ISODate(\"2020-01-24T17:31:01.670Z\"), \"average\" : 75, \"grade\" : \"C\" } 也可以看看 聚合管道更新 使用 Upsert 更新多个文档 inspectors集合包含以下文档： { \"_id\" : 92412, \"inspector\" : \"F. Drebin\", \"Sector\" : 1, \"Patrolling\" : true }, { \"_id\" : 92413, \"inspector\" : \"J. Clouseau\", \"Sector\" : 2, \"Patrolling\" : false }, { \"_id\" : 92414, \"inspector\" : \"J. Clouseau\", \"Sector\" : 3, \"Patrolling\" : true }, { \"_id\" : 92415, \"inspector\" : \"R. Coltrane\", \"Sector\" : 3, \"Patrolling\" : false } 以下操作更新Sector大于 4 且inspector等于\"R. Coltrane\"的所有文档： try { db.inspectors.updateMany( { \"Sector\" : { $gt : 4 }, \"inspector\" : \"R. Coltrane\" }, { $set: { \"Patrolling\" : false } }, { upsert: true } ); } catch (e) { print(e); } 操作返回： { \"acknowledged\" : true, \"matchedCount\" : 0, \"modifiedCount\" : 0, \"upsertedId\" : ObjectId(\"56fc5dcb39ee682bdc609b02\") } 该集合现在包含以下文档： { \"_id\" : 92412, \"inspector\" : \"F. Drebin\", \"Sector\" : 1, \"Patrolling\" : true }, { \"_id\" : 92413, \"inspector\" : \"J. Clouseau\", \"Sector\" : 2, \"Patrolling\" : false }, { \"_id\" : 92414, \"inspector\" : \"J. Clouseau\", \"Sector\" : 3, \"Patrolling\" : true }, { \"_id\" : 92415, \"inspector\" : \"R. Coltrane\", \"Sector\" : 3, \"Patrolling\" : false }, { \"_id\" : ObjectId(\"56fc5dcb39ee682bdc609b02\"), \"inspector\" : \"R.Coltrane\", \"Patrolling\" : false } 由于没有文档与过滤器匹配，并且upsert是true，updateMany插入了生成_id的文档，filter和update修饰符的等式条件。 写关注更新 给定三个成员副本集，以下操作指定majority majority和wtimeout 100： try { db.restaurant.updateMany( { \"name\" : \"Pizza Rat's Pizzaria\" }, { $inc: { \"violations\" : 3}, $set: { \"Closed\" : true } }, { w: \"majority\", wtimeout: 100 } ); } catch (e) { print(e); } 如果确认时间超过wtimeout限制，则抛出以下 exception： WriteConcernError({ \"code\" : 64, \"errInfo\" : { \"wtimeout\" : true }, \"errmsg\" : \"waiting for replication timed out\" }) : undefined wtimeout错误仅表示操作未在 time 完成。写操作本身仍然可以在 set time 限制之外成功。 指定排序规则 version 3.4 中的新内容。 整理允许用户为 string 比较指定 language-specific 规则，例如字母和重音标记的规则。 集合myColl具有以下文档： { _id: 1, category: \"cafe\", status: \"A\" } { _id: 2, category: \"cafe\", status: \"a\" } { _id: 3, category: \"cafE\", status: \"a\" } 以下操作包括整理选项： db.myColl.updateMany( { category: \"cafe\" }, { $set: { status: \"Updated\" } }, { collation: { locale: \"fr\", strength: 1 } } ); 为 Array Update Operations 指定 arrayFilters version 3.6 中的新内容。 从 MongoDB 3.6 开始，在更新 array 字段时，您可以指定arrayFilters来确定要更新的 array 元素。 更新元素 Match arrayFilters Criteria 使用以下文档创建集合students： db.students.insert([ { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] }, { \"_id\" : 2, \"grades\" : [ 98, 100, 102 ] }, { \"_id\" : 3, \"grades\" : [ 95, 110, 100 ] } ]) 要更新grades array 中大于或等于100的所有元素，请使用带有arrayFilters选项的已过滤位置 operator $ []： db.students.updateMany( { grades: { $gte: 100 } }, { $set: { \"grades.$[element]\" : 100 } }, { arrayFilters: [ { \"element\": { $gte: 100 } } ] } ) 操作后，该集合包含以下文档： { \"_id\" : 1, \"grades\" : [ 95, 92, 90 ] } { \"_id\" : 2, \"grades\" : [ 98, 100, 100 ] } { \"_id\" : 3, \"grades\" : [ 95, 100, 100 ] } 更新 Array 文档的特定元素 使用以下文档创建集合students2： db.students2.insert([ { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 90, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 6 } ] }, { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ] } ]) 要修改grades array 中等级大于或等于85的所有元素的mean字段的 value，请使用已过滤的位置 operator $ []和arrayFilters： db.students2.updateMany( { }, { $set: { \"grades.$[elem].mean\" : 100 } }, { arrayFilters: [ { \"elem.grade\": { $gte: 85 } } ] } ) 操作后，该集合包含以下文件： { \"_id\" : 1, \"grades\" : [ { \"grade\" : 80, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 6 } ] } { \"_id\" : 2, \"grades\" : [ { \"grade\" : 90, \"mean\" : 100, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 100, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 100, \"std\" : 4 } ] } 指定hint更新操作 4.2.1版中的新功能。 members使用以下文档创建样本集合： db.members.insertMany([ { \"_id\" : 1, \"member\" : \"abc123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 2, \"member\" : \"xyz123\", \"status\" : \"A\", \"points\" : 60, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" }, { \"_id\" : 3, \"member\" : \"lmn123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 4, \"member\" : \"pqr123\", \"status\" : \"D\", \"points\" : 20, \"misc1\" : \"Deactivated\", \"misc2\" : null }, { \"_id\" : 5, \"member\" : \"ijk123\", \"status\" : \"P\", \"points\" : 0, \"misc1\" : null, \"misc2\" : null }, { \"_id\" : 6, \"member\" : \"cde123\", \"status\" : \"A\", \"points\" : 86, \"misc1\" : \"reminder: ping me at 100pts\", \"misc2\" : \"Some random comment\" } ]) 在集合上创建以下索引： db.members.createIndex( { status: 1 } ) db.members.createIndex( { points: 1 } ) 以下更新操作明确暗示要使用索引：{ status: 1 } 注意 如果指定的索引不存在，则操作错误。 db.members.updateMany( { \"points\": { $lte: 20 }, \"status\": \"P\" }, { $set: { \"misc1\": \"Need to activate\" } }, { hint: { status: 1 } } ) update命令返回以下内容： { \"acknowledged\" : true, \"matchedCount\" : 3, \"modifiedCount\" : 3 } 要查看使用的索引，可以使用$indexStats管道： db.members.aggregate( [ { $indexStats: { } }, { $sort: { name: 1 } } ] ) 译者：李冠飞 校对： 参见 原文 - db.collection.updateMany() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/47-db.collection.watch.html":{"url":"16-reference/03-method/01-js-collection/47-db.collection.watch.html","title":"db.collection.watch（）","keywords":"","body":" db.collection.watch（） 在本页面 定义 可用性 部署方式 存储引擎 阅读关注majority支持 行为 可恢复 完整文档查找和更新操作 访问控制 例子 打开更改流 使用完整文档更新查找更改流 使用聚合管道过滤器更改流 恢复变更流 定义 db.collection. watch(管道，选项) 仅适用于副本集和分片群集 在集合上打开改变流游标。 参数 类型 描述 pipeline array 以下一个或多个聚合阶段的序列： $match $project $addFields $replaceRoot $replaceWith（从MongoDB 4.2开始可用） $redact$set（从MongoDB 4.2开始可用）$unset（从MongoDB 4.2开始可用）指定管道以过滤/修改变更事件输出。从MongoDB 4.2开始，如果更改流聚合管道修改了事件的_id字段，则更改流将引发异常。 options document 可选的。修改watch()行为的其他选项。 如果未指定管道但传递options文档，则必须将空 array []传递给pipeline参数。 options文档可以包含以下字段和值： 字段 类型 描述 resumeAfter document 可选的。指示watch尝试在恢复令牌中指定的操作之后重新开始通知。 每个更改流 event 文档都包含一个恢复标记作为_id字段。传递 change event 文档的整个_id字段，该字段表示您要在之后恢复的操作。resumeAfter与startAfter和 互斥startAtOperationTime。 startAfter document 可选的。指示watch在恢复令牌中指定的操作之后尝试启动新的更改流。允许在事件无效后恢复通知。每个变更流事件文档都包括一个恢复令牌作为 _id字段。传递更改事件文档的整个 _id字段，该字段代表您要恢复的操作。startAfter与resumeAfter和 互斥startAtOperationTime。4.2版中的新功能。 fullDocument string 可选的。默认情况下，watch()返回由更新操作修改的字段的增量，而不是整个更新的文档。 设置fullDocument为“ \"updateLookup\"直接” watch()以查找更新文档的最新多数批准版本。 watch()返回一个fullDocument字段，其中包含除了updateDescription增量以外的文档查找。 batchSize int 可选的。指定 MongoDB集群的每批响应中返回的最大更改次数。 具有与cursor.batchSize()的功能相同。 maxAwaitTimeMS int 可选的。服务器等待新数据更改以在返回空批处理之前向更改流游标报告的最大时间(以毫秒为单位)。 默认为1000毫秒。 collation document 可选的。传递排序规则文件为更改流游标指定排序。从MongoDB 4.2开始，simple如果省略，默认为二进制比较。在早期版本中，在单个集合上打开的更改流将继承该集合的默认排序规则。 startAtOperationTime Timestamp 可选的。变更流的起点。如果指定的起点是过去的时间，则必须在操作日志的时间范围内。要查看操作日志的时间范围，请参阅 rs.printReplicationInfo()。startAtOperationTime与resumeAfter 和互斥startAfter。版本4.0中的新功能。 返回值： 一个游标是保持被打开，以MongoDB的部署的连接保持打开状态，并收集存在。有关变更事件文档的示例，请参见变更事件。 也可以看看 db.watch() 和 Mongo.watch() 可用性 部署 db.collection.watch()可用于副本集和分片群集部署： 对于副本集，您可以db.collection.watch()在任何数据承载成员上发行。 对于分片群集，必须db.collection.watch()在mongos实例上发出。 存储引擎 您只能db.collection.watch()与Wired Tiger存储引擎一起使用。 阅读关注majority支持 从MongoDB 4.2开始，无论是否支持读关注，更改流都可用\"majority\"。也就是说，majority可以启用（默认）读取关注支持或禁用 以使用更改流。 在MongoDB 4.0和更早版本中，更改流仅在\"majority\"启用了阅读关注支持后才可用（默认）。 行为 db.collection.watch()仅通知持续存在于大多数 data-bearing 成员的数据更改。 改变流游标保持打开状态，直到出现以下情况之一： 游标显式关闭。 发生无效事件；例如：集合删除或重命名。 与 MongoDB 部署的连接已关闭。 如果部署是分片集群，则删除分片可能会导致打开更改流游标关闭，并且关闭的更改流游标可能无法完全恢复。 可恢复 与 MongoDB 驱动程序不同，mongo shell 在发生错误后不会自动尝试恢复更改流游标。 MongoDB 驱动程序尝试在某些错误后自动恢复更改流游标。 db.collection.watch()使用存储在 oplog 中的信息来生成更改 event 描述并生成与该操作关联的恢复标记。如果由传递给resumeAfteror startAfter选项的恢复令牌标识的操作已经从oplog中删除，db.collection.watch()则无法恢复更改流。 有关恢复更改流的更多信息，请参阅恢复变更流。 注意 resumeAfter在无效事件（例如，集合删除或重命名）关闭流之后，您不能用来恢复更改 流。从MongoDB 4.2开始，您可以使用 startAfter在invalidate事件之后启动新的更改流。 如果部署是分片集群，则分片删除可能会导致打开的更改流游标关闭，并且关闭的更改流游标可能无法完全恢复。 恢复令牌 恢复令牌_data类型取决于MongoDB版本，在某些情况下，取决于更改流打开/恢复时的功能兼容性版本（fcv）（即，fcv值的更改不会影响已打开的更改流的恢复令牌。 ）： MongoDB版本 功能兼容版本 恢复令牌_data类型 MongoDB 4.2及更高版本 “ 4.2”或“ 4.0” 十六进制编码的字符串（v1） MongoDB 4.0.7及更高版本 “ 4.0”或“ 3.6” 十六进制编码的字符串（v1） MongoDB 4.0.6及更早版本 “ 4.0” 十六进制编码的字符串（v0） MongoDB 4.0.6及更早版本 “ 3.6” BinData MongoDB 3.6 “ 3.6” BinData 使用十六进制编码的字符串恢复令牌，您可以对恢复令牌进行比较和排序。 无论fcv值如何，4.0部署都可以使用BinData恢复令牌或十六进制字符串恢复令牌来恢复更改流。这样，4.0部署可以使用在3.6部署的集合中打开的更改流中的恢复令牌。 MongoDB版本中引入的新的恢复令牌格式不能被早期MongoDB版本使用。 完整文档查找和更新操作 默认情况下，更改流游标返回用于更新操作的特定字段更改/增量。您还可以配置更改流以查找并返回更改文档的当前多数提交版本。根据更新和查找之间可能发生的其他写入操作，返回的文档可能与更新时的文档有很大不同。 根据更新操作期间应用的更改数量和整个文档的大小，存在更新操作的更改事件文档的大小大于16MB BSON文档限制的风险。如果发生这种情况，服务器将关闭更改流游标并返回错误。 访问控制 使用访问控制运行时，用户必须对集合资源具有 find和changeStream特权操作。也就是说，用户必须具有授予以下特权的角色： { resource: { db: , collection: }, actions: [ \"find\", \"changeStream\" ] } 内置read角色提供适当的特权。 例子 打开更改流 以下操作将针对data.sensors集合打开更改流游标： watchCursor = db.getSiblingDB(\"data\").sensors.watch() 迭代光标以检查新的 events。使用cursor.isExhausted()方法确保循环仅在更改流游标关闭且最新批次中没有 objects 时退出： while (!watchCursor.isExhausted()){ if (watchCursor.hasNext()){ watchCursor.next(); } } 有关更改流输出的完整文档，请参阅变更事件。 使用完整文档更新查找更改流 设置fullDocument选项以\"updateLookup\"指示更改流游标查找与更新更改流事件相关联的文档的最新的多数提交版本。 以下操作使用fullDocument : \"updateLookup\"该选项针对集合 data.sensors打开更改流游标。 watchCursor = db.getSiblingDB(\"data\").sensors.watch( [], { fullDocument : \"updateLookup\" } ) 迭代光标以检查新的 events。使用cursor.isExhausted()方法确保循环仅在更改流游标关闭且最新批次中没有 objects 时退出： while (!watchCursor.isExhausted()){ if (watchCursor.hasNext()){ watchCursor.next(); } } 对于任何更新操作，change事件都会在fullDocument字段中返回文档查找的结果。 有关完整文档更新输出的示例，请参阅更改流更新事件。 有关更改流输出的完整文档，请参阅改变事件。 使用聚合管道过滤器更改流 注意 从MongoDB 4.2开始，如果更改流聚合管道修改了事件的_id字段，则更改流将引发异常。 以下操作使用聚合管道打开针对data.sensors集合的更改流游标： watchCursor = db.getSiblingDB(\"data\").sensors.watch( [ { $match : {\"operationType\" : \"insert\" } } ] ) 迭代光标以检查新的事件。使用cursor.isExhausted()方法确保循环仅在更改流游标关闭且最新批次中没有 objects 时退出： while (!watchCursor.isExhausted()){ if (watchCursor.hasNext()){ watchCursor.next(); } } 更改流游标仅返回为insert的 change events。有关更改流输出的完整文档，请参阅变更事件。 恢复变更流 更改流游标返回的每个文档都包含一个恢复标记作为_id字段。要恢复更改流，请将要恢复的更改事件的整个_id文档传递给watch()的resumeAfter或startAfter选项。 以下操作data.sensors使用恢复令牌恢复针对集合的更改流游标 。假设生成恢复令牌的操作尚未脱离集群的操作日志。 let watchCursor = db.getSiblingDB(\"data\").sensors.watch(); let firstChange; while (!watchCursor.isExhausted()) { if (watchCursor.hasNext()) { firstChange = watchCursor.next(); break; } } watchCursor.close(); let resumeToken = firstChange._id; resumedWatchCursor = db.getSiblingDB(\"data\").sensors.watch( [], { resumeAfter : resumeToken } ) 迭代光标以检查新的事件。使用cursor.isExhausted()方法确保循环仅在更改流游标关闭且最新批次中没有 objects 时退出： while (!resumedWatchCursor.isExhausted()){ if (resumedWatchCursor.hasNext()){ resumedWatchCursor.next(); } } 有关恢复更改流的完整文档，请参阅恢复变更流。 译者：李冠飞 校对： 参见 原文 - db.collection.watch() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/01-js-collection/48-db.collection.validate.html":{"url":"16-reference/03-method/01-js-collection/48-db.collection.validate.html","title":"db.collection.validate（）","keywords":"","body":" db.collection.validate（） 在本页面 定义 行为 例子 定义 db.collection. validate(true) 验证集合。该方法扫描集合数据和索引的正确性并返回结果。有关输出的详细信息，请参阅验证输出。 db.collection.validate()方法具有以下语法： db.collection.validate( { full: // Optional } ) 要指定full选项，您还可以使用： db.collection.validate( ) // full option db.collection.validate()方法可以使用以下可选文档参数： 字段 类型 描述 full boolean 可选的。一个标志，用于确定命令是执行较慢但更彻底的检查还是更快但不太彻底的检查。 1. 如果true，则执行更彻底的检查。 2. 如果false，省略一些检查，但不太彻底的检查。 默认为false。 从 MongoDB 3.6 开始，对于 WiredTiger 存储引擎，只有full 验证过程将强制检查点并将所有内存中数据刷新到磁盘，然后再验证磁盘上的数据。 在以前的版本中，WT 存储引擎的数据验证 process 总是强制检查点。 db.collection.validate()方法是验证 数据库命令的包装。 行为 db.collection.validate()方法可能会占用大量资源，并且可能会影响MongoDB实例的性能。 db.collection.validate()方法获取集合的排他锁。这将阻止对集合的所有读取和写入，直到操作完成。当运行在辅助节点上时，该操作可以阻止该辅助节点上的所有其他操作，直到它完成。 db.collection.validate()方法可能很慢，特别是在较大的数据集上。 注意 由于验证扫描数据结构的方式，即使完整的集合验证也无法检测到 MMAPv1 存储引擎数据 files 上的所有形式的损坏。 例子 使用默认设置(即：full: false)验证集合myCollection db.myCollection.validate() 要对集合进行完整验证myCollection db.myCollection.validate( { full: true } ) db.myCollection.validate(true) 有关输出的详细信息，请参阅验证输出。 译者：李冠飞 校对： 参见 原文 - db.collection.validate() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor.html":{"url":"16-reference/03-method/02-js-cursor.html","title":"Cursor Methods","keywords":"","body":" Cursor Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Cursor Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/01-cursor.addOption.html":{"url":"16-reference/03-method/02-js-cursor/01-cursor.addOption.html","title":"cursor.addOption()","keywords":"","body":" cursor.addOption() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.addOption() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/02-cursor.allowDiskUse.html":{"url":"16-reference/03-method/02-js-cursor/02-cursor.allowDiskUse.html","title":"cursor.allowDiskUse()","keywords":"","body":" cursor.allowDiskUse() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.allowDiskUse() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/03-cursor.allowPartialResults.html":{"url":"16-reference/03-method/02-js-cursor/03-cursor.allowPartialResults.html","title":"cursor.allowPartialResults()","keywords":"","body":" cursor.allowPartialResults() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.allowPartialResults() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/04-cursor.batchSize.html":{"url":"16-reference/03-method/02-js-cursor/04-cursor.batchSize.html","title":"cursor.batchSize()","keywords":"","body":" cursor.batchSize() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.batchSize() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/05-cursor.close.html":{"url":"16-reference/03-method/02-js-cursor/05-cursor.close.html","title":"cursor.close()","keywords":"","body":" cursor.close() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.close() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/06-cursor.isClosed.html":{"url":"16-reference/03-method/02-js-cursor/06-cursor.isClosed.html","title":"cursor.isClosed()","keywords":"","body":" cursor.isClosed() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.isClosed() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/07-cursor.collation.html":{"url":"16-reference/03-method/02-js-cursor/07-cursor.collation.html","title":"cursor.collation()","keywords":"","body":" cursor.collation() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.collation() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/08-cursor.comment.html":{"url":"16-reference/03-method/02-js-cursor/08-cursor.comment.html","title":"cursor.comment()","keywords":"","body":" cursor.comment() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.comment() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/09-cursor.count.html":{"url":"16-reference/03-method/02-js-cursor/09-cursor.count.html","title":"cursor.count()","keywords":"","body":" cursor.count() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.count() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/10-cursor.explain.html":{"url":"16-reference/03-method/02-js-cursor/10-cursor.explain.html","title":"cursor.explain()","keywords":"","body":" cursor.explain() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.explain() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/11-cursor.forEach.html":{"url":"16-reference/03-method/02-js-cursor/11-cursor.forEach.html","title":"cursor.forEach()","keywords":"","body":" cursor.forEach() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.forEach() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/12-cursor.hasNext.html":{"url":"16-reference/03-method/02-js-cursor/12-cursor.hasNext.html","title":"cursor.hasNext()","keywords":"","body":" cursor.hasNext() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.hasNext() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/13-cursor.hint.html":{"url":"16-reference/03-method/02-js-cursor/13-cursor.hint.html","title":"cursor.hint()","keywords":"","body":" cursor.hint() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.hint() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/14-cursor.isExhausted.html":{"url":"16-reference/03-method/02-js-cursor/14-cursor.isExhausted.html","title":"cursor.isExhausted()","keywords":"","body":" cursor.isExhausted() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.isExhausted() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/15-cursor.itcount.html":{"url":"16-reference/03-method/02-js-cursor/15-cursor.itcount.html","title":"cursor.itcount()","keywords":"","body":" cursor.itcount() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.itcount() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/16-cursor.limit.html":{"url":"16-reference/03-method/02-js-cursor/16-cursor.limit.html","title":"cursor.limit()","keywords":"","body":" cursor.limit() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.limit() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/17-cursor.map.html":{"url":"16-reference/03-method/02-js-cursor/17-cursor.map.html","title":"cursor.map()","keywords":"","body":" cursor.map() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.map() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/18-cursor.max.html":{"url":"16-reference/03-method/02-js-cursor/18-cursor.max.html","title":"cursor.max()","keywords":"","body":" cursor.max() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.max() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/19-cursor.maxTimeMS.html":{"url":"16-reference/03-method/02-js-cursor/19-cursor.maxTimeMS.html","title":"cursor.maxTimeMS()","keywords":"","body":" cursor.maxTimeMS() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.maxTimeMS() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/20-cursor.min.html":{"url":"16-reference/03-method/02-js-cursor/20-cursor.min.html","title":"cursor.min()","keywords":"","body":" cursor.min() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.min() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/21-cursor.next.html":{"url":"16-reference/03-method/02-js-cursor/21-cursor.next.html","title":"cursor.next()","keywords":"","body":" cursor.next() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.next() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/22-cursor.noCursorTimeout.html":{"url":"16-reference/03-method/02-js-cursor/22-cursor.noCursorTimeout.html","title":"cursor.noCursorTimeout()","keywords":"","body":" cursor.noCursorTimeout() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.noCursorTimeout() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/23-cursor.objsLeftInBatch.html":{"url":"16-reference/03-method/02-js-cursor/23-cursor.objsLeftInBatch.html","title":"cursor.objsLeftInBatch()","keywords":"","body":" cursor.objsLeftInBatch() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.objsLeftInBatch() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/24-cursor.pretty.html":{"url":"16-reference/03-method/02-js-cursor/24-cursor.pretty.html","title":"cursor.pretty()","keywords":"","body":" cursor.pretty() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.pretty() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/25-cursor.readConcern.html":{"url":"16-reference/03-method/02-js-cursor/25-cursor.readConcern.html","title":"cursor.readConcern()","keywords":"","body":" cursor.readConcern() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.readConcern() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/26-cursor.readPref.html":{"url":"16-reference/03-method/02-js-cursor/26-cursor.readPref.html","title":"cursor.readPref()","keywords":"","body":" cursor.readPref() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.readPref() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/27-cursor.returnKey.html":{"url":"16-reference/03-method/02-js-cursor/27-cursor.returnKey.html","title":"cursor.returnKey()","keywords":"","body":" cursor.returnKey() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.returnKey() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/28-cursor.showRecordId.html":{"url":"16-reference/03-method/02-js-cursor/28-cursor.showRecordId.html","title":"cursor.showRecordId()","keywords":"","body":" cursor.showRecordId() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.showRecordId() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/29-cursor.size.html":{"url":"16-reference/03-method/02-js-cursor/29-cursor.size.html","title":"cursor.size()","keywords":"","body":" cursor.size() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.size() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/30-cursor.skip.html":{"url":"16-reference/03-method/02-js-cursor/30-cursor.skip.html","title":"cursor.skip()","keywords":"","body":" cursor.skip() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.skip() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/31-cursor.sort.html":{"url":"16-reference/03-method/02-js-cursor/31-cursor.sort.html","title":"cursor.sort()","keywords":"","body":" cursor.sort() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.sort() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/32-cursor.tailable.html":{"url":"16-reference/03-method/02-js-cursor/32-cursor.tailable.html","title":"cursor.tailable()","keywords":"","body":" cursor.tailable() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.tailable() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/02-js-cursor/33-cursor.toArray.html":{"url":"16-reference/03-method/02-js-cursor/33-cursor.toArray.html","title":"cursor.toArray()","keywords":"","body":" cursor.toArray() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cursor.toArray() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database.html":{"url":"16-reference/03-method/03-js-database.html","title":"Database Methods","keywords":"","body":" Database Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Database Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/01-db.adminCommand.html":{"url":"16-reference/03-method/03-js-database/01-db.adminCommand.html","title":"db.adminCommand()","keywords":"","body":" db.adminCommand() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.adminCommand() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/02-db.aggregate.html":{"url":"16-reference/03-method/03-js-database/02-db.aggregate.html","title":"db.aggregate()","keywords":"","body":" db.aggregate() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.aggregate() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/03-db.cloneDatabase.html":{"url":"16-reference/03-method/03-js-database/03-db.cloneDatabase.html","title":"db.cloneDatabase()","keywords":"","body":" db.cloneDatabase() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.cloneDatabase() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/04-db.commandHelp.html":{"url":"16-reference/03-method/03-js-database/04-db.commandHelp.html","title":"db.commandHelp()","keywords":"","body":" db.commandHelp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.commandHelp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/05-db.copyDatabase.html":{"url":"16-reference/03-method/03-js-database/05-db.copyDatabase.html","title":"db.copyDatabase()","keywords":"","body":" db.copyDatabase() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.copyDatabase() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/06-db.createCollection.html":{"url":"16-reference/03-method/03-js-database/06-db.createCollection.html","title":"db.createCollection()","keywords":"","body":" db.createCollection() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.createCollection() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/07-db.createView.html":{"url":"16-reference/03-method/03-js-database/07-db.createView.html","title":"db.createView()","keywords":"","body":" db.createView() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.createView() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/08-db.currentOp.html":{"url":"16-reference/03-method/03-js-database/08-db.currentOp.html","title":"db.currentOp()","keywords":"","body":" db.currentOp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.currentOp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/09-db.dropDatabase.html":{"url":"16-reference/03-method/03-js-database/09-db.dropDatabase.html","title":"db.dropDatabase()","keywords":"","body":" db.dropDatabase() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.dropDatabase() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/10-db.eval.html":{"url":"16-reference/03-method/03-js-database/10-db.eval.html","title":"db.eval()","keywords":"","body":" db.eval() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.eval() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/11-db.fsyncLock.html":{"url":"16-reference/03-method/03-js-database/11-db.fsyncLock.html","title":"db.fsyncLock()","keywords":"","body":" db.fsyncLock() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.fsyncLock() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/12-db.fsyncUnlock.html":{"url":"16-reference/03-method/03-js-database/12-db.fsyncUnlock.html","title":"db.fsyncUnlock()","keywords":"","body":" db.fsyncUnlock() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.fsyncUnlock() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/13-db.getCollection.html":{"url":"16-reference/03-method/03-js-database/13-db.getCollection.html","title":"db.getCollection()","keywords":"","body":" db.getCollection() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getCollection() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/14-db.getCollectionInfos.html":{"url":"16-reference/03-method/03-js-database/14-db.getCollectionInfos.html","title":"db.getCollectionInfos()","keywords":"","body":" db.getCollectionInfos() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getCollectionInfos() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/15-db.getCollectionNames.html":{"url":"16-reference/03-method/03-js-database/15-db.getCollectionNames.html","title":"db.getCollectionNames()","keywords":"","body":" db.getCollectionNames() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getCollectionNames() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/16-db.getLastError.html":{"url":"16-reference/03-method/03-js-database/16-db.getLastError.html","title":"db.getLastError()","keywords":"","body":" db.getLastError() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getLastError() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/17-db.getLastErrorObj.html":{"url":"16-reference/03-method/03-js-database/17-db.getLastErrorObj.html","title":"db.getLastErrorObj()","keywords":"","body":" db.getLastErrorObj() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getLastErrorObj() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/18-db.getLogComponents.html":{"url":"16-reference/03-method/03-js-database/18-db.getLogComponents.html","title":"db.getLogComponents()","keywords":"","body":" db.getLogComponents() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getLogComponents() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/19-db.getMongo.html":{"url":"16-reference/03-method/03-js-database/19-db.getMongo.html","title":"db.getMongo()","keywords":"","body":" db.getMongo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getMongo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/20-db.getName.html":{"url":"16-reference/03-method/03-js-database/20-db.getName.html","title":"db.getName()","keywords":"","body":" db.getName() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getName() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/21-db.getProfilingLevel.html":{"url":"16-reference/03-method/03-js-database/21-db.getProfilingLevel.html","title":"db.getProfilingLevel()","keywords":"","body":" db.getProfilingLevel() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getProfilingLevel() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/22-db.getProfilingStatus.html":{"url":"16-reference/03-method/03-js-database/22-db.getProfilingStatus.html","title":"db.getProfilingStatus()","keywords":"","body":" db.getProfilingStatus() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getProfilingStatus() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/23-db.getReplicationInfo.html":{"url":"16-reference/03-method/03-js-database/23-db.getReplicationInfo.html","title":"db.getReplicationInfo()","keywords":"","body":" db.getReplicationInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getReplicationInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/24-db.getSiblingDB.html":{"url":"16-reference/03-method/03-js-database/24-db.getSiblingDB.html","title":"db.getSiblingDB()","keywords":"","body":" db.getSiblingDB() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getSiblingDB() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/25-db.help.html":{"url":"16-reference/03-method/03-js-database/25-db.help.html","title":"db.help()","keywords":"","body":" db.help() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.help() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/26-db.hostInfo.html":{"url":"16-reference/03-method/03-js-database/26-db.hostInfo.html","title":"db.hostInfo()","keywords":"","body":" db.hostInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.hostInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/27-db.isMaster.html":{"url":"16-reference/03-method/03-js-database/27-db.isMaster.html","title":"db.isMaster()","keywords":"","body":" db.isMaster() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.isMaster() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/28-db.killOp.html":{"url":"16-reference/03-method/03-js-database/28-db.killOp.html","title":"db.killOp()","keywords":"","body":" db.killOp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.killOp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/29-db.listCommands.html":{"url":"16-reference/03-method/03-js-database/29-db.listCommands.html","title":"db.listCommands()","keywords":"","body":" db.listCommands() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.listCommands() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/30-db.logout.html":{"url":"16-reference/03-method/03-js-database/30-db.logout.html","title":"db.logout()","keywords":"","body":" db.logout() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.logout() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/31-db.printCollectionStats.html":{"url":"16-reference/03-method/03-js-database/31-db.printCollectionStats.html","title":"db.printCollectionStats()","keywords":"","body":" db.printCollectionStats() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.printCollectionStats() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/32-db.printReplicationInfo.html":{"url":"16-reference/03-method/03-js-database/32-db.printReplicationInfo.html","title":"db.printReplicationInfo()","keywords":"","body":" db.printReplicationInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.printReplicationInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/33-db.printShardingStatus.html":{"url":"16-reference/03-method/03-js-database/33-db.printShardingStatus.html","title":"db.printShardingStatus()","keywords":"","body":" db.printShardingStatus() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.printShardingStatus() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/34-db.printSlaveReplicationInfo.html":{"url":"16-reference/03-method/03-js-database/34-db.printSlaveReplicationInfo.html","title":"db.printSlaveReplicationInfo()","keywords":"","body":" db.printSlaveReplicationInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.printSlaveReplicationInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/35-db.resetError.html":{"url":"16-reference/03-method/03-js-database/35-db.resetError.html","title":"db.resetError()","keywords":"","body":" db.resetError() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.resetError() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/36-db.runCommand.html":{"url":"16-reference/03-method/03-js-database/36-db.runCommand.html","title":"db.runCommand()","keywords":"","body":" db.runCommand() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.runCommand() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/37-db.serverBuildInfo.html":{"url":"16-reference/03-method/03-js-database/37-db.serverBuildInfo.html","title":"db.serverBuildInfo()","keywords":"","body":" db.serverBuildInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.serverBuildInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/38-db.serverCmdLineOpts.html":{"url":"16-reference/03-method/03-js-database/38-db.serverCmdLineOpts.html","title":"db.serverCmdLineOpts()","keywords":"","body":" db.serverCmdLineOpts() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.serverCmdLineOpts() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/39-db.serverStatus.html":{"url":"16-reference/03-method/03-js-database/39-db.serverStatus.html","title":"db.serverStatus()","keywords":"","body":" db.serverStatus() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.serverStatus() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/40-db.setLogLevel.html":{"url":"16-reference/03-method/03-js-database/40-db.setLogLevel.html","title":"db.setLogLevel()","keywords":"","body":" db.setLogLevel() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.setLogLevel() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/41-db.setProfilingLevel.html":{"url":"16-reference/03-method/03-js-database/41-db.setProfilingLevel.html","title":"db.setProfilingLevel()","keywords":"","body":" db.setProfilingLevel() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.setProfilingLevel() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/42-db.shutdownServer.html":{"url":"16-reference/03-method/03-js-database/42-db.shutdownServer.html","title":"db.shutdownServer()","keywords":"","body":" db.shutdownServer() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.shutdownServer() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/43-db.stats.html":{"url":"16-reference/03-method/03-js-database/43-db.stats.html","title":"db.stats()","keywords":"","body":" db.stats() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.stats() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/44-db.version.html":{"url":"16-reference/03-method/03-js-database/44-db.version.html","title":"db.version()","keywords":"","body":" db.version() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.version() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/03-js-database/45-db.watch.html":{"url":"16-reference/03-method/03-js-database/45-db.watch.html","title":"db.watch()","keywords":"","body":" db.watch() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.watch() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache.html":{"url":"16-reference/03-method/04-js-plan-cache.html","title":"Query Plan Cache Methods","keywords":"","body":" Query Plan Cache Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Query Plan Cache Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache/01-db.collection.getPlanCache.html":{"url":"16-reference/03-method/04-js-plan-cache/01-db.collection.getPlanCache.html","title":"db.collection.getPlanCache()","keywords":"","body":" db.collection.getPlanCache() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.collection.getPlanCache() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache/02-PlanCache.clear.html":{"url":"16-reference/03-method/04-js-plan-cache/02-PlanCache.clear.html","title":"PlanCache.clear()","keywords":"","body":" PlanCache.clear() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - PlanCache.clear() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache/03-PlanCache.clearPlansByQuery.html":{"url":"16-reference/03-method/04-js-plan-cache/03-PlanCache.clearPlansByQuery.html","title":"PlanCache.clearPlansByQuery()","keywords":"","body":" PlanCache.clearPlansByQuery() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - PlanCache.clearPlansByQuery() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache/04-PlanCache.help.html":{"url":"16-reference/03-method/04-js-plan-cache/04-PlanCache.help.html","title":"PlanCache.help()","keywords":"","body":" PlanCache.help() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - PlanCache.help() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/04-js-plan-cache/05-PlanCache.list.html":{"url":"16-reference/03-method/04-js-plan-cache/05-PlanCache.list.html","title":"PlanCache.list()","keywords":"","body":" PlanCache.list() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - PlanCache.list() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk.html":{"url":"16-reference/03-method/05-js-bulk.html","title":"Bulk Operation Methods","keywords":"","body":" Bulk Operation Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk Operation Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/01-db.collection.initializeOrderedBulkOp.html":{"url":"16-reference/03-method/05-js-bulk/01-db.collection.initializeOrderedBulkOp.html","title":"db.collection.initializeOrderedBulkOp()","keywords":"","body":" db.collection.initializeOrderedBulkOp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.collection.initializeOrderedBulkOp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/02-db.collection.initializeUnorderedBulkOp.html":{"url":"16-reference/03-method/05-js-bulk/02-db.collection.initializeUnorderedBulkOp.html","title":"db.collection.initializeUnorderedBulkOp()","keywords":"","body":" db.collection.initializeUnorderedBulkOp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.collection.initializeUnorderedBulkOp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/03-Bulk.html":{"url":"16-reference/03-method/05-js-bulk/03-Bulk.html","title":"Bulk()","keywords":"","body":" Bulk() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/04-Bulk.execute.html":{"url":"16-reference/03-method/05-js-bulk/04-Bulk.execute.html","title":"Bulk.execute()","keywords":"","body":" Bulk.execute() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.execute() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/05-Bulk.find.html":{"url":"16-reference/03-method/05-js-bulk/05-Bulk.find.html","title":"Bulk.find()","keywords":"","body":" Bulk.find() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/06-Bulk.find.arrayFilters.html":{"url":"16-reference/03-method/05-js-bulk/06-Bulk.find.arrayFilters.html","title":"Bulk.find.arrayFilters()","keywords":"","body":" Bulk.find.arrayFilters() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.arrayFilters() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/07-Bulk.find.collation.html":{"url":"16-reference/03-method/05-js-bulk/07-Bulk.find.collation.html","title":"Bulk.find.collation()","keywords":"","body":" Bulk.find.collation() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.collation() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/08-Bulk.find.hint.html":{"url":"16-reference/03-method/05-js-bulk/08-Bulk.find.hint.html","title":"Bulk.find.hint()","keywords":"","body":" Bulk.find.hint() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.hint() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/09-Bulk.find.remove.html":{"url":"16-reference/03-method/05-js-bulk/09-Bulk.find.remove.html","title":"Bulk.find.remove()","keywords":"","body":" Bulk.find.remove() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.remove() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/10-Bulk.find.removeOne.html":{"url":"16-reference/03-method/05-js-bulk/10-Bulk.find.removeOne.html","title":"Bulk.find.removeOne()","keywords":"","body":" Bulk.find.removeOne() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.removeOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/11-Bulk.find.replaceOne.html":{"url":"16-reference/03-method/05-js-bulk/11-Bulk.find.replaceOne.html","title":"Bulk.find.replaceOne()","keywords":"","body":" Bulk.find.replaceOne() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.replaceOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/12-Bulk.find.updateOne.html":{"url":"16-reference/03-method/05-js-bulk/12-Bulk.find.updateOne.html","title":"Bulk.find.updateOne()","keywords":"","body":" Bulk.find.updateOne() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.updateOne() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/13-Bulk.find.update.html":{"url":"16-reference/03-method/05-js-bulk/13-Bulk.find.update.html","title":"Bulk.find.update()","keywords":"","body":" Bulk.find.update() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.update() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/14-Bulk.find.upsert.html":{"url":"16-reference/03-method/05-js-bulk/14-Bulk.find.upsert.html","title":"Bulk.find.upsert()","keywords":"","body":" Bulk.find.upsert() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.find.upsert() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/15-Bulk.getOperations.html":{"url":"16-reference/03-method/05-js-bulk/15-Bulk.getOperations.html","title":"Bulk.getOperations()","keywords":"","body":" Bulk.getOperations() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.getOperations() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/16-Bulk.insert.html":{"url":"16-reference/03-method/05-js-bulk/16-Bulk.insert.html","title":"Bulk.insert()","keywords":"","body":" Bulk.insert() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.insert() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/17-Bulk.tojson.html":{"url":"16-reference/03-method/05-js-bulk/17-Bulk.tojson.html","title":"Bulk.tojson()","keywords":"","body":" Bulk.tojson() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.tojson() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/05-js-bulk/18-Bulk.toString.html":{"url":"16-reference/03-method/05-js-bulk/18-Bulk.toString.html","title":"Bulk.toString()","keywords":"","body":" Bulk.toString() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Bulk.toString() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management.html":{"url":"16-reference/03-method/06-js-user-management.html","title":"User Management Methods","keywords":"","body":" User Management Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - User Management Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/01-db.auth.html":{"url":"16-reference/03-method/06-js-user-management/01-db.auth.html","title":"db.auth()","keywords":"","body":" db.auth() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.auth() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/02-db.changeUserPassword.html":{"url":"16-reference/03-method/06-js-user-management/02-db.changeUserPassword.html","title":"db.changeUserPassword()","keywords":"","body":" db.changeUserPassword() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.changeUserPassword() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/03-db.createUser.html":{"url":"16-reference/03-method/06-js-user-management/03-db.createUser.html","title":"db.createUser()","keywords":"","body":" db.createUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.createUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/04-db.dropUser.html":{"url":"16-reference/03-method/06-js-user-management/04-db.dropUser.html","title":"db.dropUser()","keywords":"","body":" db.dropUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.dropUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/05-db.dropAllUsers.html":{"url":"16-reference/03-method/06-js-user-management/05-db.dropAllUsers.html","title":"db.dropAllUsers()","keywords":"","body":" db.dropAllUsers() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.dropAllUsers() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/06-db.getUser.html":{"url":"16-reference/03-method/06-js-user-management/06-db.getUser.html","title":"db.getUser()","keywords":"","body":" db.getUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/07-db.getUsers.html":{"url":"16-reference/03-method/06-js-user-management/07-db.getUsers.html","title":"db.getUsers()","keywords":"","body":" db.getUsers() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getUsers() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/08-db.grantRolesToUser.html":{"url":"16-reference/03-method/06-js-user-management/08-db.grantRolesToUser.html","title":"db.grantRolesToUser()","keywords":"","body":" db.grantRolesToUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.grantRolesToUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/09-db.removeUser.html":{"url":"16-reference/03-method/06-js-user-management/09-db.removeUser.html","title":"db.removeUser()","keywords":"","body":" db.removeUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.removeUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/10-db.revokeRolesFromUser.html":{"url":"16-reference/03-method/06-js-user-management/10-db.revokeRolesFromUser.html","title":"db.revokeRolesFromUser()","keywords":"","body":" db.revokeRolesFromUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.revokeRolesFromUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/11-db.updateUser.html":{"url":"16-reference/03-method/06-js-user-management/11-db.updateUser.html","title":"db.updateUser()","keywords":"","body":" db.updateUser() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.updateUser() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/06-js-user-management/12-passwordPrompt.html":{"url":"16-reference/03-method/06-js-user-management/12-passwordPrompt.html","title":"passwordPrompt()","keywords":"","body":" passwordPrompt() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - passwordPrompt() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management.html":{"url":"16-reference/03-method/07-js-role-management.html","title":"Role Management Methods","keywords":"","body":" Role Management Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Role Management Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/01-db.createRole.html":{"url":"16-reference/03-method/07-js-role-management/01-db.createRole.html","title":"db.createRole()","keywords":"","body":" db.createRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.createRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/02-db.dropRole.html":{"url":"16-reference/03-method/07-js-role-management/02-db.dropRole.html","title":"db.dropRole()","keywords":"","body":" db.dropRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.dropRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/03-db.dropAllRoles.html":{"url":"16-reference/03-method/07-js-role-management/03-db.dropAllRoles.html","title":"db.dropAllRoles()","keywords":"","body":" db.dropAllRoles() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.dropAllRoles() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/04-db.getRole.html":{"url":"16-reference/03-method/07-js-role-management/04-db.getRole.html","title":"db.getRole()","keywords":"","body":" db.getRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/05-db.getRoles.html":{"url":"16-reference/03-method/07-js-role-management/05-db.getRoles.html","title":"db.getRoles()","keywords":"","body":" db.getRoles() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getRoles() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/06-db.grantPrivilegesToRole.html":{"url":"16-reference/03-method/07-js-role-management/06-db.grantPrivilegesToRole.html","title":"db.grantPrivilegesToRole()","keywords":"","body":" db.grantPrivilegesToRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.grantPrivilegesToRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/07-db.revokePrivilegesFromRole.html":{"url":"16-reference/03-method/07-js-role-management/07-db.revokePrivilegesFromRole.html","title":"db.revokePrivilegesFromRole()","keywords":"","body":" db.revokePrivilegesFromRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.revokePrivilegesFromRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/08-db.grantRolesToRole.html":{"url":"16-reference/03-method/07-js-role-management/08-db.grantRolesToRole.html","title":"db.grantRolesToRole()","keywords":"","body":" db.grantRolesToRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.grantRolesToRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/09-db.revokeRolesFromRole.html":{"url":"16-reference/03-method/07-js-role-management/09-db.revokeRolesFromRole.html","title":"db.revokeRolesFromRole()","keywords":"","body":" db.revokeRolesFromRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.revokeRolesFromRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/07-js-role-management/10-db.updateRole.html":{"url":"16-reference/03-method/07-js-role-management/10-db.updateRole.html","title":"db.updateRole()","keywords":"","body":" db.updateRole() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.updateRole() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication.html":{"url":"16-reference/03-method/08-js-replication.html","title":"Replication Methods","keywords":"","body":" Replication Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Replication Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/01-rs.add.html":{"url":"16-reference/03-method/08-js-replication/01-rs.add.html","title":"rs.add()","keywords":"","body":" rs.add() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.add() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/02-rs.addArb.html":{"url":"16-reference/03-method/08-js-replication/02-rs.addArb.html","title":"rs.addArb()","keywords":"","body":" rs.addArb() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.addArb() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/03-rs.conf.html":{"url":"16-reference/03-method/08-js-replication/03-rs.conf.html","title":"rs.conf()","keywords":"","body":" rs.conf() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.conf() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/04-rs.freeze.html":{"url":"16-reference/03-method/08-js-replication/04-rs.freeze.html","title":"rs.freeze()","keywords":"","body":" rs.freeze() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.freeze() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/05-rs.help.html":{"url":"16-reference/03-method/08-js-replication/05-rs.help.html","title":"rs.help()","keywords":"","body":" rs.help() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.help() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/06-rs.initiate.html":{"url":"16-reference/03-method/08-js-replication/06-rs.initiate.html","title":"rs.initiate()","keywords":"","body":" rs.initiate() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.initiate() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/07-rs.printReplicationInfo.html":{"url":"16-reference/03-method/08-js-replication/07-rs.printReplicationInfo.html","title":"rs.printReplicationInfo()","keywords":"","body":" rs.printReplicationInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.printReplicationInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/08-rs.printSlaveReplicationInfo.html":{"url":"16-reference/03-method/08-js-replication/08-rs.printSlaveReplicationInfo.html","title":"rs.printSlaveReplicationInfo()","keywords":"","body":" rs.printSlaveReplicationInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.printSlaveReplicationInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/09-rs.reconfig.html":{"url":"16-reference/03-method/08-js-replication/09-rs.reconfig.html","title":"rs.reconfig()","keywords":"","body":" rs.reconfig() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.reconfig() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/10-rs.remove.html":{"url":"16-reference/03-method/08-js-replication/10-rs.remove.html","title":"rs.remove()","keywords":"","body":" rs.remove() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.remove() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/11-rs.status.html":{"url":"16-reference/03-method/08-js-replication/11-rs.status.html","title":"rs.status()","keywords":"","body":" rs.status() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.status() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/12-rs.stepDown.html":{"url":"16-reference/03-method/08-js-replication/12-rs.stepDown.html","title":"rs.stepDown()","keywords":"","body":" rs.stepDown() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.stepDown() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/08-js-replication/13-rs.syncFrom.html":{"url":"16-reference/03-method/08-js-replication/13-rs.syncFrom.html","title":"rs.syncFrom()","keywords":"","body":" rs.syncFrom() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - rs.syncFrom() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding.html":{"url":"16-reference/03-method/09-js-sharding.html","title":"Sharding Methods","keywords":"","body":" Sharding Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Sharding Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/01-sh.addShard.html":{"url":"16-reference/03-method/09-js-sharding/01-sh.addShard.html","title":"sh.addShard()","keywords":"","body":" sh.addShard() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.addShard() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/02-sh.addShardTag.html":{"url":"16-reference/03-method/09-js-sharding/02-sh.addShardTag.html","title":"sh.addShardTag()","keywords":"","body":" sh.addShardTag() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.addShardTag() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/03-sh.addShardToZone.html":{"url":"16-reference/03-method/09-js-sharding/03-sh.addShardToZone.html","title":"sh.addShardToZone()","keywords":"","body":" sh.addShardToZone() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.addShardToZone() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/04-sh.addTagRange.html":{"url":"16-reference/03-method/09-js-sharding/04-sh.addTagRange.html","title":"sh.addTagRange()","keywords":"","body":" sh.addTagRange() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.addTagRange() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/05-sh.balancerCollectionStatus.html":{"url":"16-reference/03-method/09-js-sharding/05-sh.balancerCollectionStatus.html","title":"sh.balancerCollectionStatus()","keywords":"","body":" sh.balancerCollectionStatus() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.balancerCollectionStatus() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/06-sh.disableBalancing.html":{"url":"16-reference/03-method/09-js-sharding/06-sh.disableBalancing.html","title":"sh.disableBalancing()","keywords":"","body":" sh.disableBalancing() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.disableBalancing() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/07-sh.enableBalancing.html":{"url":"16-reference/03-method/09-js-sharding/07-sh.enableBalancing.html","title":"sh.enableBalancing()","keywords":"","body":" sh.enableBalancing() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.enableBalancing() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/08-sh.disableAutoSplit.html":{"url":"16-reference/03-method/09-js-sharding/08-sh.disableAutoSplit.html","title":"sh.disableAutoSplit","keywords":"","body":" sh.disableAutoSplit ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.disableAutoSplit Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/09-sh.enableAutoSplit.html":{"url":"16-reference/03-method/09-js-sharding/09-sh.enableAutoSplit.html","title":"sh.enableAutoSplit","keywords":"","body":" sh.enableAutoSplit ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.enableAutoSplit Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/10-sh.enableSharding.html":{"url":"16-reference/03-method/09-js-sharding/10-sh.enableSharding.html","title":"sh.enableSharding()","keywords":"","body":" sh.enableSharding() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.enableSharding() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/11-sh.getBalancerHost.html":{"url":"16-reference/03-method/09-js-sharding/11-sh.getBalancerHost.html","title":"sh.getBalancerHost()","keywords":"","body":" sh.getBalancerHost() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.getBalancerHost() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/12-sh.getBalancerState.html":{"url":"16-reference/03-method/09-js-sharding/12-sh.getBalancerState.html","title":"sh.getBalancerState()","keywords":"","body":" sh.getBalancerState() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.getBalancerState() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/13-sh.removeTagRange.html":{"url":"16-reference/03-method/09-js-sharding/13-sh.removeTagRange.html","title":"sh.removeTagRange()","keywords":"","body":" sh.removeTagRange() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.removeTagRange() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/14-sh.removeRangeFromZone.html":{"url":"16-reference/03-method/09-js-sharding/14-sh.removeRangeFromZone.html","title":"sh.removeRangeFromZone()","keywords":"","body":" sh.removeRangeFromZone() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.removeRangeFromZone() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/15-sh.help.html":{"url":"16-reference/03-method/09-js-sharding/15-sh.help.html","title":"sh.help()","keywords":"","body":" sh.help() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.help() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/16-sh.isBalancerRunning.html":{"url":"16-reference/03-method/09-js-sharding/16-sh.isBalancerRunning.html","title":"sh.isBalancerRunning()","keywords":"","body":" sh.isBalancerRunning() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.isBalancerRunning() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/17-sh.moveChunk.html":{"url":"16-reference/03-method/09-js-sharding/17-sh.moveChunk.html","title":"sh.moveChunk()","keywords":"","body":" sh.moveChunk() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.moveChunk() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/18-sh.removeShardTag.html":{"url":"16-reference/03-method/09-js-sharding/18-sh.removeShardTag.html","title":"sh.removeShardTag()","keywords":"","body":" sh.removeShardTag() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.removeShardTag() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/19-sh.removeShardFromZone.html":{"url":"16-reference/03-method/09-js-sharding/19-sh.removeShardFromZone.html","title":"sh.removeShardFromZone()","keywords":"","body":" sh.removeShardFromZone() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.removeShardFromZone() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/20-sh.setBalancerState.html":{"url":"16-reference/03-method/09-js-sharding/20-sh.setBalancerState.html","title":"sh.setBalancerState()","keywords":"","body":" sh.setBalancerState() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.setBalancerState() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/21-sh.shardCollection.html":{"url":"16-reference/03-method/09-js-sharding/21-sh.shardCollection.html","title":"sh.shardCollection()","keywords":"","body":" sh.shardCollection() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.shardCollection() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/22-sh.splitAt.html":{"url":"16-reference/03-method/09-js-sharding/22-sh.splitAt.html","title":"sh.splitAt()","keywords":"","body":" sh.splitAt() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.splitAt() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/23-sh.splitFind.html":{"url":"16-reference/03-method/09-js-sharding/23-sh.splitFind.html","title":"sh.splitFind()","keywords":"","body":" sh.splitFind() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.splitFind() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/24-sh.startBalancer.html":{"url":"16-reference/03-method/09-js-sharding/24-sh.startBalancer.html","title":"sh.startBalancer()","keywords":"","body":" sh.startBalancer() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.startBalancer() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/25-sh.status.html":{"url":"16-reference/03-method/09-js-sharding/25-sh.status.html","title":"sh.status()","keywords":"","body":" sh.status() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.status() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/26-sh.stopBalancer.html":{"url":"16-reference/03-method/09-js-sharding/26-sh.stopBalancer.html","title":"sh.stopBalancer()","keywords":"","body":" sh.stopBalancer() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.stopBalancer() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/27-sh.waitForBalancer.html":{"url":"16-reference/03-method/09-js-sharding/27-sh.waitForBalancer.html","title":"sh.waitForBalancer()","keywords":"","body":" sh.waitForBalancer() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.waitForBalancer() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/28-sh.waitForBalancerOff.html":{"url":"16-reference/03-method/09-js-sharding/28-sh.waitForBalancerOff.html","title":"sh.waitForBalancerOff()","keywords":"","body":" sh.waitForBalancerOff() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.waitForBalancerOff() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/29-sh.waitForPingChange.html":{"url":"16-reference/03-method/09-js-sharding/29-sh.waitForPingChange.html","title":"sh.waitForPingChange()","keywords":"","body":" sh.waitForPingChange() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.waitForPingChange() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/30-sh.updateZoneKeyRange.html":{"url":"16-reference/03-method/09-js-sharding/30-sh.updateZoneKeyRange.html","title":"sh.updateZoneKeyRange()","keywords":"","body":" sh.updateZoneKeyRange() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sh.updateZoneKeyRange() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/09-js-sharding/31-convertShardKeyToHashed.html":{"url":"16-reference/03-method/09-js-sharding/31-convertShardKeyToHashed.html","title":"convertShardKeyToHashed","keywords":"","body":" convertShardKeyToHashed ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - convertShardKeyToHashed Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/10-js-free-monitoring.html":{"url":"16-reference/03-method/10-js-free-monitoring.html","title":"Free Monitoring Methods","keywords":"","body":" Free Monitoring Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Free Monitoring Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/10-js-free-monitoring/01-db.disableFreeMonitoring.html":{"url":"16-reference/03-method/10-js-free-monitoring/01-db.disableFreeMonitoring.html","title":"db.disableFreeMonitoring()","keywords":"","body":" db.disableFreeMonitoring() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.disableFreeMonitoring() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/10-js-free-monitoring/02-db.enableFreeMonitoring.html":{"url":"16-reference/03-method/10-js-free-monitoring/02-db.enableFreeMonitoring.html","title":"db.enableFreeMonitoring()","keywords":"","body":" db.enableFreeMonitoring() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.enableFreeMonitoring() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/10-js-free-monitoring/03-db.getFreeMonitoringStatus.html":{"url":"16-reference/03-method/10-js-free-monitoring/03-db.getFreeMonitoringStatus.html","title":"db.getFreeMonitoringStatus","keywords":"","body":" db.getFreeMonitoringStatus ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - db.getFreeMonitoringStatus Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor.html":{"url":"16-reference/03-method/11-js-constructor.html","title":"Object Constructors and Methods","keywords":"","body":" Object Constructors and Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Object Constructors and Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/01-BulkWriteResult.html":{"url":"16-reference/03-method/11-js-constructor/01-BulkWriteResult.html","title":"BulkWriteResult()","keywords":"","body":" BulkWriteResult() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - BulkWriteResult() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/02-Date.html":{"url":"16-reference/03-method/11-js-constructor/02-Date.html","title":"Date()","keywords":"","body":" Date() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Date() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/03-ObjectId.html":{"url":"16-reference/03-method/11-js-constructor/03-ObjectId.html","title":"ObjectId","keywords":"","body":" ObjectId ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ObjectId Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/04-ObjectId.getTimestamp.html":{"url":"16-reference/03-method/11-js-constructor/04-ObjectId.getTimestamp.html","title":"ObjectId.getTimestamp()","keywords":"","body":" ObjectId.getTimestamp() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ObjectId.getTimestamp() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/05-ObjectId.toString.html":{"url":"16-reference/03-method/11-js-constructor/05-ObjectId.toString.html","title":"ObjectId.toString()","keywords":"","body":" ObjectId.toString() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ObjectId.toString() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/06-ObjectId.valueOf.html":{"url":"16-reference/03-method/11-js-constructor/06-ObjectId.valueOf.html","title":"ObjectId.valueOf()","keywords":"","body":" ObjectId.valueOf() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ObjectId.valueOf() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/07-UUID.html":{"url":"16-reference/03-method/11-js-constructor/07-UUID.html","title":"UUID()","keywords":"","body":" UUID() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - UUID() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/08-WriteResult.html":{"url":"16-reference/03-method/11-js-constructor/08-WriteResult.html","title":"WriteResult()","keywords":"","body":" WriteResult() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - WriteResult() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/09-WriteResult.hasWriteError.html":{"url":"16-reference/03-method/11-js-constructor/09-WriteResult.hasWriteError.html","title":"WriteResult.hasWriteError()","keywords":"","body":" WriteResult.hasWriteError() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - WriteResult.hasWriteError() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/11-js-constructor/10-WriteResult.hasWriteConcernError.html":{"url":"16-reference/03-method/11-js-constructor/10-WriteResult.hasWriteConcernError.html","title":"WriteResult.hasWriteConcernError()","keywords":"","body":" WriteResult.hasWriteConcernError() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - WriteResult.hasWriteConcernError() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection.html":{"url":"16-reference/03-method/12-js-connection.html","title":"Connection Methods","keywords":"","body":" Connection Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Connection Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/01-connect.html":{"url":"16-reference/03-method/12-js-connection/01-connect.html","title":"connect()","keywords":"","body":" connect() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - connect() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/02-Mongo.html":{"url":"16-reference/03-method/12-js-connection/02-Mongo.html","title":"Mongo()","keywords":"","body":" Mongo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/03-Mongo.getDB.html":{"url":"16-reference/03-method/12-js-connection/03-Mongo.getDB.html","title":"Mongo.getDB()","keywords":"","body":" Mongo.getDB() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.getDB() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/04-Mongo.getReadPrefMode.html":{"url":"16-reference/03-method/12-js-connection/04-Mongo.getReadPrefMode.html","title":"Mongo.getReadPrefMode()","keywords":"","body":" Mongo.getReadPrefMode() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.getReadPrefMode() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/05-Mongo.getReadPrefTagSet.html":{"url":"16-reference/03-method/12-js-connection/05-Mongo.getReadPrefTagSet.html","title":"Mongo.getReadPrefTagSet()","keywords":"","body":" Mongo.getReadPrefTagSet() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.getReadPrefTagSet() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/06-Mongo.isCausalConsistency.html":{"url":"16-reference/03-method/12-js-connection/06-Mongo.isCausalConsistency.html","title":"Mongo.isCausalConsistency()","keywords":"","body":" Mongo.isCausalConsistency() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.isCausalConsistency() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/07-Mongo.setCausalConsistency.html":{"url":"16-reference/03-method/12-js-connection/07-Mongo.setCausalConsistency.html","title":"Mongo.setCausalConsistency()","keywords":"","body":" Mongo.setCausalConsistency() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.setCausalConsistency() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/08-Mongo.setReadPref.html":{"url":"16-reference/03-method/12-js-connection/08-Mongo.setReadPref.html","title":"Mongo.setReadPref()","keywords":"","body":" Mongo.setReadPref() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.setReadPref() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/09-Mongo.startSession.html":{"url":"16-reference/03-method/12-js-connection/09-Mongo.startSession.html","title":"Mongo.startSession()","keywords":"","body":" Mongo.startSession() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.startSession() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/10-Mongo.watch.html":{"url":"16-reference/03-method/12-js-connection/10-Mongo.watch.html","title":"Mongo.watch()","keywords":"","body":" Mongo.watch() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Mongo.watch() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/11-Session.html":{"url":"16-reference/03-method/12-js-connection/11-Session.html","title":"Session","keywords":"","body":" Session ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Session Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/11-Session/01-Session.abortTransaction.html":{"url":"16-reference/03-method/12-js-connection/11-Session/01-Session.abortTransaction.html","title":"Session.abortTransaction()","keywords":"","body":" Session.abortTransaction() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Session.abortTransaction() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/11-Session/02-Session.commitTransaction.html":{"url":"16-reference/03-method/12-js-connection/11-Session/02-Session.commitTransaction.html","title":"Session.commitTransaction()","keywords":"","body":" Session.commitTransaction() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Session.commitTransaction() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/11-Session/03-Session.startTransaction.html":{"url":"16-reference/03-method/12-js-connection/11-Session/03-Session.startTransaction.html","title":"Session.startTransaction()","keywords":"","body":" Session.startTransaction() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Session.startTransaction() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/12-js-connection/12-SessionOptions.html":{"url":"16-reference/03-method/12-js-connection/12-SessionOptions.html","title":"SessionOptions","keywords":"","body":" SessionOptions ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - SessionOptions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native.html":{"url":"16-reference/03-method/13-js-native.html","title":"Native Methods","keywords":"","body":" Native Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Native Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/01-cat.html":{"url":"16-reference/03-method/13-js-native/01-cat.html","title":"cat()","keywords":"","body":" cat() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cat() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/02-cd.html":{"url":"16-reference/03-method/13-js-native/02-cd.html","title":"cd()","keywords":"","body":" cd() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - cd() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/03-copyDbpath.html":{"url":"16-reference/03-method/13-js-native/03-copyDbpath.html","title":"copyDbpath()","keywords":"","body":" copyDbpath() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - copyDbpath() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/04-getHostName.html":{"url":"16-reference/03-method/13-js-native/04-getHostName.html","title":"getHostName()","keywords":"","body":" getHostName() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getHostName() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/05-getMemInfo.html":{"url":"16-reference/03-method/13-js-native/05-getMemInfo.html","title":"getMemInfo()","keywords":"","body":" getMemInfo() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getMemInfo() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/06-hostname.html":{"url":"16-reference/03-method/13-js-native/06-hostname.html","title":"hostname()","keywords":"","body":" hostname() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - hostname() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/07-isInteractive.html":{"url":"16-reference/03-method/13-js-native/07-isInteractive.html","title":"isInteractive()","keywords":"","body":" isInteractive() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - isInteractive() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/08-listFiles.html":{"url":"16-reference/03-method/13-js-native/08-listFiles.html","title":"listFiles()","keywords":"","body":" listFiles() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - listFiles() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/09-load.html":{"url":"16-reference/03-method/13-js-native/09-load.html","title":"load()","keywords":"","body":" load() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - load() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/10-ls.html":{"url":"16-reference/03-method/13-js-native/10-ls.html","title":"ls()","keywords":"","body":" ls() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ls() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/11-md5sumFile.html":{"url":"16-reference/03-method/13-js-native/11-md5sumFile.html","title":"md5sumFile()","keywords":"","body":" md5sumFile() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - md5sumFile() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/12-mkdir.html":{"url":"16-reference/03-method/13-js-native/12-mkdir.html","title":"mkdir()","keywords":"","body":" mkdir() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mkdir() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/13-pwd.html":{"url":"16-reference/03-method/13-js-native/13-pwd.html","title":"pwd()","keywords":"","body":" pwd() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - pwd() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/14-quit.html":{"url":"16-reference/03-method/13-js-native/14-quit.html","title":"quit()","keywords":"","body":" quit() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - quit() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/15-removeFile.html":{"url":"16-reference/03-method/13-js-native/15-removeFile.html","title":"removeFile()","keywords":"","body":" removeFile() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - removeFile() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/16-resetDbpath.html":{"url":"16-reference/03-method/13-js-native/16-resetDbpath.html","title":"resetDbpath()","keywords":"","body":" resetDbpath() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - resetDbpath() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/17-sleep.html":{"url":"16-reference/03-method/13-js-native/17-sleep.html","title":"sleep()","keywords":"","body":" sleep() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - sleep() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/18-setVerboseShell.html":{"url":"16-reference/03-method/13-js-native/18-setVerboseShell.html","title":"setVerboseShell()","keywords":"","body":" setVerboseShell() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - setVerboseShell() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/19-version.html":{"url":"16-reference/03-method/13-js-native/19-version.html","title":"version()","keywords":"","body":" version() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - version() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/20-isWindows.html":{"url":"16-reference/03-method/13-js-native/20-isWindows.html","title":"_isWindows()","keywords":"","body":" _isWindows() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - _isWindows() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/13-js-native/21-rand.html":{"url":"16-reference/03-method/13-js-native/21-rand.html","title":"_rand()","keywords":"","body":" _rand() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - _rand() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption.html","title":"Client-Side Field Level Encryption Methods","keywords":"","body":" Client-Side Field Level Encryption Methods ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Client-Side Field Level Encryption Methods Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/01-getKeyVault.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/01-getKeyVault.html","title":"getKeyVault()","keywords":"","body":" getKeyVault() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getKeyVault() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/02-KeyVault.createKey.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/02-KeyVault.createKey.html","title":"KeyVault.createKey()","keywords":"","body":" KeyVault.createKey() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.createKey() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/03-KeyVault.deleteKey.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/03-KeyVault.deleteKey.html","title":"KeyVault.deleteKey()","keywords":"","body":" KeyVault.deleteKey() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.deleteKey() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/04-KeyVault.getKey.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/04-KeyVault.getKey.html","title":"KeyVault.getKey()","keywords":"","body":" KeyVault.getKey() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.getKey() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/05-KeyVault.getKeys.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/05-KeyVault.getKeys.html","title":"KeyVault.getKeys()","keywords":"","body":" KeyVault.getKeys() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.getKeys() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/06-KeyVault.addKeyAlternateName.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/06-KeyVault.addKeyAlternateName.html","title":"KeyVault.addKeyAlternateName()","keywords":"","body":" KeyVault.addKeyAlternateName() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.addKeyAlternateName() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/07-KeyVault.removeKeyAlternateName.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/07-KeyVault.removeKeyAlternateName.html","title":"KeyVault.removeKeyAlternateName()","keywords":"","body":" KeyVault.removeKeyAlternateName() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.removeKeyAlternateName() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/08-KeyVault.getKeyByAltName.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/08-KeyVault.getKeyByAltName.html","title":"KeyVault.getKeyByAltName()","keywords":"","body":" KeyVault.getKeyByAltName() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - KeyVault.getKeyByAltName() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/09-getClientEncryption.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/09-getClientEncryption.html","title":"getClientEncryption()","keywords":"","body":" getClientEncryption() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - getClientEncryption() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/10-ClientEncryption.encrypt.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/10-ClientEncryption.encrypt.html","title":"ClientEncryption.encrypt()","keywords":"","body":" ClientEncryption.encrypt() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ClientEncryption.encrypt() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/14-js-client-side-field-level-encryption/11-ClientEncryption.decrypt.html":{"url":"16-reference/03-method/14-js-client-side-field-level-encryption/11-ClientEncryption.decrypt.html","title":"ClientEncryption.decrypt()","keywords":"","body":" ClientEncryption.decrypt() ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - ClientEncryption.decrypt() Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/03-method/Collection-Methods.html":{"url":"16-reference/03-method/Collection-Methods.html","title":"mongo Shell 方法","keywords":"","body":" mongo Shell 方法 注意 有关特定方法(包括语法和示例)的详细信息，请单击特定方法以转到其 reference 页面。 名称 描述 db.collection.aggregate() 提供对聚合管道的访问。 db.collection.bulkWrite() 提供批量写入操作功能。 db.collection.copyTo() 已过时。包装EVAL以在单个 MongoDB 实例中的集合之间复制数据。 db.collection.count() 包装计数以_return 计算集合或视图中的文档数。 db.collection.createIndex() 在集合上构建索引。 db.collection.createIndexes() 在集合上构建一个或多个索引。 db.collection.dataSize() 返回集合的大小。包装collStats输出中的尺寸字段。 db.collection.deleteOne() 删除集合中的单个文档。 db.collection.deleteMany() 删除集合中的多个文档。 db.collection.distinct() 返回具有指定字段的不同值的文档的 array。 db.collection.drop() 从数据库中删除指定的集合。 db.collection.dropIndex() 删除集合上的指定索引。 db.collection.dropIndexes() 删除集合上的所有索引。 db.collection.ensureIndex() 已过时。使用db.collection.createIndex()。 db.collection.explain() 返回有关各种方法的查询执行的信息。 db.collection.find() 对集合或视图执行查询并返回游标 object。 db.collection.findAndModify() 以原子方式修改并返回单个文档。 db.collection.findOne() 执行查询并返回单个文档。 db.collection.findOneAndDelete() 查找单个文档并将其删除。 db.collection.findOneAndReplace() 查找单个文档并替换它。 db.collection.findOneAndUpdate() 查找单个文档并进行更新。 db.collection.getIndexes() 返回描述集合上现有索引的文档的 array。 db.collection.getShardDistribution() 对于分片群集中的集合，db.collection.getShardDistribution()报告块分布的数据。 db.collection.getShardVersion() 分片 cluster 的内部诊断方法。 db.collection.group() 已过时。提供简单的数据聚合 function。通过 key 对集合中的文档进行分组，并处理结果。使用aggregate()进行更复杂的数据聚合。 db.collection.insert() 在集合中创建新文档。 db.collection.insertOne() 在集合中插入新文档。 db.collection.insertMany() 在集合中插入几个新文档。 db.collection.isCapped() 报告集合是否为上限集合。 db.collection.latencyStats() 返回集合的延迟统计信息。 db.collection.mapReduce() 执行 map-reduce 样式数据聚合。 db.collection.reIndex() 重建集合上的所有现有索引。 db.collection.remove() 从集合中删除文档。 db.collection.renameCollection() 更改集合的 name。 db.collection.replaceOne() 替换集合中的单个文档。 db.collection.save() 在insert()和update()周围提供 wrapper 以插入新文档。 db.collection.stats() 报告集合的 state。在collStats周围提供 wrapper。 db.collection.storageSize() 报告集合使用的总大小(以字节为单位)。在collStats输出的storageSize字段周围提供 wrapper。 db.collection.totalIndexSize() 报告集合上索引使用的总大小。在collStats输出的totalIndexSize字段周围提供 wrapper。 db.collection.totalSize() 报告集合的总大小，包括所有文档的大小和集合上的所有索引。 db.collection.update() 修改集合中的文档。 db.collection.updateOne() 修改集合中的单个文档。 db.collection.updateMany() 修改集合中的多个文档。 db.collection.watch() 在集合上建立变更流。 db.collection.validate() 对集合执行诊断操作。 db.collection.countDocuments() $group包装聚合阶段用$sum表达式，以返回集合或视图中文档数量的计数。 db.collection.estimatedDocumentCount() 包装count以返回集合或视图中文档的大概数量。 译者：李冠飞 校对： Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program.html":{"url":"16-reference/04-program.html","title":"MongoDB Package Components","keywords":"","body":" MongoDB Package Components ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - MongoDB Package Components Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/01-mongod.html":{"url":"16-reference/04-program/01-mongod.html","title":"mongod","keywords":"","body":" mongod ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongod Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/02-mongos.html":{"url":"16-reference/04-program/02-mongos.html","title":"mongos","keywords":"","body":" mongos ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongos Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/03-mongo.html":{"url":"16-reference/04-program/03-mongo.html","title":"mongo","keywords":"","body":" mongo ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongo Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/04-mongod.exe.html":{"url":"16-reference/04-program/04-mongod.exe.html","title":"mongod.exe","keywords":"","body":" mongod.exe ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongod.exe Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/05-mongos.exe.html":{"url":"16-reference/04-program/05-mongos.exe.html","title":"mongos.exe","keywords":"","body":" mongos.exe ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongos.exe Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/06-mongodump.html":{"url":"16-reference/04-program/06-mongodump.html","title":"mongodump","keywords":"","body":" mongodump ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongodump Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/07-mongorestore.html":{"url":"16-reference/04-program/07-mongorestore.html","title":"mongorestore","keywords":"","body":" mongorestore ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongorestore Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/08-bsondump.html":{"url":"16-reference/04-program/08-bsondump.html","title":"bsondump","keywords":"","body":" bsondump ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - bsondump Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/09-mongoimport.html":{"url":"16-reference/04-program/09-mongoimport.html","title":"mongoimport","keywords":"","body":" mongoimport ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongoimport Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/10-mongoexport.html":{"url":"16-reference/04-program/10-mongoexport.html","title":"mongoexport","keywords":"","body":" mongoexport ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongoexport Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/11-mongostat.html":{"url":"16-reference/04-program/11-mongostat.html","title":"mongostat","keywords":"","body":" mongostat ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongostat Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/12-mongotop.html":{"url":"16-reference/04-program/12-mongotop.html","title":"mongotop","keywords":"","body":" mongotop ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongotop Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/13-mongoreplay.html":{"url":"16-reference/04-program/13-mongoreplay.html","title":"mongoreplay","keywords":"","body":" mongoreplay ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongoreplay Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/14-mongoldap.html":{"url":"16-reference/04-program/14-mongoldap.html","title":"mongoldap","keywords":"","body":" mongoldap ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongoldap Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/15-mongokerberos.html":{"url":"16-reference/04-program/15-mongokerberos.html","title":"mongokerberos","keywords":"","body":" mongokerberos ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongokerberos Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/16-mongofiles.html":{"url":"16-reference/04-program/16-mongofiles.html","title":"mongofiles","keywords":"","body":" mongofiles ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - mongofiles Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/04-program/17-install_compass.html":{"url":"16-reference/04-program/17-install_compass.html","title":"install_compass","keywords":"","body":" install_compass ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - install_compass Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/05-configuration-options.html":{"url":"16-reference/05-configuration-options.html","title":"Configuration File Options","keywords":"","body":"Configuration File Options 在本页面 配置文件 文件格式 配置文件的使用 核心选项 systemLog 选项 processManagement 选项 cloud 选项 net 选项 security 选项 setParameter 选项 storage 选项 operationProfiling 选项 replication 选项 sharding 选项 auditLog 选项 snmp 选项 mongos-only 选项 Windows Service 选项 Removed MMAPv1 选项 下面的页面描述了MongoDB 4.4中可用的配置选项。有关其他版本MongoDB的配置文件选项，请参阅相应版本的MongoDB手册。 配置文件 您可以在启动时使用配置文件配置mongod和mongos 实例。配置文件包含的设置相当于mongod和mongos命令行选项。参见配置文件设置和命令行选项映射。 使用配置文件使管理mongod和mongos选项更容易，特别是对于大规模部署。您还可以向配置文件添加注释，以解释服务器的设置。 [success] 默认配置文件 在Linux上，当使用包管理器安装MongoDB时，会包含一个默认的/etc/mongod.conf配置文件。 在Windows上，安装过程中会包含一个默认的/bin/mongod.cfg 配置文件。 在macOS上，当从MongoDB的官方自制程序安装时，会包含一个默认的/usr/local/etc/mongod.conf配置文件。 文件格式 MongoDB配置文件使用YAML格式[1]。 以下示例配置文件包含几个mongod设置，您可以适应您的本地配置: [success] 注意 YAML不支持制表符缩进：使用空格代替。 systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" logAppend: true storage: journal: enabled: true processManagement: fork: true net: bindIp: 127.0.0.1 port: 27017 setParameter: enableLocalhostAuthBypass: false ... Linux包init脚本包含在官方MongoDB包依赖于特定的值systemLog.path，storage.dbPath，和processManagement.fork。如果您在默认配置文件中修改这些设置，mongod可能不会启动。 [1] YAML是JSON的超集。 外部来源的值 4.2版本中的新功能： MongoDB支持在配置文件中使用扩展指令来加载外部源值。扩展指令可以加载特定的配置文件选项 或加载整个配置文件。 可以使用以下扩展指令: 扩展指令 描述 __rest 允许用户指定一个REST端点作为配置文件选项或完整配置文件的外部源。如果配置文件包括__rest扩展,在Linux / macOS对配置文件的读访问必须是仅限于运行mongod/mongos进程的用户。 __exec 允许用户指定一个shell或终端命令作为配置文件选项或完整配置文件的外部源。如果配置文件包括__exec扩展,在Linux / macOS对配置文件的写访问必须是仅限于运行mongod/mongos过程的用户。 要获得完整的文档，请参见外部来源的配置文件值。 配置文件的使用 使用配置文件配置mongod或mongos，使用--config选项或-f选项指定一个或多个配置文件，如下例所示: 例如，下面使用 mongod --config mongos --config : mongod --config /etc/mongod.conf mongos --config /etc/mongos.conf 您还可以使用-f别名来指定配置文件，如下所示： mongod -f /etc/mongod.conf mongos -f /etc/mongos.conf 如果您从包中安装并使用系统的init脚本启动了MongoDB，那么您已经使用了一个配置文件。 扩展指令和 --configExpand 如果您正在使用扩展指令配置文件,您必须包括——configExpand选项时启动mongod或mongos。例如: mongod --config /etc/mongod.conf --configExpand \"rest,exec\" mongos --config /etc/mongos.conf --configExpand \"rest,exec\" 如果配置文件包括一个扩展指令启动mongod /mongos没有指定的指令——configExpand选项,mongod/mongos启动失败。 要获得完整的文档，请参见外部来源的配置文件值。 核心选项 systemLog 选项 systemLog: verbosity: quiet: traceAllExceptions: syslogFacility: path: logAppend: logRotate: destination: timeStampFormat: component: accessControl: verbosity: command: verbosity: COMMENT additional component verbosity settings omitted for brevity systemLog.verbosity Type：integer Default：0 components的默认log message详细程度级别。详细级别决定了MongoDB输出的Informational and Debug消息的数量。[2]详细程度可以从0到5： 0是MongoDB的默认日志详细程度，包括Informational消息。 1到5增加了包含Debug消息的详细级别。 若要为命名组件使用不同的详细级别，请使用组件的详细设置。例如，使用systemLog.component.accessControl.verbosity为ACCESS组件设置详细级别。 请参阅systemLog.component..verbosity设置以获得特定组件的详细设置。 有关设置日志详细级别的各种方法，请参阅配置日志详细级别。 | | | | ------------------------------------------------------------ | ------------------------------------------------------------ | | [2] | 从4.2版本开始，MongoDB在log messages中包含了调试详细级别(1-5)。例如，如果详细级别是2,MongoDB记录的日志是D2。在以前的版本中，MongoDB日志消息只指定D作为调试级别。 | systemLog.quiet Type: boolean 运行mongos或mongod在一个安静的模式,试图限制输出。systemLog.quiet 不推荐给生产系统,因为它可能使跟踪问题特定的连接更加困难。 systemLog.traceAllExceptions Type: boolean 打印详细信息以便调试。用于附加日志，用于与支持相关的故障排除。 systemLog.syslogFacility Type: string Default: user 将消息记录到syslog时使用的设施级别。您指定的值必须由您的操作系统的syslog实现支持。要使用此选项，必须将systemLog.destination设置为syslog。 systemLog.path Type: string 日志文件的路径,mongod或mongos应该发送诊断日志记录所有信息,而不是标准输出或主机的syslog。MongoDB在指定的路径上创建日志文件。 Linux软件包的初始化脚本不希望systemLog.path更改默认值。如果您使用Linux包并更改systemLog.path，您将不得不使用自己的init脚本并禁用内置脚本。 systemLog.logAppend Type: boolean Default: false 当为true的时候，mongos或mongod追加新的条目到现有的日志文件时，结束mongos或mongod 实例重新启动。如果没有此选项，mongod将备份现有日志并创建一个新文件。 systemLog.logRotate Type: string Default: rename 命令的行为。指定rename或reopen： rename 重命名日志文件。 reopen按照典型的Linux / Unix日志轮换行为，关闭并重新打开日志文件。使用reopen的Linux / Unix logrotate的工具，以避免日志丢失时。 如果指定reopen，则还必须设置systemLog.logAppend为true。 systemLog.destination Type: string MongoDB将所有日志输出发送到的目标。指定 file或syslog。如果指定file，则还必须指定 systemLog.path。 如果未指定systemLog.destination，则MongoDB将所有日志输出发送到标准输出。 [warning] 警告 syslog守护进程在记录消息时生成时间戳，而不是在MongoDB发出消息时生成。这可能会导致日志条目的时间戳出现错误，特别是在系统处于高负载时。我们建议在生产系统中使用file选项，以确保准确的时间戳。 systemLog.timeStampFormat Type: string Default: iso8601-local 日志消息中时间戳的时间格式。指定以下值之一: | 值 | 描述 | | --------------- | ------------------------------------------------------------ | | iso8601-utc | 以ISO-8601格式的协调世界时(UTC)显示时间戳。例如，对于纪元之初的纽约:1970-01-01T00:00:00.000Z | | iso8601-local | 以ISO-8601格式本地时间显示时间戳。例如，对于纪元初期的纽约:1969-12-31T19:00:00.000-05:00 | [success] 注意 从MongoDB 4.4开始，systemLog.timeStampFormat不再支持ctime。ctime格式化的日期的一个例子是:Wed Dec 31 18:17:54.811。 systemLog.component 选项 systemLog: component: accessControl: verbosity: command: verbosity: COMMENT some component verbosity settings omitted for brevity replication: verbosity: election: verbosity: heartbeats: verbosity: initialSync: verbosity: rollback: verbosity: storage: verbosity: journal: verbosity: recovery: verbosity: write: verbosity: [success] 注意 从4.2版本开始，MongoDB在log messages中包含了调试详细级别(1-5)。例如，如果冗余级别是2,MongoDB记录的日志是D2。在以前的版本中，MongoDB日志消息只指定D作为调试级别。 systemLog.component.accessControl.verbosity Type: integer Default: 0 与访问控制相关的组件的日志消息详细程度级别。查看ACCESS组件。 详细程度可以从0到5: 0是MongoDB的默认日志冗余级别，用于包含 Informational信息。 1到5增加了包含Debug消息的冗余级别。 systemLog.component.command.verbosity Type: integer Default: 0 与命令相关的组件的日志消息详细级别。查看COMMAND组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括 Informational 信息。 1到5增加详细级别，以包括 Debug消息。 systemLog.component.control.verbosity Type: integer Default: 0 与控制操作相关的组件的日志消息详细级别。查看CONTROL组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括Informational信息。 1到5增加详细级别，以包括 Debug消息。 systemLog.component.ftdc.verbosity Type: integer Default: 0 version 3.2中的新功能。 与诊断数据收集操作相关的组件的日志消息详细级别。查看FTDC组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括 Informational信息。 1到5增加详细级别，以包括 Debug消息。 systemLog.component.geo.verbosity Type: integer Default: 0 与地理空间解析操作相关的组件的日志消息详细级别。查看GEO组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括Informational信息。 1到5增加详细级别，以包括Debug信息。 systemLog.component.index.verbosity Type: integer Default: 0 与索引操作相关的组件的日志消息详细级别。查看INDEX组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括 Informational 消息。 1到5增加详细级别，以包括Debug 消息。 systemLog.component.network.verbosity Type: integer Default: 0 与联网操作相关的组件的日志消息详细级别。查看NETWORK组件。 详细程度的范围为0到5： 0是MongoDB的默认日志级别，包括 Informational消息。 1到5增加详细级别，以包括 Debug消息。 systemLog.component.query.``verbosity Type: integerDefault: 0The log message verbosity level for components related to query operations. See QUERY components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.replication.``verbosity Type: integerDefault: 0The log message verbosity level for components related to replication. See REPL components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.replication.election.``verbosity Type: integerDefault: 0New in version 4.2.The log message verbosity level for components related to election. See ELECTION components.If systemLog.component.replication.election.verbosity is unset, systemLog.component.replication.verbosity level also applies to election components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.replication.heartbeats.``verbosity Type: integerDefault: 0New in version 3.6.The log message verbosity level for components related to heartbeats. See REPL_HB components.If systemLog.component.replication.heartbeats.verbosity is unset, systemLog.component.replication.verbosity level also applies to heartbeats components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.replication.initialSync.``verbosity Type: integerDefault: 0New in version 4.2.The log message verbosity level for components related to initialSync. See INITSYNC components.If systemLog.component.replication.initialSync.verbosity is unset, systemLog.component.replication.verbosity level also applies to initialSync components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.replication.rollback.``verbosity Type: integerDefault: 0New in version 3.6.The log message verbosity level for components related to rollback. See ROLLBACK components.If systemLog.component.replication.rollback.verbosity is unset, systemLog.component.replication.verbosity level also applies to rollback components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.sharding.``verbosity Type: integerDefault: 0The log message verbosity level for components related to sharding. See SHARDING components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.storage.``verbosity Type: integerDefault: 0The log message verbosity level for components related to storage. See STORAGE components.If systemLog.component.storage.journal.verbosity is unset, systemLog.component.storage.verbosity level also applies to journaling components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.storage.journal.``verbosity Type: integerDefault: 0The log message verbosity level for components related to journaling. See JOURNAL components.If systemLog.component.storage.journal.verbosity is unset, the journaling components have the same verbosity level as the parent storage components: i.e. either the systemLog.component.storage.verbosity level if set or the default verbosity level.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.storage.recovery.``verbosity Type: integerDefault: 0New in version 4.0.The log message verbosity level for components related to recovery. See RECOVERY components.If systemLog.component.storage.recovery.verbosity is unset, systemLog.component.storage.verbosity level also applies to recovery components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.transaction.``verbosity Type: integerDefault: 0New in version 4.0.2.The log message verbosity level for components related to transaction. See TXN components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. systemLog.component.write.``verbosity Type: integerDefault: 0The log message verbosity level for components related to write operations. See WRITE components.The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages. processManagement 选项 copycopied processManagement: fork: pidFilePath: timeZoneInfo: processManagement.``fork Type: booleanDefault: falseEnable a daemon mode that runs the mongos or mongod process in the background. By default mongos or mongod does not run as a daemon: typically you will run mongos or mongod as a daemon, either by using processManagement.fork or by using a controlling process that handles the daemonization process (e.g. as with upstart and systemd).The processManagement.fork option is not supported on Windows.The Linux package init scripts do not expect processManagement.fork to change from the defaults. If you use the Linux packages and change processManagement.fork, you will have to use your own init scripts and disable the built-in scripts. processManagement.``pidFilePath Type: stringSpecifies a file location to store the process ID (PID) of the mongos or mongod process. The user running the mongod or mongos process must be able to write to this path. If the processManagement.pidFilePath option is not specified, the process does not create a PID file. This option is generally only useful in combination with the processManagement.fork setting.LINUXOn Linux, PID file management is generally the responsibility of your distro’s init system: usually a service file in the /etc/init.d directory, or a systemd unit file registered with systemctl. Only use the processManagement.pidFilePath option if you are not using one of these init systems. For more information, please see the respective Installation Guide for your operating system.MACOSOn macOS, PID file management is generally handled by brew. Only use the processManagement.pidFilePath option if you are not using brew on your macOS system. For more information, please see the respective Installation Guide for your operating system. processManagement.``timeZoneInfo Type: stringThe full path from which to load the time zone database. If this option is not provided, then MongoDB will use its built-in time zone database.The configuration file included with Linux and macOS packages sets the time zone database path to /usr/share/zoneinfo by default.The built-in time zone database is a copy of the Olson/IANA time zone database. It is updated along with MongoDB releases, but the release cycle of the time zone database differs from the release cycle of MongoDB. A copy of the most recent release of the time zone database can be downloaded from https://downloads.mongodb.org/olson_tz_db/timezonedb-latest.zip. cloud 选项 New in version 4.0. copycopied cloud: monitoring: free: state: tags: cloud.monitoring.free.``state Type: stringNew in version 4.0: Available for MongoDB Community Edition.Enables or disables free MongoDB Cloud monitoring. cloud.monitoring.free.state accepts the following values:runtimeDefault. You can enable or disable free monitoring during runtime.To enable or disable free monitoring during runtime, see db.enableFreeMonitoring() and db.disableFreeMonitoring().To enable or disable free monitoring during runtime when running with access control, users must have required privileges. See db.enableFreeMonitoring() and db.disableFreeMonitoring() for details.onEnables free monitoring at startup; i.e. registers for free monitoring. When enabled at startup, you cannot disable free monitoring during runtime.offDisables free monitoring at startup, regardless of whether you have previously registered for free monitoring. When disabled at startup, you cannot enable free monitoring during runtime.Once enabled, the free monitoring state remains enabled until explicitly disabled. That is, you do not need to re-enable each time you start the server.For the corresponding command-line option, see --enableFreeMonitoring. cloud.monitoring.free.``tags Type: stringNew in version 4.0: Available for MongoDB Community Edition.Optional tag to describe environment context. The tag can be sent as part of the free MongoDB Cloud monitoring registration at start up.For the corresponding command-line option, see --freeMonitoringTag. net 选项 Changed in version 4.2: MongoDB 4.2 deprecates ssl options in favor of tls options with identical functionality. copycopied net: port: bindIp: bindIpAll: maxIncomingConnections: wireObjectCheck: ipv6: unixDomainSocket: enabled: pathPrefix: filePermissions: tls: certificateSelector: clusterCertificateSelector: mode: certificateKeyFile: certificateKeyFilePassword: clusterFile: clusterPassword: CAFile: clusterCAFile: CRLFile: allowConnectionsWithoutCertificates: allowInvalidCertificates: allowInvalidHostnames: disabledProtocols: FIPSMode: compression: compressors: serviceExecutor: net.``port Type: integerDefault:27017 for mongod (if not a shard member or a config server member) or mongos instance27018 if mongod is a shard member27019 if mongod is a config server memberThe TCP port on which the MongoDB instance listens for client connections. net.``bindIp Type: stringDefault: localhostNOTEStarting in MongoDB 3.6, mongos or mongod bind to localhost by default. See Default Bind to Localhost.The hostnames and/or IP addresses and/or full Unix domain socket paths on which mongos or mongod should listen for client connections. You may attach mongos or mongod to any interface. To bind to multiple addresses, enter a list of comma-separated values.EXAMPLElocalhost,/tmp/mongod.sockYou can specify both IPv4 and IPv6 addresses, or hostnames that resolve to an IPv4 or IPv6 address.EXAMPLElocalhost, 2001:0DB8:e132:ba26:0d5c:2774:e7f9:d513NOTEIf specifying an IPv6 address or a hostname that resolves to an IPv6 address to net.bindIp, you must start mongos or mongod with net.ipv6 : true to enable IPv6 support. Specifying an IPv6 address to net.bindIp does not enable IPv6 support.If specifying a link-local IPv6 address (fe80::/10), you must append the zone index to that address (i.e. fe80::%).EXAMPLElocalhost,fe80::a00:27ff:fee0:1fcf%enp0s3TIPWhen possible, use a logical DNS hostname instead of an ip address, particularly when configuring replica set members or sharded cluster members. The use of logical DNS hostnames avoids configuration changes due to ip address changes.WARNINGBefore binding to a non-localhost (e.g. publicly accessible) IP address, ensure you have secured your cluster from unauthorized access. For a complete list of security recommendations, see Security Checklist. At minimum, consider enabling authentication and hardening network infrastructure.For more information about IP Binding, refer to the IP Binding documentation.To bind to all IPv4 addresses, enter 0.0.0.0.To bind to all IPv4 and IPv6 addresses, enter ::,0.0.0.0 or starting in MongoDB 4.2, an asterisk \"*\" (enclose the asterisk in quotes to distinguish from YAML alias nodes). Alternatively, use the net.bindIpAll setting.NOTEnet.bindIp and net.bindIpAll are mutually exclusive. That is, you can specify one or the other, but not both.The command-line option --bind_ip overrides the configuration file setting net.bindIp. net.``bindIpAll Type: booleanDefault: falseNew in version 3.6.If true, the mongos or mongod instance binds to all IPv4 addresses (i.e. 0.0.0.0). If mongos or mongod starts with net.ipv6 : true, net.bindIpAll also binds to all IPv6 addresses (i.e. ::).mongos or mongod only supports IPv6 if started with net.ipv6 : true. Specifying net.bindIpAll alone does not enable IPv6 support.WARNINGBefore binding to a non-localhost (e.g. publicly accessible) IP address, ensure you have secured your cluster from unauthorized access. For a complete list of security recommendations, see Security Checklist. At minimum, consider enabling authentication and hardening network infrastructure.For more information about IP Binding, refer to the IP Binding documentation.Alternatively, set net.bindIp to ::,0.0.0.0 or, starting in MongoDB 4.2, to an asterisk \"*\" (enclose the asterisk in quotes to distinguish from YAML alias nodes) to bind to all IP addresses.NOTEnet.bindIp and net.bindIpAll are mutually exclusive. Specifying both options causes mongos or mongod to throw an error and terminate. net.``maxIncomingConnections Type: integerDefault: 65536The maximum number of simultaneous connections that mongos or mongod will accept. This setting has no effect if it is higher than your operating system’s configured maximum connection tracking threshold.Do not assign too low of a value to this option, or you will encounter errors during normal application operation.This is particularly useful for a mongos if you have a client that creates multiple connections and allows them to timeout rather than closing them.In this case, set maxIncomingConnections to a value slightly higher than the maximum number of connections that the client creates, or the maximum size of the connection pool.This setting prevents the mongos from causing connection spikes on the individual shards. Spikes like these may disrupt the operation and memory allocation of the sharded cluster. net.``wireObjectCheck Type: booleanDefault: trueWhen true, the mongod or mongos instance validates all requests from clients upon receipt to prevent clients from inserting malformed or invalid BSON into a MongoDB database.For objects with a high degree of sub-document nesting, net.wireObjectCheck can have a small impact on performance. net.``ipv6 Type: booleanDefault: falseSet net.ipv6 to true to enable IPv6 support. mongos/mongod disables IPv6 support by default.Setting net.ipv6 does not direct the mongos/mongod to listen on any local IPv6 addresses or interfaces. To configure the mongos/mongod to listen on an IPv6 interface, you must either:Configure net.bindIp with one or more IPv6 addresses or hostnames that resolve to IPv6 addresses, orSet net.bindIpAll to true. net.unixDomainSocket 选项 copycopied net: unixDomainSocket: enabled: pathPrefix: filePermissions: net.unixDomainSocket.``enabled Type: booleanDefault: trueEnable or disable listening on the UNIX domain socket. net.unixDomainSocket.enabled applies only to Unix-based systems.When net.unixDomainSocket.enabled is true, mongos or mongod listens on the UNIX socket.The mongos or mongod process always listens on the UNIX socket unless one of the following is true:net.unixDomainSocket.enabled is false``--nounixsocket is set. The command line option takes precedence over the configuration file setting.net.bindIp is not setnet.bindIp does not specify localhost or its associated IP addressmongos or mongod installed from official .deb and .rpm packages have the bind_ip configuration set to 127.0.0.1 by default. net.unixDomainSocket.``pathPrefix Type: stringDefault: /tmpThe path for the UNIX socket. net.unixDomainSocket.pathPrefix applies only to Unix-based systems.If this option has no value, the mongos or mongod process creates a socket with /tmp as a prefix. MongoDB creates and listens on a UNIX socket unless one of the following is true:net.unixDomainSocket.enabled is false``--nounixsocket is setnet.bindIp is not setnet.bindIp does not specify localhost or its associated IP address net.unixDomainSocket.``filePermissions Type: intDefault: 0700Sets the permission for the UNIX domain socket file.net.unixDomainSocket.filePermissions applies only to Unix-based systems. net.http 选项 Changed in version 3.6: MongoDB 3.6 removes the deprecated net.http options. The options have been deprecated since version 3.2. net.tls 选项 New in version 4.2: The tls options provide identical functionality as the previous ssl options. copycopied net: tls: mode: certificateKeyFile: certificateKeyFilePassword: certificateSelector: clusterCertificateSelector: clusterFile: clusterPassword: CAFile: clusterCAFile: CRLFile: allowConnectionsWithoutCertificates: allowInvalidCertificates: allowInvalidHostnames: disabledProtocols: FIPSMode: net.tls.``mode Type: stringNew in version 4.2.Enables TLS used for all network connections. The argument to the net.tls.mode setting can be one of the following:ValueDescriptiondisabledThe server does not use TLS.allowTLSConnections between servers do not use TLS. For incoming connections, the server accepts both TLS and non-TLS.preferTLSConnections between servers use TLS. For incoming connections, the server accepts both TLS and non-TLS.requireTLSThe server uses and accepts only TLS encrypted connections.If --tlsCAFile or tls.CAFile is not specified and you are not using x.509 authentication, the system-wide CA certificate store will be used when connecting to an TLS-enabled server.If using x.509 authentication, --tlsCAFile or tls.CAFile must be specified unless using --tlsCertificateSelector.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``certificateKeyFile Type: stringNew in version 4.2: The .pem file that contains both the TLS certificate and key.Starting with MongoDB 4.0 on macOS or Windows, you can use the net.tls.certificateSelector setting to specify a certificate from the operating system’s secure certificate store instead of a PEM key file. certificateKeyFile and net.tls.certificateSelector are mutually exclusive. You can only specify one.On Linux/BSD, you must specify net.tls.certificateKeyFile when TLS is enabled.On Windows or macOS, you must specify either net.tls.certificateKeyFile or net.tls.certificateSelector when TLS is enabled.IMPORTANTFor Windows only, MongoDB 4.0 and later do not support encrypted PEM files. The mongod fails to start if it encounters an encrypted PEM file. To securely store and access a certificate for use with TLS on Windows, use net.tls.certificateSelector.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``certificateKeyFilePassword Type: stringNew in version 4.2: The password to de-crypt the certificate-key file (i.e. certificateKeyFile). Use the net.tls.certificateKeyPassword option only if the certificate-key file is encrypted. In all cases, the mongos or mongod will redact the password from all logging and reporting output.Starting in MongoDB 4.0:On Linux/BSD, if the private key in the PEM file is encrypted and you do not specify the net.tls.certificateKeyFukePassword option, MongoDB will prompt for a passphrase. See TLS/SSL Certificate Passphrase.On macOS, if the private key in the PEM file is encrypted, you must explicitly specify the net.tls.certificateKeyFilePassword option. Alternatively, you can use a certificate from the secure system store (see net.tls.certificateSelector) instead of a PEM key file or use an unencrypted PEM file.On Windows, MongoDB does not support encrypted certificates. The mongod fails if it encounters an encrypted PEM file. Use net.tls.certificateSelector instead.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``certificateSelector Type: stringNew in version 4.2: Available on Windows and macOS as an alternative to net.tls.certificateKeyFile. In MongoDB 4.0, see net.ssl.certificateSelector.Specifies a certificate property in order to select a matching certificate from the operating system’s certificate store to use for TLS/SSL.net.tls.certificateKeyFile and net.tls.certificateSelector options are mutually exclusive. You can only specify one.net.tls.certificateSelector accepts an argument of the format = where the property can be one of the following:PropertyValue typeDescriptionsubjectASCII stringSubject name or common name on certificatethumbprinthex stringA sequence of bytes, expressed as hexadecimal, used to identify a public key by its SHA-1 digest.The thumbprint is sometimes referred to as a fingerprint.When using the system SSL certificate store, OCSP (Online Certificate Status Protocol) is used to validate the revocation status of certificates.The mongod searches the operating system’s secure certificate store for the CA certificates required to validate the full certificate chain of the specified TLS certificate. Specifically, the secure certificate store must contain the root CA and any intermediate CA certificates required to build the full certificate chain to the TLS certificate. Do not use net.tls.CAFile or net.tls.clusterFile to specify the root and intermediate CA certificateFor example, if the TLS certificate was signed with a single root CA certificate, the secure certificate store must contain that root CA certificate. If the TLS certificate was signed with an intermediate CA certificate, the secure certificate store must contain the intermedia CA certificate and the root CA certificate. net.tls.``clusterCertificateSelector Type: stringNew in version 4.2: Available on Windows and macOS as an alternative to net.tls.clusterFile.Specifies a certificate property to select a matching certificate from the operating system’s secure certificate store to use for internal x.509 membership authentication.net.tls.clusterFile and net.tls.clusterCertificateSelector options are mutually exclusive. You can only specify one.net.tls.clusterCertificateSelector accepts an argument of the format = where the property can be one of the following:PropertyValue typeDescriptionsubjectASCII stringSubject name or common name on certificatethumbprinthex stringA sequence of bytes, expressed as hexadecimal, used to identify a public key by its SHA-1 digest.The thumbprint is sometimes referred to as a fingerprint.The mongod searches the operating system’s secure certificate store for the CA certificates required to validate the full certificate chain of the specified cluster certificate. Specifically, the secure certificate store must contain the root CA and any intermediate CA certificates required to build the full certificate chain to the cluster certificate. Do not use net.tls.CAFile or net.tls.clusterCAFile to specify the root and intermediate CA certificate.For example, if the cluster certificate was signed with a single root CA certificate, the secure certificate store must contain that root CA certificate. If the cluster certificate was signed with an intermediate CA certificate, the secure certificate store must contain the intermediate CA certificate and the root CA certificate.Changed in version 4.4: mongod / mongos logs a warning on connection if the presented x.509 certificate expires within 30 days of the mongod/mongos host system time. See x.509 Certificates Nearing Expiry Trigger Warnings for more information. net.tls.``clusterFile Type: stringNew in version 4.2: The .pem file that contains the x.509 certificate-key file for membership authentication for the cluster or replica set.Starting with MongoDB 4.0 on macOS or Windows, you can use the net.tls.clusterCertificateSelector option to specify a certificate from the operating system’s secure certificate store instead of a PEM key file. net.tls.clusterFile and net.tls.clusterCertificateSelector options are mutually exclusive. You can only specify one.If net.tls.clusterFile does not specify the .pem file for internal cluster authentication or the alternative net.tls.clusterCertificateSelector, the cluster uses the .pem file specified in the certificateKeyFile setting or the certificate returned by the net.tls.certificateSelector.If using x.509 authentication, --tlsCAFile or tls.CAFile must be specified unless using --tlsCertificateSelector.Changed in version 4.4: mongod / mongos logs a warning on connection if the presented x.509 certificate expires within 30 days of the mongod/mongos host system time. See x.509 Certificates Nearing Expiry Trigger Warnings for more information.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients .IMPORTANTFor Windows only, MongoDB 4.0 and later do not support encrypted PEM files. The mongod fails to start if it encounters an encrypted PEM file. To securely store and access a certificate for use with membership authentication on Windows, use net.tls.clusterCertificateSelector. net.tls.``clusterPassword Type: stringNew in version 4.2: The password to de-crypt the x.509 certificate-key file specified with --sslClusterFile. Use the net.tls.clusterPassword option only if the certificate-key file is encrypted. In all cases, the mongos or mongod will redact the password from all logging and reporting output.Starting in MongoDB 4.0:On Linux/BSD, if the private key in the x.509 file is encrypted and you do not specify the net.tls.clusterPassword option, MongoDB will prompt for a passphrase. See TLS/SSL Certificate Passphrase.On macOS, if the private key in the x.509 file is encrypted, you must explicitly specify the net.tls.clusterPassword option. Alternatively, you can either use a certificate from the secure system store (see net.tls.clusterCertificateSelector) instead of a cluster PEM file or use an unencrypted PEM file.On Windows, MongoDB does not support encrypted certificates. The mongod fails if it encounters an encrypted PEM file. Use net.tls.clusterCertificateSelector.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``CAFile Type: stringNew in version 4.2: The .pem file that contains the root certificate chain from the Certificate Authority. Specify the file name of the .pem file using relative or absolute paths.Windows/macOS OnlyIf using net.tls.certificateSelector and/or net.tls.clusterCertificateSelector, do not use net.tls.CAFile to specify the root and intermediate CA certificates. Store all CA certificates required to validate the full trust chain of the net.tls.certificateSelector and/or net.tls.clusterCertificateSelector certificates in the secure certificate store.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``clusterCAFile Type: stringNew in version 4.2: The .pem file that contains the root certificate chain from the Certificate Authority used to validate the certificate presented by a client establishing a connection. Specify the file name of the .pem file using relative or absolute paths. net.tls.clusterCAFile requires that net.tls.CAFile is set.If net.tls.clusterCAFile does not specify the .pem file for validating the certificate from a client establishing a connection, the cluster uses the .pem file specified in the net.tls.CAFile option.net.tls.clusterCAFile lets you use separate Certificate Authorities to verify the client to server and server to client portions of the TLS handshake.Starting in 4.0, on macOS or Windows, you can use a certificate from the operating system’s secure store instead of a PEM key file. See net.tls.clusterCertificateSelector. When using the secure store, you do not need to, but can, also specify the net.tls.clusterCAFile.Windows/macOS OnlyIf using net.tls.certificateSelector and/or net.tls.clusterCertificateSelector, do not use net.tls.clusterCAFile to specify the root and intermediate CA certificates. Store all CA certificates required to validate the full trust chain of the net.tls.certificateSelector and/or net.tls.clusterCertificateSelector certificates in the secure certificate store.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``CRLFile Type: stringNew in version 4.2: In MongoDB 4.0 and earlier, see net.ssl.CRLFile.The .pem file that contains the Certificate Revocation List. Specify the file name of the .pem file using relative or absolute paths.NOTEStarting in MongoDB 4.0, you cannot specify net.tls.CRLFile on macOS. Instead, you can use the system SSL certificate store, which uses OCSP (Online Certificate Status Protocol) to validate the revocation status of certificates. See net.ssl.certificateSelector in MongoDB 4.0 and net.tls.certificateSelector in MongoDB 4.2+ to use the system SSL certificate store.Starting in version 4.4, to check for certificate revocation, MongoDB enables the use of OCSP (Online Certificate Status Protocol) by default as an alternative to specifying a CRL file or using the system SSL certificate store.ource/reference/configuration-options.txt .. include:: /includes/extracts/tls-facts-see-more.rst net.tls.``allowConnectionsWithoutCertificates Type: booleanNew in version 4.2.For clients that do not present certificates, mongos or mongod bypasses TLS/SSL certificate validation when establishing the connection.For clients that present a certificate, however, mongos or mongod performs certificate validation using the root certificate chain specified by CAFile and reject clients with invalid certificates.Use the net.tls.allowConnectionsWithoutCertificates option if you have a mixed deployment that includes clients that do not or cannot present certificates to the mongos or mongod.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``allowInvalidCertificates Type: booleanNew in version 4.2.Enable or disable the validation checks for TLS certificates on other servers in the cluster and allows the use of invalid certificates to connect.NOTEIf you specify --tlsAllowInvalidCertificates or tls.allowInvalidCertificates: true when using x.509 authentication, an invalid certificate is only sufficient to establish a TLS connection but is insufficient for authentication.When using the net.tls.allowInvalidCertificates setting, MongoDB logs a warning regarding the use of the invalid certificate.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``allowInvalidHostnames Type: booleanDefault: falseWhen net.tls.allowInvalidHostnames is true, MongoDB disables the validation of the hostnames in TLS certificates, allowing mongod to connect to MongoDB instances if the hostname their certificates do not match the specified hostname.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.tls.``disabledProtocols Type: stringNew in version 4.2.Prevents a MongoDB server running with TLS from accepting incoming connections that use a specific protocol or protocols. To specify multiple protocols, use a comma separated list of protocols.net.tls.disabledProtocols recognizes the following protocols: TLS1_0, TLS1_1, TLS1_2, and starting in version 4.0.4 (and 3.6.9), TLS1_3.On macOS, you cannot disable TLS1_1 and leave both TLS1_0 and TLS1_2 enabled. You must disable at least one of the other two, for example, TLS1_0,TLS1_1.To list multiple protocols, specify as a comma separated list of protocols. For example TLS1_0,TLS1_1.Specifying an unrecognized protocol will prevent the server from starting.The specified disabled protocols overrides any default disabled protocols.Starting in version 4.0, MongoDB disables the use of TLS 1.0 if TLS 1.1+ is available on the system. To enable the disabled TLS 1.0, specify none to net.tls.disabledProtocols. See Disable TLS 1.0.Members of replica sets and sharded clusters must speak at least one protocol in common.SEE ALSODisallow Protocols net.tls.``FIPSMode Type: booleanNew in version 4.2.Enable or disable the use of the FIPS mode of the TLS library for the mongos or mongod. Your system must have a FIPS compliant library to use the net.tls.FIPSMode option.NOTEFIPS-compatible TLS/SSL is available only in MongoDB Enterprise. See Configure MongoDB for FIPS for more information. net.ssl 选项 IMPORTANT All SSL options are deprecated since 4.2. Use the TLS counterparts instead, as they have identical functionality to the SSL options. The SSL protocol is deprecated and MongoDB supports TLS 1.0 and later. copycopied net: ssl: deprecated since 4.2 sslOnNormalPorts: deprecated since 2.6 mode: PEMKeyFile: PEMKeyPassword: certificateSelector: clusterCertificateSelector: clusterFile: clusterPassword: CAFile: clusterCAFile: CRLFile: allowConnectionsWithoutCertificates: allowInvalidCertificates: allowInvalidHostnames: disabledProtocols: FIPSMode: net.ssl.``sslOnNormalPorts Type: booleanDeprecated since version 2.6: Use net.tls.mode: requireTLS instead.Enable or disable TLS/SSL for mongos or mongod.With net.ssl.sslOnNormalPorts, a mongos or mongod requires TLS/SSL encryption for all connections on the default MongoDB port, or the port specified by net.port. By default, net.ssl.sslOnNormalPorts is disabled.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``mode Type: stringDeprecated since version 4.2: Use net.tls.mode instead.Enables TLS/SSL or mixed TLS/SSL used for all network connections. The argument to the net.ssl.mode setting can be one of the following:ValueDescriptiondisabledThe server does not use TLS/SSL.allowSSLConnections between servers do not use TLS/SSL. For incoming connections, the server accepts both TLS/SSL and non-TLS/non-SSL.preferSSLConnections between servers use TLS/SSL. For incoming connections, the server accepts both TLS/SSL and non-TLS/non-SSL.requireSSLThe server uses and accepts only TLS/SSL encrypted connections.Starting in version 3.4, if --tlsCAFile/net.tls.CAFile (or their aliases --sslCAFile/net.ssl.CAFile) is not specified and you are not using x.509 authentication, the system-wide CA certificate store will be used when connecting to an TLS/SSL-enabled server.To use x.509 authentication, --tlsCAFile or net.tls.CAFile must be specified unless using --tlsCertificateSelector or --net.tls.certificateSelector. Or if using the ssl aliases, --sslCAFile or net.ssl.CAFile must be specified unless using --sslCertificateSelector or net.ssl.certificateSelector.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``PEMKeyFile Type: stringDeprecated since version 4.2: Use net.tls.certificateKeyFile instead.The .pem file that contains both the TLS/SSL certificate and key.Starting with MongoDB 4.0 on macOS or Windows, you can use the net.ssl.certificateSelector setting to specify a certificate from the operating system’s secure certificate store instead of a PEM key file. PEMKeyFile and net.ssl.certificateSelector are mutually exclusive. You can only specify one.On Linux/BSD, you must specify net.ssl.PEMKeyFile when TLS/SSL is enabled.On Windows or macOS, you must specify either net.ssl.PEMKeyFile or net.ssl.certificateSelector when TLS/SSL is enabled.IMPORTANTFor Windows only, MongoDB 4.0 and later do not support encrypted PEM files. The mongod fails to start if it encounters an encrypted PEM file. To securely store and access a certificate for use with TLS/SSL on Windows, use net.ssl.certificateSelector.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``PEMKeyPassword Type: stringDeprecated since version 4.2: Use net.tls.certificateKeyFilePassword instead.The password to de-crypt the certificate-key file (i.e. PEMKeyFile). Use the net.ssl.PEMKeyPassword option only if the certificate-key file is encrypted. In all cases, the mongos or mongod will redact the password from all logging and reporting output.Starting in MongoDB 4.0:On Linux/BSD, if the private key in the PEM file is encrypted and you do not specify the net.ssl.PEMKeyPassword option, MongoDB will prompt for a passphrase. See TLS/SSL Certificate Passphrase.On macOS, if the private key in the PEM file is encrypted, you must explicitly specify the net.ssl.PEMKeyPassword option. Alternatively, you can use a certificate from the secure system store (see net.ssl.certificateSelector) instead of a PEM key file or use an unencrypted PEM file.On Windows, MongoDB does not support encrypted certificates. The mongod fails if it encounters an encrypted PEM file. Use net.ssl.certificateSelector instead.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``certificateSelector Type: stringDeprecated since version 4.2: Use net.tls.certificateSelector instead.New in version 4.0: Available on Windows and macOS as an alternative to net.ssl.PEMKeyFile.Specifies a certificate property in order to select a matching certificate from the operating system’s certificate store to use for TLS/SSL.net.ssl.PEMKeyFile and net.ssl.certificateSelector options are mutually exclusive. You can only specify one.net.ssl.certificateSelector accepts an argument of the format = where the property can be one of the following:PropertyValue typeDescriptionsubjectASCII stringSubject name or common name on certificatethumbprinthex stringA sequence of bytes, expressed as hexadecimal, used to identify a public key by its SHA-1 digest.The thumbprint is sometimes referred to as a fingerprint.When using the system SSL certificate store, OCSP (Online Certificate Status Protocol) is used to validate the revocation status of certificates.The mongod searches the operating system’s secure certificate store for the CA certificates required to validate the full certificate chain of the specified TLS/SSL certificate. Specifically, the secure certificate store must contain the root CA and any intermediate CA certificates required to build the full certificate chain to the TLS/SSL certificate. Do not use net.ssl.CAFile or net.ssl.clusterFile to specify the root and intermediate CA certificateFor example, if the TLS/SSL certificate was signed with a single root CA certificate, the secure certificate store must contain that root CA certificate. If the TLS/SSL certificate was signed with an intermediate CA certificate, the secure certificate store must contain the intermedia CA certificate and the root CA certificate. net.ssl.``clusterCertificateSelector Type: stringDeprecated since version 4.2: Use net.tls.clusterCertificateSelector instead.New in version 4.0: Available on Windows and macOS as an alternative to net.ssl.clusterFile.Specifies a certificate property to select a matching certificate from the operating system’s secure certificate store to use for internal x.509 membership authentication.net.ssl.clusterFile and net.ssl.clusterCertificateSelector options are mutually exclusive. You can only specify one.net.ssl.clusterCertificateSelector accepts an argument of the format = where the property can be one of the following:PropertyValue typeDescriptionsubjectASCII stringSubject name or common name on certificatethumbprinthex stringA sequence of bytes, expressed as hexadecimal, used to identify a public key by its SHA-1 digest.The thumbprint is sometimes referred to as a fingerprint.The mongod searches the operating system’s secure certificate store for the CA certificates required to validate the full certificate chain of the specified cluster certificate. Specifically, the secure certificate store must contain the root CA and any intermediate CA certificates required to build the full certificate chain to the cluster certificate. Do not use net.ssl.CAFile or net.ssl.clusterFile to specify the root and intermediate CA certificate.For example, if the cluster certificate was signed with a single root CA certificate, the secure certificate store must contain that root CA certificate. If the cluster certificate was signed with an intermediate CA certificate, the secure certificate store must contain the intermedia CA certificate and the root CA certificate. net.ssl.``clusterFile Type: stringDeprecated since version 4.2: Use net.tls.clusterFile instead.The .pem file that contains the x.509 certificate-key file for membership authentication for the cluster or replica set.Starting with MongoDB 4.0 on macOS or Windows, you can use the net.ssl.clusterCertificateSelector option to specify a certificate from the operating system’s secure certificate store instead of a PEM key file. net.ssl.clusterFile and net.ssl.clusterCertificateSelector options are mutually exclusive. You can only specify one.If net.ssl.clusterFile does not specify the .pem file for internal cluster authentication or the alternative net.ssl.clusterCertificateSelector, the cluster uses the .pem file specified in the PEMKeyFile setting or the certificate returned by the net.ssl.certificateSelector.To use x.509 authentication, --tlsCAFile or net.tls.CAFile must be specified unless using --tlsCertificateSelector or --net.tls.certificateSelector. Or if using the ssl aliases, --sslCAFile or net.ssl.CAFile must be specified unless using --sslCertificateSelector or net.ssl.certificateSelector.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients .IMPORTANTFor Windows only, MongoDB 4.0 and later do not support encrypted PEM files. The mongod fails to start if it encounters an encrypted PEM file. To securely store and access a certificate for use with membership authentication on Windows, use net.ssl.clusterCertificateSelector. net.ssl.``clusterPassword Type: stringDeprecated since version 4.2: Use net.tls.clusterPassword instead.The password to de-crypt the x.509 certificate-key file specified with --sslClusterFile. Use the net.ssl.clusterPassword option only if the certificate-key file is encrypted. In all cases, the mongos or mongod will redact the password from all logging and reporting output.Starting in MongoDB 4.0:On Linux/BSD, if the private key in the x.509 file is encrypted and you do not specify the net.ssl.clusterPassword option, MongoDB will prompt for a passphrase. See TLS/SSL Certificate Passphrase.On macOS, if the private key in the x.509 file is encrypted, you must explicitly specify the net.ssl.clusterPassword option. Alternatively, you can either use a certificate from the secure system store (see net.ssl.clusterCertificateSelector) instead of a cluster PEM file or use an unencrypted PEM file.On Windows, MongoDB does not support encrypted certificates. The mongod fails if it encounters an encrypted PEM file. Use net.ssl.clusterCertificateSelector.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``CAFile Type: stringDeprecated since version 4.2: Use net.tls.CAFile instead.The .pem file that contains the root certificate chain from the Certificate Authority. Specify the file name of the .pem file using relative or absolute paths.Windows/macOS OnlyIf using net.ssl.certificateSelector and/or net.ssl.clusterCertificateSelector, do not use net.ssl.CAFile to specify the root and intermediate CA certificates. Store all CA certificates required to validate the full trust chain of the net.ssl.certificateSelector and/or net.ssl.clusterCertificateSelector certificates in the secure certificate store.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``clusterCAFile Type: stringDeprecated since version 4.2: Use net.tls.clusterCAFile instead.The .pem file that contains the root certificate chain from the Certificate Authority used to validate the certificate presented by a client establishing a connection. Specify the file name of the .pem file using relative or absolute paths. net.ssl.clusterCAFile requires that net.ssl.CAFile is set.If net.ssl.clusterCAFile does not specify the .pem file for validating the certificate from a client establishing a connection, the cluster uses the .pem file specified in the net.ssl.CAFile option.net.ssl.clusterCAFile lets you use separate Certificate Authorities to verify the client to server and server to client portions of the TLS handshake.Starting in 4.0, on macOS or Windows, you can use a certificate from the operating system’s secure store instead of a PEM key file. See net.ssl.clusterCertificateSelector. When using the secure store, you do not need to, but can, also specify the net.ssl.clusterCAFile.Windows/macOS OnlyIf using net.ssl.certificateSelector and/or net.ssl.clusterCertificateSelector, do not use net.ssl.clusterCAFile to specify the root and intermediate CA certificates. Store all CA certificates required to validate the full trust chain of the net.ssl.certificateSelector and/or net.ssl.clusterCertificateSelector certificates in the secure certificate store.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``CRLFile Type: stringDeprecated since version 4.2: Use net.tls.CRLFile instead.The .pem file that contains the Certificate Revocation List. Specify the file name of the .pem file using relative or absolute paths.NOTEStarting in MongoDB 4.0, you cannot specify net.ssl.CRLFile on macOS. Instead, you can use the system SSL certificate store, which uses OCSP (Online Certificate Status Protocol) to validate the revocation status of certificates. See net.ssl.certificateSelector in MongoDB 4.0 and net.tls.certificateSelector in MongoDB 4.2 to use the system SSL certificate store.Starting in version 4.4, MongoDB enables, by default, the use of OCSP (Online Certificate Status Protocol) to check for certificate revocation as an alternative to specifying a CRL file or using the system SSL certificate store.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``allowConnectionsWithoutCertificates Type: booleanDeprecated since version 4.2: Use net.tls.allowConnectionsWithoutCertificates instead.For clients that do not present certificates, mongos or mongod bypasses TLS/SSL certificate validation when establishing the connection.For clients that present a certificate, however, mongos or mongod performs certificate validation using the root certificate chain specified by CAFile and reject clients with invalid certificates.Use the net.ssl.allowConnectionsWithoutCertificates option if you have a mixed deployment that includes clients that do not or cannot present certificates to the mongos or mongod.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``allowInvalidCertificates Type: booleanDeprecated since version 4.2: Use net.tls.allowInvalidCertificates instead.Enable or disable the validation checks for TLS/SSL certificates on other servers in the cluster and allows the use of invalid certificates to connect.NOTEStarting in MongoDB 4.0, if you specify --sslAllowInvalidCertificates or net.ssl.allowInvalidCertificates: true (or in MongoDB 4.2, the alias --tlsAllowInvalidateCertificates or net.tls.allowInvalidCertificates: true) when using x.509 authentication, an invalid certificate is only sufficient to establish a TLS/SSL connection but is insufficient for authentication.When using the net.ssl.allowInvalidCertificates setting, MongoDB logs a warning regarding the use of the invalid certificate.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``allowInvalidHostnames Type: booleanDefault: falseDeprecated since version 4.2.Use net.tls.allowInvalidHostnames instead.When net.ssl.allowInvalidHostnames is true, MongoDB disables the validation of the hostnames in TLS/SSL certificates, allowing mongod to connect to MongoDB instances if the hostname their certificates do not match the specified hostname.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . net.ssl.``disabledProtocols Type: stringDeprecated since version 4.2: Use net.tls.disabledProtocols instead.Prevents a MongoDB server running with TLS/SSL from accepting incoming connections that use a specific protocol or protocols. To specify multiple protocols, use a comma separated list of protocols.net.ssl.disabledProtocols recognizes the following protocols: TLS1_0, TLS1_1, TLS1_2, and starting in version 4.0.4 (and 3.6.9), TLS1_3.On macOS, you cannot disable TLS1_1 and leave both TLS1_0 and TLS1_2 enabled. You must disable at least one of the other two, for example, TLS1_0,TLS1_1.To list multiple protocols, specify as a comma separated list of protocols. For example TLS1_0,TLS1_1.Specifying an unrecognized protocol will prevent the server from starting.The specified disabled protocols overrides any default disabled protocols.Starting in version 4.0, MongoDB disables the use of TLS 1.0 if TLS 1.1+ is available on the system. To enable the disabled TLS 1.0, specify none to net.ssl.disabledProtocols. See Disable TLS 1.0.Members of replica sets and sharded clusters must speak at least one protocol in common.SEE ALSODisallow Protocols net.ssl.``FIPSMode Type: booleanDeprecated since version 4.2: Use net.tls.FIPSMode instead.Enable or disable the use of the FIPS mode of the TLS/SSL library for the mongos or mongod. Your system must have a FIPS compliant library to use the net.ssl.FIPSMode option.NOTEFIPS-compatible TLS/SSL is available only in MongoDB Enterprise. See Configure MongoDB for FIPS for more information. net.compression 选项 copycopied net: compression: compressors: net.compression.``compressors Default: snappy,zstd,zlibNew in version 3.4.Specifies the default compressor(s) to use for communication between this mongod or mongos instance and:other members of the deployment if the instance is part of a replica set or a sharded clustera mongo shelldrivers that support the OP_COMPRESSED message format.MongoDB supports the following compressors:snappyzlib (Available starting in MongoDB 3.6)zstd (Available starting in MongoDB 4.2)In versions 3.6 and 4.0, mongod and mongos enable network compression by default with snappy as the compressor.Starting in version 4.2, mongod and mongos instances default to both snappy,zstd,zlib compressors, in that order.To disable network compression, set the value to disabled.IMPORTANTMessages are compressed when both parties enable network compression. Otherwise, messages between the parties are uncompressed.If you specify multiple compressors, then the order in which you list the compressors matter as well as the communication initiator. For example, if a mongo shell specifies the following network compressors zlib,snappy and the mongod specifies snappy,zlib, messages between mongo shell and mongod uses zlib.If the parties do not share at least one common compressor, messages between the parties are uncompressed. For example, if a mongo shell specifies the network compressor zlib and mongod specifies snappy, messages between mongo shell and mongod are not compressed. net.``serviceExecutor Type: stringDefault: synchronousNew in version 3.6.Determines the threading and execution model mongos or mongod uses to execute client requests. The --serviceExecutor option accepts one of the following values:ValueDescriptionsynchronousThe mongos or mongod uses synchronous networking and manages its networking thread pool on a per connection basis. Previous versions of MongoDB managed threads in this way.adaptiveThe mongos or mongod uses the new experimental asynchronous networking mode with an adaptive thread pool which manages threads on a per request basis. This mode should have more consistent performance and use less resources when there are more inactive connections than database requests. security 选项 copycopied security: keyFile: clusterAuthMode: authorization: transitionToAuth: javascriptEnabled: redactClientLogData: clusterIpSourceWhitelist: - sasl: hostName: serviceName: saslauthdSocketPath: enableEncryption: encryptionCipherMode: encryptionKeyFile: kmip: keyIdentifier: rotateMasterKey: serverName: port: clientCertificateFile: clientCertificatePassword: clientCertificateSelector: serverCAFile: connectRetries: connectTimeoutMS: ldap: servers: bind: method: saslMechanisms: queryUser: queryPassword: useOSDefaults: transportSecurity: timeoutMS: userToDNMapping: authz: queryTemplate: validateLDAPServerConfig: security.``keyFile Type: stringThe path to a key file that stores the shared secret that MongoDB instances use to authenticate to each other in a sharded cluster or replica set. keyFile implies security.authorization. See Internal/Membership Authentication for more information.Starting in MongoDB 4.2, keyfiles for internal membership authentication use YAML format to allow for multiple keys in a keyfile. The YAML format accepts content of:a single key string (same as in earlier versions),multiple key strings (each string must be enclosed in quotes), orsequence of key strings.The YAML format is compatible with the existing single-key keyfiles that use the text file format. security.``clusterAuthMode Type: stringDefault: keyFileThe authentication mode used for cluster authentication. If you use internal x.509 authentication, specify so here. This option can have one of the following values:ValueDescriptionkeyFileUse a keyfile for authentication. Accept only keyfiles.sendKeyFileFor rolling upgrade purposes. Send a keyfile for authentication but can accept both keyfiles and x.509 certificates.sendX509For rolling upgrade purposes. Send the x.509 certificate for authentication but can accept both keyfiles and x.509 certificates.x509Recommended. Send the x.509 certificate for authentication and accept only x.509 certificates.If --tlsCAFile or tls.CAFile is not specified and you are not using x.509 authentication, the system-wide CA certificate store will be used when connecting to an TLS-enabled server.If using x.509 authentication, --tlsCAFile or tls.CAFile must be specified unless using --tlsCertificateSelector.For more information about TLS and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients . security.``authorization Type: stringDefault: disabledEnable or disable Role-Based Access Control (RBAC) to govern each user’s access to database resources and operations.Set this option to one of the following:ValueDescriptionenabledA user can access only the database resources and actions for which they have been granted privileges.disabledA user can access any database and perform any action.See Role-Based Access Control for more information.The security.authorization setting is available only for mongod. security.``transitionToAuth Type: booleanDefault: falseNew in version 3.4: Allows the mongod or mongos to accept and create authenticated and non-authenticated connections to and from other mongod and mongos instances in the deployment. Used for performing rolling transition of replica sets or sharded clusters from a no-auth configuration to internal authentication. Requires specifying a internal authentication mechanism such as security.keyFile.For example, if using keyfiles for internal authentication, the mongod or mongos creates an authenticated connection with any mongod or mongos in the deployment using a matching keyfile. If the security mechanisms do not match, the mongod or mongos utilizes a non-authenticated connection instead.A mongod or mongos running with security.transitionToAuth does not enforce user access controls. Users may connect to your deployment without any access control checks and perform read, write, and administrative operations.NOTEA mongod or mongos running with internal authentication and without security.transitionToAuth requires clients to connect using user access controls. Update clients to connect to the mongod or mongos using the appropriate user prior to restarting mongod or mongos without security.transitionToAuth. security.``javascriptEnabled Type: booleanDefault: trueEnables or disables server-side JavaScript execution. When disabled, you cannot use operations that perform server-side execution of JavaScript code, such as the $where query operator, mapReduce command, $accumulator, and $function.If you do not use these operations, disable server-side scripting.Starting in version 4.4, the security.javascriptEnabled is available for both mongod and mongos. In earlier versions, the setting is only available for mongod. security.``redactClientLogData Type: booleanNew in version 3.4: Available in MongoDB Enterprise only.A mongod or mongos running with security.redactClientLogData redacts any message accompanying a given log event before logging. This prevents the mongod or mongos from writing potentially sensitive data stored on the database to the diagnostic log. Metadata such as error or operation codes, line numbers, and source file names are still visible in the logs.Use security.redactClientLogData in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements.For example, a MongoDB deployment might store Personally Identifiable Information (PII) in one or more collections. The mongod or mongos logs events such as those related to CRUD operations, sharding metadata, etc. It is possible that the mongod or mongos may expose PII as a part of these logging operations. A mongod or mongos running with security.redactClientLogData removes any message accompanying these events before being output to the log, effectively removing the PII.Diagnostics on a mongod or mongos running with security.redactClientLogData may be more difficult due to the lack of data related to a log event. See the process logging manual page for an example of the effect of security.redactClientLogData on log output.On a running mongod or mongos, use setParameter with the redactClientLogData parameter to configure this setting. security.``clusterIpSourceWhitelist Type: listNew in version 3.6.A list of IP addresses/CIDR (Classless Inter-Domain Routing) ranges against which the mongod validates authentication requests from other members of the replica set and, if part of a sharded cluster, the mongos instances. The mongod verifies that the originating IP is either explicitly in the list or belongs to a CIDR range in the list. If the IP address is not present, the server does not authenticate the mongod or mongos.security.clusterIpSourceWhitelist has no effect on a mongod started without authentication.security.clusterIpSourceWhitelist requires specifying each IPv4/6 address or Classless Inter-Domain Routing (CIDR) range as a YAML list:copycopiedsecurity: clusterIpSourceWhitelist: - 192.0.2.0/24 - 127.0.0.1 - ::1IMPORTANTEnsure security.clusterIpSourceWhitelist includes the IP address or CIDR ranges that include the IP address of each replica set member or mongos in the deployment to ensure healthy communication between cluster components. 密钥管理配置选项 copycopied security: enableEncryption: encryptionCipherMode: encryptionKeyFile: kmip: keyIdentifier: rotateMasterKey: serverName: port: clientCertificateFile: clientCertificatePassword: clientCertificateSelector: serverCAFile: connectRetries: connectTimeoutMS: security.``enableEncryption Type: booleanDefault: falseNew in version 3.2: Enables encryption for the WiredTiger storage engine. You must set to true to pass in encryption keys and configurations.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.``encryptionCipherMode Type: stringDefault: AES256-CBCNew in version 3.2.The cipher mode to use for encryption at rest:ModeDescriptionAES256-CBC256-bit Advanced Encryption Standard in Cipher Block Chaining ModeAES256-GCM256-bit Advanced Encryption Standard in Galois/Counter ModeAvailable only on Linux.Changed in version 4.0: MongoDB Enterprise on Windows no longer supports AES256-GCM. This cipher is now available only on Linux.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.``encryptionKeyFile Type: stringNew in version 3.2.The path to the local keyfile when managing keys via process other than KMIP. Only set when managing keys via process other than KMIP. If data is already encrypted using KMIP, MongoDB will throw an error.Requires security.enableEncryption to be true.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``keyIdentifier Type: stringNew in version 3.2.Unique KMIP identifier for an existing key within the KMIP server. Include to use the key associated with the identifier as the system key. You can only use the setting the first time you enable encryption for the mongod instance. Requires security.enableEncryption to be true.If unspecified, MongoDB will request that the KMIP server create a new key to utilize as the system key.If the KMIP server cannot locate a key with the specified identifier or the data is already encrypted with a key, MongoDB will throw an error.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``rotateMasterKey Type: booleanDefault: falseNew in version 3.2.If true, rotate the master key and re-encrypt the internal keystore.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only.SEE ALSOKMIP Master Key Rotation security.kmip.``serverName Type: stringNew in version 3.2.Hostname or IP address of the KMIP server to connect to. Requires security.enableEncryption to be true.Starting in MongoDB 4.2.1 (and 4.0.14), you can specify multiple KMIP servers as a comma-separated list, e.g. server1.example.com,server2.example.com. On startup, the mongod will attempt to establish a connection to each server in the order listed, and will select the first server to which it can successfully establish a connection. KMIP server selection occurs only at startup.When connecting to a KMIP server, the mongod verifies that the specified security.kmip.serverName matches the Subject Alternative Name SAN (or, if SAN is not present, the Common Name CN) in the certificate presented by the KMIP server. If SAN is present, mongod does not match against the CN. If the hostname does not match the SAN (or CN), the mongod will fail to connect.Starting in MongoDB 4.2, when performing comparison of SAN, MongoDB supports comparison of DNS names or IP addresses. In previous versions, MongoDB only supports comparisons of DNS names.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``port Type: stringDefault: 5696New in version 3.2.Port number to use to communicate with the KMIP server. Requires security.kmip.serverName. Requires security.enableEncryption to be true.If specifying multiple KMIP servers with security.kmip.serverName, the mongod will use the port specified with security.kmip.port for all provided KMIP servers.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``clientCertificateFile Type: stringNew in version 3.2.String containing the path to the client certificate used for authenticating MongoDB to the KMIP server. Requires that a security.kmip.serverName be provided.NOTEStarting in 4.0, on macOS or Windows, you can use a certificate from the operating system’s secure store instead of a PEM key file. See security.kmip.clientCertificateSelector.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``clientCertificatePassword Type: stringNew in version 3.2.The password to decrypt the client certificate (i.e. security.kmip.clientCertificateFile), used to authenticate MongoDB to the KMIP server. Use the option only if the certificate is encrypted.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``clientCertificateSelector Type: stringNew in version 4.0: Available on Windows and macOS as an alternative to security.kmip.clientCertificateFile.security.kmip.clientCertificateFile and security.kmip.clientCertificateSelector options are mutually exclusive. You can only specify one.Specifies a certificate property in order to select a matching certificate from the operating system’s certificate store to authenticate MongoDB to the KMIP server.security.kmip.clientCertificateSelector accepts an argument of the format = where the property can be one of the following:PropertyValue typeDescriptionsubjectASCII stringSubject name or common name on certificatethumbprinthex stringA sequence of bytes, expressed as hexadecimal, used to identify a public key by its SHA-1 digest.The thumbprint is sometimes referred to as a fingerprint.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``serverCAFile Type: stringNew in version 3.2.Path to CA File. Used for validating secure client connection to KMIP server.NOTEStarting in 4.0, on macOS or Windows, you can use a certificate from the operating system’s secure store instead of a PEM key file. See security.kmip.clientCertificateSelector. When using the secure store, you do not need to, but can, also specify the security.kmip.serverCAFile.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``connectRetries Type: intDefault: 0New in version 4.4.How many times to retry the initial connection to the KMIP server. Use together with connectTimeoutMS to control how long the mongod waits for a response between each retry.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.kmip.``connectTimeoutMS Type: intDefault: 5000New in version 4.4.Timeout in milliseconds to wait for a response from the KMIP server. If the connectRetries setting is specified, the mongod will wait up to the value specified with connectTimeoutMS for each retry.Value must be 1000 or greater.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. security.sasl 选项 copycopied security: sasl: hostName: serviceName: saslauthdSocketPath: security.sasl.``hostName Type: stringA fully qualified server domain name for the purpose of configuring SASL and Kerberos authentication. The SASL hostname overrides the hostname only for the configuration of SASL and Kerberos.For mongo shell and other MongoDB tools to connect to the new hostName, see the gssapiHostName option in the mongo shell and other tools. security.sasl.``serviceName Type: stringRegistered name of the service using SASL. This option allows you to override the default Kerberos service name component of the Kerberos principal name, on a per-instance basis. If unspecified, the default value is mongodb.MongoDB permits setting this option only at startup. The setParameter can not change this setting.This option is available only in MongoDB Enterprise.IMPORTANTEnsure that your driver supports alternate service names. For mongo shell and other MongoDB tools to connect to the new serviceName, see the gssapiServiceName option. security.sasl.``saslauthdSocketPath Type: stringThe path to the UNIX domain socket file for saslauthd. security.ldap 选项 copycopied security: ldap: servers: bind: method: saslMechanisms: queryUser: queryPassword: useOSDefaults: transportSecurity: timeoutMS: userToDNMapping: authz: queryTemplate: validateLDAPServerConfig: security.ldap.``servers Type: stringNew in version 3.4: Available in MongoDB Enterprise only.The LDAP server against which the mongod or mongos authenticates users or determines what actions a user is authorized to perform on a given database. If the LDAP server specified has any replicated instances, you may specify the host and port of each replicated server in a comma-delimited list.If your LDAP infrastructure partitions the LDAP directory over multiple LDAP servers, specify one LDAP server or any of its replicated instances to security.ldap.servers. MongoDB supports following LDAP referrals as defined in RFC 4511 4.1.10. Do not use security.ldap.servers for listing every LDAP server in your infrastructure.This setting can be configured on a running mongod or mongos using setParameter.If unset, mongod or mongos cannot use LDAP authentication or authorization. security.ldap.bind.``queryUser Type: stringNew in version 3.4: Available in MongoDB Enterprise only.The identity with which mongod or mongos binds as, when connecting to or performing queries on an LDAP server.Only required if any of the following are true:Using LDAP authorization.Using an LDAP query for security.ldap.userToDNMapping.The LDAP server disallows anonymous bindsYou must use queryUser with queryPassword.If unset, mongod or mongos will not attempt to bind to the LDAP server.This setting can be configured on a running mongod or mongos using setParameter.NOTEWindows MongoDB deployments can use bindWithOSDefaults instead of queryUser and queryPassword. You cannot specify both queryUser and bindWithOSDefaults at the same time. security.ldap.bind.``queryPassword Type: stringNew in version 3.4: Available in MongoDB Enterprise only.The password used to bind to an LDAP server when using queryUser. You must use queryPassword with queryUser.If unset, mongod or mongos will not attempt to bind to the LDAP server.This setting can be configured on a running mongod or mongos using setParameter.NOTEWindows MongoDB deployments can use bindWithOSDefaults instead of queryPassword and queryPassword. You cannot specify both queryPassword and bindWithOSDefaults at the same time. security.ldap.bind.``useOSDefaults Type: booleanDefault: falseNew in version 3.4: Available in MongoDB Enterprise for the Windows platform only.Allows mongod or mongos to authenticate, or bind, using your Windows login credentials when connecting to the LDAP server.Only required if:Using LDAP authorization.Using an LDAP query for username transformation.The LDAP server disallows anonymous bindsUse useOSDefaults to replace queryUser and queryPassword. security.ldap.bind.``method Type: stringDefault: simpleNew in version 3.4: Available in MongoDB Enterprise only.The method mongod or mongos uses to authenticate to an LDAP server. Use with queryUser and queryPassword to connect to the LDAP server.method supports the following values:simple - mongod or mongos uses simple authentication.sasl - mongod or mongos uses SASL protocol for authenticationIf you specify sasl, you can configure the available SASL mechanisms using security.ldap.bind.saslMechanisms. mongod or mongos defaults to using DIGEST-MD5 mechanism. security.ldap.bind.``saslMechanisms Type: stringDefault: DIGEST-MD5New in version 3.4: Available in MongoDB Enterprise only.A comma-separated list of SASL mechanisms mongod or mongos can use when authenticating to the LDAP server. The mongod or mongos and the LDAP server must agree on at least one mechanism. The mongod or mongos dynamically loads any SASL mechanism libraries installed on the host machine at runtime.Install and configure the appropriate libraries for the selected SASL mechanism(s) on both the mongod or mongos host and the remote LDAP server host. Your operating system may include certain SASL libraries by default. Defer to the documentation associated with each SASL mechanism for guidance on installation and configuration.If using the GSSAPI SASL mechanism for use with Kerberos Authentication, verify the following for the mongod or mongos host machine:LinuxThe KRB5_CLIENT_KTNAME environment variable resolves to the name of the client Linux Keytab Files for the host machine. For more on Kerberos environment variables, please defer to the Kerberos documentation.The client keytab includes a User Principal for the mongod or mongos to use when connecting to the LDAP server and execute LDAP queries.WindowsIf connecting to an Active Directory server, the Windows Kerberos configuration automatically generates a Ticket-Granting-Ticket.aspx) when the user logs onto the system. Set useOSDefaults to true to allow mongod or mongos to use the generated credentials when connecting to the Active Directory server and execute queries.Set method to sasl to use this option.NOTEFor a complete list of SASL mechanisms see the IANA listing. Defer to the documentation for your LDAP or Active Directory service for identifying the SASL mechanisms compatible with the service.MongoDB is not a source of SASL mechanism libraries, nor is the MongoDB documentation a definitive source for installing or configuring any given SASL mechanism. For documentation and support, defer to the SASL mechanism library vendor or owner.For more information on SASL, defer to the following resources:For Linux, please see the Cyrus SASL documentation.For Windows, please see the Windows SASL documentation. security.ldap.``transportSecurity Type: stringDefault: tlsNew in version 3.4: Available in MongoDB Enterprise only.By default, mongod or mongos creates a TLS/SSL secured connection to the LDAP server.For Linux deployments, you must configure the appropriate TLS Options in /etc/openldap/ldap.conf file. Your operating system’s package manager creates this file as part of the MongoDB Enterprise installation, via the libldap dependency. See the documentation for TLS Options in the ldap.conf OpenLDAP documentation for more complete instructions.For Windows deployment, you must add the LDAP server CA certificates to the Windows certificate management tool. The exact name and functionality of the tool may vary depending on operating system version. Please see the documentation for your version of Windows for more information on certificate management.Set transportSecurity to none to disable TLS/SSL between mongod or mongos and the LDAP server.WARNINGSetting transportSecurity to none transmits plaintext information and possibly credentials between mongod or mongos and the LDAP server. security.ldap.``timeoutMS Type: intDefault: 10000New in version 3.4: Available in MongoDB Enterprise only.The amount of time in milliseconds mongod or mongos should wait for an LDAP server to respond to a request.Increasing the value of timeoutMS may prevent connection failure between the MongoDB server and the LDAP server, if the source of the failure is a connection timeout. Decreasing the value of timeoutMS reduces the time MongoDB waits for a response from the LDAP server.This setting can be configured on a running mongod or mongos using setParameter. security.ldap.``userToDNMapping Type: stringNew in version 3.4: Available in MongoDB Enterprise only.Maps the username provided to mongod or mongos for authentication to a LDAP Distinguished Name (DN). You may need to use userToDNMapping to transform a username into an LDAP DN in the following scenarios:Performing LDAP authentication with simple LDAP binding, where users authenticate to MongoDB with usernames that are not full LDAP DNs.Using an LDAP authorization query template that requires a DN.Transforming the usernames of clients authenticating to Mongo DB using different authentication mechanisms (e.g. x.509, kerberos) to a full LDAP DN for authorization.userToDNMapping expects a quote-enclosed JSON-string representing an ordered array of documents. Each document contains a regular expression match and either a substitution or ldapQuery template used for transforming the incoming username.Each document in the array has the following form:copycopied{ match: \"\" substitution: \"\" | ldapQuery: \"\" }FieldDescriptionExamplematchAn ECMAScript-formatted regular expression (regex) to match against a provided username. Each parenthesis-enclosed section represents a regex capture group used by substitution or ldapQuery.\"(.+)ENGINEERING\" \"(.+)DBA\"``substitutionAn LDAP distinguished name (DN) formatting template that converts the authentication name matched by the match regex into a LDAP DN. Each curly bracket-enclosed numeric value is replaced by the corresponding regex capture group extracted from the authentication username via the match regex.The result of the substitution must be an RFC4514 escaped string.\"cn={0},ou=engineering, dc=example,dc=com\"``ldapQueryA LDAP query formatting template that inserts the authentication name matched by the match regex into an LDAP query URI encoded respecting RFC4515 and RFC4516. Each curly bracket-enclosed numeric value is replaced by the corresponding regex capture group extracted from the authentication username via the match expression. mongod or mongos executes the query against the LDAP server to retrieve the LDAP DN for the authenticated user. mongod or mongos requires exactly one returned result for the transformation to be successful, or mongod or mongos skips this transformation.\"ou=engineering,dc=example, dc=com??one?(user={0})\"NOTEAn explanation of RFC4514, RFC4515, RFC4516, or LDAP queries is out of scope for the MongoDB Documentation. Please review the RFC directly or use your preferred LDAP resource.For each document in the array, you must use either substitution or ldapQuery. You cannot specify both in the same document.When performing authentication or authorization, mongod or mongos steps through each document in the array in the given order, checking the authentication username against the match filter. If a match is found, mongod or mongos applies the transformation and uses the output for authenticating the user. mongod or mongos does not check the remaining documents in the array.If the given document does not match the provided authentication name, mongod or mongos continues through the list of documents to find additional matches. If no matches are found in any document, or the transformation the document describes fails, mongod or mongos returns an error.Starting in MongoDB 4.4, mongod or mongos also returns an error if one of the transformations cannot be evaluated due to networking or authentication failures to the LDAP server. mongod or mongos rejects the connection request and does not check the remaining documents in the array.EXAMPLEThe following shows two transformation documents. The first document matches against any string ending in @ENGINEERING, placing anything preceeding the suffix into a regex capture group. The second document matches against any string ending in @DBA, placing anything preceeding the suffix into a regex capture group.IMPORTANTYou must pass the array to userToDNMapping as a string.copycopied\"[ { match: \"(.+)@ENGINEERING.EXAMPLE.COM\", substitution: \"cn={0},ou=engineering,dc=example,dc=com\" }, { match: \"(.+)@DBA.EXAMPLE.COM\", ldapQuery: \"ou=dba,dc=example,dc=com??one?(user={0})\" } ]\"A user with username alice@ENGINEERING.EXAMPLE.COM matches the first document. The regex capture group {0} corresponds to the string alice. The resulting output is the DN \"cn=alice,ou=engineering,dc=example,dc=com\".A user with username bob@DBA.EXAMPLE.COM matches the second document. The regex capture group {0} corresponds to the string bob. The resulting output is the LDAP query \"ou=dba,dc=example,dc=com??one?(user=bob)\". mongod or mongos executes this query against the LDAP server, returning the result \"cn=bob,ou=dba,dc=example,dc=com\".If userToDNMapping is unset, mongod or mongos applies no transformations to the username when attempting to authenticate or authorize a user against the LDAP server.This setting can be configured on a running mongod or mongos using the setParameter database command. security.ldap.authz.``queryTemplate Type: stringNew in version 3.4: Available in MongoDB Enterprise only.A relative LDAP query URL formatted conforming to RFC4515 and RFC4516 that mongod executes to obtain the LDAP groups to which the authenticated user belongs to. The query is relative to the host or hosts specified in security.ldap.servers.In the URL, you can use the following substituion tokens:Substitution TokenDescription{USER}Substitutes the authenticated username, or the transformed username if a userToDNMapping is specified.{PROVIDED_USER}Substitutes the supplied username, i.e. before either authentication or LDAP transformation.New in version 4.2.When constructing the query URL, ensure that the order of LDAP parameters respects RFC4516:copycopied[ dn [ ? [attributes] [ ? [scope] [ ? [filter] [ ? [Extensions] ] ] ] ] ]If your query includes an attribute, mongod assumes that the query retrieves a list of the DNs which this entity is a member of.If your query does not include an attribute, mongod assumes the query retrieves all entities which the user is member of.For each LDAP DN returned by the query, mongod assigns the authorized user a corresponding role on the admin database. If a role on the on the admin database exactly matches the DN, mongod grants the user the roles and privileges assigned to that role. See the db.createRole() method for more information on creating roles.EXAMPLEThis LDAP query returns any groups listed in the LDAP user object’s memberOf attribute.copycopied\"{USER}?memberOf?base\"Your LDAP configuration may not include the memberOf attribute as part of the user schema, may possess a different attribute for reporting group membership, or may not track group membership through attributes. Configure your query with respect to your own unique LDAP configuration.If unset, mongod cannot authorize users using LDAP.This setting can be configured on a running mongod using the setParameter database command.NOTEAn explanation of RFC4515, RFC4516 or LDAP queries is out of scope for the MongoDB Documentation. Please review the RFC directly or use your preferred LDAP resource. security.ldap.``validateLDAPServerConfig Type: booleanDefault: trueAvailable in MongoDB EnterpriseA flag that determines if the mongod or mongos instance checks the availability of the LDAP server(s) as part of its startup:If true, the mongod or mongos instance performs the availability check and only continues to start up if the LDAP server is available.If false, the mongod or mongos instance skips the availability check; i.e. the instance starts up even if the LDAP server is unavailable. setParameter 选项 setParameter Set MongoDB parameter or parameters described in MongoDB Server ParametersTo set parameters in the YAML configuration file, use the following format:copycopiedsetParameter: : : For example, to specify the enableLocalhostAuthBypass in the configuration file:copycopiedsetParameter: enableLocalhostAuthBypass: false LDAP参数 setParameter.``ldapUserCacheInvalidationInterval Type: intDefault: 30For use with mongod servers using LDAP Authorization.The interval (in seconds) mongod waits between external user cache flushes. After mongod flushes the external user cache, MongoDB reacquires authorization data from the LDAP server the next time an LDAP-authorized user issues an operation.Increasing the value specified increases the amount of time mongod and the LDAP server can be out of sync, but reduces the load on the LDAP server. Conversely, decreasing the value specified decreases the time mongod and the LDAP server can be out of sync while increasing the load on the LDAP server. copycopied setParameter: ldapUserCacheInvalidationInterval: storage 选项 STARTING IN VERSION 4.4 MongoDB removes the storage.indexBuildRetry option and the corresponding --noIndexBuildRetry command-line option. MongoDB deprecates storage.wiredTiger.engineConfig.maxCacheOverflowFileSizeGB option. The option has no effect starting in MongoDB 4.4. copycopied storage: dbPath: journal: enabled: commitIntervalMs: directoryPerDB: syncPeriodSecs: engine: wiredTiger: engineConfig: cacheSizeGB: journalCompressor: directoryForIndexes: maxCacheOverflowFileSizeGB: // deprecated in MongoDB 4.4 collectionConfig: blockCompressor: indexConfig: prefixCompression: inMemory: engineConfig: inMemorySizeGB: oplogMinRetentionHours: storage.``dbPath Type: stringDefault:/data/db on Linux and macOS\\data\\db on WindowsThe directory where the mongod instance stores its data.The storage.dbPath setting is available only for mongod.CONFIGURATION FILESThe default mongod.conf configuration file included with package manager installations uses the following platform-specific default values for storage.dbPath:PlatformPackage ManagerDefault storage.dbPathRHEL / CentOS and Amazonyum``/var/lib/mongoSUSEzypper``/var/lib/mongoUbuntu and Debianapt``/var/lib/mongodbmacOSbrew``/usr/local/var/mongodbThe Linux package init scripts do not expect storage.dbPath to change from the defaults. If you use the Linux packages and change storage.dbPath, you will have to use your own init scripts and disable the built-in scripts. storage.journal.``enabled Type: booleanDefault: true on 64-bit systems, false on 32-bit systemsEnable or disable the durability journal to ensure data files remain valid and recoverable. This option applies only when you specify the storage.dbPath setting. mongod enables journaling by default.The storage.journal.enabled setting is available only for mongod.Not available for mongod instances that use the in-memory storage engine.Starting in MongoDB 4.0, you cannot specify --nojournal option or storage.journal.enabled: false for replica set members that use the WiredTiger storage engine. storage.journal.``commitIntervalMs Type: numberDefault: 100The maximum amount of time in milliseconds that the mongod process allows between journal operations. Values can range from 1 to 500 milliseconds. Lower values increase the durability of the journal, at the expense of disk performance.On WiredTiger, the default journal commit interval is 100 milliseconds. Additionally, a write that includes or implies j:true will cause an immediate sync of the journal. For details or additional conditions that affect the frequency of the sync, see Journaling Process.The storage.journal.commitIntervalMs setting is available only for mongod.Not available for mongod instances that use the in-memory storage engine.NOTEKnown Issue in 4.2.0: The storage.journal.commitIntervalMs is missing in 4.2.0. storage.``directoryPerDB Type: booleanDefault: falseWhen true, MongoDB uses a separate directory to store data for each database. The directories are under the storage.dbPath directory, and each subdirectory name corresponds to the database name.The storage.directoryPerDB setting is available only for mongod.Not available for mongod instances that use the in-memory storage engine.To change the storage.directoryPerDB option for existing deployments:For standalone instances:Use mongodump on the existing mongod instance to generate a backup.Stop the mongod instance.Add the storage.directoryPerDB value and configure a new data directoryRestart the mongod instance.Use mongorestore to populate the new data directory.For replica sets:Stop a secondary member.Add the storage.directoryPerDB value and configure a new data directory to that secondary member.Restart that secondary.Use initial sync to populate the new data directory.Update remaining secondaries in the same fashion.Step down the primary, and update the stepped-down member in the same fashion. storage.``syncPeriodSecs Type: numberDefault: 60The amount of time that can pass before MongoDB flushes data to the data files via an fsync operation.Do not set this value on production systems. In almost every situation, you should use the default setting.WARNINGIf you set storage.syncPeriodSecs to 0, MongoDB will not sync the memory mapped files to disk.The mongod process writes data very quickly to the journal and lazily to the data files. storage.syncPeriodSecs has no effect on the journal files or journaling, but if storage.syncPeriodSecs is set to 0 the journal will eventually consume all available disk space. If you set storage.syncPeriodSecs to 0 for testing purposes, you should also set --nojournal to true.The serverStatus command reports the background flush thread’s status via the backgroundFlushing field.The storage.syncPeriodSecs setting is available only for mongod.Not available for mongod instances that use the in-memory storage engine. storage.``engine Default: wiredTigerNOTEStarting in version 4.2, MongoDB removes the deprecated MMAPv1 storage engine.The storage engine for the mongod database. Available values include:ValueDescriptionwiredTigerTo specify the WiredTiger Storage Engine.inMemoryTo specify the In-Memory Storage Engine.New in version 3.2: Available in MongoDB Enterprise only.If you attempt to start a mongod with a storage.dbPath that contains data files produced by a storage engine other than the one specified by storage.engine, mongod will refuse to start. storage.``oplogMinRetentionHours Type: doubleNew in version 4.4: Specifies the minimum number of hours to preserve an oplog entry, where the decimal values represent the fractions of an hour. For example, a value of 1.5 represents one hour and thirty minutes.The value must be greater than or equal to 0. A value of 0 indicates that the mongod should truncate the oplog starting with the oldest entries to maintain the configured maximum oplog size.Defaults to 0.A mongod started with oplogMinRetentionHours only removes an oplog entry if:The oplog has reached the maximum configured oplog size andThe oplog entry is older than the configured number of hours based on the host system clock.The mongod has the following behavior when configured with a minimum oplog retention period:The oplog can grow without constraint so as to retain oplog entries for the configured number of hours. This may result in reduction or exhaustion of system disk space due to a combination of high write volume and large retention period.If the oplog grows beyond its maximum size, the mongod may continue to hold that disk space even if the oplog returns to its maximum size or is configured for a smaller maximum size. See Reducing Oplog Size Does Not Immediately Return Disk Space.The mongod compares the system wall clock to an oplog entries creation wall clock time when enforcing oplog entry retention. Clock drift between cluster components may result in unexpected oplog retention behavior. See Clock Synchronization for more information on clock synchronization across cluster members.To change the minimum oplog retention period after starting the mongod, use replSetResizeOplog. replSetResizeOplog enables you to resize the oplog dynamically without restarting the mongod process. To persist the changes made using replSetResizeOplog through a restart, update the value of oplogMinRetentionHours. storage.wiredTiger 选项 copycopied storage: wiredTiger: engineConfig: cacheSizeGB: journalCompressor: directoryForIndexes: maxCacheOverflowFileSizeGB: // Deprecated in MongoDB 4.4 collectionConfig: blockCompressor: indexConfig: prefixCompression: storage.wiredTiger.engineConfig.``cacheSizeGB Type: floatDefines the maximum size of the internal cache that WiredTiger will use for all data. The memory consumed by an index build (see maxIndexBuildMemoryUsageMegabytes) is separate from the WiredTiger cache memory.Values can range from 0.25 GB to 10000 GB.Starting in MongoDB 3.4, the default WiredTiger internal cache size is the larger of either:50% of (RAM - 1 GB), or256 MB.For example, on a system with a total of 4GB of RAM the WiredTiger cache will use 1.5GB of RAM (0.5 * (4 GB - 1 GB) = 1.5 GB). Conversely, a system with a total of 1.25 GB of RAM will allocate 256 MB to the WiredTiger cache because that is more than half of the total RAM minus one gigabyte (0.5 * (1.25 GB - 1 GB) = 128 MB ).NOTEIn some instances, such as when running in a container, the database can have memory constraints that are lower than the total system memory. In such instances, this memory limit, rather than the total system memory, is used as the maximum RAM available.To see the memory limit, see hostInfo.system.memLimitMB.Avoid increasing the WiredTiger internal cache size above its default value.With WiredTiger, MongoDB utilizes both the WiredTiger internal cache and the filesystem cache.Via the filesystem cache, MongoDB automatically uses all free memory that is not used by the WiredTiger cache or by other processes.NOTEThe storage.wiredTiger.engineConfig.cacheSizeGB limits the size of the WiredTiger internal cache. The operating system will use the available free memory for filesystem cache, which allows the compressed MongoDB data files to stay in memory. In addition, the operating system will use any free RAM to buffer file system blocks and file system cache.To accommodate the additional consumers of RAM, you may have to decrease WiredTiger internal cache size.The default WiredTiger internal cache size value assumes that there is a single mongod instance per machine. If a single machine contains multiple MongoDB instances, then you should decrease the setting to accommodate the other mongod instances.If you run mongod in a container (e.g. lxc, cgroups, Docker, etc.) that does not have access to all of the RAM available in a system, you must set storage.wiredTiger.engineConfig.cacheSizeGB to a value less than the amount of RAM available in the container. The exact amount depends on the other processes running in the container. See memLimitMB. storage.wiredTiger.engineConfig.``journalCompressor Default: snappySpecifies the type of compression to use to compress WiredTiger journal data.Available compressors are:nonesnappyzlibzstd (Available starting in MongoDB 4.2) storage.wiredTiger.engineConfig.``directoryForIndexes Type: booleanDefault: falseWhen storage.wiredTiger.engineConfig.directoryForIndexes is true, mongod stores indexes and collections in separate subdirectories under the data (i.e. storage.dbPath) directory. Specifically, mongod stores the indexes in a subdirectory named index and the collection data in a subdirectory named collection.By using a symbolic link, you can specify a different location for the indexes. Specifically, when mongod instance is not running, move the index subdirectory to the destination and create a symbolic link named index under the data directory to the new destination. storage.wiredTiger.engineConfig.``maxCacheOverflowFileSizeGB Type: floatDEPRECATED IN MONGODB 4.4MongoDB deprecates the storage.wiredTiger.engineConfig.maxCacheOverflowFileSizeGB option. The option has no effect starting in MongoDB 4.4.Specifies the maximum size (in GB) for the “lookaside (or cache overflow) table” file WiredTigerLAS.wt for MongoDB 4.2.1-4.2.x and 4.0.12-4.0.x. The file no longer exists starting in version 4.4.The setting can accept the following values:ValueDescription0The default value. If set to 0, the file size is unbounded.number >= 0.1The maximum size (in GB). If the WiredTigerLAS.wt file exceeds this size, mongod exits with a fatal assertion. You can clear the WiredTigerLAS.wt file and restart mongod.To change the maximum size during runtime, use the wiredTigerMaxCacheOverflowSizeGB parameter.Available starting in MongoDB 4.2.1 (and 4.0.12) storage.wiredTiger.collectionConfig.``blockCompressor Default: snappySpecifies the default compression for collection data. You can override this on a per-collection basis when creating collections.Available compressors are:nonesnappyzlibzstd (Available starting MongoDB 4.2)storage.wiredTiger.collectionConfig.blockCompressor affects all collections created. If you change the value of storage.wiredTiger.collectionConfig.blockCompressor on an existing MongoDB deployment, all new collections will use the specified compressor. Existing collections will continue to use the compressor specified when they were created, or the default compressor at that time. storage.wiredTiger.indexConfig.``prefixCompression Default: trueEnables or disables prefix compression for index data.Specify true for storage.wiredTiger.indexConfig.prefixCompression to enable prefix compression for index data, or false to disable prefix compression for index data.The storage.wiredTiger.indexConfig.prefixCompression setting affects all indexes created. If you change the value of storage.wiredTiger.indexConfig.prefixCompression on an existing MongoDB deployment, all new indexes will use prefix compression. Existing indexes are not affected. storage.inmemory 选项 copycopied storage: inMemory: engineConfig: inMemorySizeGB: storage.inMemory.engineConfig.``inMemorySizeGB Type: floatDefault: 50% of physical RAM less 1 GBChanged in version 3.4: Values can range from 256MB to 10TB and can be a float.Maximum amount of memory to allocate for in-memory storage engine data, including indexes, oplog if the mongod is part of replica set, replica set or sharded cluster metadata, etc.By default, the in-memory storage engine uses 50% of physical RAM minus 1 GB.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only. operationProfiling 选项 copycopied operationProfiling: mode: slowOpThresholdMs: slowOpSampleRate: operationProfiling.``mode Type: stringDefault: offSpecifies which operations should be profiled. The following profiler levels are available:LevelDescriptionoffThe profiler is off and does not collect any data. This is the default profiler level.slowOpThe profiler collects data for operations that take longer than the value of slowms.allThe profiler collects data for all operations.IMPORTANTProfiling can impact performance and shares settings with the system log. Carefully consider any performance and security implications before configuring and enabling the profiler on a production deployment.See Profiler Overhead for more information on potential performance degradation. operationProfiling.``slowOpThresholdMs Type: integerDefault: 100The slow operation time threshold, in milliseconds. Operations that run for longer than this threshold are considered slow.When logLevel is set to 0, MongoDB records slow operations to the diagnostic log at a rate determined by slowOpSampleRate. Starting in MongoDB 4.2, the secondaries of replica sets log all oplog entry messages that take longer than the slow operation threshold to apply regardless of the sample rate.At higher logLevel settings, all operations appear in the diagnostic log regardless of their latency with the following exception: the logging of slow oplog entry messages by the secondaries. The secondaries log only the slow oplog entries; increasing the logLevel does not log all oplog entries.Changed in version 4.0: The slowOpThresholdMs setting is available for mongod and mongos. In earlier versions, slowOpThresholdMs is available for mongod only.For mongod instances, the setting affects both the diagnostic log and, if enabled, the profiler.For mongos instances, the setting affects the diagnostic log only and not the profiler since profiling is not available on mongos. operationProfiling.``slowOpSampleRate Type: doubleDefault: 1.0The fraction of slow operations that should be profiled or logged. operationProfiling.slowOpSampleRate accepts values between 0 and 1, inclusive.operationProfiling.slowOpSampleRate does not affect the slow oplog entry logging by the secondary members of a replica set. Secondary members log all oplog entries that take longer than the slow operation threshold regardless of the operationProfiling.slowOpSampleRate.Changed in version 4.0: The slowOpSampleRate setting is available for mongod and mongos. In earlier versions, slowOpSampleRate is available for mongod only.For mongod instances, the setting affects both the diagnostic log and, if enabled, the profiler.For mongos instances, the setting affects the diagnostic log only and not the profiler since profiling is not available on mongos. replication 选项 copycopied replication: oplogSizeMB: replSetName: enableMajorityReadConcern: replication.``oplogSizeMB Type: integerThe maximum size in megabytes for the replication operation log (i.e., the oplog).NOTEStarting in MongoDB 4.0, the oplog can grow past its configured size limit to avoid deleting the majority commit point.By default, the mongod process creates an oplog based on the maximum amount of space available. For 64-bit systems, the oplog is typically 5% of available disk space.Once the mongod has created the oplog for the first time, changing the replication.oplogSizeMB option will not affect the size of the oplog. To change the maximum oplog size after starting the mongod, use replSetResizeOplog. replSetResizeOplog enables you to resize the oplog dynamically without restarting the mongod process. To persist the changes made using replSetResizeOplog through a restart, update the value of oplogSizeMB.See Oplog Size for more information.The replication.oplogSizeMB setting is available only for mongod. replication.``replSetName Type: stringThe name of the replica set that the mongod is part of. All hosts in the replica set must have the same set name.If your application connects to more than one replica set, each set should have a distinct name. Some drivers group replica set connections by replica set name.The replication.replSetName setting is available only for mongod.Starting in MongoDB 4.0:The setting replication.replSetName cannot be used in conjunction with storage.indexBuildRetry.For the WiredTiger storage engine, storage.journal.enabled: false cannot be used in conjunction with replication.replSetName. replication.``enableMajorityReadConcern Default: trueStarting in MongoDB 3.6, MongoDB enables support for \"majority\" read concern by default.You can disable read concern \"majority\" to prevent the storage cache pressure from immobilizing a deployment with a three-member primary-secondary-arbiter (PSA) architecture. For more information about disabling read concern \"majority\", see Disable Read Concern Majority.To disable, set replication.enableMajorityReadConcern to false. replication.enableMajorityReadConcern has no effect for MongoDB versions: 4.0.0, 4.0.1, 4.0.2, 3.6.0.IMPORTANTIn general, avoid disabling \"majority\" read concern unless necessary. However, if you have a three-member replica set with a primary-secondary-arbiter (PSA) architecture or a sharded cluster with a three-member PSA shards, disable to prevent the storage cache pressure from immobilizing the deployment.Disabling \"majority\" read concern affects support for transactions on sharded clusters. Specifically:A transaction cannot use read concern \"snapshot\" if the transaction involves a shard that has disabled read concern “majority”.A transaction that writes to multiple shards errors if any of the transaction’s read or write operations involves a shard that has disabled read concern \"majority\".However, it does not affect transactions on replica sets. For transactions on replica sets, you can specify read concern \"majority\" (or \"snapshot\" or \"local\" ) for multi-document transactions even if read concern \"majority\" is disabled.Disabling \"majority\" read concern prevents collMod commands which modify an index from rolling back. If such an operation needs to be rolled back, you must resync the affected nodes with the primary node.Disabling \"majority\" read concern disables support for Change Streams for MongoDB 4.0 and earlier. For MongoDB 4.2+, disabling read concern \"majority\" has no effect on change streams availability. sharding 选项 copycopied sharding: clusterRole: archiveMovedChunks: sharding.``clusterRole Type: stringThe role that the mongod instance has in the sharded cluster. Set this setting to one of the following:ValueDescriptionconfigsvrStart this instance as a config server. The instance starts on port 27019 by default.shardsvrStart this instance as a shard. The instance starts on port 27018 by default.NOTESetting sharding.clusterRole requires the mongod instance to be running with replication. To deploy the instance as a replica set member, use the replSetName setting and specify the name of the replica set.The sharding.clusterRole setting is available only for mongod. sharding.``archiveMovedChunks Type: booleanChanged in version 3.2: Starting in 3.2, MongoDB uses false as the default.During chunk migration, a shard does not save documents migrated from the shard. auditLog 选项 NOTE Available only in MongoDB Enterprise and MongoDB Atlas. copycopied auditLog: destination: format: path: filter: auditLog.``destination Type: stringWhen set, auditLog.destination enables auditing and specifies where mongos or mongod sends all audit events.auditLog.destination can have one of the following values:ValueDescriptionsyslogOutput the audit events to syslog in JSON format. Not available on Windows. Audit messages have a syslog severity level of info and a facility level of user.The syslog message limit can result in the truncation of audit messages. The auditing system will neither detect the truncation nor error upon its occurrence.consoleOutput the audit events to stdout in JSON format.fileOutput the audit events to the file specified in auditLog.path in the format specified in auditLog.format.NOTEAvailable only in MongoDB Enterprise and MongoDB Atlas. auditLog.``format Type: stringThe format of the output file for auditing if destination is file. The auditLog.format option can have one of the following values:ValueDescriptionJSONOutput the audit events in JSON format to the file specified in auditLog.path.BSONOutput the audit events in BSON binary format to the file specified in auditLog.path.Printing audit events to a file in JSON format degrades server performance more than printing to a file in BSON format.NOTEAvailable only in MongoDB Enterprise and MongoDB Atlas. auditLog.``path Type: stringThe output file for auditing if destination has value of file. The auditLog.path option can take either a full path name or a relative path name.NOTEAvailable only in MongoDB Enterprise and MongoDB Atlas. auditLog.``filter Type: string representation of a documentThe filter to limit the types of operations the audit system records. The option takes a string representation of a query document of the form:copycopied{ : , ... }The can be any field in the audit message, including fields returned in the param document. The is a query condition expression.To specify an audit filter, enclose the filter document in single quotes to pass the document as a string.To specify the audit filter in a configuration file, you must use the YAML format of the configuration file.NOTEAvailable only in MongoDB Enterprise and MongoDB Atlas. snmp 选项 NOTE MongoDB Enterprise on macOS does not include support for SNMP due to SERVER-29352. copycopied snmp: disabled: subagent: master: snmp.``disabled Type: booleanDefault: falseDisables SNMP access to mongod. The option is incompatible with snmp.subagent and snmp.master.Set to true to disable SNMP access.The snmp.disabled setting is available only for mongod.New in version 4.0.6. snmp.``subagent Type: booleanWhen snmp.subagent is true, SNMP runs as a subagent. The option is incompatible with snmp.disabled set to true.The snmp.subagent setting is available only for mongod. snmp.``master Type: booleanWhen snmp.master is true, SNMP runs as a master. The option is incompatible with snmp.disabled set to true.The snmp.master setting is available only for mongod. SEE ALSO Monitor MongoDB With SNMP on Linux Monitor MongoDB Windows with SNMP Troubleshoot SNMP mongos-only 选项 Changed in version 3.4: MongoDB 3.4 removes sharding.chunkSize and sharding.autoSplit settings. copycopied replication: localPingThresholdMs: sharding: configDB: replication.``localPingThresholdMs Type: integerDefault: 15The ping time, in milliseconds, that mongos uses to determine which secondary replica set members to pass read operations from clients. The default value of 15 corresponds to the default value in all of the client drivers.When mongos receives a request that permits reads to secondary members, the mongos will:Find the member of the set with the lowest ping time.Construct a list of replica set members that is within a ping time of 15 milliseconds of the nearest suitable member of the set.If you specify a value for the replication.localPingThresholdMs option, mongos will construct the list of replica members that are within the latency allowed by this value.Select a member to read from at random from this list.The ping time used for a member compared by the replication.localPingThresholdMs setting is a moving average of recent ping times, calculated at most every 10 seconds. As a result, some queries may reach members above the threshold until the mongos recalculates the average.See the Read Preference for Replica Sets section of the read preference documentation for more information. sharding.``configDB Type: stringChanged in version 3.2.The configuration servers for the sharded cluster.Starting in MongoDB 3.2, config servers for sharded clusters can be deployed as a replica set. The replica set config servers must run the WiredTiger storage engine. MongoDB 3.2 deprecates the use of three mirrored mongod instances for config servers.Specify the config server replica set name and the hostname and port of at least one of the members of the config server replica set.copycopiedsharding: configDB: /cfg1.example.net:27019, cfg2.example.net:27019,...The mongos instances for the sharded cluster must specify the same config server replica set name but can specify hostname and port of different members of the replica set. Windows Service 选项 copycopied processManagement: windowsService: serviceName: displayName: description: serviceUser: servicePassword: processManagement.windowsService.``serviceName Type: stringDefault: MongoDBThe service name of mongos or mongod when running as a Windows Service. Use this name with the net start and net stop operations.You must use processManagement.windowsService.serviceName in conjunction with either the --install or --remove option. processManagement.windowsService.``displayName Type: stringDefault: MongoDBThe name listed for MongoDB on the Services administrative application. processManagement.windowsService.``description Type: stringDefault: MongoDB ServerRun mongos or mongod service description.You must use processManagement.windowsService.description in conjunction with the --install option.For descriptions that contain spaces, you must enclose the description in quotes. processManagement.windowsService.``serviceUser Type: stringThe mongos or mongod service in the context of a certain user. This user must have “Log on as a service” privileges.You must use processManagement.windowsService.serviceUser in conjunction with the --install option. processManagement.windowsService.``servicePassword Type: stringThe password for for mongos or mongod when running with the processManagement.windowsService.serviceUser option.You must use processManagement.windowsService.servicePassword in conjunction with the --install option. Removed MMAPv1 选项 Starting in version 4.2, MongoDB removes the deprecated MMAPv1 storage engine and the MMAPv1-specific configuration options: Removed Configuration File Setting Removed Command-line Option storage.mmapv1.journal.commitIntervalMs storage.mmapv1.journal.debugFlags mongod --journalOptions storage.mmapv1.nsSize mongod --nssize storage.mmapv1.preallocDataFiles mongod --noprealloc storage.mmapv1.quota.enforced mongod --quota storage.mmapv1.quota.maxFilesPerDB mongod --quotaFiles storage.mmapv1.smallFiles mongod --smallfiles storage.repairPath mongod --repairpath replication.secondaryIndexPrefetch mongod --replIndexPrefetch For earlier versions of MongoDB, refer to the corresponding version of the manual. For example: https://docs.mongodb.com/v4.0 https://docs.mongodb.com/v3.6 https://docs.mongodb.com/v3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/05-configuration-options/01-expansion-directives.html":{"url":"16-reference/05-configuration-options/01-expansion-directives.html","title":"Externally Sourced Configuration File Values","keywords":"","body":" Externally Sourced Configuration File Values ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Externally Sourced Configuration File Values Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/05-configuration-options/02-convert-command-line-options-to-yaml.html":{"url":"16-reference/05-configuration-options/02-convert-command-line-options-to-yaml.html","title":"Convert Command-Line Options to YAML","keywords":"","body":" Convert Command-Line Options to YAML Starting in MongoDB 4.2, mongod and mongos accept --outputConfig command-line option to output the configuration used by the mongod/mongos instance. You can use this option to convert command-line options to YAML configuration. Examples Convert mongod Command-Line Options to YAML Consider the following mongod invocation that uses the command-line options: mongod --shardsvr --replSet myShard --dbpath /var/lib/mongodb --bind_ip localhost,My-Example-Hostname --fork --logpath /var/log/mongodb/mongod.log --clusterAuthMode x509 --tlsMode requireTLS --tlsCAFile /path/to/my/CA/file --tlsCertificateKeyFile /path/to/my/certificate/file --tlsClusterFile /path/to/my/cluster/membership/file Include the --outputConfig command-line option to generate the corresponding YAML file. copycopied mongod --shardsvr --replSet myShard --dbpath /var/lib/mongodb --bind_ip localhost,My-Example-Hostname --fork --logpath /var/log/mongodb/mongod.log --clusterAuthMode x509 --tlsMode requireTLS --tlsCAFile /path/to/my/CA/file --tlsCertificateKeyFile /path/to/my/certificate/file --tlsClusterFile /path/to/my/cluster/membership/file --outputConfig The mongod outputs the following YAML to stdout and exits: copycopied net: bindIp: localhost,My-Example-Hostname tls: CAFile: /path/to/my/CA/file certificateKeyFile: /path/to/my/certificate/file clusterFile: /path/to/my/cluster/membership/file mode: requireTLS outputConfig: true processManagement: fork: true replication: replSet: myShard security: clusterAuthMode: x509 sharding: clusterRole: shardsvr storage: dbPath: /var/lib/mongodb systemLog: destination: file path: /var/log/mongodb/mongod.log To create a configuration file, copy the generated content into a file and delete the outputConfig setting from the YAML. Convert mongos Command-Line Options to YAML Consider the following mongos invocation that uses the command-line options: mongos --configdb myCSRS/cfg1.example.net:27019,cfg2.example.net:27019 --bind_ip localhost,My-Example-MONGOS-Hostname --fork --logpath /var/log/mongodb/mongos.log --clusterAuthMode x509 --tlsMode requireTLS --tlsCAFile /path/to/my/CA/file --tlsCertificateKeyFile /path/to/my/certificate/file --tlsClusterFile /path/to/my/cluster/membership/file Include the --outputConfig command-line option to generate the corresponding YAML for the mongos instance: copycopied mongos --configdb myCSRS/cfg1.example.net:27019,cfg2.example.net:27019 --bind_ip localhost,My-Example-MONGOS-Hostname --fork --logpath /var/log/mongodb/mongos.log --clusterAuthMode x509 --tlsMode requireTLS --tlsCAFile /path/to/my/CA/file --tlsCertificateKeyFile /path/to/my/certificate/file --tlsClusterFile /path/to/my/cluster/membership/file --outputConfig The mongos outputs the following YAML to stdout and exits: copycopied net: bindIp: localhost,My-Example-MONGOS-Hostname tls: CAFile: /path/to/my/CA/file certificateKeyFile: /path/to/my/certificate/file clusterFile: /path/to/my/cluster/membership/file mode: requireTLS outputConfig: true processManagement: fork: true security: clusterAuthMode: x509 sharding: configDB: myCSRS/cfg1.example.net:27019,cfg2.example.net:27019 systemLog: destination: file path: /var/log/mongodb/mongos.log To create a configuration file, copy the generated content into a file and delete the outputConfig setting from the YAML. 参见 原文 - Convert Command-Line Options to YAML Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/05-configuration-options/03-configuration-file-settings-command-line-options-mapping.html":{"url":"16-reference/05-configuration-options/03-configuration-file-settings-command-line-options-mapping.html","title":"Configuration File Settings and Command-Line Options Mapping","keywords":"","body":" Configuration File Settings and Command-Line Options Mapping The following table maps the configuration file settings and the related mongod and mongos command-line options. Configuration File Setting mongod and mongos Command-Line Options auditLog.destination mongod --auditDestinationmongos --auditDestination auditLog.filter mongod --auditFiltermongos --auditFilter auditLog.format mongod --auditFormatmongos --auditFormat auditLog.path mongod --auditPathmongos --auditPath cloud.monitoring.free.state mongod --enableFreeMonitoring cloud.monitoring.free.tags mongod --freeMonitoringTag net.bindIp mongod --bind_ipmongos --bind_ip net.bindIpAll mongod --bind_ip_allmongos --bind_ip_all net.compression.compressors mongod --networkMessageCompressorsmongos --networkMessageCompressors net.ipv6 mongod --ipv6mongos --ipv6 net.maxIncomingConnections mongod --maxConnsmongos --maxConns net.port mongod --portmongos --port net.serviceExecutor mongod --serviceExecutormongos --serviceExecutor net.tls.allowConnectionsWithoutCertificates mongod --tlsAllowConnectionsWithoutCertificatesmongos --tlsAllowConnectionsWithoutCertificates net.tls.allowInvalidCertificates mongod --tlsAllowInvalidCertificatesmongos --tlsAllowInvalidCertificates net.tls.allowInvalidHostnames mongod --tlsAllowInvalidHostnamesmongos --tlsAllowInvalidHostnames net.tls.CAFile mongod --tlsCAFilemongos --tlsCAFile net.tls.clusterCAFile mongod --tlsClusterCAFilemongos --tlsClusterCAFile net.tls.certificateSelector mongod --tlsCertificateSelectormongos --tlsCertificateSelector net.tls.clusterCertificateSelector mongod --tlsClusterCertificateSelectormongos --tlsClusterCertificateSelector net.tls.clusterFile mongod --tlsClusterFilemongos --tlsClusterFile net.tls.clusterPassword mongod --tlsClusterPasswordmongos --tlsClusterPassword net.tls.CRLFile mongod --tlsCRLFilemongos --tlsCRLFile net.tls.disabledProtocols mongod --tlsDisabledProtocolsmongos --tlsDisabledProtocols net.tls.FIPSMode mongod --tlsFIPSModemongos --tlsFIPSMode net.tls.mode mongod --tlsModemongos --tlsMode net.tls.certificateKeyFile mongod --tlsCertificateKeyFilemongos --tlsCertificateKeyFile net.tls.certificateKeyFilePassword mongod --tlsCertificateKeyFilePasswordmongos --tlsCertificateKeyFilePassword net.ssl.sslOnNormalPorts mongod --sslOnNormalPortsmongos --sslOnNormalPorts net.unixDomainSocket.enabled mongod --nounixsocketmongos --nounixsocket net.unixDomainSocket.filePermissions mongod --filePermissionsmongos --filePermissions net.unixDomainSocket.pathPrefix mongod --unixSocketPrefixmongos --unixSocketPrefix net.wireObjectCheck operationProfiling.mode mongod --profile operationProfiling.slowOpSampleRate mongod --slowOpSampleRatemongos --slowOpSampleRate operationProfiling.slowOpThresholdMs mongod --slowmsmongos --slowms processManagement.fork mongod --forkmongos --fork processManagement.pidFilePath mongod --pidfilepathmongos --pidfilepath processManagement.timeZoneInfo mongod --timeZoneInfomongos --timeZoneInfo processManagement.windowsService.description mongod.exe --serviceDescriptionmongos.exe --serviceDescription processManagement.windowsService.displayName mongod.exe --serviceDisplayNamemongos.exe --serviceDisplayName processManagement.windowsService.serviceName mongod.exe --serviceNamemongos.exe --serviceName processManagement.windowsService.servicePassword mongod.exe --servicePasswordmongos.exe --servicePassword processManagement.windowsService.serviceUser mongod.exe --serviceUsermongos.exe --serviceUser replication.enableMajorityReadConcern mongod --enableMajorityReadConcern replication.localPingThresholdMs mongos --localThreshold replication.oplogSizeMB mongod --oplogSize replication.replSetName mongod --replSet security.authorization mongod --authmongod --noauth security.clusterAuthMode mongod --clusterAuthModemongos --clusterAuthMode security.enableEncryption mongod --enableEncryption security.encryptionCipherMode mongod --encryptionCipherMode security.encryptionKeyFile mongod --encryptionKeyFile security.javascriptEnabled mongod --noscriptingmongos --noscripting security.keyFile mongod --keyFilemongos --keyFile security.kmip.clientCertificateFile mongod --kmipClientCertificateFile security.kmip.clientCertificatePassword mongod --kmipClientCertificatePassword security.kmip.clientCertificateSelector mongod --kmipClientCertificateSelector security.kmip.connectRetries mongod --kmipConnectRetries security.kmip.connectTimeoutMS mongod --kmipConnectTimeoutMS security.kmip.keyIdentifier mongod --kmipKeyIdentifier security.kmip.port mongod --kmipPort security.kmip.rotateMasterKey mongod --kmipRotateMasterKey security.kmip.serverCAFile mongod --kmipServerCAFile security.kmip.serverName mongod --kmipServerName security.ldap.authz.queryTemplate mongod --ldapAuthzQueryTemplate security.ldap.bind.method mongod --ldapBindMethodmongos --ldapBindMethod security.ldap.bind.queryPassword mongod --ldapQueryPasswordmongos --ldapQueryPassword security.ldap.bind.queryUser mongod --ldapQueryUsermongos --ldapQueryUser security.ldap.bind.saslMechanisms mongod --ldapBindSaslMechanismsmongos --ldapBindSaslMechanisms security.ldap.bind.useOSDefaults mongod --ldapBindWithOSDefaultsmongos --ldapBindWithOSDefaults security.ldap.servers mongod --ldapServersmongos --ldapServers security.ldap.timeoutMS mongod --ldapTimeoutMSmongos --ldapTimeoutMS security.ldap.transportSecurity mongod --ldapTransportSecuritymongos --ldapTransportSecurity security.ldap.userToDNMapping mongod --ldapUserToDNMappingmongos --ldapUserToDNMapping security.redactClientLogData mongod --redactClientLogDatamongos --redactClientLogData security.sasl.hostName mongod --setParameter saslHostName=...mongos --setParameter saslHostName=... security.sasl.saslauthdSocketPath mongod --setParameter saslauthdPath=...mongos --setParameter saslauthdPath=... security.sasl.serviceName mongod --setParameter saslServiceName=...mongos --setParameter saslServiceName=... security.transitionToAuth mongod --transitionToAuthmongos --transitionToAuth setParameter mongod --setParametermongos --setParameter sharding.archiveMovedChunks mongod --moveParanoiamongod --noMoveParanoia sharding.clusterRole mongod --shardsvrmongod --configsvr sharding.configDB mongos --configdb snmp.disabled mongod --snmp-disabled snmp.master mongod --snmp-master snmp.subagent mongod --snmp-subagent storage.dbPath mongod --dbpath storage.directoryPerDB mongod --directoryperdb storage.engine mongod --storageEngine storage.inMemory.engineConfig.inMemorySizeGB mongod --inMemorySizeGB storage.journal.commitIntervalMs mongod --journalCommitInterval storage.journal.enabled mongod --journalmongod --nojournal storage.syncPeriodSecs mongod --syncdelay storage.wiredTiger.collectionConfig.blockCompressor mongod --wiredTigerCollectionBlockCompressor storage.wiredTiger.engineConfig.cacheSizeGB mongod --wiredTigerCacheSizeGB storage.wiredTiger.engineConfig.directoryForIndexes mongod --wiredTigerDirectoryForIndexes storage.wiredTiger.engineConfig.journalCompressor mongod --wiredTigerJournalCompressor storage.wiredTiger.indexConfig.prefixCompression mongod --wiredTigerIndexPrefixCompression systemLog.component.accessControl.verbosity mongod --setParameter \"logComponentVerbosity={accessControl: ... }\"mongos --setParameter \"logComponentVerbosity={accessControl: ... }\" systemLog.component.command.verbosity mongod --setParameter \"logComponentVerbosity={command: ... }\"mongos --setParameter \"logComponentVerbosity={command: ... }\" systemLog.component.control.verbosity mongod --setParameter \"logComponentVerbosity={control: ... }\"mongos --setParameter \"logComponentVerbosity={control: ... }\" systemLog.component.ftdc.verbosity mongod --setParameter \"logComponentVerbosity={ftdc: ... }\"mongos --setParameter \"logComponentVerbosity={ftdc: ... }\" systemLog.component.geo.verbosity mongod --setParameter \"logComponentVerbosity={geo: ... }\"mongos --setParameter \"logComponentVerbosity={geo: ... }\" systemLog.component.index.verbosity mongod --setParameter \"logComponentVerbosity={index: ... }\"mongos --setParameter \"logComponentVerbosity={index: ... }\" systemLog.component.network.verbosity mongod --setParameter \"logComponentVerbosity={network: ... }\"mongos --setParameter \"logComponentVerbosity={network: ... }\" systemLog.component.query.verbosity mongod --setParameter \"logComponentVerbosity={query: ... }\"mongos --setParameter \"logComponentVerbosity={query: ... }\" systemLog.component.replication.heartbeats.verbosity mongod --setParameter \"logComponentVerbosity={replication: {heartbeats: ... }}\"mongos --setParameter \"logComponentVerbosity={replication: {heartbeats: ... }}\" systemLog.component.replication.rollback.verbosity mongod --setParameter \"logComponentVerbosity={replication: {rollback: ... }}\"mongos --setParameter \"logComponentVerbosity={replication: {rollback: ... }}\" systemLog.component.replication.verbosity mongod --setParameter \"logComponentVerbosity={replication: ... }\"mongos --setParameter \"logComponentVerbosity={replication: ... }\" systemLog.component.sharding.verbosity mongod --setParameter \"logComponentVerbosity={sharding: ... }\"mongos --setParameter \"logComponentVerbosity={sharding: ... }\" systemLog.component.storage.journal.verbosity mongod --setParameter \"logComponentVerbosity={storage: {journal: ... }}\"mongos --setParameter \"logComponentVerbosity={storage: {journal: ... }}\" systemLog.component.storage.recovery.verbosity mongod --setParameter \"logComponentVerbosity={storage: {recovery: ... }}\"mongos --setParameter \"logComponentVerbosity={storage: {recovery: ... }}\" systemLog.component.storage.verbosity mongod --setParameter \"logComponentVerbosity={storage: ... }\"mongos --setParameter \"logComponentVerbosity={storage: ... }\" systemLog.component.write.verbosity mongod --setParameter \"logComponentVerbosity={write: ... }\"mongos --setParameter \"logComponentVerbosity={write: ... }\" systemLog.destination mongod --logpathmongos --logpathmongod --syslogmongos --syslog systemLog.logAppend mongod --logappendmongos --logappend systemLog.logRotate mongod --logRotatemongos --logRotate systemLog.path mongod --logpathmongos --logpath systemLog.quiet mongod --quietmongos --quiet systemLog.syslogFacility mongod --syslogFacilitymongos --syslogFacility systemLog.timeStampFormat mongod --timeStampFormatmongos --timeStampFormat systemLog.traceAllExceptions mongod --traceExceptions systemLog.verbosity mongod --verbosemongos --verbose ChangeLog Starting in version 4.4: MongoDB removes the --noIndexBuildRetry command-line option and the corresponding storage.indexBuildRetry option. Starting in version 4.2: MongoDB removes the deprecated MMAPv1 storage engine and the MMAPv1-specific configuration options:Removed Configuration File SettingRemoved Command-line Optionstorage.mmapv1.journal.commitIntervalMs storage.mmapv1.journal.debugFlags``mongod --journalOptions``storage.mmapv1.nsSize``mongod --nssize``storage.mmapv1.preallocDataFiles``mongod --noprealloc``storage.mmapv1.quota.enforced``mongod --quota``storage.mmapv1.quota.maxFilesPerDB``mongod --quotaFiles``storage.mmapv1.smallFiles``mongod --smallfiles``storage.repairPath``mongod --repairpath``replication.secondaryIndexPrefetch``mongod --replIndexPrefetchFor earlier versions of MongoDB, refer to the corresponding version of the manual. For example:https://docs.mongodb.com/v4.0https://docs.mongodb.com/v3.6https://docs.mongodb.com/v3.4 参见 原文 - Configuration File Settings and Command-Line Options Mapping Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/05-configuration-options/Externally-Sourced-Configuration-File-Values.html":{"url":"16-reference/05-configuration-options/Externally-Sourced-Configuration-File-Values.html","title":"Externally Sourced Configuration File Values","keywords":"","body":" Externally Sourced Configuration File Values On this page Use the __rest Expansion Directive Use the __exec Expansion Directive Expansion Directives Reference Output the Configuration File with Resolved Expansion Directive Values New in version 4.2. MongoDB supports using expansion directives in configuration files to load externally sourced values. Expansion directives can load values for specific configuration file options or load the entire configuration file. Expansion directives help obscure confidential information like security certificates and passwords. copycopied storage: dbPath: \"/var/lib/mongo\" systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" net: bindIp: __exec: \"python /home/user/getIPAddresses.py\" type: \"string\" trim: \"whitespace\" digest: 85fed8997aac3f558e779625f2e51b4d142dff11184308dc6aca06cff26ee9ad digest_key: 68656c6c30303030307365637265746d796f6c64667269656e64 tls: mode: requireTLS certificateKeyFile: \"/etc/tls/mongod.pem\" certificateKeyFilePassword: __rest: \"https://myrestserver.example.net/api/config/myCertKeyFilePassword\" type: \"string\" digest: b08519162ba332985ac18204851949611ef73835ec99067b85723e10113f5c26 digest_key: 6d795365637265744b65795374756666 If the configuration file includes the __rest expansion, on Linux/macOS, the read access to the configuration file must be limited to the user running the mongod/mongos process only. If the configuration file includes the __exec expansion, on Linux/macOS, the write access to the configuration file must be limited to the user running the mongod/mongos process only. To use expansion directives, you must specify the --configExpand command-line option with the complete list of expansion directives used: copycopied mongod --config \"/path/to/config/mongod.conf\" --configExpand \"rest,exec\" If you omit the --configExpand option or if you do not specify the complete list of expansion directives used in the configuration file, the mongod/mongos returns an error and terminates. You can only specify the --configExpand option on the command line. Use the __rest Expansion Directive The __rest expansion directive loads configuration file values from a REST endpoint. __rest supports loading specific values in the configuration file or loading the entire configuration file. Specific Value Full Configuration File The following configuration file uses the __rest expansion directive to load the setting net.tls.certificateKeyFilePassword value from an external REST endpoint: copycopied storage: dbPath: \"/var/lib/mongo\" systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" net: bindIp: 192.51.100.24,127.0.0.1 tls: mode: requireTLS certificateKeyFile: \"/etc/tls/mongod.pem\" certificateKeyFilePassword: __rest: \"https://myrestserver.example.net/api/config/myCertKeyFilePassword\" type: \"string\" File Permission If the configuration file includes the __rest expansion, on Linux/macOS, the read access to the configuration file must be limited to the user running the mongod/mongos process only. Expansion Parsing To parse the __rest blocks, start the mongod/mongos with the --configExpand \"rest\" option.The mongod/mongos issues a GET request against specified URL. If successful, the mongod/mongos replaces the value of certificateKeyFilePassword with the returned value. If the URL fails to resolve or if the REST endpoint returns an invalid value, the mongod/mongos throws an error and terminates. IMPORTANT The value returned by the specified REST endpoint cannot include any additional expansion directives. The mongod/mongos does not perform additional processing on the returned data and will terminate with an error code if the returned data includes additional expansion directives. Use the __exec Expansion Directive The __exec expansion directive loads configuration file values from a shell or terminal command. __exec supports loading specific values in the configuration file or loading the entire configuration file. Specific Value Full Configuration File The following example configuration file uses the __exec expansion directive to to load the setting net.tls.certificateKeyFilePassword value from the output of a shell or terminal command: copycopied storage: dbPath: \"/var/lib/mongo\" systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" net: bindIp: 192.51.100.24,127.0.0.1 TLS: mode: requireTLS certificateKeyFile: \"/etc/tls/mongod.pem\" certificateKeyFilePassword: __exec: \"python /home/myUserName/getPEMPassword.py\" type: \"string\" File Permission If the configuration file includes the __exec expansion, on Linux/macOS, the write access to the configuration file must be limited to the user running the mongod/mongos process only. Expansion Parsing To parse the __exec blocks, start the mongod/mongos with the --configExpand \"exec\" option.The mongod/mongos attempts to execute the specified operation. If the command executes successfully, the mongod/mongos replaces the value of certificateKeyFilePassword with the returned value. If the command fails or returns an invalid value for the configuration file setting, the mongod/mongos throws an error and terminates. IMPORTANT The data returned by executing the specified __exec string cannot include any additional expansion directives. The mongod/mongos does not perform additional processing on the returned data and will terminate with an error code if the returned data includes additional expansion directives. Expansion Directives Reference __rest The __rest expansion directive loads configuration file values from a REST endpoint. __rest supports loading specific values in the configuration file or loading the entire configuration file. The mongod/mongos then starts using the externally sourced values as part of its configuration.The __rest expansion directive has the following syntax:To specify a REST endpoint for a specific configuration file setting or settings:copycopied: __rest: \"\" type: \"string\" trim: \"none|whitespace\" digest: \"\" digest_key: \"\"To specify a REST endpoint for the entire configuration file:copycopied__rest: \"\" type: \"yaml\" trim: \"none|whitespace\"If specifying the entire configuration file via REST endpoint, the expansion directive and its options must be the only values specified in the configuration file.__rest takes the following fields:FieldTypeDescription__reststringRequired The URL against which the mongod/mongos issues a GET request to retrieve the externally sourced value.For non-localhost REST endpoints (e.g. a REST endpoint hosted on a remote server), __rest requires encrypted (https://) URLs where both the host machine and the remote server support TLS 1.1 or later.If the REST endpoint specified in the URL requires authentication, encode credentials into the URL with the standard RFC 3986 User Information format.For localhost REST endpoints (e.g. a REST endpoint listening on the host machine), __rest allows unencrypted (http://) URLs.IMPORTANTThe value returned by the specified REST endpoint cannot include any additional expansion directives. The mongod/mongos does not perform additional processing on the returned data and will terminate with an error code if the returned data includes additional expansion directives.typestringOptional Controls how __rest parses the returned value from the specified URL.Possible values are:string (Default)Directs __rest to parse the returned data as a literal string. If specifying string, the entire __rest block and supporting options must be nested under the field for which you are loading externally sourced values.yamlDirects __rest to parse the returned data as a yaml formatted file. If specifying yaml, the __rest block must be the only content in the configuration file. The mongod/mongos replaces the configuration file contents with the yaml retrieved from the REST resource.trimstringOptional Specify whitespace to direct __rest to trim any leading or trailing whitespace, specifically occurrences of \" \", \"\\r\", \"\\n\", \"\\t\", \"\\v\", and \"\\f\". Defaults to none, or no trimming.digeststringOptional. The SHA-256 digest of the expansion result.If specified, you must also specify the digest_key.digest_keystringOptional. The hexadecimal string representation of the secret used to calculate the SHA-256 digest.If specified, you must also specify the digest.NOTEIf the configuration file includes the __rest expansion, on Linux/macOS, the read access to the configuration file must be limited to the user running the mongod/mongos process only.To enable parsing of the __rest expansion directive, start the mongod/mongos with the --configExpand \"rest\" option.For examples, see Use the __rest Expansion Directive. __exec The __exec expansion directive loads configuration file values from the output of a shell or terminal command. __exec supports loading specific values in the configuration file or loading the entire configuration file. The mongod/mongos then starts using the externally sourced values as part of its configuration.The __exec expansion directive has the following syntax:To specify a shell or terminal command for a specific configuration file setting or settings:copycopied: __exec: \"\" type: \"string\" trim: \"none|whitespace\"To specify a a shell or terminal command for the entire configuration file:copycopied__exec: \"\" type: \"yaml\" trim: \"none|whitespace\"If specifying the entire configuration file via a terminal or shell command, the expansion directive and its options must be the only values specified in the configuration file.__exec takes the following fields:FieldTypeDescription__execstringRequired The string which the mongod/mongos executes on the terminal or shell to retrieve the externally sourced value.On Linux and OSX hosts, execution is handled via POSIX popen(). On Windows hosts, execution is handled via the process control API. __exec opens a read-only pipe as the same user that started the mongod or mongos.IMPORTANTThe data returned by executing the specified command cannot include any additional expansion directives. The mongod/mongos does not perform additional processing on the returned data and will terminate with an error code if the returned data includes additional expansion directives.typestringOptional Controls how __exec parses the value returned by the executed command.Possible values are:string (Default )Directs __exec to parse the returned data as a literal string. If specifying string, the entire __exec block and supporting options must be nested under the field for which you are loading externally sourced values.yamlDirects __exec to parse the returned data as a yaml formatted file. If specifying yaml, the __exec block must be the only content in the configuration file. The mongod/mongos replaces the configuration file contents with the yaml retrieved from the executed command.trimstringOptional Specify whitespace to direct __exec to trim any leading or trailing whitespace, specifically occurrences of \" \", \"\\r\", \"\\n\", \"\\t\", \"\\v\", and \"\\f\". Defaults to none, or no trimming.digeststringOptional. The SHA-256 digest of the expansion result.If specified, you must also specify the digest_keydigest_keystringOptional. The hexadecimal string representation of the secret used to calculate the SHA-256 digest.If specified, you must also specify the digestNOTEIf the configuration file includes the __exec expansion, on Linux/macOS, the write access to the configuration file must be limited to the user running the mongod/mongos process only.To enable parsing of the __exec expansion directives, start the mongod/mongos with the --configExpand \"exec\" option.For examples, see Use the __exec Expansion Directive. Output the Configuration File with Resolved Expansion Directive Values You can test the final output of a configuration file that specifies one or more expansion directives by starting the mongod/mongos with the --outputConfig option. A mongod/mongos started with --outputConfig outputs the resolved YAML configuration document to stdout and halts. If any expansion directive specified in the configuration file returns additional expansion directives, the mongod/mongos throws an error and terminates. WARNING The --outputConfig option returns the resolved values for any field using an expansion directive. This includes any private or sensitive information previously obscured by using an external source for the configuration option. For example, the following configuration file mongod.conf contains a __rest expansion directive: copycopied storage: dbPath: \"/var/lib/mongo\" systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" net: port: __rest: \"https://mongoconf.example.net:8080/record/1\" type: string The string recorded at the specified URL is 20128 If the configuration file includes the __rest expansion, on Linux/macOS, the read access to the configuration file must be limited to the user running the mongod/mongos process only. Start the mongod with the --configExpand \"rest\" and --outputConfig options: copycopied mongod -f mongod.conf --configExpand rest --outputConfig The mongod outputs the following to stdout before terminating: copycopied config: mongod.conf storage: dbPath: \"/var/lib/mongo\" systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" net: port: 20128 outputConfig: true Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/06-parameters.html":{"url":"16-reference/06-parameters.html","title":"MongoDB Server Parameters","keywords":"","body":" MongoDB Server Parameters On this page Synopsis Parameters Authentication Parameters General Parameters Logging Parameters Diagnostic Parameters Logical Session Replication Parameters Sharding Parameters Storage Parameters WiredTiger Parameters Auditing Parameters Transaction Parameters Synopsis MongoDB provides a number of configuration options that you can set using: the setParameter command: copycopied db.adminCommand( { setParameter: 1, : } ) the setParameter configuration setting: copycopied setParameter: : ... the --setParameter command-line option for mongod and mongos: copycopied mongod --setParameter = mongos --setParameter = For additional configuration options, see Configuration File Options, mongod and mongos. Parameters Authentication Parameters authenticationMechanisms Changed in version 4.0: Remove support for the deprecated MONGODB-CR authentication mechanism.Available for both mongod and mongos.Specifies the list of authentication mechanisms the server accepts. Set this to one or more of the following values. If you specify multiple values, use a comma-separated list and no spaces. For descriptions of the authentication mechanisms, see Authentication.ValueDescriptionSCRAM-SHA-1RFC 5802 standard Salted Challenge Response Authentication Mechanism using the SHA-1 hash function.SCRAM-SHA-256RFC 7677 standard Salted Challenge Response Authentication Mechanism using the SHA-256 hash function.Requires featureCompatibilityVersion set to 4.0.New in version 4.0.MONGODB-X509MongoDB TLS/SSL certificate authentication.GSSAPI (Kerberos)External authentication using Kerberos. This mechanism is available only in MongoDB Enterprise.PLAIN (LDAP SASL)External authentication using LDAP. You can also use PLAIN for authenticating in-database users. PLAIN transmits passwords in plain text. This mechanism is available only in MongoDB Enterprise.You can only set authenticationMechanisms during start-up.For example, to specify both PLAIN and SCRAM-SHA-256 as the authentication mechanisms, use the following command:copycopiedmongod --setParameter authenticationMechanisms=PLAIN,SCRAM-SHA-256 --auth clusterAuthMode Available for both mongod and mongos.Set the clusterAuthMode to either sendX509 or x509. Useful during rolling upgrade to use x509 for membership authentication to minimize downtime.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients .copycopieddb.adminCommand( { setParameter: 1, clusterAuthMode: \"sendX509\" } ) enableLocalhostAuthBypass Available for both mongod and mongos.Specify 0 or false to disable localhost authentication bypass. Enabled by default.enableLocalhostAuthBypass is not available using setParameter database command. Use the setParameter option in the configuration file or the --setParameter option on the command line.See Localhost Exception for more information. KeysRotationIntervalSec New in version 3.6.**Default: 7776000 seconds (90 days)Specifies the number of seconds for which an HMAC signing key is valid before rotating to the next one. This parameter is intended primarily to facilitate authentication testing.You can only set KeysRotationIntervalSec during start-up, and cannot change this setting with the setParameter database command. ldapUserCacheInvalidationInterval For use with MongoDB deployments using LDAP Authorization. Available for mongod instances only.The interval (in seconds) that the mongod instance waits between external user cache flushes. After MongoDB flushes the external user cache, MongoDB reacquires authorization data from the LDAP server the next time an LDAP-authorized user issues an operation.Increasing the value specified increases the amount of time MongoDB and the LDAP server can be out of sync, but reduces the load on the LDAP server. Conversely, decreasing the value specified decreases the time MongoDB and the LDAP server can be out of sync while increasing the load on the LDAP server.Defaults to 30 seconds. ldapUseConnectionPool New in version 4.0.9.Specifies whether MongoDB should use connection pooling when connecting to the LDAP server for authentication/authorization.Starting in version 4.2, MongoDB uses the following default values:true on Windows.true on Linux where MongoDB Enterprise binaries are linked against libldap_r.false on Linux where MongoDB Enterprise binaries are linked against libldap.In earlier versions (versions 4.0.9+), the default value is false.You can only set ldapUseConnectionPool during start-up, and cannot change this setting with the setParameter database command. ldapConnectionPoolUseLatencyForHostPriority New in version 4.2.1 and 4.0.13**Default: trueA boolean that determines whether the LDAP connection pool (see ldapUseConnectionPool) should use latency of the LDAP servers to determine the connection order (from lowest latency to highest).You can only set ldapConnectionPoolUseLatencyForHostPriority during start-up, and cannot change this setting during runtime with the setParameter database command. ldapConnectionPoolMinimumConnectionsPerHost New in version 4.2.1 and 4.0.13**Default: 1The minimum number of connections to keep open to each LDAP server.You can only set ldapConnectionPoolMinimumConnectionsPerHost during start-up, and cannot change this setting during runtime with the setParameter database command. ldapConnectionPoolMaximumConnectionsPerHost New in version 4.2.1 and 4.0.13**Changed in version 4.4 Changed default value to 2. In previous versions, the default is unset.Default: 2The maximum number of connections to keep open to each LDAP server.You can only set ldapConnectionPoolMaximumConnectionsPerHost during start-up, and cannot change this setting during runtime with the setParameter database command. ldapConnectionPoolMaximumConnectionsInProgressPerHost New in version 4.2.1 and 4.0.13The maximum number of in-progress connect operations to each LDAP server.You can only set ldapConnectionPoolMaximumConnectionsInProgressPerHost during start-up, and cannot change this setting with the setParameter database command. ldapConnectionPoolHostRefreshIntervalMillis New in version 4.2.1 and 4.0.13**Default: 60000The number of milliseconds in-between health checks of the pooled LDAP connections.You can only set ldapConnectionPoolHostRefreshIntervalMillis during start-up, and cannot change this setting with the setParameter database command. ldapConnectionPoolIdleHostTimeoutSecs New in version 4.2.1 and 4.0.13**Default: 300The maximum number of seconds that the pooled connections to an LDAP server can remain idle before being closed.You can only set ldapConnectionPoolIdleHostTimeoutSecs during start-up, and cannot change this setting with the setParameter database command. ocspEnabled New in version 4.4: Available on Linux and macOS.Default: trueThe flag that enables or disables OCSP.You can only set ocspEnabled during startup in the configuration file or with the --setParameter option on the command line. For example, the following disables OCSP:copycopiedmongod --setParameter ocspEnabled=false ...SEE ALSOocspValidationRefreshPeriodSecstlsOCSPStaplingTimeoutSecstlsOCSPVerifyTimeoutSecs ocspValidationRefreshPeriodSecs New in version 4.4: Available on Linux.The number of seconds to wait before refreshing the stapled OCSP status response. Specify a number greater than or equal to 1.You can only set ocspValidationRefreshPeriodSecs during startup in the configuration file or with the --setParameter option on the command line. For example, the following sets the parameter to 3600 seconds:copycopiedmongod --setParameter ocspValidationRefreshPeriodSecs=3600 ...SEE ALSOocspEnabledtlsOCSPStaplingTimeoutSecstlsOCSPVerifyTimeoutSecs opensslCipherConfig New in version 3.6.**Changed in version 4.0: With the use of native TLS/SSL libraries, the parameter opensslCipherConfig is supported for Linux/BSD and no longer supported in Windows and macOS. See MongoDB 4.0 TLS/SSL.Specify the cipher string for OpenSSL when using TLS/SSL encryption. For a list of cipher strings, see https://www.openssl.org/docs/man1.0.2/apps/ciphers.htmlCIPHER-STRINGSYou can only set opensslCipherConfig during start-up, and cannot change this setting using the setParameter database command.For version 4.2 and greater, the use of TLS options is preferred over SSL options. The TLS options have the same functionality as the SSL options.copycopiedmongod --setParameter opensslCipherConfig='HIGH:!EXPORT:!aNULL@STRENGTH' --tlsMode requireTLS --tlsCertificateKeyFile Certs/server.pemFor versions 4.0 and earlier:copycopiedmongod --setParameter opensslCipherConfig='HIGH:!EXPORT:!aNULL@STRENGTH' --sslMode requireSSL --sslPEMKeyFile Certs/server.pem opensslDiffieHellmanParameters New in version 3.6.**Available on Linux onlySpecify the path to the PEM file that contains the OpenSSL Diffie-Hellman parameters. Specifying the OpenSSL Diffie-Hellman parameters enables support for Ephemeral Diffie-Hellman (DHE) cipher suites during TLS/SSL encryption.Ephemeral Diffie-Hellman (DHE) cipher suites (and Ephemeral Elliptic Curve Diffie-Hellman (ECDHE) cipher suites) provide Forward Secrecy. Forward Secrecy cipher suites create an ephemeral session key that is protected by the server’s private key but never transmitted. This ensures that even if a server’s private key is compromised, you cannot decrypt past sessions with the compromised key.NOTEStarting in MongoDB 4.2, if opensslDiffieHellmanParameters is unset but ECDHE is enabled, MongoDB enables DHE using ffdhe3072 Diffie-Hellman parameter, as defined in RFC 7919appendix-A.2. The ffdhe3072 is a strong parameter (i.e. size is greater than 1024). Strong parameters are not supported with Java 6 and 7 unless extended support has been purchased from Oracle.You can only set opensslDiffieHellmanParameters during startup, and cannot change this setting using the setParameter database command.If for performance reasons, you need to disable support for DHE cipher suites, use the opensslCipherConfig parameter:copycopiedmongod --setParameter opensslCipherConfig='HIGH:!EXPORT:!aNULL:!DHE:!kDHE@STRENGTH' ... saslauthdPath NOTEAvailable only in MongoDB Enterprise (except MongoDB Enterprise for Windows).Available for both mongod and mongos.Specify the path to the Unix Domain Socket of the saslauthd instance to use for proxy authentication. saslHostName Available for both mongod and mongos.saslHostName overrides MongoDB’s default hostname detection for the purpose of configuring SASL and Kerberos authentication.saslHostName does not affect the hostname of the mongod or mongos instance for any purpose beyond the configuration of SASL and Kerberos.You can only set saslHostName during start-up, and cannot change this setting using the setParameter database command.NOTEsaslHostName supports Kerberos authentication and is only included in MongoDB Enterprise. For more information, see the following:Linux: Configure MongoDB with Kerberos Authentication on LinuxWindows: Configure MongoDB with Kerberos Authentication on Windows saslServiceName Available for both mongod and mongos.Allows users to override the default Kerberos service name component of the Kerberos principal name, on a per-instance basis. If unspecified, the default value is mongodb.MongoDB only permits setting saslServiceName at startup. The setParameter command can not change this setting.saslServiceName is only available in MongoDB Enterprise.IMPORTANTEnsure that your driver supports alternate service names. scramIterationCount Default: 10000Available for both mongod and mongos.Changes the number of hashing iterations used for all new SCRAM-SHA-1 passwords. More iterations increase the amount of time required for clients to authenticate to MongoDB, but makes passwords less susceptible to brute-force attempts. The default value is ideal for most common use cases and requirements.If you modify this value, it does not change the iteration count for existing passwords. The scramIterationCount value must be 5000 or greater.For example, the following sets the scramIterationCount to 12000.copycopiedmongod --setParameter scramIterationCount=12000Or, if using the setParameter command within the mongo shell:copycopieddb.adminCommand( { setParameter: 1, scramIterationCount: 12000 } )SEE ALSOdb.changeUserPassword()db.createUser()db.updateUser() scramSHA256IterationCount New in version 4.0.**Default: 15000Available for both mongod and mongos.Changes the number of hashing iterations used for all new SCRAM-SHA-256 passwords. More iterations increase the amount of time required for clients to authenticate to MongoDB, but makes passwords less susceptible to brute-force attempts. The default value is ideal for most common use cases and requirements.If you modify this value, it does not change iteration count for existing passwords. The scramSHA256IterationCount value must be 5000 or greater.For example, the following sets the scramSHA256IterationCount to 20000.copycopiedmongod --setParameter scramSHA256IterationCount=20000Or, if using the setParameter command within the mongo shell:copycopieddb.adminCommand( { setParameter: 1, scramSHA256IterationCount: 20000 } )SEE ALSOdb.changeUserPassword()db.createUser()db.updateUser() sslMode Available for both mongod and mongos.Set the net.ssl.mode to either preferSSL or requireSSL. Useful during rolling upgrade to TLS/SSL to minimize downtime.For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients .copycopieddb.adminCommand( { setParameter: 1, sslMode: \"preferSSL\" } )SEE ALSOtlsMode tlsMode New in version 4.2.Available for both mongod and mongos.Set to either:preferTLS``requireTLSThe tlsMode parameter is useful during rolling upgrade to TLS/SSL to minimize downtime.copycopieddb.adminCommand( { setParameter: 1, tlsMode: \"preferTLS\" } )For more information about TLS/SSL and MongoDB, see Configure mongod and mongos for TLS/SSL and TLS/SSL Configuration for Clients .SEE ALSOsslMode tlsOCSPStaplingTimeoutSecs New in version 4.4: Available for Linux.The maximum number of seconds the mongod/mongos instance should wait to receive the OCSP status response for its certificates.Specify an integer greater than or equal to (>=) 1. If unset, tlsOCSPStaplingTimeoutSecs uses the tlsOCSPVerifyTimeoutSecs value.You can only set tlsOCSPStaplingTimeoutSecs during startup in the configuration file or with the --setParameter option on the command line. For example, the following sets the tlsOCSPStaplingTimeoutSecs to 20 seconds:copycopiedmongod --setParameter tlsOCSPStaplingTimeoutSecs=20 ...SEE ALSOocspEnabledocspValidationRefreshPeriodSecstlsOCSPVerifyTimeoutSecs tlsOCSPVerifyTimeoutSecs New in version 4.4: Available for Linux and Windows.Default: 5The maximum number of seconds that the mongod/mongos should wait for the OCSP response when verifying client certificates.Specify an integer greater than or equal to (>=) 1. Default is unlimited.You can only set tlsOCSPVerifyTimeoutSecs during startup in the configuration file or with the --setParameter option on the command line. For example, the following sets the tlsOCSPVerifyTimeoutSecs to 20 seconds:copycopiedmongod --setParameter tlsOCSPVerifyTimeoutSecs=20 ...SEE ALSOocspEnabledocspValidationRefreshPeriodSecstlsOCSPStaplingTimeoutSecs tlsWithholdClientCertificate Default: falseNew in version 4.2.Available for both mongod and mongos.A TLS certificate is set for a mongod or mongos either by the --tlsClusterFile option or by the --tlsCertificateKeyFile option when --tlsClusterFile is not set. If the TLS certificate is set, by default, the instance sends the certificate when initiating intra-cluster communications with other mongod or mongos instances in the deployment. Set tlsWithholdClientCertificate to 1 or true to direct the instance to withhold sending its TLS certificate during these communications. Use this option with --tlsAllowConnectionsWithoutCertificates (to allow inbound connections without certificates) on all members of the deployment. tlsWithholdClientCertificate is mutually exclusive with --clusterAuthMode x509. tlsX509ClusterAuthDNOverride New in version 4.2.Available for both mongod and mongos.An alternative Distinguished Name (DN) that the instance can also use to identify members of the deployment.For a MongoDB deployment that uses x.509 certificates for clusterAuthMode, deployment members identify each other using x.509 certificates ( net.tls.clusterFile, if specified, and net.tls.certificateKeyFile) during intra-cluster communications. For members of the same deployment, the DN from their certificates must have the same Organization attributes (O’s), the Organizational Unit attributes (OU’s), and the Domain Components (DC’s).If tlsX509ClusterAuthDNOverride is set for a member, the member can also use the override value when comparing the DN components (O’s, OU’s, and DC’s) of the presented certificates. That is the member checks the presented certificates against its net.tls.clusterFile/net.tls.certificateKeyFile. If the DN does not match, the member checks the presented certificate against the tlsX509ClusterAuthDNOverride value.NOTEIf set, you must set this parameter on all members of the deployment.You can use this parameter for a rolling update of certificates to new certificates that contain a new DN value. See Rolling Update of x.509 Cluster Certificates that Contain New DN.For more information about membership certificate requirements, see Member Certificate Requirements for details. tlsX509ExpirationWarningThresholdDays New in version 4.4.**Default : 30Available for both mongod and mongos.Starting in MongoDB 4.4, mongod/mongos logs a warning on connection if the presented x.509 certificate expires within 30 days of the mongod/mongos system clock. Use the tlsX509ExpirationWarningThresholdDays parameter to control the certificate expiration warning threshold:Increase the parameter value to trigger warnings farther ahead of the certificate expiration date.Decrease the parameter value to trigger warnings closer to the certificate expiration date.Set the parameter to 0 to disable the warning.This parameter has a minimum value of 0.You can only set tlsX509ExpirationWarningThresholdDays during mongod/mongos startup using either:The setParameter configuration setting, orThe mongod --setParameter / mongos --setParameter command line option.See x.509 Certificates Nearing Expiry Trigger Warnings for more information on x.509 expiration warnings in MongoDB 4.4.For more information on x.509 certificate validity, see RFC 5280 4.1.2.5. sslWithholdClientCertificate Default: falseDeprecated since version 4.2: Use tlsWithholdClientCertificate instead.Available for both mongod and mongos.A TLS certificate is set for a mongod or mongos either by the --tlsClusterFile option or by the --tlsCertificateKeyFile option when --tlsClusterFile is not set. If the TLS certificate is set, by default, the instance sends the certificate when initiating intra-cluster communications with other mongod or mongos instances in the deployment. Set sslWithholdClientCertificate to 1 or true to direct the instance to withhold sending its TLS certificate during these communications. Use this option with --tlsAllowConnectionsWithoutCertificates (to allow inbound connections without certificates) on all members of the deployment. sslWithholdClientCertificate is mutually exclusive with --clusterAuthMode x509. userCacheInvalidationIntervalSecs Default: 30Available for mongos only.On a mongos instance, specifies the interval (in seconds) at which the mongos instance checks to determine whether the in-memory cache of user objects has stale data, and if so, clears the cache. If there are no changes to user objects, mongos will not clear the cache.This parameter has a minimum value of 1 second and a maximum value of 86400 seconds (24 hours). authFailedDelayMs Default: 0Available for both mongod and mongos.New in version 3.4.ENTERPRISE FEATUREAvailable in MongoDB Enterprise only.The number of milliseconds to wait before informing clients that their authentication attempt has failed. This parameter may be in the range 0 to 5000, inclusive.Setting this parameter makes brute-force login attacks on a database more time-consuming. However, clients waiting for a response from the MongoDB server still consume server resources, and this may adversely impact benign login attempts if the server is denying access to many other clients simultaneously. allowRolesFromX509Certificates Default: trueAvailable for both mongod and mongos.Available starting in MongoDB 4.0.11 (and 3.6.14 and 3.4.22)A boolean flag that allows or disallows the retrieval of authorization roles from client x.509 certificates.You can only set allowRolesFromX509Certificates during startup in the config file or on the command line. General Parameters connPoolMaxShardedConnsPerHost Default: 200Available for both mongod and mongos.Sets the maximum size of the legacy connection pools for communication to the shards. The size of a pool does not prevent the creation of additional connections, but does prevent the connection pools from retaining connections above this limit.NOTEThe parameter is separate from the connections in TaskExecutor pools. See ShardingTaskExecutorPoolMaxSize.Increase the connPoolMaxShardedConnsPerHost value only if the number of connections in a connection pool has a high level of churn or if the total number of created connections increase.You can only set connPoolMaxShardedConnsPerHost during startup in the config file or on the command line. For example:copycopiedmongos --setParameter connPoolMaxShardedConnsPerHost=250 connPoolMaxShardedInUseConnsPerHost New in version 3.6.3.Available for both mongod and mongos.Sets the maximum number of in-use connections at any given time for the legacy sharded cluster connection pools.By default, the parameter is unset.You can only set connPoolMaxShardedConnsPerHost during startup in the config file or on the command line. For example:copycopiedmongos --setParameter connPoolMaxShardedInUseConnsPerHost=100SEE ALSOconnPoolMaxShardedConnsPerHost shardedConnPoolIdleTimeoutMinutes New in version 3.6.3.Available for both mongod and mongos.Sets the time limit that a connection in the legacy sharded cluster connection pool can remain idle before being closed.By default, the parameter is unset.You can only set shardedConnPoolIdleTimeoutMinutes during startup in the config file or on the command line. For example:copycopiedmongos --setParameter shardedConnPoolIdleTimeoutMinutes=10SEE ALSOconnPoolMaxShardedConnsPerHost connPoolMaxConnsPerHost Default: 200Available for both mongod and mongos.Sets the maximum size of the legacy connection pools for outgoing connections to other mongod instances in the global connection pool. The size of a pool does not prevent the creation of additional connections, but does prevent a connection pool from retaining connections in excess of the value of connPoolMaxConnsPerHost.NOTEThe parameter is separate from the connections in TaskExecutor pools. See ShardingTaskExecutorPoolMaxSize.Only adjust this setting if your driver does not pool connections and you’re using authentication in the context of a sharded cluster.You can only set connPoolMaxConnsPerHost during startup in the config file or on the command line. For example:copycopiedmongod --setParameter connPoolMaxConnsPerHost=250 connPoolMaxInUseConnsPerHost New in version 3.6.3.Available for both mongod and mongos.Sets the maximum number of in-use connections at any given time for for outgoing connections to other mongod instances in the legacy global connection pool.By default, the parameter is unset.You can only set connPoolMaxInUseConnsPerHost during startup in the config file or on the command line. For example:copycopiedmongod --setParameter connPoolMaxInUseConnsPerHost=100SEE ALSOconnPoolMaxConnsPerHost globalConnPoolIdleTimeoutMinutes New in version 3.6.3.Available for both mongod and mongos.Sets the time limit that connection in the legacy global connection pool can remain idle before being closed.By default, the parameter is unset.You can only set globalConnPoolIdleTimeoutMinutes during startup in the config file or on the command line. For example:copycopiedmongos --setParameter globalConnPoolIdleTimeoutMinutes=10SEE ALSOconnPoolMaxShardedConnsPerHost cursorTimeoutMillis Default: 600000 (i.e. 10 minutes)Available for both mongod and mongos.Sets the expiration threshold in milliseconds for idle cursors before MongoDB removes them; i.e. MongoDB removes cursors that have been idle for the specified cursorTimeoutMillis.For example, the following sets the cursorTimeoutMillis to 300000 milliseconds (i.e. 5 minutes).copycopiedmongod --setParameter cursorTimeoutMillis=300000Or, if using the setParameter command within the mongo shell:copycopieddb.adminCommand( { setParameter: 1, cursorTimeoutMillis: 300000 } )Setting cursorTimeoutMillis to less than or equal to 0 results in all cursors being immediately eligible for timeout. Generally, the timeout value should be greater than the average amount of time for a query to return results. Use tools like the cursor.explain() cursor modifier to analyze the average query time and select an appropriate timeout period. failIndexKeyTooLong Removed in 4.4IMPORTANTMongoDB 4.4 removes the deprecated failIndexKeyTooLong parameter. Attempting to use this parameter with MongoDB 4.4 will result in an error.MongoDB 4.2 deprecates the failIndexKeyTooLong parameter and removes the Index Key Length Limit for featureCompatibilityVersion (fCV) set to \"4.2\" or greater.For MongoDB 2.6 through MongoDB versions with featureCompatibilityVersion (fCV) set to \"4.0\" or earlier, Index Key Length Limit applies. If you attempt to insert or update a document whose index field exceeds the Index Key Length Limit, the operation will fail and return an error to the client.To avoid this issue, consider using hashed indexes or indexing a computed value. If you have an existing data set and want to disable this behavior so you can upgrade and then gradually resolve these indexing issues, you can use failIndexKeyTooLong to disable this behavior.Setting failIndexKeyTooLong to false is a temporary workaround, not a permanent solution to the problem of oversized index keys. With failIndexKeyTooLong set to false, queries can return incomplete results if they use indexes that skip over documents whose indexed fields exceed the Index Key Length Limit.failIndexKeyTooLong defaults to true.Issue the following command to disable the index key length validation:copycopieddb.adminCommand( { setParameter: 1, failIndexKeyTooLong: false } )You can also set failIndexKeyTooLong at startup time with the following option:copycopiedmongod --setParameter failIndexKeyTooLong=false notablescan Available for mongod only.Specify whether all queries must use indexes. If 1, MongoDB will not execute queries that require a collection scan and will return an error.Consider the following example which sets notablescan to 1 or true:copycopieddb.adminCommand( { setParameter: 1, notablescan: 1 } )Setting notablescan to 1 can be useful for testing application queries, for example, to identify queries that scan an entire collection and cannot use an index.To detect unindexed queries without notablescan, consider reading the Evaluate Performance of Current Operations and Optimize Query Performance sections and using the logLevel parameter, mongostat and profiling.Don’t run production mongod instances with notablescan because preventing collection scans can potentially affect queries in all databases, including administrative queries. ttlMonitorEnabled Available for mongod only.To support TTL Indexes, mongod instances have a background thread that is responsible for deleting documents from collections with TTL indexes.To disable this worker thread for a mongod, set ttlMonitorEnabled to false, as in the following operations:copycopieddb.adminCommand( { setParameter: 1, ttlMonitorEnabled: false } )Alternately, you may disable the thread at startup time by starting the mongod instance with the following option:copycopiedmongod --setParameter ttlMonitorEnabled=false tcpFastOpenServer New in version 4.4.Available for both mongod and mongos.Default: trueEnables support for accepting inbound TCP Fast Open (TFO) connections to the mongod/mongos from a client. TFO requires both the client and mongod/mongos host machine support and enable TFO:WindowsThe following Windows operating systems support TFO:Microsoft Windows Server 2016 and later.Microsoft Windows 10 Update 1607 and later.macOSmacOS 10.11 (El Capitan) and later support TFO.LinuxLinux operating systems running Linux Kernel 3.7 or later can support inbound TFO.Set the value of /proc/sys/net/ipv4/tcp_fastopen to enable inbound TFO connections:Set to 2 to enable only inbound TFO connections.Set to 3 to enable inbound and outbound TFO connections.This parameter has no effect if the host operating system does not support or is not configured to support TFO connections.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option.See Support for TCP Fast Open for more information on MongoDB TFO support.SEE ALSORFC7413. tcpFastOpenClient New in version 4.4.Available for both mongod and mongos.Default: trueLinux Operating System OnlyEnables support for outbound TCP Fast Open (TFO) connections from the mongod/mongos to a client. TFO requires both the client and the mongod/mongos host machine support and enable TFO.Linux operating systems running Linux Kernel 4.11 or later can support outbound TFO.Set the value of /proc/sys/net/ipv4/tcp_fastopen to enable outbound TFO connections:1 to enable only outbound TFO connections.3 to enable inbound and outbound TFO connections.This parameter has no effect if the host operating system does not support or is not configured to support TFO connections.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option.See Support for TCP Fast Open for more information on MongoDB TFO support.SEE ALSORFC7413. tcpFastOpenQueueSize New in version 4.4.Available for both mongod and mongos.Default: 1024As part of establishing a TCP Fast Open (TFO) connection, the client submits a valid TFO cookie to the mongod/mongos before completion of the standard TCP 3-way handshake. The mongod/mongos keeps a queue of all such pending TFO connections.The tcpFastOpenQueueSize parameter sets the size of the queue of pending TFO connections. While the queue is full, the mongod/mongos falls back to the normal three-way handshake for incoming client requests and ignores the presence of TFO cookies. Once the queue size falls back below the limit, the mongod/mongos begins accepting new TFO cookies.Increasing the default queue size may improve the effect of TFO on network performance. However, large queue sizes also increase the risk of server resource exhaustion due to excessive incoming TFO requests.Decreasing the default queue size may reduce the risk of resource server resource exhaustion due to excessive incoming TFO requests. However, small queue sizes may also reduce the effect of TFO on network performance.The minimum queue size is 0. A queue of 0 effectively disables TFO.This parameter has no effect on host operating systems that do not support or are not configured for TFO connections. See Support for TCP Fast Open for more information on MongoDB TFO support.SEE ALSORFC7413 TCP Fast Open Section 5: Security ConsiderationsRFC7413 TCP Fast Open Section 6: TFO Applicability disableJavaScriptJIT Changed in version 4.0: The JavaScript engine’s JIT compiler is now disabled by default.Available for mongod only.The MongoDB JavaScript engine uses SpiderMonkey, which implements Just-in-Time (JIT) compilation for improved performance when running scripts.To enable the JIT, set disableJavaScriptJIT to false, as in the following example:copycopieddb.adminCommand( { setParameter: 1, disableJavaScriptJIT: false } )NOTE$where will reuse existing JavaScript interpreter contexts, so changes to disableJavaScriptJIT may not take effect immediately for these operations.Alternately, you may enable the JIT at startup time by starting the mongod instance with the following option:copycopiedmongod --setParameter disableJavaScriptJIT=false maxIndexBuildMemoryUsageMegabytes New in version 3.4.**Default:200 (For versions 4.2.3 and later)500 (For versions 4.2.2 and earlier)Limits the amount of memory that simultaneous index builds on one collection may consume for the duration of the builds. The specified amount of memory is shared between all indexes built using a single createIndexes command or its shell helper db.collection.createIndexes().The memory consumed by an index build is separate from the WiredTiger cache memory (see cacheSizeGB).Index builds may be initiated either by a user command such as Create Index or by an administrative process such as an initial sync. Both are subject to the limit set by maxIndexBuildMemoryUsageMegabytes.An initial sync operation populates only one collection at a time and has no risk of exceeding the memory limit. However, it is possible for a user to start index builds on multiple collections in multiple databases simultaneously and potentially consume an amount of memory greater than the limit set in maxIndexBuildMemoryUsageMegabytes.TIPTo minimize the impact of building an index on replica sets and sharded clusters with replica set shards, use a rolling index build procedure as described on Rolling Index Builds on Replica Sets.Changed in version 4.2.For feature compatibility version (fcv) \"4.2\", the index build memory limit applies to all index builds.For feature compatibility version (fcv) \"4.0\", the index build memory limit only applies to foreground index builds. reportOpWriteConcernCountersInServerStatus New in version 4.0.6.**Default: falseA boolean flag that determines whether the db.serverStatus() method and serverStatus command return opWriteConcernCounters information. [1]You can only set reportOpWriteConcernCountersInServerStatus during startup in the config file or on the command line. For example:copycopiedmongod --setParameter reportOpWriteConcernCountersInServerStatus=true[1]Enabling reportOpWriteConcernCountersInServerStatus can have a negative performance impact; specificaly, when running without TLS. watchdogPeriodSeconds Available for mongod only.Type: integerDefault: -1 (disabled)NOTEStarting in MongoDB 4.2, the Storage Node Watchdog is available in both the Community and MongoDB Enterprise editions.In earlier versions (3.2.16+, 3.4.7+, 3.6.0+, 4.0.0+), the Storage Node Watchdog is only available in MongoDB Enterprise edition.Determines how frequent the Storage Node Watchdog checks the status of the monitored filesystems:The --dbpath directoryThe journal directory inside the --dbpath directory if journaling is enabledThe directory of --logpath fileThe directory of --auditPath fileValid values for watchdogPeriodSeconds are:-1 (the default), to disable/pause Storage Node Watchdog, orAn integer greater than or equal to 60.NOTEIf a filesystem on a monitored directory becomes unresponsive, it can take a maximum of nearly twice the value of watchdogPeriodSeconds to terminate the mongod.If any of its monitored directory is a symlink to other volumes, the Storage Node Watchdog does not monitor the symlink target. For example, if the mongod uses storage.directoryPerDB: true (or --directoryperdb) and symlinks a database directory to another volume, the Storage Node Watchdog does not follow the symlink to monitor the target.To enable Storage Node Watchdog, watchdogPeriodSeconds must be set during startup.copycopiedmongod --setParameter watchdogPeriodSeconds=60You can only enable the Storage Node Watchdog at startup. However, once enabled, you can pause the Storage Node Watchdog or change the watchdogPeriodSeconds during runtime.Once enabled,To pause the Storage Node Watchdog during runtime, set watchdogPeriodSeconds to -1.copycopieddb.adminCommand( { setParameter: 1, watchdogPeriodSeconds: -1 } )To resume or change the period during runtime, set watchdogPeriodSeconds to a number greater than or equal to 60.copycopieddb.adminCommand( { setParameter: 1, watchdogPeriodSeconds: 120 } )NOTEIt is an error to set watchdogPeriodSeconds at runtime if the Storage Node Watchdog was not enabled at startup time. tcmallocReleaseRate New in version 4.2.3: Also available in 3.6.17+ and 4.0.14+Default: 1.0Specifies the tcmalloc release rate (TCMALLOC_RELEASE_RATE). Per https://gperftools.github.io/gperftools/tcmalloc.htmlruntime TCMALLOC_RELEASE_RATE is described as:Rate at which we release unused memory to the system, via madvise(MADV_DONTNEED), on systems that support it. Zero means we never release memory back to the system. Increase this flag to return memory faster; decrease it to return memory slower. Reasonable rates are in the range [0,10].—https://gperftools.github.io/gperftools/tcmalloc.htmlruntimeTo modify the release rate during runtime, you can use the setParameter command; for example:copycopieddb.adminCommand( { setParameter: 1, tcmallocReleaseRate: 5.0 } )You can also set tcmallocReleaseRate at startup time; for example:copycopiedmongod --setParameter \"tcmallocReleaseRate=5.0\" Logging Parameters logLevel Available for both mongod and mongos.Specify an integer between 0 and 5 signifying the verbosity of the logging, where 5 is the most verbose. [2]The default logLevel is 0 (Informational).The following example sets the logLevel to 2:copycopieddb.adminCommand( { setParameter: 1, logLevel: 2 } )SEE ALSOlogComponentVerbositysystemLog.verbosity[2]Starting in version 4.2, MongoDB includes the Debug verbosity level (1-5) in the log messages. For example, if the verbosity level is 2, MongoDB logs D2. In previous versions, MongoDB log messages only specified D for Debug level. logComponentVerbosity Available for both mongod and mongos.Sets the verbosity levels of various components for log messages. The verbosity level determines the amount of Informational and Debug messages MongoDB outputs. [3]The verbosity level can range from 0 to 5:0 is the MongoDB’s default log verbosity level, to include Informational messages.1 to 5 increases the verbosity level to include Debug messages.For a component, you can also specify -1 to inherit the parent’s verbosity level.To specify the verbosity level, use a document similar to the following:copycopied{ verbosity: , : { verbosity: }, : { verbosity: , : { verbosity: } }, ... }For the components, you can specify just the : in the document, unless you are setting both the parent verbosity level and that of the child component(s) as well:copycopied{ verbosity: , : , : { verbosity: , : } ... }The top-level verbosity field corresponds to systemLog.verbosity which sets the default level for all components. The default value of systemLog.verbosity is 0.The components correspond to the following settings:accessControlcommandcontrolftdcgeoindexnetworkqueryreplicationreplication.electionreplication.heartbeatsreplication.initialSyncreplication.rollbackrecoveryshardingstoragestorage.journaltransactionwriteUnless explicitly set, the component has the verbosity level of its parent. For example, storage is the parent of storage.journal. That is, if you specify a storage verbosity level, this level also applies to:storage.journal components unless you specify the verbosity level for storage.journal.storage.recovery components unless you specify the verbosity level for storage.recovery.For example, the following sets the default verbosity level to 1, the query to 2, the storage to 2, and the storage.journal to 1.copycopieddb.adminCommand( { setParameter: 1, logComponentVerbosity: { verbosity: 1, query: { verbosity: 2 }, storage: { verbosity: 2, journal: { verbosity: 1 } } } } )You can also set parameter logComponentVerbosity at startup time, passing the verbosity level document as a string.copycopiedmongod --setParameter \"logComponentVerbosity={command: 3}\"The mongo shell also provides the db.setLogLevel() to set the log level for a single component. For various ways to set the log verbosity level, see Configure Log Verbosity Levels.[3]Starting in version 4.2, MongoDB includes the Debug verbosity level (1-5) in the log messages. For example, if the verbosity level is 2, MongoDB logs D2. In previous versions, MongoDB log messages only specified D for Debug level. maxLogSizeKB New in version 3.4.Available for both mongod and mongos.Type: non-negative integerDefault: 10Specifies the maxium size, in kilobytes, for an individual attribute field in a log entry; attributes exceeding this limit are truncated.Truncated attribute fields print field content up to the maxLogSizeKB limit and excise field content past that limit, retaining valid JSON formating. Log entires that contain truncated attributes append a truncated object to the end of the log entry.See log message truncation for more information.A value of 0 disables truncation entirely. Negative values for this parameter are not valid.WARNINGUsing a large value, or disabling truncation with a value of 0, may adversely affect system performance and negatively impact database operations.The following example sets the maximum log line size to 20 kilobytes:copycopiedmongod --setParameter maxLogSizeKB=20 quiet Available for both mongod and mongos.Sets quiet logging mode. If 1, mongod will go into a quiet logging mode which will not log the following events/activities:connection events;the drop command, the dropIndexes command, the diagLogging command, the validate command, and the clean command; andreplication synchronization activities.Consider the following example which sets the quiet to 1:copycopieddb.adminCommand( { setParameter: 1, quiet: 1 } )SEE ALSOsystemLog.quiet redactClientLogData New in version 3.4.Available for both mongod and mongos.Type: booleanENTERPRISE FEATUREAvailable in MongoDB Enterprise only.Configure the mongod or mongos to redact any message accompanying a given log event before logging. This prevents the program from writing potentially sensitive data stored on the database to the diagnostic log. Metadata such as error or operation codes, line numbers, and source file names are still visible in the logs.Use redactClientLogData in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements.To enable log redaction on a running mongod or mongos, use the following command:copycopieddb.adminCommand( { setParameter: 1, redactClientLogData : true } )SEE ALSOsecurity.redactClientLogData traceExceptions Available for both mongod and mongos.Configures mongod to log full source code stack traces for every database and socket C++ exception, for use with debugging. If true, mongod will log full stack traces.Consider the following example which sets the traceExceptions to true:copycopieddb.adminCommand( { setParameter: 1, traceExceptions: true } )SEE ALSOsystemLog.traceAllExceptions suppressNoTLSPeerCertificateWarning New in version 4.0.1.Available for both mongod and mongos.Type: booleanDefault: falseBy default, a mongod or mongos with TLS/SSL enabled and net.ssl.allowConnectionsWithoutCertificates : true lets clients connect without providing a certificate for validation while logging an warning. Set suppressNoTLSPeerCertificateWarning to 1 or true to suppress those warnings.The following operation sets suppressNoTLSPeerCertificateWarning to true:copycopieddb.adminCommand( { setParameter: 1, suppressNoTLSPeerCertificateWarning: true} ) Diagnostic Parameters To facilitate analysis of the MongoDB server behavior by MongoDB engineers, MongoDB logs server statistics to diagnostic files at periodic intervals. For mongod, the diagnostic data files are stored in the diagnostic.data directory under the mongod instance’s --dbpath or storage.dbPath. For mongos, the diagnostic data files, by default, are stored in a directory under the mongos instance’s --logpath or systemLog.path directory. The diagnostic data directory is computed by truncating the logpath’s file extension(s) and concatenating diagnostic.data to the remaining name. For example, if mongos has --logpath /var/log/mongodb/mongos.log.201708015, then the diagnostic data directory is /var/log/mongodb/mongos.diagnostic.data/ directory. To specify a different diagnostic data directory for mongos, set the diagnosticDataCollectionDirectoryPath parameter. The following parameters support diagnostic data capture (FTDC): NOTE The default values for the diagnostic data capture interval and the maximum sizes are chosen to provide useful data to MongoDB engineers with minimal impact on performance and storage size. Typically, these values will only need modifications as requested by MongoDB engineers for specific diagnostic purposes. diagnosticDataCollectionEnabled New in version 3.2.**Changed in version 3.4.14: Available for both mongod and mongos.Type: booleanDefault: trueDetermines whether to enable the collecting and logging of data for diagnostic purposes. Diagnostic logging is enabled by default.For example, the following disables the diagnostic collection:copycopiedmongod --setParameter diagnosticDataCollectionEnabled=false diagnosticDataCollectionDirectoryPath New in version 3.4.14.**Type: StringAvailable for mongos only.Specify the directory for the diagnostic directory for mongos. If the directory does not exist, mongos creates the directory.If unspecified, the diagnostic data directory is computed by truncating the mongos instance’s --logpath or systemLog.path file extension(s) and concatenating diagnostic.data.For example, if mongos has --logpath /var/log/mongodb/mongos.log.201708015, then the diagnostic data directory is /var/log/mongodb/mongos.diagnostic.data/.IMPORTANTIf mongos cannot create the specified directory, e.g. a file exists with the same name in the path or the process does not have permissions to create the directory, the diagnostic data capture will be disabled for that instance. diagnosticDataCollectionDirectorySizeMB New in version 3.2.**Changed in version 3.4: Increased default size to 200 megabytes.Changed in version 3.4.14: Available for both mongod and mongos.Type: integerDefault: 200Specifies the maximum size, in megabytes, of the diagnostic.data directory. If directory size exceeds this number, the oldest diagnostic files in the directory are automatically deleted based on the timestamp in the file name.For example, the following sets the maximum size of the directory to 250 megabytes:copycopiedmongod --setParameter diagnosticDataCollectionDirectorySizeMB=250The minimum value for diagnosticDataCollectionDirectorySizeMB is 10 megabytes. diagnosticDataCollectionDirectorySizeMB must be greater than maximum diagnostic file size diagnosticDataCollectionFileSizeMB. diagnosticDataCollectionFileSizeMB New in version 3.2.**Changed in version 3.4.14: Available for both mongod and mongos.Type: integerDefault: 10Specifies the maximum size, in megabytes, of each diagnostic file. If the file exceeds the maximum file size, MongoDB creates a new file.For example, the following sets the maximum size of each diagnostic file to 20 megabytes:copycopiedmongod --setParameter diagnosticDataCollectionFileSizeMB=20The minimum value for diagnosticDataCollectionFileSizeMB is 1 megabyte. diagnosticDataCollectionPeriodMillis New in version 3.2.**Changed in version 3.4.14: Available for both mongod and mongos.Type: integerDefault: 1000Specifies the interval, in milliseconds, at which to collect diagnostic data.For example, the following sets the interval to 5000 milliseconds or 5 seconds:copycopiedmongod --setParameter diagnosticDataCollectionPeriodMillis=5000The minimum value for diagnosticDataCollectionPeriodMillis is 100 milliseconds. Logical Session logicalSessionRefreshMillis AVAILABILITYNew in version 4.0.4 (and version 3.6.9).Available for both mongod and mongos.Type: integerDefault: 300000 (i.e. 5 minutes)The interval (in milliseconds) at which the cache refreshes its logical session records against the main session store.You can only set logicalSessionRefreshMillis at startup and cannot change this setting with the setParameter command.For example, to set the logicalSessionRefreshMillis for a mongod instance to 10 minutes:copycopiedmongod --setParameter logicalSessionRefreshMillis=600000 localLogicalSessionTimeoutMinutes New in version 3.6.Available for both mongod and mongos.Type: integerDefault: 30FOR TESTING PURPOSES ONLYThis parameter is intended for testing purposes only and not for production use.The time in minutes that a session remains active after its most recent use. Sessions that have not received a new read/write operation from the client or been refreshed with refreshSessions within this threshold are cleared from the cache. State associated with an expired session may be cleaned up by the server at any time.This parameter applies only to the instance on which it is set. To set this parameter on replica sets and sharded clusters, you must specify the same value on every member; otherwise, sessions will not function properly.You can only set localLogicalSessionTimeoutMinutes at startup and cannot change this setting with the setParameter command.For example, to set the localLogicalSessionTimeoutMinutes for a test mongod instance to 20 minutes:copycopiedmongod --setParameter localLogicalSessionTimeoutMinutes=20 maxAcceptableLogicalClockDriftSecs New in version 3.6.Available for both mongod and mongos.Type: integerDefault: 31536000 (1 year)The maximum amount by which the current cluster time can be advanced; i.e., maxAcceptableLogicalClockDriftSecs is the maximum difference between the new value of the cluster time and the current cluster time. Cluster time is a logical time used for ordering of operations.You cannot advance the cluster time to a new value if the new cluster time differs from the current cluster time by more than maxAcceptableLogicalClockDriftSecs,You can only set maxAcceptableLogicalClockDriftSecs at startup and cannot change this setting with the setParameter command.For example, to set the maxAcceptableLogicalClockDriftSecs for a mongod instance to 15 minutes:copycopiedmongod --setParameter maxAcceptableLogicalClockDriftSecs=900 maxSessions New in version 4.0.1.Available for both mongod and mongos.Type: integerDefault: 1000000The maximum number of sessions that can be cached.You can only set maxSessions during start-up.For example, to set the maxSessions for a mongod instance to 1000:copycopiedmongod --setParameter maxSessions=1000 TransactionRecordMinimumLifetimeMinutes New in version 3.6.Available for mongod only.Type: integerDefault: 30The minimum lifetime a transaction record exists in the transactions collection before the record becomes eligible for cleanup.You can only set TransactionRecordMinimumLifetimeMinutes at startup and cannot change this setting with the setParameter command.For example, to set the TransactionRecordMinimumLifetimeMinutes for a mongod instance to 20 minutes:copycopiedmongod --setParameter TransactionRecordMinimumLifetimeMinutes=20SEE ALSOlocalLogicalSessionTimeoutMinutes Replication Parameters enableFlowControl New in version 4.2.**Type: booleanDefault: trueEnables or disables the mechanism that controls the rate at which the primary applies its writes with the goal of keeping the secondary members’ majority committed lag under a configurable maximum value.NOTEFor flow control to engage, the replica set/sharded cluster must have: featureCompatibilityVersion (FCV) of 4.2 and read concern majority enabled. That is, enabled flow control has no effect if FCV is not 4.2 or if read concern majority is disabled. flowControlTargetLagSeconds New in version 4.2.**Type: integerDefault: 10The target maximum majority committed lag when running with flow control. When flow control is enabled, the mechanism attempts to keep the majority committed lag under the specified seconds. The parameter has no effect if flow control is disabled.The specified value must be greater than 0.In general, the default settings should suffice; however, if modifying from the default value, decreasing, rather than increasing, the value may prove to be more useful. flowControlWarnThresholdSeconds New in version 4.2.**Type: integerDefault: 10The amount of time to wait to log a warning once the flow control mechanism detects the majority commit point has not moved.The specified value must be greater than or equal to 0, with 0 to disable warnings. initialSyncTransientErrorRetryPeriodSeconds New in version 4.4.**Type: integerDefault: 86400The amount of time in seconds a secondary performing initial sync attempts to resume the process if interrupted by a transient network error. The default value is equivalent to 24 hours. initialSyncSourceReadPreference New in version 4.4.**Type: StringAvailable for mongod only.The preferred source for performing initial sync. Specify one of the following read preference modes:primaryprimaryPreferred (Default for voting replica set members)secondarysecondaryPreferrednearest (Default for newly added or non-voting replica set members)If the replica set has disabled chaining, the default initialSyncSourceReadPreference read preference mode is primary.You cannot specify a tag set or maxStalenessSeconds to initialSyncSourceReadPreference.If the mongod cannot find a sync source based on the specified read preference, it logs an error and restarts the initial sync process. The mongod exits with an error if it cannot complete the initial sync process after 10 attempts. For more information on sync source selection, see Initial Sync Source Selection.initialSyncSourceReadPreference takes precedence over the replica set’s settings.chainingAllowed setting when selecting an initial sync source. After a replica set member successfully completes initial sync, it defers to the value of chainingAllowed when selecting a replication sync source.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option. oplogFetcherUsesExhaust New in version 4.4.Available for mongod only.Type: booleanDefault: trueEnables or disables streaming replication. Set the value to true to enable streaming replication.Set the value to false to disable streaming replication. If disabled, secondaries fetch batches of oplog entries by issuing a request to their sync from source and waiting for a response. This requires a network roundtrip for each batch of oplog entries.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option. oplogInitialFindMaxSeconds New in version 3.6.**Type: integerDefault: 60Available for mongod only.Maximum time in seconds for a member of a replica set to wait for the find command to finish during data synchronization. replWriterThreadCount New in version 3.2.**Type: integerDefault: 16Available for mongod only.Number of threads to use to apply replicated operations in parallel. Values can range from 1 to 256 inclusive. You can only set replWriterThreadCount at startup and cannot change this setting with the setParameter command. rollbackTimeLimitSecs Type: 64-bit integerDefault: 86400 (1 day)Maximum age of data that can be rolled back. Negative values for this parameter are not valid.Starting in MongoDB 4.2+ and 4.0.13+, if the time between the end of the to-be-rolledback instance’s oplog and the first operation after the common point (the last point where the source node and the to-be-rolledback node had the same data) exceeds this value, the rollback will fail.In MongoDB 4.0.0-4.0.12, if the time between the end of the to-be-rolledback instance’s oplog and the common point (the last point where the source node and the to-be-rolledback node had the same data) exceeds this value, the rollback will fail.To effectively have an unlimited rollback period, set the value to 2147483647 which is the maximum value allowed and equivalent to roughly 68 years.New in version 4.0. waitForSecondaryBeforeNoopWriteMS New in version 3.6.Available for mongod only.Type: integerDefault: 10The length of time (in milliseconds) that a secondary must wait if the afterClusterTime is greater than the last applied time from the oplog. After the waitForSecondaryBeforeNoopWriteMS passes, if the afterClusterTime is still greater than the last applied time, the secondary makes a no-op write to advance the last applied time.The following example sets the waitForSecondaryBeforeNoopWriteMS to 20 milliseconds:copycopiedmongod --setParameter waitForSecondaryBeforeNoopWriteMS=20During runtime, you can also set the parameter with the setParameter command:copycopieddb.adminCommand( { setParameter: 1, waitForSecondaryBeforeNoopWriteMS: 20 } ) createRollbackDataFiles Available for mongod only.Type: booleanDefault: trueNew in version 4.0.Flag that determines whether MongoDB creates rollback files that contains documents affected during a rollback.By default, createRollbackDataFiles is true and MongoDB creates the rollback files.The following example sets createRollbackDataFiles to false so that the rollback files are not created:copycopiedmongod --setParameter createRollbackDataFiles=falseDuring runtime, you can also set the parameter with the setParameter command:copycopieddb.adminCommand( { setParameter: 1, createRollbackDataFiles: false } )For more information, see Collect Rollback Data. enableElectionHandoff New in version 4.0.2.**Type: booleanDefault: trueA flag that can reduce the downtime after the primary steps down from either the rs.stepDown() method or the replSetStepDown command. Specifically, if true, when a primary steps down after rs.stepDown() (or the replSetStepDown command without the force: true), it nominates an eligible secondary to call an election immediately. If false, after the step down, secondaries can wait up to settings.electionTimeoutMillis before calling an election.An eligible secondary must be caught up with the stepped down primary and have priority greater than 0. If multiple secondary members meet this criteria, the stepped down primary selects the eligible secondary with the highest priority. If the more than one eligible secondary members have the same priority, the stepped down primary selects the secondary with the lowest _id. The stepped down primary does not wait for the effects of the handoff.The parameter has no impact if the primary steps down for reasons other than rs.stepDown() (or the replSetStepDown command without the force: true). replBatchLimitBytes Default: 104857600 (100MB)Sets the maximum oplog application batch size in bytes.Values can range from 16777216 (16MB) to 104857600 (100MB) inclusive.The following example sets replBatchLimitBytes to 64 MB so that the rollback files are not created:copycopiedmongod --setParameter replBatchLimitBytes=67108864During runtime, you can also set the parameter with the setParameter command:copycopieddb.adminCommand( { setParameter: 1, replBatchLimitBytes: 64 * 1024 * 1024 } )New in version 4.0.10. mirrorReads Available for mongod only.New in version 4.4**Type: DocumentDefault: { samplingRate: 0.01, maxTimeMS: 1000 }Specifies the settings for mirrored reads for the mongod instance. The settings only take effect when the member is a primary.The parameter mirrorReads takes a JSON document with the following fields:FieldDescriptionsamplingRateThe sampling rate used to mirror a subset of operations that support mirroring to a subset of electable (i.e. priority greater than 0) secondaries. That is, the primary mirrors reads to each electable secondary at the specified sampling rate.Valid values are:0.0Turns off mirroring.1.0The primary mirrors all operations that supports mirroring to each electable secondary.Number between 0.0 and 1.0 (exclusive)The primary randomly samples each electable secondary at the specified rate to be sent mirrored reads.For example, given a replica set with a primary and two electable secondaries and a sampling rate of 0.10, the primary mirrors reads to each electable secondary at the sampling rate of 10 percent such that one read may be mirrored to one secondary and not to the other or to both or to neither. That is, if the primary receives 100 operations that can be mirrored, the sampling rate of 0.10 may result in 8 reads being mirrored to one secondary and 13 reads to the other or 10 to each, etc.The default value is 0.01.maxTimeMSThe maximum time in milliseconds for the mirrored reads. The default value is 1000.The maxTimeMS for the mirrored reads is separate from the maxTimeMS of the original read being mirrored.You can set mirrorReads during startup in the configuration file or with the --setParameter option on the command line. If specifying from the configuration file or on the command line, enclose the mirrorReads document in quotes.For example, the following sets the mirror reads sampling rate to 0.10 from the command line:copycopiedmongod --setParameter mirrorReads='{ samplingRate: 0.10 }'Or, to specify in a configuration file:copycopiedsetParameter: mirrorReads: '{samplingRate: 0.10}'Or if using the setParameter command in a mongo shell connected to a running mongod, do not enclose the document in quotes:copycopieddb.adminCommand( { setParameter: 1, mirrorReads: { samplingRate: 0.10 } } ) Sharding Parameters NOTE Starting in version 4.2, MongoDB removes the parameter AsyncRequestsSenderUseBaton and always enables the performance enhancement controlled by the parameter. disableResumableRangeDeleter New in version 4.4.**Type: booleanDefault: falseAvailable for mongod only.If set on a shard’s primary, specifies if range deletion is paused on the shard. If set to true, cleanup of chunkranges containing :term:orphaned documents is paused. The shard can continue to donate chunks to other shards, but the donated documents will not be removed from this shard until you set this parameter to false. This shard can continue to receive chunks from other shards as long as it does not have a pending range deletion task in the config.rangeDeletions collection that overlaps with the incoming chunk’s range.When disableResumableRangeDeleter is true, chunk migrations fail if orphaned documents exist on the recipient shard’s primary in the same range as the incoming chunks.The parameter has no effect on the mongod if it is not the shard’s primary.IMPORTANTIf you set disableResumableRangeDeleter parameter to true, ensure that you apply it consistently for all members in the shard’s replica set. In the event of a failover, this setting’s value on the new primary dictates the behavior of the range deleter.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongod --setParameter disableResumableRangeDeleter=false enableShardedIndexConsistencyCheck New in version 4.4 (and 4.2.6).**Type: booleanDefault: trueAvailable for mongod only.If set on the config server’s primary, enables or disables the index consistency check for sharded collections. The parameter has no effect on the mongod if it is not the config server’s primary.The following example sets enableShardedIndexConsistencyCheck to false for a config server primary:copycopiedmongod --setParameter enableShardedIndexConsistencyCheck=falseDuring runtime, you can also set the parameter with the setParameter command:copycopieddb.adminCommand( { setParameter: 1, enableShardedIndexConsistencyCheck: false } )SEE ALSOshardedIndexConsistencyCheckIntervalMS parametershardedIndexConsistency metrics returned by the serverStatus command. shardedIndexConsistencyCheckIntervalMS New in version 4.4 (and 4.2.6).**Type: integerDefault: 600000Available for mongod only.If set on the config server’s primary, the interval, in milliseconds, at which the config server’s primary checks the index consistency of sharded collections. The parameter has no effect on the mongod if it is not the config server’s primary.You can only set the parameter during startup, and cannot change this setting using the setParameter database command.For example, the following sets the interval at 300000 milliseconds (i.e. 5 minutes) at startup:copycopiedmongod --setParameter shardedIndexConsistencyCheckIntervalMS=300000SEE ALSOenableShardedIndexConsistencyCheck parametershardedIndexConsistency metrics returned by the serverStatus commandq enableFinerGrainedCatalogCacheRefresh New in version 4.4.**Type: booleanDefault: trueAvailable for both mongod and mongos.This parameter allows the catalog cache to be refreshed only if the shard needs to be refreshed. If disabled, any stale chunk will cause the entire chunk distribution for a collection to be considered stale and force all routers who contact the shard to refresh their shard catalog cache.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongod --setParameter enableFinerGrainedCatalogCacheRefresh=true mongos --setParameter enableFinerGrainedCatalogCacheRefresh=trueSEE ALSOShardingshardingStatistics.catalogCache maxTimeMSForHedgedReads New in version 4.4.**Type: integerDefault: 150Available for mongos only.Specifies the maximimum time limit (in milliseconds) for the hedged read. That is, the additional read sent to hedge the read operation uses the maxTimeMS value of maxTimeMSForHedgedReads while the read operation that is being hedged uses the maxTimeMS value specified for the operation.For example, to set the limit to 200 milliseconds, you can issue the following during startup:copycopiedmongos --setParameter maxTimeMSForHedgedReads=200Or if using the setParameter command in a mongo shell connected to a running mongos:copycopieddb.adminCommand( { setParameter: 1, maxTimeMSForHedgedReads: 200 } )SEE ALSOreadHedgingModeHedged Reads readHedgingMode New in version 4.4.**Type: stringDefault: onAvailable for mongos only.Specifies whether mongos supports hedged reads for those read operations whose read preference have enabled the hedged read option.Available values are:ValueDescriptiononThe mongos instance supports hedged reads for read operations whose read preference have enabled the hedged read option.offThe mongos instance does not support hedged reads. That is, hedged reads are unavailable, even for read operations whose read preference have enabled the hedged read option.For example, to turn off hedged read support for a mongos instance, you can issue the following during startup:copycopiedmongos --setParameter readHedgingMode=offOr if using the setParameter command in a mongo shell connected to a running mongos:copycopieddb.adminCommand( { setParameter: 1, readHedgingMode: \"off\" } )SEE ALSOHedged ReadsmaxTimeMSForHedgedReads replMonitorMaxFailedChecks Available in MongoDB 3.2 onlyType: integerDefault: 30The number of times the mongod or mongos instance tries to reach the replica sets in the sharded cluster (e.g. shard replica sets, config server replica set) to monitor the replica set status and topology.When the number of consecutive unsuccessful attempts exceeds this parameter value, the mongod or mongos instance denotes the monitored replica set as unavailable. If the monitored replica set is the config server replica set:For MongoDB 3.2.0-3.2.9, the monitoring mongod or mongos instance will become unusable and needs to be restarted. See the v3.2 troubleshooting guide for more details.For MongoDB 3.2.10 and later 3.2-series, see also timeOutMonitoringReplicaSets. timeOutMonitoringReplicaSets Available in MongoDB 3.2.10 and later 3.2-series onlyType: integerDefault: falseThe flag that determines whether the mongod or mongos instance should stop its attempt to reach the monitored replica set after unsuccessfully trying replMonitorMaxFailedChecks number of times.If the monitored replica set is the config server replica set and timeOutMonitoringReplicaSets is set to true, you must restart mongod or mongos if the mongod or mongos instance cannot reach any of the config servers for the specified number of times. See the v3.2 troubleshooting guide for more details. ShardingTaskExecutorPoolHostTimeoutMS Type: integerDefault: 300000 (i.e. 5 minutes)Available for mongos only.Maximum time that mongos goes without communication to a host before mongos drops all connections to the host.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.If set, ShardingTaskExecutorPoolHostTimeoutMS should be greater than the sum of ShardingTaskExecutorPoolRefreshRequirementMS and ShardingTaskExecutorPoolRefreshTimeoutMS. Otherwise, mongos adjusts the value of ShardingTaskExecutorPoolHostTimeoutMS to be greater than the sum.copycopiedmongos --setParameter ShardingTaskExecutorPoolHostTimeoutMS=120000 ShardingTaskExecutorPoolMaxConnecting New in version 3.6.Type: integerDefault: 2Available for mongos only.Maximum number of simultaneous initiating connections (including pending connections in setup/refresh state) each TaskExecutor connection pool can have to a mongod instance. You can set this parameter to control the rate at which mongos adds connections to a mongod instance.If set, ShardingTaskExecutorPoolMaxConnecting should be less than or equal to ShardingTaskExecutorPoolMaxSize. If it is greater, mongos ignores the ShardingTaskExecutorPoolMaxConnecting value.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongos --setParameter ShardingTaskExecutorPoolMaxConnecting=20 ShardingTaskExecutorPoolMaxSize Type: integerDefault: 264 - 1Available for mongos only.Maximum number of outbound connections each TaskExecutor connection pool can open to any given mongod instance. The maximum possible connections to any given host across all TaskExecutor pools is:copycopiedShardingTaskExecutorPoolMaxSize * taskExecutorPoolSizeYou can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongos --setParameter ShardingTaskExecutorPoolMaxSize=4mongos can have up to n TaskExecutor connection pools, where n is the number of cores. See taskExecutorPoolSize.SEE ALSOShardingTaskExecutorPoolMinSize ShardingTaskExecutorPoolMinSize Type: integerDefault: 1Available for both mongod and mongos.Minimum number of outbound connections each TaskExecutor connection pool can open to any given mongod instance.ShardingTaskExecutorPoolMinSize connections are created the first time a connection to a new host is requested from the pool. While the pool is idle, the pool maintains this number of connections until ShardingTaskExecutorPoolHostTimeoutMS milliseconds pass without any application using that pool.For a mongos using the warmMinConnectionsInShardingTaskExecutorPoolOnStartup parameter, the ShardingTaskExecutorPoolMinSize parameter also controls how many connections to each shard host are established on startup of the mongos instance before it begins accepting incoming client connections.NOTEIn MongoDB 4.4, the warmMinConnectionsInShardingTaskExecutorPoolOnStartup parameter is enabled by default for the mongos.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongos --setParameter ShardingTaskExecutorPoolMinSize=2mongos can have up to n TaskExecutor connection pools, where n is the number of cores. See taskExecutorPoolSize.SEE ALSOShardingTaskExecutorPoolMaxSizewarmMinConnectionsInShardingTaskExecutorPoolOnStartup ShardingTaskExecutorPoolRefreshRequirementMS Type: integerDefault: 60000 (1 minute)Available for mongos only.Maximum time the mongos waits before attempting to heartbeat a resting connection in the pool.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.If set, ShardingTaskExecutorPoolRefreshRequirementMS should be greater than ShardingTaskExecutorPoolRefreshTimeoutMS. Otherwise, mongos adjusts the value of ShardingTaskExecutorPoolRefreshTimeoutMS to be less than ShardingTaskExecutorPoolRefreshRequirementMS.copycopiedmongos --setParameter ShardingTaskExecutorPoolRefreshRequirementMS=90000 ShardingTaskExecutorPoolRefreshTimeoutMS Type: integerDefault: 20000 (20 seconds)Available for mongos only.Maximum time the mongos waits for a heartbeat before timing out the heartbeat.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.If set, ShardingTaskExecutorPoolRefreshTimeoutMS should be less than ShardingTaskExecutorPoolRefreshRequirementMS. Otherwise, mongos adjusts the value of ShardingTaskExecutorPoolRefreshTimeoutMS to be less than ShardingTaskExecutorPoolRefreshRequirementMS.copycopiedmongos --setParameter ShardingTaskExecutorPoolRefreshTimeoutMS=30000 ShardingTaskExecutorPoolReplicaSetMatching New in version 4.2.Type: stringDefault: “matchPrimaryNode”Available for mongos only.The policy that determines the minimum size limit of the mongos instance’s connection pools to the sharded cluster’s replica set secondaries.Available values are:Matching PolicyDescription\"matchPrimaryNode\" (Default)For each replica set in the sharded cluster (i.e. shard replica set and config servers), the minimum size limit of the mongos instance’s connection pool to each secondary of that replica set is equal to the size of its connection pool to the primary.In case of primary stepdown, matchPrimaryNode ensures that any secondary that becomes the primary can handle the current level of primary reads and writes.\"matchBusiestNode\"For each replica set in the sharded cluster (i.e. shard replica set and config servers), the minimum size limit of the mongos instance’s connection pool to each member of that replica set is equal to the largest among the active connections counts to the primary and each secondary members.With \"matchBusiestNode\", mongos maintains enough connections to each secondary to handle the current level of primary and secondary reads and writes. The number of connections to maintain in the pool decreases as the number of active connections decreases.\"disabled\"For each replica set in the sharded cluster (i.e. shard replica set and config servers), the minimum number of connections in the mongos instance’s connection pool to each secondary is equal to the ShardingTaskExecutorPoolMinSize.The following example sets the ShardingTaskExecutorPoolReplicaSetMatching to \"matchBusiestNode\" during startup:copycopiedmongod --setParameter ShardingTaskExecutorPoolReplicaSetMatching=\"matchBusiestNode\"During runtime, you can also set the parameter with the setParameter command:copycopieddb.adminCommand( { setParameter: 1, ShardingTaskExecutorPoolReplicaSetMatching: \"matchBusiestNode\" } ) taskExecutorPoolSize Changed in version 4.0.Type: integerDefault: 1Available for mongos only.The number of Task Executor connection pools to use for a given mongos.If the parameter value is 0 or less, the number of Task Executor connection pools is the number of cores with the following exceptions:If the number of cores is less than 4, the number of Task Executor connection pools is 4.If the number of cores is greater than 64, the number of Task Executor connection pools is 64.Starting in MongoDB 4.0, the default value of taskExecutorPoolSize is 1:In MongoDB 4.0 deployment, you can set taskExecutorPoolSize to 0 and, on Linux, set AsyncRequestsSenderUseBaton to false for the previous behavior.In MongoDB 4.2+ deployment, MongoDB removes the AsyncRequestsSenderUseBaton parameter and always enables the performance enhancement controlled by the parameter.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongos --setParameter taskExecutorPoolSize=6SEE ALSOShardingTaskExecutorPoolMaxSizeShardingTaskExecutorPoolMinSize loadRoutingTableOnStartup New in version 4.4.Type: booleanDefault: trueAvailable for mongos only.Configures a mongos instance to preload the routing table for a sharded cluster on startup. With this setting enabled, the mongos caches the cluster-wide routing table for each sharded collection as part of its startup procedure, before it begins accepting client connections.Without this setting enabled, the mongos only loads a routing table as needed for incoming client connections, and only loads the specific routing table for the namespace of a given request.A mongos instance with the loadRoutingTableOnStartup parameter enabled may experience longer startup times, but will result in faster servicing of initial client connections once started.loadRoutingTableOnStartup is enabled by default.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option. warmMinConnectionsInShardingTaskExecutorPoolOnStartup New in version 4.4.Type: booleanDefault: trueAvailable for mongos only.Configures a mongos instance to prewarm its connection pool on startup. With this parameter enabled, the mongos attempts to establish ShardingTaskExecutorPoolMinSize network connections to each shard server as part of its startup procedure, before it begins accepting client connections.A timeout for this behavior can be configured with the warmMinConnectionsInShardingTaskExecutorPoolOnStartupWaitMS parameter. If this timeout is reached, the mongos will begin accepting client connections regardless of the size of its connection pool.A mongos instance with this parameter enabled may experience longer startup times, but will result in faster servicing of initial client connections once started.warmMinConnectionsInShardingTaskExecutorPoolOnStartup is enabled by default.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option.SEE ALSOwarmMinConnectionsInShardingTaskExecutorPoolOnStartupWaitMSShardingTaskExecutorPoolMinSize warmMinConnectionsInShardingTaskExecutorPoolOnStartupWaitMS New in version 4.4.Type: integerDefault: 2000 (i.e. 2 seconds)Available for mongos only.Sets the timeout threshold in milliseconds for a mongos to wait for ShardingTaskExecutorPoolMinSize connections to be established per shard host when using the warmMinConnectionsInShardingTaskExecutorPoolOnStartup parameter. If this timeout is reached, the mongos will begin accepting client connections regardless of the size of its connection pool.You can only set this parameter on startup, using either the setParameter configuration file setting or the --setParameter command line option.SEE ALSOwarmMinConnectionsInShardingTaskExecutorPoolOnStartupShardingTaskExecutorPoolMinSize migrateCloneInsertionBatchDelayMS New in version 4.0.5: The parameter is also available starting in 3.4.18 and 3.6.10Available for mongod only.Type: Non-negative integerDefault: 0Time in milliseconds to wait between batches of insertions during cloning step of the migration process. This wait is in addition to the secondaryThrottle.The default value of 0 indicates no additional wait.The following sets the migrateCloneInsertionBatchDelayMS to 200 milliseconds:copycopiedmongod --setParameter migrateCloneInsertionBatchDelayMS=200The parameter may also be set using the setParameter command:copycopieddb.adminCommand( { setParameter: 1, migrateCloneInsertionBatchDelayMS: 200 } ) migrateCloneInsertionBatchSize New in version 4.0.5: The parameter is also available starting in 3.4.18 and 3.6.10Available for mongod only.Type: Non-negative integerDefault: 0The maximum number of documents to insert in a single batch during the cloning step of the migration process.The default value of 0 indicates no maximum number of documents per batch. However, in practice, this results in batches that contain up to 16 MB of documents.The following sets the migrateCloneInsertionBatchSize to 100 documents:copycopiedmongod --setParameter migrateCloneInsertionBatchSize=100The parameter may also be set using the setParameter command:copycopieddb.adminCommand( { setParameter: 1, migrateCloneInsertionBatchSize: 100 } ) orphanCleanupDelaySecs New in version 3.6.Default: 900 (15 minutes)Available for mongod only.Minimum delay before a migrated chunk is deleted from the source shard.Before deleting the chunk during chunk migration, MongoDB waits for orphanCleanupDelaySecs or for in-progress queries involving the chunk to complete on the shard primary, whichever is longer.However, because the shard primary has no knowledge of in-progress queries run on the shard secondaries, queries that use the chunk but are run on secondaries may see documents disappear if these queries take longer than the time to complete the shard primary queries and the orphanCleanupDelaySecs.NOTEThis behavior only affects in-progress queries that start before the chunk migration. Queries that start after the chunk migration starts will not use the migrating chunk.If a shard has storage constraints, consider reducing this value temporarily. If running queries that exceed 15 minutes on shard secondaries, consider increasing this value.The following sets the orphanCleanupDelaySecs to 20 minutes:copycopiedmongod --setParameter orphanCleanupDelaySecs=1200This may also be set using the setParameter command:copycopieddb.adminCommand( { setParameter: 1, orphanCleanupDelaySecs: 1200 } ) rangeDeleterBatchDelayMS New in version 4.0.1: The parameter is also available starting in 3.4.17 and 3.6.7.Available for mongod only.Type: Non-negative integerDefault: 20The amount of time in milliseconds to wait before the next batch of deletion during the cleanup stage of chunk migration (or the cleanupOrphaned command).In MongoDB 3.4, consider whether _secondaryThrottle is set before modifying the rangeDeleterBatchDelayMS. In MongoDB 3.4, the _secondaryThrottle replication delay occurs after each document deletion instead of after the batch deletion.In MongoDB 3.6+, the _secondaryThrottle replication delay occurs after each batch deletion.The following sets the rangeDeleterBatchDelayMS to 200 milliseconds:copycopiedmongod --setParameter rangeDeleterBatchDelayMS=200The parameter may also be set using the setParameter command:copycopieddb.adminCommand( { setParameter: 1, rangeDeleterBatchDelayMS: 200 } ) rangeDeleterBatchSize New in version 4.0.5: The parameter is also available starting in 3.4.19 and 3.6.10Available for mongod only.Type: Non-negative integerDefault: 0The maximum number of documents in each batch to delete during the cleanup stage of chunk migration (or the cleanupOrphaned command).The default value of 0 indicates that the system chooses an appropriate value, generally 128 documents.The following sets the rangeDeleterBatchSize to 100 documents:copycopiedmongod --setParameter rangeDeleterBatchSize=100The parameter may also be set using the setParameter command:copycopieddb.adminCommand( { setParameter: 1, rangeDeleterBatchSize: 100 } ) skipShardingConfigurationChecks New in version 3.6.3.Available for mongod only.Type: booleanDefault: falseWhen true, allows for starting a shard member or config server member as a standalone for maintenance operations. This parameter is mutually exclusive with the --configsvr or --shardsvr options.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongod --setParameter skipShardingConfigurationChecks=trueIMPORTANTOnce maintenance has completed, remove the skipShardingConfigurationChecks parameter when restarting the mongod.The parameter is also available for MongoDB versions:MongoDB 3.2.19+MongoDB 3.4.11+ Storage Parameters journalCommitInterval Available for mongod only.Specify an integer between 1 and 500 signifying the number of milliseconds (ms) between journal commits.Consider the following example which sets the journalCommitInterval to 200 ms:copycopieddb.adminCommand( { setParameter: 1, journalCommitInterval: 200 } )SEE ALSOstorage.journal.commitIntervalMs syncdelay Available for mongod only.Specify the interval in seconds between fsync operations where mongod flushes its working memory to disk. By default, mongod flushes memory to disk every 60 seconds. In almost every situation you should not set this value and use the default setting.Consider the following example which sets the syncdelay to 60 seconds:copycopieddb.adminCommand( { setParameter: 1, syncdelay: 60 } )SEE ALSOjournalCommitIntervalstorage.syncPeriodSecs honorSystemUmask New in version 3.6.Available for mongod only.Default: falseIf honorSystemUmask is set to true, new files created by MongoDB have permissions in accordance with the user’s umask settings. You cannot set processUmask if honorSystemUmask is set to true.If honorSystemUmask is set to false, new files created by MongoDB have permissions set to 600, which gives read and write permissions only to the owner. New directories have permissions set to 700. You can use processUmask to override the default permissions for groups and other users on all new files created by MongoDB.You can only set this parameter during start-up and cannot change this setting using the setParameter database command.copycopiedmongod --setParameter honorSystemUmask=trueNOTEhonorSystemUmask is not available on Windows systems. processUmask New in version 4.4.Available for mongod only.Overrides the default permissions used for groups and other users when honorSystemUmask is set to false. By default, when honorSystemUmask is set to false, new files created by MongoDB have permissions set to 600. Use the processUmask parameter to override this default with a custom umask value. The file owner inherits permissions from the system umask.You cannot set this parameter if honorSystemUmask is set to true. You can only set this parameter during start-up and cannot change this setting using the setParameter database command.Consider the following example, which sets the permissions for groups and other users to read/write only and retains the system umask settings for the owner:copycopiedmongod --setParameter processUmask=011NOTEprocessUmask is not available on Windows systems. WiredTiger Parameters wiredTigerMaxCacheOverflowSizeGB DEPRECATED IN MONGODB 4.4MongoDB deprecates the wiredTigerMaxCacheOverflowSizeGB parameter. The parameter has no effect starting in MongoDB 4.4.Default: 0 (No specified maximum)Available for mongod only.Specify the maximum size (in GB) for the “lookaside (or cache overflow) table” file WiredTigerLAS.wt for MongoDB 4.2.1-4.2.x and 4.0.12-4.0.x. The file no longer exists starting in version 4.4.The parameter can accept the following values:ValueDescription0The default value. If set to 0, the file size is unbounded.number >= 0.1The maximum size (in GB). If the WiredTigerLAS.wt file exceeds this size, mongod exits with a fatal assertion. You can clear the WiredTigerLAS.wt file and restart mongod.You can only set this parameter during runtime using the setParameter database command:copycopieddb.adminCommand( { setParameter: 1, wiredTigerMaxCacheOverflowSizeGB: 100 } )To set the maximum size during start up, use the storage.wiredTiger.engineConfig.maxCacheOverflowFileSizeGB instead.Available starting in MongoDB 4.2.1 (and 4.0.12) wiredTigerConcurrentReadTransactions Available for mongod only.Available for the WiredTiger storage engine only.Specify the maximum number of concurrent read transactions allowed into the WiredTiger storage engine.copycopieddb.adminCommand( { setParameter: 1, wiredTigerConcurrentReadTransactions: } )SEE ALSOwiredTiger.concurrentTransactions wiredTigerConcurrentWriteTransactions Available for mongod only.Available for the WiredTiger storage engine only.Specify the maximum number of concurrent write transactions allowed into the WiredTiger storage engine.copycopieddb.adminCommand( { setParameter: 1, wiredTigerConcurrentWriteTransactions: } )SEE ALSOwiredTiger.concurrentTransactions wiredTigerEngineRuntimeConfig Available for mongod only.Specify wiredTiger storage engine configuration options for a running mongod instance. You can only set this parameter using the setParameter command and not using the command line or configuration file option.WARNINGAvoid modifying the wiredTigerEngineRuntimeConfig unless under the direction from MongoDB engineers as this setting has major implication across both WiredTiger and MongoDB.Consider the following operation prototype:copycopieddb.adminCommand({ \"setParameter\": 1, \"wiredTigerEngineRuntimeConfig\": \"=,=\" })See the WiredTiger documentation for all available WiredTiger configuration options. Auditing Parameters auditAuthorizationSuccess Default: falseNOTEAvailable only in MongoDB Enterprise and MongoDB Atlas.Available for both mongod and mongos.Enables the auditing of authorization successes for the authCheck action.When auditAuthorizationSuccess is false, the audit system only logs the authorization failures for authCheck.To enable the audit of authorization successes, issue the following command:copycopieddb.adminCommand( { setParameter: 1, auditAuthorizationSuccess: true } )Enabling auditAuthorizationSuccess degrades performance more than logging only the authorization failures. SEE ALSO getParameter Transaction Parameters transactionLifetimeLimitSeconds New in version 4.0.Available for mongod only.Default: 60Specifies the lifetime of multi-document transactions. Transactions that exceeds this limit are considered expired and will be aborted by a periodic cleanup process. The cleanup process runs every transactionLifetimeLimitSeconds/2 seconds or at least once per every 60 seconds.The cleanup process helps relieve storage cache pressure.The minimum value for transactionLifetimeLimitSeconds is 1 second.The following sets the transactionLifetimeLimitSeconds to 30 seconds:copycopieddb.adminCommand( { setParameter: 1, transactionLifetimeLimitSeconds: 30 } )You can also set parameter transactionLifetimeLimitSeconds at startup time.copycopiedmongod --setParameter \"transactionLifetimeLimitSeconds=30\"To set the parameter for a sharded cluster, the parameter must be modified for all shard replica set members. maxTransactionLockRequestTimeoutMillis New in version 4.0.Available for mongod only.Type: integerDefault: 5The maximum amount of time in milliseconds that multi-document transactions should wait to acquire locks required by the operations in the transaction.If the transaction cannot acquire the locks after waiting maxTransactionLockRequestTimeoutMillis, the transaction aborts.By default, multi-document transactions wait 5 milliseconds. That is, if the transaction cannot acquire the locks within 5 milliseconds, the transaction aborts. If an operation provides a greater timeout in a lock request, maxTransactionLockRequestTimeoutMillis overrides the operation-specific timeout.You can set maxTransactionLockRequestTimeoutMillis to:0 such that if the transaction cannot acquire the required locks immediately, the transaction aborts.A number greater than 0 to wait the specified time to acquire the required locks. This can help obviate transaction aborts on momentary concurrent lock acquisitions, like fast-running metadata operations. However, this could possibly delay the abort of deadlocked transaction operations.-1 to use the operation specific timeout.The following sets the maxTransactionLockRequestTimeoutMillis to 20 milliseconds:copycopieddb.adminCommand( { setParameter: 1, maxTransactionLockRequestTimeoutMillis: 20 } )You can also set this parameter during start-up:copycopiedmongod --setParameter maxTransactionLockRequestTimeoutMillis=20 shouldMultiDocTxnCreateCollectionAndIndexes New in version 4.4.**Type: booleanDefault: trueA flag that enables or disables the creation of a collection or an index inside transactions. Set the parameter to:true to enable. (Default)false to disable.You can set the parameter during startup or runtime.IMPORTANTWhen setting the parameter for a sharded cluster, set the parameter on all shards.To set the parameter at startup, specify the parameter in the configuration file or with the --setParameter option on the command line. For example:copycopiedmongod --setParameter shouldMultiDocTxnCreateCollectionAndIndexes=falseTo modify during runtime, you can use the setParameter command; for example:copycopieddb.adminCommand( { setParameter: 1, shouldMultiDocTxnCreateCollectionAndIndexes: false 参见 原文 - MongoDB Server Parameters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/07-limits.html":{"url":"16-reference/07-limits.html","title":"MongoDB Limits and Thresholds","keywords":"","body":"MongoDB Limits and Thresholds On this page BSON Documents Naming Restrictions Namespaces Indexes Data Replica Sets Sharded Clusters Operations Sessions Shell This document provides a collection of hard and soft limitations of the MongoDB system. BSON Documents BSON Document Size The maximum BSON document size is 16 megabytes.The maximum document size helps ensure that a single document cannot use excessive amount of RAM or, during transmission, excessive amount of bandwidth. To store documents larger than the maximum size, MongoDB provides the GridFS API. See mongofiles and the documentation for your driver for more information about GridFS. Nested Depth for BSON Documents MongoDB supports no more than 100 levels of nesting for BSON documents. Naming Restrictions Database Name Case Sensitivity Since database names are case insensitive in MongoDB, database names cannot differ only by the case of the characters. Restrictions on Database Names for Windows For MongoDB deployments running on Windows, database names cannot contain any of the following characters:copycopied/\\. \"$*<>:|?Also database names cannot contain the null character. Restrictions on Database Names for Unix and Linux Systems For MongoDB deployments running on Unix and Linux systems, database names cannot contain any of the following characters:copycopied/\\. \"$Also database names cannot contain the null character. Length of Database Names Database names cannot be empty and must have fewer than 64 characters. Restriction on Collection Names Collection names should begin with an underscore or a letter character, and cannot:contain the $.be an empty string (e.g. \"\").contain the null character.begin with the system. prefix. (Reserved for internal use.)If your collection name includes special characters, such as the underscore character, or begins with numbers, then to access the collection use the db.getCollection() method in the mongo shell or a similar method for your driver.Namespace Length:For featureCompatibilityVersion set to \"4.4\" or greater, MongoDB raises the limit on collection/view namespace to 255 bytes. For a collection or a view, the namespace includes the database name, the dot (.) separator, and the collection/view name (e.g. .),For featureCompatibilityVersion set to \"4.2\" or earlier, the maximum length of the collection/view namespace remains 120 bytes. Restrictions on Field Names Field names cannot contain the null character.Top-level field names cannot start with the dollar sign ($) character.Otherwise, starting in MongoDB 3.6, the server permits storage of field names that contain dots (i.e. .) and dollar signs (i.e. $).IMPORTANTThe MongoDB Query Language cannot always meaningfully express queries over documents whose field names contain these characters (see SERVER-30575).Until support is added in the query language, the use of $ and . in field names is not recommended and is not supported by the official MongoDB drivers.MONGODB DOES NOT SUPPORT DUPLICATE FIELD NAMESThe MongoDB Query Language is undefined over documents with duplicate field names. BSON builders may support creating a BSON document with duplicate field names. While the BSON builder may not throw an error, inserting these documents into MongoDB is not supported even if the insert succeeds. For example, inserting a BSON document with duplicate field names through a MongoDB driver may result in the driver silently dropping the duplicate values prior to insertion. Namespaces Namespace Length For featureCompatibilityVersion set to \"4.4\" or greater, MongoDB raises the limit on collection/view namespace to 255 bytes. For a collection or a view, the namespace includes the database name, the dot (.) separator, and the collection/view name (e.g. .),For featureCompatibilityVersion set to \"4.2\" or earlier, the maximum length of the collection/view namespace remains 120 bytes.SEE ALSONaming Restrictions Indexes Index Key Limit CHANGED IN VERSION 4.2Starting in version 4.2, MongoDB removes the Index Key Limit for featureCompatibilityVersion (fCV) set to \"4.2\" or greater.For MongoDB 2.6 through MongoDB versions with fCV set to \"4.0\" or earlier, the total size of an index entry, which can include structural overhead depending on the BSON type, must be less than 1024 bytes.When the Index Key Limit applies:MongoDB will not create an index on a collection if the index entry for an existing document exceeds the index key limit.Reindexing operations will error if the index entry for an indexed field exceeds the index key limit. Reindexing operations occur as part of the compact command as well as the db.collection.reIndex() method.Because these operations drop all the indexes from a collection and then recreate them sequentially, the error from the index key limit prevents these operations from rebuilding any remaining indexes for the collection.MongoDB will not insert into an indexed collection any document with an indexed field whose corresponding index entry would exceed the index key limit, and instead, will return an error. Previous versions of MongoDB would insert but not index such documents.Updates to the indexed field will error if the updated value causes the index entry to exceed the index key limit.If an existing document contains an indexed field whose index entry exceeds the limit, any update that results in the relocation of that document on disk will error.mongorestore and mongoimport will not insert documents that contain an indexed field whose corresponding index entry would exceed the index key limit.In MongoDB 2.6, secondary members of replica sets will continue to replicate documents with an indexed field whose corresponding index entry exceeds the index key limit on initial sync but will print warnings in the logs.Secondary members also allow index build and rebuild operations on a collection that contains an indexed field whose corresponding index entry exceeds the index key limit but with warnings in the logs.With mixed version replica sets where the secondaries are version 2.6 and the primary is version 2.4, secondaries will replicate documents inserted or updated on the 2.4 primary, but will print error messages in the log if the documents contain an indexed field whose corresponding index entry exceeds the index key limit.For existing sharded collections, chunk migration will fail if the chunk has a document that contains an indexed field whose index entry exceeds the index key limit. Number of Indexes per Collection A single collection can have no more than 64 indexes. Index Name Length CHANGED IN VERSION 4.2Starting in version 4.2, MongoDB removes the Index Name Length Limit for MongoDB versions with featureCompatibilityVersion (fCV) set to \"4.2\" or greater.In previous versions of MongoDB or MongoDB versions with fCV set to \"4.0\" or earlier, fully qualified index names, which include the namespace and the dot separators (i.e. ..$), cannot be longer than 127 bytes.By default, is the concatenation of the field names and index type. You can explicitly specify the to the createIndex() method to ensure that the fully qualified index name does not exceed the limit. Number of Indexed Fields in a Compound Index There can be no more than 32 fields in a compound index. Queries cannot use both text and Geospatial Indexes You cannot combine the $text query, which requires a special text index, with a query operator that requires a different type of special index. For example you cannot combine $text query with the $near operator. Fields with 2dsphere Indexes can only hold Geometries Fields with 2dsphere indexes must hold geometry data in the form of coordinate pairs or GeoJSON data. If you attempt to insert a document with non-geometry data in a 2dsphere indexed field, or build a 2dsphere index on a collection where the indexed field has non-geometry data, the operation will fail. SEE ALSO The unique indexes limit in Sharding Operational Restrictions. NaN values returned from Covered Queries by the WiredTiger Storage Engine are always of type double If the value of a field returned from a query that is covered by an index is NaN, the type of that NaN value is always double. Multikey Index Multikey indexes cannot cover queries over array field(s). Geospatial Index Geospatial indexes cannot cover a query. Memory Usage in Index Builds createIndexes supports building one or more indexes on a collection. createIndexes uses a combination of memory and temporary files on disk to complete index builds. The default limit on memory usage for createIndexes is 200 megabytes (for versions 4.2.3 and later) and 500 (for versions 4.2.2 and earlier), shared between all indexes built using a single createIndexes command. Once the memory limit is reached, createIndexes uses temporary disk files in a subdirectory named _tmp within the --dbpath directory to complete the build.You can override the memory limit by setting the maxIndexBuildMemoryUsageMegabytes server parameter. Setting a higher memory limit may result in faster completion of index builds. However, setting this limit too high relative to the unused RAM on your system can result in memory exhaustion and server shutdown.Changed in version 4.2.For feature compatibility version (fcv) \"4.2\", the index build memory limit applies to all index builds.For feature compatibility version (fcv) \"4.0\", the index build memory limit only applies to foreground index builds.Index builds may be initiated either by a user command such as Create Index or by an administrative process such as an initial sync. Both are subject to the limit set by maxIndexBuildMemoryUsageMegabytes.An initial sync operation populates only one collection at a time and has no risk of exceeding the memory limit. However, it is possible for a user to start index builds on multiple collections in multiple databases simultaneously and potentially consume an amount of memory greater than the limit set in maxIndexBuildMemoryUsageMegabytes.TIPTo minimize the impact of building an index on replica sets and sharded clusters with replica set shards, use a rolling index build procedure as described on Rolling Index Builds on Replica Sets. Collation and Index Types The following index types only support simple binary comparison and do not support collation:text indexes,2d indexes, andgeoHaystack indexes.TIPTo create a text, a 2d, or a geoHaystack index on a collection that has a non-simple collation, you must explicitly specify {collation: {locale: \"simple\"} } when creating the index. Hidden Indexes You cannot hide the _id index.You cannot use hint() on a hidden index. Data Maximum Number of Documents in a Capped Collection If you specify a maximum number of documents for a capped collection using the max parameter to create, the limit must be less than 232 documents. If you do not specify a maximum number of documents when creating a capped collection, there is no limit on the number of documents. Replica Sets Number of Members of a Replica Set Replica sets can have up to 50 members. Number of Voting Members of a Replica Set Replica sets can have up to 7 voting members. For replica sets with more than 7 total members, see Non-Voting Members. Maximum Size of Auto-Created Oplog If you do not explicitly specify an oplog size (i.e. with oplogSizeMB or --oplogSize) MongoDB will create an oplog that is no larger than 50 gigabytes. [1][1]Starting in MongoDB 4.0, the oplog can grow past its configured size limit to avoid deleting the majority commit point. Sharded Clusters Sharded clusters have the restrictions and thresholds described here. Sharding Operational Restrictions Operations Unavailable in Sharded Environments $where does not permit references to the db object from the $where function. This is uncommon in un-sharded collections.The geoSearch command is not supported in sharded environments. Covered Queries in Sharded Clusters Starting in MongoDB 3.0, an index cannot cover a query on a sharded collection when run against a mongos if the index does not contain the shard key, with the following exception for the _id index: If a query on a sharded collection only specifies a condition on the _id field and returns only the _id field, the _id index can cover the query when run against a mongos even if the _id field is not the shard key.In previous versions, an index cannot cover a query on a sharded collection when run against a mongos. Sharding Existing Collection Data Size An existing collection can only be sharded if its size does not exceed specific limits. These limits can be estimated based on the average size of all shard key values, and the configured chunk size.IMPORTANTThese limits only apply for the initial sharding operation. Sharded collections can grow to any size after successfully enabling sharding.Use the following formulas to calculate the theoretical maximum collection size.copycopiedmaxSplits = 16777216 (bytes) / maxCollectionSize (MB) = maxSplits * (chunkSize / 2)NOTEThe maximum BSON document size is 16MB or 16777216 bytes.All conversions should use base-2 scale, e.g. 1024 kilobytes = 1 megabyte.If maxCollectionSize is less than or nearly equal to the target collection, increase the chunk size to ensure successful initial sharding. If there is doubt as to whether the result of the calculation is too ‘close’ to the target collection size, it is likely better to increase the chunk size.After successful initial sharding, you can reduce the chunk size as needed. If you later reduce the chunk size, it may take time for all chunks to split to the new size. See Modify Chunk Size in a Sharded Cluster for instructions on modifying chunk size.This table illustrates the approximate maximum collection sizes using the formulas described above:Average Size of Shard Key Values512 bytes256 bytes128 bytes64 bytesMaximum Number of Splits32,76865,536131,072262,144Max Collection Size (64 MB Chunk Size)1 TB2 TB4 TB8 TBMax Collection Size (128 MB Chunk Size)2 TB4 TB8 TB16 TBMax Collection Size (256 MB Chunk Size)4 TB8 TB16 TB32 TB Single Document Modification Operations in Sharded Collections All update() and remove() operations for a sharded collection that specify the justOne or multi: false option must include the shard key or the _id field in the query specification. update() and remove() operations specifying justOne or multi: false in a sharded collection which do not contain either the shard key or the _id field return an error. Unique Indexes in Sharded Collections MongoDB does not support unique indexes across shards, except when the unique index contains the full shard key as a prefix of the index. In these situations MongoDB will enforce uniqueness across the full key, not a single field.SEEUnique Constraints on Arbitrary Fields for an alternate approach. Maximum Number of Documents Per Chunk to Migrate By default, MongoDB cannot move a chunk if the number of documents in the chunk is greater than 1.3 times the result of dividing the configured chunk size by the average document size. db.collection.stats() includes the avgObjSize field, which represents the average document size in the collection.For chunks that are too large to migrate, starting in MongoDB 4.4:A new balancer setting attemptToBalanceJumboChunks allows the balancer to migrate chunks too large to move as long as the chunks are not labeled jumbo. See Balance Chunks that Exceed Size Limit for details.The moveChunk command can specify a new option forceJumbo to allow for the migration of chunks that are too large to move. The chunks may or may not be labeled jumbo. Shard Key Limitations Shard Key Size Starting in version 4.4, MongoDB removes the limit on the shard key size.For MongoDB 4.2 and earlier, a shard key cannot exceed 512 bytes. Shard Key Index Type A shard key index can be an ascending index on the shard key, a compound index that start with the shard key and specify ascending order for the shard key, or a hashed index.A shard key index cannot be an index that specifies a multikey index, a text index or a geospatial index on the shard key fields. Shard Key Selection is Immutable in MongoDB 4.``2 and Earlier CHANGED IN VERSION 4.4Starting in MongoDB 4.4, you can refine a collection’s shard key by adding a suffix field or fields to the existing key. See refineCollectionShardKey.In MongoDB 4.2 and earlier, once you shard a collection, the selection of the shard key is immutable; i.e. you cannot select a different shard key for that collection.If you must change a shard key:Dump all data from MongoDB into an external format.Drop the original sharded collection.Configure sharding using the new shard key.Pre-split the shard key range to ensure initial even distribution.Restore the dumped data into MongoDB. Monotonically Increasing Shard Keys Can Limit Insert Throughput For clusters with high insert volumes, a shard keys with monotonically increasing and decreasing keys can affect insert throughput. If your shard key is the _id field, be aware that the default values of the _id fields are ObjectIds which have generally increasing values.When inserting documents with monotonically increasing shard keys, all inserts belong to the same chunk on a single shard. The system eventually divides the chunk range that receives all write operations and migrates its contents to distribute data more evenly. However, at any moment the cluster directs insert operations only to a single shard, which creates an insert throughput bottleneck.If the operations on the cluster are predominately read operations and updates, this limitation may not affect the cluster.To avoid this constraint, use a hashed shard key or select a field that does not increase or decrease monotonically.Hashed shard keys and hashed indexes store hashes of keys with ascending values. Operations Sort Operations If MongoDB cannot use an index or indexes to obtain the sort order, MongoDB must perform a blocking sort operation on the data. The name refers to the requirement that the SORT stage reads all input documents before returning any output documents, blocking the flow of data for that specific query.If MongoDB requires using more than 100 megabytes of system memory for the blocking sort operation, MongoDB returns an error unless the query specifies cursor.allowDiskUse() (New in MongoDB 4.4). allowDiskUse() allows MongoDB to use temporary files on disk to store data exceeding the 100 megabyte system memory limit while processing a blocking sort operation.Changed in version 4.4: For MongoDB 4.2 and prior, blocking sort operations could not exceed 32 megabytes of system memory.For more information on sorts and index use, see Sort and Index Use. Aggregation Pipeline Operation Pipeline stages have a limit of 100 megabytes of RAM. If a stage exceeds this limit, MongoDB will produce an error. To allow for the handling of large datasets, use the allowDiskUse option to enable aggregation pipeline stages to write data to temporary files.Changed in version 3.4.The $graphLookup stage must stay within the 100 megabyte memory limit. If allowDiskUse: true is specified for the aggregate() operation, the $graphLookup stage ignores the option. If there are other stages in the aggregate() operation, allowDiskUse: true option is in effect for these other stages.Starting in MongoDB 4.2, the profiler log messages and diagnostic log messages includes a usedDisk indicator if any aggregation stage wrote data to temporary files due to memory restrictions.SEE ALSO$sort and Memory Restrictions and $group Operator and Memory. Aggregation and Read Concern Starting in MongoDB 4.2, the $out stage cannot be used in conjunction with read concern \"linearizable\". That is, if you specify \"linearizable\" read concern for db.collection.aggregate(), you cannot include the $out stage in the pipeline.The $merge stage cannot be used in conjunction with read concern \"linearizable\". That is, if you specify \"linearizable\" read concern for db.collection.aggregate(), you cannot include the $merge stage in the pipeline. 2d Geospatial queries cannot use the $or operator SEE$or and 2d Index Internals. Geospatial Queries For spherical queries, use the 2dsphere index result.The use of 2d index for spherical queries may lead to incorrect results, such as the use of the 2d index for spherical queries that wrap around the poles. Geospatial Coordinates Valid longitude values are between -180 and 180, both inclusive.Valid latitude values are between -90 and 90, both inclusive. Area of GeoJSON Polygons For $geoIntersects or $geoWithin, if you specify a single-ringed polygon that has an area greater than a single hemisphere, include the custom MongoDB coordinate reference system in the $geometry expression; otherwise, $geoIntersects or $geoWithin queries for the complementary geometry. For all other GeoJSON polygons with areas greater than a hemisphere, $geoIntersects or $geoWithin queries for the complementary geometry. Multi-document Transactions For multi-document transactions:You can specify read/write (CRUD) operations on existing collections. For a list of CRUD operations, see CRUD Operations.When using feature compatibility version (fcv) \"4.4\" or greater, you can create collections and indexes in transactions. For details, see Create Collections and Indexes In a TransactionThe collections used in a transaction can be in different databases.NOTEYou cannot create new collections in cross-shard write transactions. For example, if you write to an existing collection in one shard and implicitly create a collection in a different shard, MongoDB cannot perform both operations in the same transaction.You cannot write to capped collections. (Starting in MongoDB 4.2)You cannot read/write to collections in the config, admin, or local databases.You cannot write to system.* collections.You cannot return the supported operation’s query plan (i.e. explain).For cursors created outside of a transaction, you cannot call getMore inside the transaction.For cursors created in a transaction, you cannot call getMore outside the transaction.Starting in MongoDB 4.2, you cannot specify killCursors as the first operation in a transaction.Changed in version 4.4.The following operations are not allowed in transactions:Operations that affect the database catalog, such as creating or dropping a collection or an index when using feature compatibility version (fcv) \"4.2\" or lower. With fcv \"4.4\" or greater, you can create collections and indexes in transactions unless the transaction is a cross-shard write transaction. For details, see Create Collections and Indexes In a Transaction.Creating new collections in cross-shard write transactions. For example, if you write to an existing collection in one shard and implicitly create a collection in a different shard, MongoDB cannot perform both operations in the same transaction.Explicit creation of collections, e.g. db.createCollection() method, and indexes, e.g. db.collection.createIndexes() and db.collection.createIndex() methods, when using a read concern level other than \"local\".The listCollections and listIndexes commands and their helper methods.Other non-CRUD and non-informational operations, such as createUser, getParameter, count, etc. and their helpers.Transactions have a lifetime limit as specified by transactionLifetimeLimitSeconds. The default is 60 seconds. Write Command Batch Limit Size 100,000 writes are allowed in a single batch operation, defined by a single request to the server.Changed in version 3.6: The limit raises from 1,000 to 100,000 writes. This limit also applies to legacy OP_INSERT messages.The Bulk() operations in the mongo shell and comparable methods in the drivers do not have this limit. Views The view definition pipeline cannot include the $out or the $merge stage. If the view definition includes nested pipeline (e.g. the view definition includes $lookup or $facet stage), this restriction applies to the nested pipelines as well.Views have the following operation restrictions:Views are read-only.You cannot rename views.find() operations on views do not support the following projection operators:$$elemMatch$slice$metaViews do not support text search.Views do not support map-reduce operations.Views do not support geoNear operations (i.e. $geoNear pipeline stage). Projection Restrictions New in version 4.4:$-Prefixed Field Path RestrictionStarting in MongoDB 4.4, the find and findAndModify projection cannot project a field that starts with $ with the exception of the DBRef fields.For example, starting in MongoDB 4.4, the following operation is invalid:db.inventory.find( {}, { \"$instock.warehouse\": 0, \"$item\": 0, \"detail.$price\": 1 } ) // Invalid starting in 4.4MongoDB already has a restriction where top-level field names cannot start with the dollar sign ($).In earlier version, MongoDB ignores the $-prefixed field projections.$ Positional Operator Placement RestrictionStarting in MongoDB 4.4, the $ projection operator can only appear at the end of the field path; e.g. \"field.$\" or \"fieldA.fieldB.$\".For example, starting in MongoDB 4.4, the following operation is invalid:db.inventory.find( { }, { \"instock.$.qty\": 1 } ) // Invalid starting in 4.4To resolve, remove the component of the field path that follows the $ projection operator.In previous versions, MongoDB ignores the part of the path that follows the $; i.e. the projection is treated as \"instock.$\".Empty Field Name Projection RestrictionStarting in MongoDB 4.4, find and findAndModify projection cannot include a projection of an empty field name.For example, starting in MongoDB 4.4, the following operation is invalid:db.inventory.find( { }, { \"\": 0 } ) // Invalid starting in 4.4In previous versions, MongoDB treats the inclusion/exclusion of the empty field as it would the projection of non-existing fields.Path Collision: Embedded Documents and Its FieldsStarting in MongoDB 4.4, it is illegal to project an embedded document with any of the embedded document’s fields.For example, consider a collection inventory with documents that contain a size field:{ ..., size: { h: 10, w: 15.25, uom: \"cm\" }, ... }Starting in MongoDB 4.4, the following operation fails with a Path collision error because it attempts to project both size document and the size.uom field:db.inventory.find( {}, { size: 1, \"size.uom\": 1 } ) // Invalid starting in 4.4In previous versions, lattermost projection between the embedded documents and its fields determines the projection:If the projection of the embedded document comes after any and all projections of its fields, MongoDB projects the embedded document. For example, the projection document { \"size.uom\": 1, size: 1 } produces the same result as the projection document { size: 1 }.If the projection of the embedded document comes before the projection any of its fields, MongoDB projects the specified field or fields. For example, the projection document { \"size.uom\": 1, size: 1, \"size.h\": 1 } produces the same result as the projection document { \"size.uom\": 1, \"size.h\": 1 }.Path Collision: $slice of an Array and Embedded FieldsStarting in MongoDB 4.4, find and findAndModify projection cannot contain both a $slice of an array and a field embedded in the array.For example, consider a collection inventory that contains an array field instock:{ ..., instock: [ { warehouse: \"A\", qty: 35 }, { warehouse: \"B\", qty: 15 }, { warehouse: \"C\", qty: 35 } ], ... }Starting in MongoDB 4.4, the following operation fails with a Path collision error:db.inventory.find( {}, { \"instock\": { $slice: 1 }, \"instock.warehouse\": 0 } ) // Invalid starting in 4.4In previous versions, the projection applies both projections and returns the first element ($slice: 1) in the instock array but suppresses the warehouse field in the projected element. Starting in MongoDB 4.4, to achieve the same result, use the db.collection.aggregate() method with two separate $project stages.$ Positional Operator and $slice RestrictionStarting in MongoDB 4.4, find and findAndModify projection cannot include $slice projection expression as part of a $ projection expression.For example, starting in MongoDB 4.4, the following operation is invalid:db.inventory.find( { \"instock.qty\": { $gt: 25 } }, { \"instock.$\": { $slice: 1 } } ) // Invalid starting in 4.4MongoDB already has a restriction where top-level field names cannot start with the dollar sign ($).In previous versions, MongoDB returns the first element (instock.$) in the instock array that matches the query condition; i.e. the positional projection \"instock.$\" takes precedence and the $slice:1 is a no-op. The \"instock.$\": { $slice: 1 } does not exclude any other document field. Sessions Sessions and $external Username Limit Changed in version 3.6.3: To use sessions with $external authentication users (i.e. Kerberos, LDAP, x.509 users), the usernames cannot be greater than 10k bytes. Session Idle Timeout Sessions that receive no read or write operations for 30 minutes or that are not refreshed using refreshSessions within this threshold are marked as expired and can be closed by the MongoDB server at any time. Closing a session kills any in-progress operations and open cursors associated with the session. This includes cursors configured with noCursorTimeout or a maxTimeMS greater than 30 minutes.Consider an application that issues a db.collection.find(). The server returns a cursor along with a batch of documents defined by the cursor.batchSize() of the find(). The session refreshes each time the application requests a new batch of documents from the server. However, if the application takes longer than 30 minutes to process the current batch of documents, the session is marked as expired and closed. When the application requests the next batch of documents, the server returns an error as the cursor was killed when the session was closed.For operations that return a cursor, if the cursor may be idle for longer than 30 minutes, issue the operation within an explicit session using Session.startSession() and periodically refresh the session using the refreshSessions command. For example:copycopiedvar session = db.getMongo().startSession() var sessionId = session.getSessionId().id var cursor = session.getDatabase(\"examples\").getCollection(\"data\").find().noCursorTimeout() var refreshTimestamp = new Date() // take note of time at operation start while (cursor.hasNext()) { // Check if more than 5 minutes have passed since the last refresh if ( (new Date()-refreshTimestamp)/1000 > 300 ) { print(\"refreshing session\") db.adminCommand({\"refreshSessions\" : [sessionId]}) refreshTimestamp = new Date() } // process cursor normally }In the example operation, the db.collection.find() method is associated with an explicit session. The cursor is configured with noCursorTimeout() to prevent the server from closing the cursor if idle. The while loop includes a block that uses refreshSessions to refresh the session every 5 minutes. Since the session will never exceed the 30 minute idle timeout, the cursor can remain open indefinitely.For MongoDB drivers, defer to the driver documentation for instructions and syntax for creating sessions. Shell The mongo shell prompt has a limit of 4095 codepoints for each line. If you enter a line with more than 4095 codepoints, the shell will truncate it. Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/08-explain-results.html":{"url":"16-reference/08-explain-results.html","title":"Explain Results","keywords":"","body":" Explain Results ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Explain Results Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/09-system-collections.html":{"url":"16-reference/09-system-collections.html","title":"System Collections","keywords":"","body":" System Collections On this page Synopsis Collections Synopsis MongoDB stores system information in collections that use the .system.* namespace, which MongoDB reserves for internal use. Do not create collections that begin with system. MongoDB also stores some additional instance-local metadata in the local database, specifically for replication purposes and in the config database for sessions information. Collections System collections include these collections stored in the admin database: admin.system.``roles The admin.system.roles collection stores custom roles that administrators create and assign to users to provide access to specific resources. admin.system.``users The admin.system.users collection stores the user’s authentication credentials as well as any roles assigned to the user. Users may define authorization roles in the admin.system.roles collection. admin.system.``version Stores the schema version of the user credential documents. System collections include these collections stored in the config database: config.system.``indexBuilds New in version 4.4.The indexBuilds collection stores information related to in-progress index builds. System collections also include these collections stored directly in each database: .system.``namespaces REMOVED IN 4.2Starting in MongoDB 4.2, .system.namespaces has been removed (access to the collection has been deprecated since 3.0). To list the collections in a database, use the listCollections command instead. .system.``indexes REMOVED IN 4.2Starting in MongoDB 4.2, .system.indexes has been removed (access to the collection has been deprecated since 3.0). To list the inndexes, use the listIndexes command instead. .system.``profile The .system.profile collection stores database profiling information. For information on profiling, see Database Profiling. .system.``js The .system.js collection holds special JavaScript code for use in server side JavaScript. See Store a JavaScript Function on the Server for more information. .system.``views The .system.views collection contains information about each view in the database. 参见 原文 - System Collections Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/10-connection-string.html":{"url":"16-reference/10-connection-string.html","title":"连接字符串URI格式","keywords":"","body":" 连接字符串URI格式 在本页面 连接字符串格式 连接字符串选项 例子 本文档介绍了URI格式，用于在官方MongoDB drivers.定义应用程序和MongoDB实例之间的连接 。有关驱动程序的列表和驱动程序文档的链接，请参见drivers。 连接字符串格式 你可以指定MongoDB连接字符串使用任何: the 标准连接字符串格式 the DNS Seedlist 连接格式. 标准连接字符串格式 本节描述用于连接到MongoDB部署的MongoDB连接URI的标准格式:独立、复制集或分片集群。 标准的URI连接方案有如下形式: mongodb://[username:password@]host1[:port1][,...hostN[:portN]][/[defaultauthdb][?options]] 例子 单机版 1.对于独立版本 mongodb://mongodb0.example.com:27017 ​ 2. 对于一个强制访问控制: mongodb://myDBReader:D1fficultP%40ssw0rd@mongodb0.example.com:27017/?authSource=admin 复制集 注意 对于一个复制集，指定副本集配置中列出的mongod实例的主机名。 对于复制集，包括replicaSet 选项。 ​ 1.对于一个复制集: mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?replicaSet=myRepl ​ 2.对于强制访问控制的复制集，包括用户凭证: mongodb://myDBReader:D1fficultP%40ssw0rd@mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?authSource=admin&replicaSet=myRepl 分片集群 注意 对于分片集群的连接字符串，在连接字符串中指定mongos主机。 ​ 1.对于分片集群: mongodb://mongos0.example.com:27017,mongos1.example.com:27017,mongos2.example.com:27017 ​ 2.对于实施访问控制的分片集群，包括用户凭证: mongodb://myDBReader:D1fficultP%40ssw0rd@mongos0.example.com:27017,mongos1.example.com:27017,mongos2.example.com:27017/?authSource=admin 如果用户名或密码包含at符号@，冒号:，斜杠/或百分号%字符，请使用百分比编码 更多示例，请参见examples。 组件 标准的URI连接字符串包括以下组件: 组件 描述 mongodb:// 标识这是标准连接格式的字符串的必需前缀。 username:password@ 可选的。身份验证凭据。如果指定，则客户端将尝试向验证用户authSource。如果 authSource未指定，则客户端将尝试向验证用户defaultauthdb。如果defaultauthdb未指定，则发送到admin 数据库。如果用户名或密码包含at符号@，冒号:，斜杠/或百分号%字符，请使用百分比编码。另请参阅authSource。 host[:port] mongod实例（或分片mongos 群集的实例）运行所在的主机（和可选的端口号） 。您可以指定主机名，IP地址或UNIX域套接字。根据您的部署拓扑指定尽可能多的主机：对于独立mongod实例，请指定独立实例的主机名 。对于复制集，请指定mongod 复制集配置中列出的实例的主机名。对于分片群集，请指定mongos实例的主机名 。如果未指定端口号，27017 则使用默认端口。 /defaultauthdb 可选的。如果连接字符串包含username:password@ 身份验证凭据但未authSource指定选项，则使用的身份验证数据库。如果两个authSource和defaultauthdb未指定，客户端将尝试以指定用户的身份验证admin数据库。 ? 可选的。查询字符串，将连接特定的选项指定为=对。有关这些选项的完整说明，请参见 连接字符串选项。如果连接字符串没有指定数据库/您必须在最后一台主机和开始选项字符串的问号之间指定一个斜杠(/)。 DNS Seedlist 连接格式 新增3.6版 除了标准的连接格式，MongoDB还支持一个DNS构造的Seedlist列表。使用DNS构造可用服务器列表允许更灵活的部署，并允许在不重新配置客户机的情况下轮流更改服务器。 为了利用DNSSeedlist列表，使用一个连接字符串前缀 mongodb+srv:，而不是标准的 mongodb:。+srv向客户端表明后面的主机名对应于一个DNS srv记录。驱动程序或mongoshell将查询DNS记录，以确定哪些主机正在运行mongod实例。 注意 使用 +srv 连接字符串修饰符自动将该连接的tls(或等效的ssl)选项设置为true。您可以通过将查询字符串中的tls (或等效ssl)选项显式设置为false通过 tls=false（或ssl=false）来覆盖此行为。 下面的例子显示了一个典型的DNS seedlist连接字符串的连接字符串: mongodb+srv://server.example.com/ 对应的DNS配置如下: Record TTL Class Priority Weight Port Target _mongodb._tcp.server.example.com. 86400 IN SRV 0 5 27317 mongodb1.example.com. _mongodb._tcp.server.example.com. 86400 IN SRV 0 5 27017 mongodb2.example.com. 重要 SRV记录中返回的主机名必须与给定的主机名共享相同的父域(在本例中为example.com)。如果父域名和主机名不匹配，您将无法连接。 与标准连接字符串一样，DNS seedlist连接字符串支持将选项指定为查询字符串。使用DNSseedlist列表连接字符串，您还可以通过TXT记录指定以下选项: replicaSet authSource 您只能为每个mongod实例指定一个TXT记录。如果多个TXT记录出现在DNS/或如果TXT记录包含一个选项，而不是replicaSet或authSource，客户端将返回一个错误。 TXT记录server.example.comDN条目类似于： 记录 TTL Class Text server.example.com. 86400 IN TXT“ replicaSet = mySet＆authSource = authDB” 综合起来，DNS SRV记录和TXT记录中指定的选项解析为以下标准格式的连接字符串: mongodb://mongodb1.example.com:27317,mongodb2.example.com:27017/?replicaSet=mySet&authSource=authDB 您可以通过在查询字符串中传递选项来重写TXT记录中指定的选项。在下面的示例中，查询字符串为TXT中配置的authSource选项提供了重写记录上面的DNS条目。 mongodb + srv：//server.example.com/？connectTimeoutMS = 300000＆authSource = aDifferentAuthDB 给定authSource的重写，标准格式的等效连接字符串为: mongodb：//mongodb1.example.com：27317，mongodb2.example.com：27017 /？connectTimeoutMS = 300000＆replicaSet = mySet＆authSource = aDifferentAuthDB 注意 如果没有与连接字符串中标识的主机名对应的可用DNS记录，mongodb+srv选项将失败。此外，使用+srv连接字符串修饰符会自动为连接设置tls（或等效 ssl）选项true。您可以通过将查询字符串中的tls (或等效ssl)选项显式设置为false通过 tls=false（或ssl=false）来覆盖此行为。 请看： 使用DNSSeedlist列表连接格式连接到复制集提供一个使用DNSseedlist列表连接格式连接mongo shell到复制集的示例。 连接字符串选项 本节列出了所有连接选项。 连接选项是成对的，格式如下：name=value。 name使用驱动程序时，该选项不区分大小写。 name使用4.2+版本的mongoShell 时，该选项不区分大小写 。 name使用4.0版或更早版本的mongoShell 时，此选项区分大小写。 value始终是区分大小写的。 用&字符分隔选项(即:&)name1=value1&name2=value2。在以下示例中，连接包括replicaSet和 connectTimeoutMS选项： mongodb：//db1.example.net：27017，db2.example.net：2500 /？replicaSet = test＆connectTimeoutMS = 300000 用于连接字符串参数的分号分隔符: 为了提供向后兼容性，驱动程序目前接受分号(即;)作为选项分隔符。 复制集选项 以下连接字符串到一个名为myRepl的复制集，成员运行在指定的主机上: mongodb：//db0.example.com：27017，db1.example.com：27017，db2.example.com：27017 /？replicaSet = myRepl 连接选项 描述 replicaSet 如果mongod是复制集的成员，则指定复制集的名称。当连接到复制集时，向uri的host[:port]组件提供复制集成员的seed列表。有关具体细节，请参考您的驱动程序文档。 连接选项 TLS选项 下面的连接字符串到一个复制集包括 tls=true选项(在MongoDB 4.2可用): mongodb：//db0.example.com,db1.example.com,db2.example.com/？replicaSet = myRepl＆tls = true 或者，你也可以使用等价的ssl=true选项: mongodb：//db0.example.com,db1.example.com,db2.example.com/？replicaSet = myRepl＆ssl = true 连接选项 描述 tls 为连接启用或禁用TLS / SSL：true：使用TLS / SSL启动连接。DNSseedlist列表连接格式的默认设置 。false：在没有TLS / SSL的情况下启动连接。标准连接字符串格式的默认设置 。注意该tls选项等效于该 ssl选项。如果mongo shell从命令行指定了额外的tls / ssl选项，则使用--tls命令行选项。4.2版中的新功能。 ssl 用于连接启用或禁用TLS / SSL的布尔值：true：使用TLS / SSL启动连接。DNSseedlist列表连接格式的默认设置 。false：在没有TLS / SSL的情况下启动连接。标准连接字符串格式的默认设置。注意该ssl选项等效于该 tls选项。如果mongo shell从命令行指定了额外的tls / ssl选项，则使用--tls命令行选项。 tlsCertificateKeyFile 指定.pem包含客户端的TLS / SSL X.509证书或客户端的TLS / SSL证书和密钥的本地文件的位置。客户端将此文件呈现给 mongod/ mongos实例。4.4版本改变：mongod / mongos记录连接上的警告如果给出x.509证书在mongod/mongos主机系统时间的30天内到期。有关更多信息，请参见 x.509证书即将过期触发警告。并非所有驱动程序都支持此选项。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。4.2版中的新功能。 tlsCertificateKeyFilePassword 指定用于反加密tlsCertificateKeyFile的密码。并非所有驱动程序都支持此选项。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。4.2版中的新功能。 tlsCAFile 指定.pem包含来自证书颁发机构的根证书链的本地文件的位置。此文件用于验证mongod/ mongos 实例提供的证书。并非所有驱动程序都支持此选项。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。4.2版中的新功能。 tlsAllowInvalidCertificates 绕过mongod/ mongos实例提供的证书的验证设置为true连接到MongoDB实例，即使服务器当前存在无效证书。并非所有驱动程序都支持此选项。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。警告禁用证书验证会产生漏洞。4.2版中的新功能。 tlsAllowInvalidHostnames 禁用mongod/ mongos实例提供的证书的主机名验证。设置为true连接到MongoDB实例，即使服务器证书中的主机名与服务器的主机不匹配。并非所有驱动程序都支持此选项。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。警告禁用证书验证会产生漏洞。4.2版中的新功能。 tlsInsecure 禁用各种证书验证。设置为true禁用证书验证。禁用的确切验证因驱动程序而异。请参阅 驱动程序文档。此连接字符串选项不适用于mongo shell。请改用命令行选项。警告禁用证书验证会产生漏洞。4.2版中的新功能。 超时选项 连接选项 描述 connectTimeoutMS 超时之前尝试连接的时间（以毫秒为单位）。默认值是永不超时，尽管不同的驱动程序可能有所不同。请参阅驱动程序 文档。 socketTimeoutMS 尝试超时之前在套接字上尝试发送或接收的时间（以毫秒为单位）。默认值是永不超时，尽管不同的驱动程序可能有所不同。请参阅 驱动程序文档。 压缩选项 连接选项 描述 compressors 由逗号分隔的压缩器字符串，用于在此客户端和mongod/ mongos实例之间进行通信时启用网络压缩。您可以指定以下压缩器：snappyzlib（在MongoDB 3.6或更高版本中可用）zstd（在MongoDB 4.2或更高版本中可用）如果指定多个压缩器，那么列出压缩器的顺序和通信启动器的顺序都很重要。例如，如果客户端指定了以下网络压缩器“zlib,snappy”，而mongod指定了“snappy,zlib”，那么客户端和mongod之间的消息就使用zlib。重要当双方都启用网络压缩时，消息将被压缩。否则，各方之间的消息将不被压缩。如果各方不共享一个公共压缩器，则各方之间的消息将不被压缩。从MongoDB 4.0.5（和MongoDB 3.6.10）开始, mongo shell支持uri连接字符串选项compressors。 zlibCompressionLevel 如果使用zlib进行网络压缩，则指定压缩级别的整数。您可以指定一个从-1到9的整数值:：值 笔记-1 默认压缩级别，通常是6级压缩。0 无压缩1 -- 9 增加压缩级别但以速度为代价，具有： 1 提供最佳速度，但压缩最少， 9 提供最佳压缩效果，但速度最慢。不被mongo shell支持。 连接池选项 大多数驱动程序实现某种类型的连接池处理。有些驱动程序不支持连接池。有关连接池实现的更多信息，请参见驱动程序文档。这些选项允许应用程序在连接到MongoDB部署时配置连接池。 连接选项 描述 maxPoolSize 连接池中的最大连接数。默认值为100。 minPoolSize 连接池中的最小连接数。默认值为0。注意并不是所有驱动程序都支持minPoolSize选项。有关驱动程序的信息，请参阅 驱动程序文档。 maxIdleTimeMS 在删除和关闭连接之前，连接在池中可以保持空闲状态的最大毫秒数。并非所有驱动程序都支持此选项。 waitQueueMultiple 驱动程序将maxPoolSize 值乘以一个数字，以提供允许等待池中的连接可用的最大线程数。有关默认值，请参见/ drivers 文档。并非所有驱动程序都支持此选项。 waitQueueTimeoutMS 线程可以等待连接可用的最长时间（以毫秒为单位）。有关默认值，请参见 / drivers文档。并非所有驱动程序都支持此选项。 写关注选项 写关注描述了MongoDB请求的确认级别。下列情况支持写关注选项： MongoDB驱动程序 mongo shell mongofiles mongoimport mongorestore 您可以在连接字符串中指定写关注，也可以将其指定为诸如insert或update等方法的参数。如果在两个地方都指定了写关注点，则method参数将覆盖连接字符串设置。 下面的连接字符串到一个复制集指定 \"majority\"写关注和5秒超时使用wtimeoutMS写关注参数: mongodb：//db0.example.com,db1.example.com,db2.example.com/？replicaSet = myRepl＆w = majority＆wtimeoutMS = 5000 连接选项 描述 w 对应于写关注w Option。该w选项请求确认写操作已传播到指定数量的mongod实例或 mongod具有指定标签的实例。您可以指定number，字符串majority或tag set有关详细信息，请参见w Option。 wtimeoutMS 对应于写关注点wtimeout. wtimeoutMS为写关注指定了一个时间限制，以毫秒为单位。如果wtimeoutMS是0，写操作永远不会超时。有关更多信息，请参见wtimeout。 journal 对应于写关注点j Option选项。该 journal选项要求MongoDB确认已将写操作写入 日志。有关详细信息，请参见j选项。如果设置journal为true，并指定w小于1 的 值，则journal优先。如果您将journal设置为true，并且 mongod未启用日志功能（如） storage.journal.enabled，则MongoDB将出错。 有关更多信息，请参见写关注点。 readConcern选项 版本3.2中的新特性:对于WiredTiger存储引擎，MongoDB 3.2为复制集和复制集分片引入了readConcern选项。 Read Concern允许客户端为从复制集读取选择隔离级别。 下面的复制集连接字符串指定 readConcernLevel=majority： mongodb：//db0.example.com,db1.example.com,db2.example.com/？replicaSet = myRepl＆readConcernLevel = majority 连接选项 描述 readConcernLevel 隔离的程度。可以接受下列值之一:localmajoritylinearizableavailable此连接字符串选项不适用于 mongoshell。指定read关注点作为特定操作的选项。 有关更多信息，请参见读关注。 阅读首选项选项 读取首选项描述了与复制集相关的读取操作的行为。这些参数允许您在连接字符串中以每个连接为基础指定读取首选项。 注意 要使用驱动程序指定已对冲的读取选项，请参考 驱动程序的读取首选项API。 例如： 以下到复制集的连接字符串指定 secondary读取首选项模式和maxStalenessSeconds120秒的值： mongodb：//db0.example.com,db1.example.com,db2.example.com/？replicaSet = myRepl＆readPreference = secondary＆maxStalenessSeconds = 120 以下到分片群集的连接字符串指定 secondary读取首选项模式和maxStalenessSeconds120秒的值： mongodb：//mongos1.example.com,mongos2.example.com/？readPreference = secondary＆maxStalenessSeconds = 120 以下到分片群集的连接字符串指定 secondary读取首选项模式以及三种 readPreferenceTags： mongodb：//mongos1.example.com,mongos2.example.com/？readPreference = secondary＆readPreferenceTags = dc：ny，rack：r1＆readPreferenceTags = dc：ny＆readPreferenceTags = 使用多个readPreferenceTags时，顺序很重要。按顺序尝试readPreferenceTags，直到找到匹配项为止。一旦找到，该规范将用于查找所有符合条件的匹配成员，并忽略任何剩余的readPreferenceTags。有关详细信息，请参见标签匹配顺序。 连接选项 描述 readPreference 指定此连接的读取首选项。可能的值为：primary（默认）primaryPreferredsecondarysecondaryPreferrednearest包含读取操作的多文档事务必须使用读取首选项primary。给定事务中的所有操作必须路由到同一成员。此连接字符串选项不适用于 mongoshell。请参阅cursor.readPref()和 Mongo.setReadPref()。 maxStalenessSeconds 指定以秒为单位的秒数，表示客户机在停止将其用于读取操作之前会过时。有关详细信息，请参见 阅读首选项maxStalenessSeconds。默认情况下，没有最大的过时度，客户机在选择将读操作指向何处时不会考虑辅助服务器的延迟。最小值maxStalenessSeconds为90秒。指定0到90秒之间的值将产生错误。MongoDB驱动程序将maxStalenessSeconds值-1视为“没有最大过时性”，就好像maxStalenessSeconds被忽略了一样 。重要要使用maxStalenessSeconds，部署中的所有MongoDB实例都必须使用MongoDB 3.4或更高版本。如果任何实例在MongoDB的早期版本上，则驱动程序或mongod/ mongos将引发错误。3.4版的新功能。 readPreferenceTags 将标签文档指定为以冒号分隔的键/值对的列表，以逗号分隔。例如，要指定标签文档{\"dc\": \"ny\"， \"rack\": \"r1\"}，在连接字符串中使用readPreferenceTags=dc:ny,rack:r1。 若要指定空标记文档{}，请使用readPreferenceTags=而不设置值。要指定标签文档列表，请使用多个readPreferenceTags。例如，readPreferenceTags=dc:ny,rack:r1&readPreferenceTags=.使用多个readPreferenceTags时，顺序很重要。按顺序尝试readPreferenceTags，直到找到匹配项为止。有关详细信息，请参见标记匹配的顺序。这个连接字符串选项对mongo shell不可用。请参阅cursor.readPref()和 Mongo.setReadPref()。 有关更多信息，请参阅阅读首选项。 验证选项 下面到复制集的连接字符串指定admin数据库的 authSource。也就是说，根据admin数据库对用户凭据进行身份验证。 mongodb：// myDBReader：D1fficultP%40ssw0rd@mongodb0.example.com：27017，mongodb1.example.com：27017，mongodb2.example.com：27017 /？replicaSet = myRepl ＆authSource = admin 如果用户名或密码包含'at'符号@，冒号:，斜杠/或百分号%字符，请使用百分比编码。 连接选项 描述 authSource 指定与用户凭据关联的数据库名称。如果authSource未指定，则 authSource默认为defaultauthdb 连接字符串中指定的。如果defaultauthdb未指定，则authSource默认为admin。普通身份验证机制(LDAP)、GSSAPI(Kerberos)和MONGODB-AWS (IAM)要求将authSource设置为$external，因为这些机制将凭据存储委托给外部服务。如果在连接字符串中或通过--username参数中没有提供用户名，MongoDB将忽略authSource值。 authMechanism 指定MongoDB将用于认证连接的认证机制。可能的值包括：SCRAM-SHA-1SCRAM-SHA-256（ MongoDB 4.0中添加）MONGODB-X509MONGODB-AWS（在MongoDB 4.4中添加了）GSSAPI（Kerberos）普通（LDAP SASL）MongoDB 4.0删除了对MONGODB-CR 身份验证机制的支持。MONGODB-CR连接到MongoDB 4.0+部署时，不能指定为身份验证机制。仅MongoDB Enterprise mongod和 mongos实例提供GSSAPI（Kerberos）和 PLAIN（LDAP）机制。要使用MONGODB-X509，您必须启用TLS / SSL。要使用MONGODB-AWS，您必须连接到已配置为支持通过AWS IAM凭证 （即AWS访问密钥ID和秘密访问密钥，以及可选的AWS会话令牌）进行身份验证的 MongoDB Atlas集群 。该认证机制需要 设置为。MONGODB-AWSauthSource$external使用时MONGODB-AWS，请提供您的AWS访问密钥ID作为用户名，并提供秘密访问密钥作为密码。如果还使用 AWS会话令牌 ，请为其提供AWS_SESSION_TOKEN authMechanismProperties值。如果AWS访问密钥ID，秘密访问密钥或会话令牌包含'at'符号@，冒号:，斜杠 /或百分号%字符，则必须使用百分比编码转换这些字符。或者，如果您使用各自的AWS IAM环境变量 在平台上定义了AWS访问密钥ID，秘密访问密钥或会话令牌，则 mongoShell将使用这些环境变量值进行身份验证；您无需在连接字符串中指定它们。有关同时使用连接字符串和环境变量方法的身份验证机制的用法，请参阅连接到Atlas群集MONGODB-AWS。有关MongoDB中身份验证系统的更多信息，请参阅身份验证。另请考虑 使用x.509证书对客户端进行身份验证，以获取有关x509身份验证的更多信息。 authMechanismProperties 将指定的属性指定authMechanism 为以逗号分隔的冒号分隔的键/值对列表。可能的键值对为：SERVICE_NAME:连接到Kerberized MongoDB实例时，设置Kerberos服务名称。该值必须与您要连接的MongoDB实例上设置的服务名称匹配。仅在使用GSSAPI 身份验证机制时有效。SERVICE_NAME``mongodb所有客户端和MongoDB实例默认为。如果更改saslServiceNameMongoDB实例上的 设置，则必须进行设置SERVICE_NAME以匹配该设置。仅在使用GSSAPI 身份验证机制时有效。`CANONICALIZE_HOST_NAME:true false连接到Kerberos服务器时，规范化客户端主机的主机名。当主机报告的主机名与Kerberos数据库中的主机名不同时，可能需要这样做。默认为false。仅在使用[GSSAPI](https://docs.mongodb.com/master/core/authentication-mechanisms-enterprise/security-auth-kerberos)身份验证机制时有效 。SERVICE_REALM:为MongoDB服务设置Kerberos领域。这对于支持跨域身份验证可能是必需的，在该跨域身份验证中，用户位于一个领域中，而服务位于另一个领域中。仅在使用[GSSAPI](https://docs.mongodb.com/master/core/authentication-mechanisms-enterprise/security-auth-kerberos)身份验证机制时有效。AWS_SESSION_TOKEN:在使用[AssumeRole](https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html) 请求或使用指定该值的AWS资源（例如Lambda）时，设置AWS会话令牌以使用临时凭证进行身份验证。仅在使用MONGODB-AWS` 身份验证机制时有效。您还必须具有一个AWS访问密钥ID和一个秘密访问密钥。有关示例用法，请参见 连接到Atlas群集。 gssapiServiceName 连接到Kerberized MongoDB实例时，设置Kerberos服务名称。该值必须与您要连接的MongoDB实例上设置的服务名称匹配。gssapiServiceNamemongodb所有客户端和MongoDB实例默认为。如果更改 saslServiceNameMongoDB实例上的设置，则必须进行设置gssapiServiceName以匹配该设置。gssapiServiceName是不推荐使用的别名 authMechanismProperties=SERVICE_NAME:mongodb。有关驱动程序支持哪些选项以及它们之间的相对优先级的更多信息，请参考首选驱动程序版本的文档。 服务器选择和查找选项 MongoDB提供以下选项来配置MongoDB驱动程序和mongos实例如何选择要将读取或写入操作定向到的服务器。 连接选项 描述 localThresholdMS 在多个合适的MongoDB实例中进行选择的等待时间窗口的大小（以毫秒为单位）。默认值：15毫秒。所有驱动程序都使用localThresholdMS。localThreshold将延迟窗口大小指定为时，请使用 别名mongos。 serverSelectionTimeoutMS 指定在引发异常之前为选择服务器而阻塞的时间（以毫秒为单位）。默认值：30,000毫秒。 serverSelectionTryOnce 仅单线程驱动程序。如果为true，则指示驱动程序在服务器选择失败后立即扫描MongoDB部署一次，然后选择服务器或引发错误。当为时false，驱动程序将阻止并搜索不超过该serverSelectionTimeoutMS值的服务器。 默认值：true。并且mongos不支持 多线程驱动程序serverSelectionTryOnce。 heartbeatFrequencyMS heartbeatFrequencyMS控制驱动程序何时检查MongoDB部署的状态。指定两次检查之间的间隔（以毫秒为单位），从上一次检查的结束到下一次检查的开始计算。默认值：单线程驱动程序：60秒。多线程驱动程序：10秒。mongos 不支持更改心跳检查的频率。 杂项配置 连接选项 描述 appName 指定自定义应用名称。应用名称出现在mongod和日志，mongos命令和方法输出中的currentOp.appName字段，currentOpdb.currentOp()数据库探查器输出中的system.profile.appName字段。如果您未指定自定义应用程序名称，则mongo 外壳程序将使用默认的“ ”。MongoDB Shell版本4.0中的新功能。 retryReads 启用可重试的读取。可能的值为：true。启用连接的可重试读取。与MongoDB Server 4.2及更高版本兼容的官方MongoDB驱动程序默认为true。false。禁用连接的可重试读取。在mongo外壳不支持重试读取。4.2版中的新功能。 retryWrites 启用可重试写入。可能的值为：true。启用连接的可重试写入。兼容MongoDB 4.2的官方驱动程序默认为true。false。禁用该连接的可重试写入。官方的MongoDB 4.0和3.6兼容驱动程序默认为false。MongoDB驱动程序将重试 事务提交和中止操作， 而与的值无关retryWrites。有关事务可重试性的更多信息，请参见 事务错误处理。3.6版的新功能。 uuidRepresentation 可能的值为：standard标准二进制表示形式。csharpLegacyC＃驱动程序的默认表示。javaLegacyJava驱动程序的默认表示形式。pythonLegacyPython驱动程序的默认表示形式。对于默认设置，请参阅驱动程序的驱动程序 文档。注意并非所有驱动程序都支持该uuidRepresentation 选项。有关驱动程序的信息，请参阅驱动程序文档。 例子 以下提供了用于公共连接目标的示例URI字符串。 在本地运行的数据库服务器 以下连接到在默认端口上本地运行的数据库服务器： mongodb：//本地主机 admin数据库 以下内容admin以用户身份sysop使用密码连接并登录到数据库 moon： mongodb：// sysop：moon @ localhost records数据库 以下内容records以用户身份sysop使用密码连接并登录到数据库 moon： mongodb：// sysop：moon @ localhost / records UNIX域套接字 连接到UNIX域套接字时，请使用URL编码的连接字符串。 以下连接到具有文件路径的UNIX域套接字 /tmp/mongodb-27017.sock： mongodb：//%2Ftmp%2Fmongodb-27017.sock 注意 并非所有驱动程序都支持UNIX域套接字。有关驱动程序的信息，请参阅驱动程序 文档。 在不同计算机上具有成员的副本集 以下内容连接到具有两个成员的副本集，一个成员db1.example.net在另一个成员 上db2.example.net： 注意 对于副本集，请指定mongod 副本集配置中列出的实例的主机名。 mongodb：//db1.example.net,db2.example.com/？replicaSet = test 带有成员的副本集localhost 下面连接到副本集具有三个成员上运行localhost的端口27017，27018以及27019： 注意 对于副本集，请指定mongod 副本集配置中列出的实例的主机名。 mongodb：//本地主机，本地主机：27018，本地主机：27019 /？replicaSet = test 具有读取分布的副本集 以下内容连接到具有三个成员的副本集，并将读取内容分发给第二副本： 注意 对于副本集，请指定mongod 副本集配置中列出的实例的主机名。 mongodb：//example1.com,example2.com,example3.com/？replicaSet = test＆readPreference = secondary 具有写关注级别的副本集 以下内容连接到具有写关注点的副本集，该副本集被配置为等待跨大多数数据承载投票成员的复制成功，并具有两秒的超时。 注意 对于副本集，请指定mongod 副本集配置中列出的实例的主机名。 mongodb：//example1.com,example2.com,example3.com/？replicaSet = test＆w = majority＆wtimeoutMS = 2000 分片群集 以下连接到具有三个mongos实例的分片群集： mongodb：//router1.example.com：27017，router2.example2.com：27017，router3.example3.com：27017 / MongoDB Atlas集群 版本4.4中的新功能。 以下连接到已配置为支持通过AWS IAM凭证进行身份验证的MongoDB Atlas集群： mongo'mongodb + srv：// ： @ cluster0.example.com / testdb？authSource = $ external＆authMechanism = MONGODB-AWS' 如本示例所示，以这种方式使用AWS IAM凭据连接到Atlas使用 和和。MONGODB-AWS [`$external authSource 如果还使用AWS会话令牌，请为其提供AWS_SESSION_TOKEN authMechanismProperties值，如下所示： mongo'mongodb + srv：// ： @ cluster0.example.com / testdb？authSource = $ external＆authMechanism = MONGODB-AWS＆authMechanismProperties = AWS_SESSION_TOKEN：' 如果AWS访问密钥ID，秘密访问密钥或会话令牌包括'at'符号@，冒号:，斜杠/或百分号%字符，则必须使用百分比编码转换这些字符 。 您也可以使用标准AWS IAM环境变量在平台上设置这些凭证 。使用mongo以下命令时，shell将检查以下环境变量：MONGODB-AWS authentication mechanism AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN 如果设置，则无需在连接字符串中指定这些凭据。 以下示例在bash 外壳中设置这些环境变量： 导出AWS_ACCESS_KEY_ID ='' 导出AWS_SECRET_ACCESS_KEY ='' 导出AWS_SESSION_TOKEN ='' 在其他shell中设置环境变量的语法将有所不同。有关更多信息，请查阅您平台的文档。 您可以使用以下命令验证是否已设置这些环境变量： env | grep AWS 设置完成后，以下示例将使用以下环境变量连接到MongoDB Atlas集群： mongo'mongodb + srv：//cluster0.example.com/testdb？authSource = $ external＆authMechanism 参见 原文 - Connection String URI Format Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/11-collation.html":{"url":"16-reference/11-collation.html","title":"排序","keywords":"","body":" 排序 在本页面 排序文件 支持排序的操作 行为 新版本3.4 排序允许用户为字符串比较指定特定于语言的规则，例如字母大小写和重音符号的规则。 可以为集合或视图、索引或支持排序的特定操作指定排序。 排序文件 一个排序文档有以下字段: { locale: , caseLevel: , caseFirst: , strength: , numericOrdering: , alternate: , maxVariable: , backwards: } 在指定排序时，locale字段是强制性的;所有其他排序字段都是可选的。有关字段的描述，请参见Collation Document。 默认的排序参数值因指定的语言环境而异。有关默认排序参数和它们关联的地区的完整列表，请参见排序默认参数。 字段 Type Description locale string ICU的语言环境。参见支持的语言和地区获取支持的地区列表。若要指定简单二进制比较，请将locale值指定为simple。 strength integer 可选的。要执行的比较级别。对应ICU比较水平。值可能是:值 描述1. 初级水平的比较。排序只对基本字符进行比较，忽略其他差异，如变音符号和大小写.2. 二级比较。排序会执行到次要差异的比较，比如变音符号。也就是说，排序执行基本字符(主要差异)和变音符号(次要差异)的比较。基本字符之间的差异优先于次要字符之间的差异.3. 三级比较。排序执行到第三级差异的比较，例如大小写和字母变体。也就是说，排序执 行基本字符(主要差异)、变音符号(次要差异)以及大小写和变体(第三差异)的比较。基本字符之间的差异优先于次要差异，后者优先于第三级差异. 这是默认级别.4. 四级比较。当级别1-3忽略标点符号或用于处理日语文本时，限制了特定用例考虑标点符号。5. 相同的水平。限制了连接断路器的特定用例. 参见ICU排序:比较级别了解详细信息. caseLevel boolean 可选。决定是否在级别1或2包含大小写比较的标志。如果为true，包括大小写比较;即: 当与strength:1一起使用时，排序比较基本字符和大小写。 当与strength:2一起使用时，排序比较基本字符、变音符号(以及可能的其他次要差异)和大小写。如果为false，不要在1或2级别包括大小写比较。默认值是false。更多信息，请参见ICU Collation: Case Level. caseFirst string 可选的。一个字段，用于确定第三级比较时大小写差异的排序顺序。值可能是:值 描述upper 大写排序在小写之前。lower 小写排序在大写排序之前。off 默认值。与lower相似，但略有不同。有关差异的详细信息，请参阅http://userguide.icu-project.org/collation/customization。 numericOrdering boolean 可选的。决定将数字字符串作为数字或字符串比较的标志。如果为true, 比较数字;即.“10”大于“2”。如果为 false, 比较字符串;即.“10”比“2”小。默认设置是false。 alternate string 可选的。确定排序规则是否应将空格和标点符号视为基本字符以便进行比较的字段。值可能是：值 描述\"non-ignorable\" 空格和标点符号被认为是基本字符。\"shifted\" 空格和标点符号不被认为是基本字符，只在强度级别大于3时区分。更多信息请参见ICU Collation: Comparison Levels。默认是non-ignorable的. maxVariable string 可能的. 当alternate:”shift时，决定哪些字符被认为是可忽略的字段。如果alternate: non-ignorable没有任何影响.值可能是:值 描述\"punct\" 空格和标点符号都是“可忽略的”，即:不考虑基本字符。\"space\" 空格是“可忽略的”，即:不考虑基本字符。 backwards boolean 可选的。确定带有变音符号的字符串是否从字符串后面排序的标志，例如使用法语字典排序。如果为 true, 从后面到前面比较。如果为 false, 从前面到后面进行比较。默认值是false。 normalization boolean 可选的。决定是否检查文本是否需要标准化以及是否执行标准化的标志。通常，大多数文本不需要这种规范化处理。如果为 true, 检查是否完全标准化，并执行标准化来比较文本。如果为 false, 不检查。默认值是false。有关详细信息，请参阅http://userguide.icu-project.org/collation/conceptsTOC-Normalization。 支持排序的操作 您可以为以下操作指定排序规则: 注意 不能为操作指定多个排序规则。例如，不能为每个字段指定不同的排序规则，如果使用排序执行查找，则不能对查找使用一个排序规则，对排序使用另一个排序规则。 命令 mongo Shell 方法 create db.createCollection()db.createView() createIndexes db.collection.createIndex() aggregate db.collection.aggregate() distinct db.collection.distinct() findAndModify db.collection.findAndModify()db.collection.findOneAndDelete()db.collection.findOneAndReplace()db.collection.findOneAndUpdate() find cursor.collation() 指定排序 db.collection.find() mapReduce db.collection.mapReduce() delete db.collection.deleteOne()db.collection.deleteMany()db.collection.remove() update db.collection.update()db.collection.updateOne(),db.collection.updateMany(),db.collection.replaceOne() shardCollection sh.shardCollection() count db.collection.count() db.collection.bulkWrite()中的个别更新、替换和删除操作 行为 局部变量 一些排序区域有变量，它们使用特定于语言的规则。要指定语言环境变量，请使用以下语法: { \"locale\" : \"@collation=\" } 例如，使用中文排序的unihan变体: { \"locale\" : \"zh@collation=unihan\" } 有关所有排序locale及其变量的完整列表，请参见排序locale。 排序和视图 您可以在创建时为视图指定一个默认的collation。如果没有指定排序，视图的默认排序规则是“简单”二进制比较排序。也就是说，视图不继承集合的默认排序。 视图上的字符串比较使用视图的默认排序。试图更改或覆盖视图默认排序规则的操作将失败并出现错误。 如果从另一个视图创建视图，则不能指定与源视图的排序不同的排序。 如果执行涉及多个视图的聚合，例如使用$lookup或$graphLookup，视图必须具有相同的collation。 排序和索引的使用 若要使用索引进行字符串比较，操作还必须指定相同的排序。也就是说，如果索引指定了不同的排序，则具有排序的索引不能支持对索引字段执行字符串比较的操作。 例如，集合myColl 在字符串字段category 上有一个索引，其排序区域设置为\"fr\" 。 db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) 下面的查询操作指定了与索引相同的排序，可以使用索引: db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) 但是，以下查询操作，默认使用“simple”二进制排序器，不能使用索引: db.myColl.find( { category: \"cafe\" } ) 对于索引前缀键不是字符串、数组和嵌入文档的复合索引，指定不同排序规则的操作仍然可以使用索引来支持对索引前缀键的比较。 例如，集合myColl在数值字段score和price以及字符串字段category上有一个复合索引;索引是用collation locale \"fr\"创建的，用于字符串比较: db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) 以下使用\"simple\"二进制排序来进行字符串比较的操作可以使用索引: db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) 下面的操作使用\"simple\"二进制排序来对索引的category字段进行字符串比较，可以使用索引来完成查询的score: 5部分: db.myColl.find( { score: 5, category: \"cafe\" } ) 排序和不支持的索引类型 以下索引只支持简单的二进制比较，不支持collation: 文字索引 2d索引 geoHaystack索引。 提示 要在具有非简单排序规则的集合上创建text、2d或geoHaystack索引，必须在创建索引时显式指定{collation: {locale: \"simple\"}}。 译者：李冠飞 校对： 参见 原文 - Collation Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/11-collation/01-collation-locales-defaults.html":{"url":"16-reference/11-collation/01-collation-locales-defaults.html","title":"排序区域和默认参数","keywords":"","body":" 排序区域和默认参数 在本页面 行为 支持的语言和语言环境 排序默认参数 3.4版本新增. Collation允许用户为字符串比较指定特定于语言的规则，比如字母大小写和重音符号的规则。 行为 一些排序区域有变体，它们使用特定于语言的规则。要指定语言环境变量，请使用以下语法: { \"locale\" : \"@collation=\" } 例如，使用中文排序的unihan变体: { \"locale\" : \"zh@collation=unihan\" } 查看排序规则页面获取排序行为和语法的完整描述。 支持的语言和语言环境 MongoDB的排序特性支持以下语言。下表列出了ICU语言环境ID所定义的受支持的语言和相关的语言环境。 语言 Locale Variants Afrikaans af Albanian sq Amharic am Arabic ar compat Armenian hy Assamese as Azeri az search Bengali bn Belarusian be Bengali bn traditional Bosnian bs search Bosnian (Cyrillic) bs_Cyrl Bulgarian bg Burmese my Catalan ca search Cherokee chr Chinese zh big5han``gb2312han``unihan``zhuyin Chinese (Traditional) zh_Hant Croatian hr search Czech cs search Danish da search Dutch nl Dzongkha dz English en English (United States) en_US English (United States, Computer) en_US_POSIX Esperanto eo Estonian et Ewe ee Faroese fo Filipino fil Finnish fi search``traditional French fr French (Canada) fr_CA Galician gl search Georgian ka German de search``eor``phonebook German (Austria) de_AT phonebook Greek el Gujarati gu Hausa ha Hawaiian haw Hebrew he search Hindi hi Hungarian hu Icelandic is search Igbo ig Inari Sami smn search Indonesian id Irish ga Italian it Japanese ja unihan Language Locale Variants Kalaallisut kl search Kannada kn traditional Kazakh kk Khmer km Konkani kok Korean ko search``searchjl``unihan Kyrgyz ky Lakota lkt Lao lo Latvian lv Lingala ln phonetic Lithuanian lt Lower Sorbian dsb Luxembourgish lb Macedonian mk Malay ms Malayalam ml Maltese mt Marathi mr Mongolian mn Nepali ne Northern Sami se search Norwegian Bokmål nb search Norwegian Nynorsk nn search Oriya or Oromo om Pashto ps Persian fa Persian (Afghanistan) fa_AF Polish pl Portuguese pt Punjabi pa Romanian ro Russian ru Serbian sr Serbian (Latin) sr_Latn search Sinhala si dictionary Slovak sk search Slovenian sl Spanish es search``traditional Swahili sw Swedish sv search Tamil ta Telugu te Thai th Tibetan bo Tongan to Turkish tr search Ukrainian uk Upper Sorbian hsb Urdu ur Uyghur ug Vietnamese vi traditional Walser wae Welsh cy Yiddish yi search Yoruba yo Zulu zu 提示 要显式指定简单二进制比较，请将locale值指定为simple。 排序默认参数 除了必需的locale参数外，一个排序文档还包含几个可选参数。根据您使用的“locale”，默认参数可能会有所不同。查看排序页面获取排序语法的完整描述。 以下默认参数在所有地区都是一致的: caseLevel : false strength : 3 numericOrdering : false maxVariable : punct 下表显示了默认的排序规则参数，这些参数可能会因不同的地区而不同: 语言环境 caseFirst 替换 normalization backwards af off non-ignorable FALSE FALSE sq off non-ignorable FALSE FALSE am off non-ignorable FALSE FALSE ar off non-ignorable FALSE FALSE ar@collation=compat off non-ignorable FALSE FALSE hy off non-ignorable FALSE FALSE as off non-ignorable TRUE FALSE az off non-ignorable FALSE FALSE az@collation=search off non-ignorable TRUE FALSE be off non-ignorable FALSE FALSE bn off non-ignorable TRUE FALSE bn@collation=traditional off non-ignorable TRUE FALSE bs off non-ignorable FALSE FALSE bs@collation=search off non-ignorable TRUE FALSE bs_Cyrl off non-ignorable FALSE FALSE bg off non-ignorable FALSE FALSE my off non-ignorable TRUE FALSE ca off non-ignorable FALSE FALSE ca@collation=search off non-ignorable TRUE FALSE chr off non-ignorable FALSE FALSE zh off non-ignorable FALSE FALSE zh@collation=big5han off non-ignorable FALSE FALSE zh@collation=gb2312han off non-ignorable FALSE FALSE zh@collation=unihan off non-ignorable FALSE FALSE zh@collation=zhuyin off non-ignorable FALSE FALSE zh_Hant off non-ignorable FALSE FALSE hr off non-ignorable FALSE FALSE hr@collation=search off non-ignorable TRUE FALSE cs off non-ignorable FALSE FALSE cs@collation=search off non-ignorable TRUE FALSE da upper non-ignorable FALSE FALSE da@collation=search off non-ignorable TRUE FALSE nl off non-ignorable FALSE FALSE dz off non-ignorable FALSE FALSE en off non-ignorable FALSE FALSE en_US_POSIX off non-ignorable FALSE FALSE en_US off non-ignorable FALSE FALSE eo off non-ignorable FALSE FALSE et off non-ignorable FALSE FALSE ee off non-ignorable FALSE FALSE fo off non-ignorable FALSE FALSE fo@collation=search off non-ignorable TRUE FALSE fil off non-ignorable FALSE FALSE fi off non-ignorable FALSE FALSE fi@collation=search off non-ignorable TRUE FALSE fi@collation=traditional off non-ignorable FALSE FALSE fr off non-ignorable FALSE FALSE fr_CA off non-ignorable FALSE TRUE gl off non-ignorable FALSE FALSE gl@collation=search off non-ignorable TRUE FALSE ka off non-ignorable FALSE FALSE de off non-ignorable FALSE FALSE de@collation=search off non-ignorable TRUE FALSE de@collation=phonebook off non-ignorable FALSE FALSE de@collation=eor off non-ignorable FALSE FALSE de_AT off non-ignorable FALSE FALSE de_AT@collation=phonebook off non-ignorable FALSE FALSE el off non-ignorable TRUE FALSE gu off non-ignorable TRUE FALSE ha off non-ignorable FALSE FALSE haw off non-ignorable FALSE FALSE he off non-ignorable TRUE FALSE he@collation=search off non-ignorable TRUE FALSE hi off non-ignorable TRUE FALSE hu off non-ignorable FALSE FALSE is off non-ignorable FALSE FALSE is@collation=search off non-ignorable TRUE FALSE ig off non-ignorable TRUE FALSE smn off non-ignorable FALSE FALSE smn@collation=search off non-ignorable TRUE FALSE id off non-ignorable FALSE FALSE ga off non-ignorable FALSE FALSE it off non-ignorable FALSE FALSE ja off non-ignorable FALSE FALSE ja@collation=unihan off non-ignorable FALSE FALSE kl off non-ignorable FALSE FALSE kl@collation=search off non-ignorable TRUE FALSE kn off non-ignorable TRUE FALSE kn@collation=traditional off non-ignorable TRUE FALSE kk off non-ignorable FALSE FALSE km off non-ignorable TRUE FALSE kok off non-ignorable TRUE FALSE ko off non-ignorable FALSE FALSE ko@collation=search off non-ignorable TRUE FALSE ko@collation=searchjl off non-ignorable TRUE FALSE ko@collation=unihan off non-ignorable FALSE FALSE ky off non-ignorable FALSE FALSE lkt off non-ignorable FALSE FALSE lo off non-ignorable FALSE FALSE lv off non-ignorable FALSE FALSE ln off non-ignorable FALSE FALSE ln@collation=phonetic off non-ignorable FALSE FALSE lt off non-ignorable FALSE FALSE dsb off non-ignorable FALSE FALSE lb off non-ignorable FALSE FALSE mk off non-ignorable FALSE FALSE ms off non-ignorable FALSE FALSE ml off non-ignorable FALSE FALSE mt upper non-ignorable FALSE FALSE mr off non-ignorable TRUE FALSE mn off non-ignorable FALSE FALSE ne off non-ignorable FALSE FALSE se off non-ignorable FALSE FALSE se@collation=search off non-ignorable TRUE FALSE nb off non-ignorable FALSE FALSE nb@collation=search off non-ignorable TRUE FALSE nn off non-ignorable FALSE FALSE nn@collation=search off non-ignorable TRUE FALSE or off non-ignorable TRUE FALSE om off non-ignorable FALSE FALSE ps off non-ignorable TRUE FALSE fa off non-ignorable TRUE FALSE fa_AF off non-ignorable TRUE FALSE pl off non-ignorable FALSE FALSE pt off non-ignorable FALSE FALSE pa off non-ignorable TRUE FALSE ro off non-ignorable FALSE FALSE ru off non-ignorable FALSE FALSE sr off non-ignorable FALSE FALSE sr_Latn off non-ignorable FALSE FALSE sr_Latn@collation=search off non-ignorable TRUE FALSE si off non-ignorable TRUE FALSE si@collation=dictionary off non-ignorable TRUE FALSE sk off non-ignorable FALSE FALSE sk@collation=search off non-ignorable TRUE FALSE sl off non-ignorable FALSE FALSE es off non-ignorable FALSE FALSE es@collation=search off non-ignorable TRUE FALSE es@collation=traditional off non-ignorable FALSE FALSE sw off non-ignorable FALSE FALSE sv off non-ignorable FALSE FALSE sv@collation=search off non-ignorable TRUE FALSE ta off non-ignorable TRUE FALSE te off non-ignorable TRUE FALSE th off shifted TRUE FALSE bo off non-ignorable FALSE FALSE to off non-ignorable FALSE FALSE tr off non-ignorable FALSE FALSE tr@collation=search off non-ignorable TRUE FALSE uk off non-ignorable FALSE FALSE hsb off non-ignorable FALSE FALSE ur off non-ignorable FALSE FALSE ug off non-ignorable FALSE FALSE vi off non-ignorable TRUE FALSE vi@collation=traditional off non-ignorable TRUE FALSE wae off non-ignorable FALSE FALSE cy off non-ignorable FALSE FALSE yi off non-ignorable TRUE FALSE yi@collation=search off non-ignorable TRUE FALSE yo off non-ignorable TRUE FALSE zu off non-ignorable FALSE FALSE 参见 原文 - Collation Locales and Default Parameters Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/12-mongodb-wire-protocol.html":{"url":"16-reference/12-mongodb-wire-protocol.html","title":"MongoDB的Wire协议","keywords":"","body":" MongoDB的Wire协议 在本页面 介绍 TCP / IP套接字 消息类型和格式 标准消息头 客户端请求消息 数据库响应消息 介绍 MongoDB有线协议是一个简单的基于套接字的请求-响应风格的协议。客户端通过一个常规的TCP/IP套接字与数据库服务器通信。 TCP / IP套接字 客户机应该使用常规的TCP/IP套接字连接到数据库。没有连接握手。 Port 实例mongod和mongos的默认端口号是27017。mongod和mongos的xw端口号是可配置的，可能会有所不同。 字节次序 MongoDB线路协议中的所有整数都使用little-end字节顺序:也就是说，最低有效字节优先。 消息类型和格式 有两种类型的消息:客户机请求和数据库响应。 注意 该页面使用类似于C的struct形式描述消息结构。 本文档中使用的类型(cstring、int32等)与BSON规范中定义的类型相同。 为了表示重复，文档使用了来自BSON规范的星号符号。例如，int64*表示可以将一个或多个指定类型依次写入套接字。 标准的消息标题类型为MsgHeader。整型常量用大写字母表示(例如:0表示整数值0)。 标准消息头 通常，每个消息由一个标准消息头和特定于请求的数据组成。标准消息头的结构如下: struct MsgHeader { int32 messageLength; // total message size, including this int32 requestID; // identifier for this message int32 responseTo; // requestID from the original request // (used in responses from db) int32 opCode; // request type - see table below for details } 字段 Description messageLength 消息的总大小，以字节为单位。这个总数包括保存消息长度的4个字节。 requestID 客户端或数据库生成的唯一标识符，用于标识此消息。客户端生成的消息(如OP_QUERY和OP_GET_MORE),它将返回的“幻想”字段OP_REPLY消息。客户端可以使用 requestID 和 responseTo 字段将查询响应与原始查询关联起来。 responseTo 从数据库的消息这将是从客户机的OP_QUERY或OP_GET_MORE消息中提取的 requestID。客户端可以使用 requestID 和 responseTo 字段将查询响应与原始查询关联起来。 opCode 类型的消息。详细信息请参见请求操作码。 请求操作码 注意 启动MongoDB 2.6和maxWireVersion3,MongoDB使用数据库命令插入,更新,和删除而不是OP_INSERT,OP_UPDATE和OP_DELETE公认写。大多数驱动程序继续对未确认的写操作使用操作码。 在4.2版本中，MongoDB删除了内部不赞成的OP_COMMAND和OP_COMMANDREPLY协议。 以下是支持的操作码: 操作码的名字 值 评论 OP_REPLY 1 响应客户端请求。responseTo被设置 OP_UPDATE 2001 更新文档。 OP_INSERT 2002 插入新文档。 RESERVED 2003 以前用于OP_GET_BY_OID。 OP_QUERY 2004 查询集合。 OP_GET_MORE 2005 从查询中获取更多数据。看到游标。 OP_DELETE 2006 删除文件。 OP_KILL_CURSORS 2007 通知数据库客户机已经使用完游标。 OP_MSG 2013 使用MongoDB 3.6中引入的格式发送消息。 客户端请求消息 客户端可以发送除OP_REPLY之外的所有操作码的请求消息。OP_REPLY为数据库保留使用。 只有OP_QUERY和OP_GET_MORE消息会导致数据库的响应。将不会发送任何其他消息的响应。 您可以使用getLastError命令确定消息是否成功。 OP_UPDATE OP_UPDATE消息用于更新集合中的文档。OP_UPDATE消息的格式如下: struct OP_UPDATE { MsgHeader header; // standard message header int32 ZERO; // 0 - reserved for future use cstring fullCollectionName; // \"dbname.collectionname\" int32 flags; // bit vector. see below document selector; // the query to select the document document update; // specification of the update to perform } 字段 Description header 消息头，正如在标准消息头中描述的那样。 ZERO 整数值为0。留作将来使用。 fullCollectionName 完整的集合名称;即名称空间。完整的集合名称是数据库名称与集合名称的连接，使用a.为了连接。例如，对于数据库foo和集合bar，完整的集合名称是foo.bar。 flags 位向量，用于指定操作的标志。位值对应如下:0对应于插入。如果设置，没有找到匹配的文档，数据库将把提供的对象插入到集合中.1对应于多数插入。如果设置，数据库将更新集合中所有匹配的对象。否则只更新第一个匹配的文档。2--31 保留。必须设置为0。 selector BSON文档，为选择要更新的文档指定查询。 update 指定要执行的更新的BSON文档。有关指定更新的信息，请参阅MongoDB手册中的Update Operations文档。 没有对OP_UPDATE消息的响应。 OP_INSERT OP_INSERT消息用于将一个或多个文档插入到集合中。OP_INSERT消息的格式为 struct { MsgHeader header; // standard message header int32 flags; // bit vector - see below cstring fullCollectionName; // \"dbname.collectionname\" document* documents; // one or more documents to insert into the collection } 字段 Description header 消息头，正如在标准消息头中描述的那样。 flags 位向量，用于指定操作的标志。位值对应如下:0对应于ContinueOnError。如果设置了该设置，那么如果大容量插入失败(例如由于id重复)，数据库将不会停止处理。 这使得大容量插入的行为类似于一系列单个插入，只是如果任何插入失败(而不仅仅是最后一个插入失败)将设置lastError。如果出现多个错误，getLastError只报告最近的错误。(新1.9.1)1--31 保留。必须设置为0. fullCollectionName 完整的集合名称;即名称空间。 完整的集合名称是数据库名称与集合名称的连接，使用a.为了连接. 例如, 对于数据库foo和集合bar，完整的集合名称是foo.bar。 documents 要插入到集合中的一个或多个文档。如果有多个，则依次将它们写入套接字。 没有对OP_INSERT消息的响应。 OP_QUERY OP_QUERY消息用于在数据库中查询集合中的文档。OP_QUERY消息的格式为: struct OP_QUERY { MsgHeader header; // standard message header int32 flags; // bit vector of query options. See below for details. cstring fullCollectionName ; // \"dbname.collectionname\" int32 numberToSkip; // number of documents to skip int32 numberToReturn; // number of documents to return // in the first OP_REPLY batch document query; // query object. See below for details. [ document returnFieldsSelector; ] // Optional. Selector indicating the fields // to return. See below for details. } 字段 Description header 消息头，正如在标准消息头中描述的那样。 flags 位向量，用于指定操作标志。这些位值对应于以下内容：0被预定了。必须设置为0。 1对应于TailableCursor。可拖尾表示检索到最后一个数据时光标未关闭。而是，光标标记最终对象的位置。如果收到更多数据，您可以稍后从其所在位置继续使用光标。像任何“潜在游标”一样，游标可能会在某个时候失效（CursorNotFound）–例如，如果删除了它所引用的最终对象。 2对应于SlaveOk。允许查询副本从属。通常，这些返回错误，但名称空间“ local”除外。 3对应于OplogReplay。从MongoDB 4.4开始，您无需指定此标志，因为优化是针对oplog上的合格查询自动进行的。有关更多信息，请参见 oplogReplay。 4对应于NoCursorTimeout。服务器通常在闲置时间（10分钟）后使空闲游标超时，以防止过多使用内存。设置此选项可以防止这种情况。 5对应于AwaitData。与TailableCursor一起使用。如果我们在数据的末尾，请阻塞一会而不是不返回任何数据。超时后，我们照常返回。 6对应于排气。假设客户端将完全读取所有查询的数据，则将数据以多个“更多”包的形式完整传输。当您提取大量数据并知道要全部提取时，速度更快。注意：除非客户端关闭连接，否则不允许客户端不读取所有数据。 7对应于部分。如果某些分片发生故障，则从mongos获得部分结果（而不是引发错误） 8- 31保留。必须设置为0。 fullCollectionName 完整的集合名称;即名称空间。完整的集合名称是数据库名称与集合名称的连接，使用a.为了连接。例如，对于数据库foo和集合bar，完整的集合名称是foo.bar。 numberToSkip 在返回查询结果时，设置要省略的文档数量—从结果数据集中的第一个文档开始。 numberToReturn 限制第一个OP_REPLY消息中查询的文档数量。但是，如果结果多于numberToReturn，数据库仍然会建立一个游标并返回cursorID给客户端。如果客户端驱动程序提供了limit功能(如SQL limit关键字)，那么由客户端驱动程序来确保返回给调用应用程序的文档数量不超过指定的数量。如果numberToReturn是0，db将使用默认的返回大小。如果数字是负数，那么数据库将返回该数字并关闭游标。无法获取该查询的进一步结果。如果numberToReturn是1，服务器将把它视为-1(自动关闭光标)。 query 表示查询的BSON文档。查询将包含一个或多个元素，所有元素都必须匹配才能包含在结果集中的文档。可能的元素包括$query、$orderby、$hint和$explain。 returnFieldsSelector 可选的。限制返回文档中的字段的BSON文档。returnFieldsSelector包含一个或多个元素，每个元素是应该返回的字段的名称，以及整数值1。在JSON表示法中，限制为a、b和c的returnFieldsSelector将是:{ a : 1, b : 1, c : 1} 数据库将用一个OP_REPLY消息响应一个OP_QUERY消息。 OP_GET_MORE OP_GET_MORE消息用于在数据库中查询集合中的文档。OP_GET_MORE消息的格式为: struct { MsgHeader header; // standard message header int32 ZERO; // 0 - reserved for future use cstring fullCollectionName; // \"dbname.collectionname\" int32 numberToReturn; // number of documents to return int64 cursorID; // cursorID from the OP_REPLY } Field Description header 消息头，正如在标准消息头中描述的那样。 ZERO 整数值为0。留作将来使用。 fullCollectionName 完整的集合名称;即名称空间。完整的集合名称是数据库名称与集合名称的连接，使用a.为了连接。例如，对于数据库foo和集合bar，完整的集合名称是foo.bar。 numberToReturn 限制第一个OP_REPLY消息中查询的文档数量。但是，如果结果多于numberToReturn，数据库仍然会建立一个游标并返回cursorID给客户端。如果客户端驱动程序提供了limit功能(如SQL limit关键字)，那么由客户端驱动程序来确保返回给调用应用程序的文档数量不超过指定的数量。如果numberToReturn是0，db将使用默认的返回大小。 cursorID 在OP_REPLY中的光标标识符。这必须是来自数据库的值。 数据库将用一个OP_REPLY消息响应一个OP_GET_MORE消息。 OP_DELETE OP_DELETE消息用于从集合中删除一个或多个文档。OP_DELETE消息的格式为: struct { MsgHeader header; // standard message header int32 ZERO; // 0 - reserved for future use cstring fullCollectionName; // \"dbname.collectionname\" int32 flags; // bit vector - see below for details. document selector; // query object. See below for details. } 字段 Description header 消息头，正如在标准消息头中描述的那样。 ZERO 整数值为0。留作将来使用。 fullCollectionName 完整的集合名称;即名称空间。完整的集合名称是数据库名称与集合名称的连接，使用a.为了连接。例如，对于数据库foo和集合bar，完整的集合名称是foo.bar。 flags 位向量，用于指定操作的标志。位值对应如下:0对应于SingleRemove。如果设置，数据库将只删除集合中第一个匹配的文档。否则，所有匹配的文件将被删除。1--31保留。必须设置为0。 selector 表示用于选择要删除的文档的查询的BSON文档。选择器将包含一个或多个元素，所有元素必须匹配才能从集合中删除文档。 没有对OP_DELETE消息的响应。 OP_KILL_CURSORS OP_KILL_CURSORS消息用于关闭数据库中的活动游标。这对于确保在查询结束时回收数据库资源是必要的。OP_KILL_CURSORS消息的格式为: struct { MsgHeader header; // standard message header int32 ZERO; // 0 - reserved for future use int32 numberOfCursorIDs; // number of cursorIDs in message int64* cursorIDs; // sequence of cursorIDs to close } 字段 Description header 消息头，正如在标准消息头中描述的那样。 ZERO 整数值为0。留作将来使用。 numberOfCursorIDs 消息中游标id的数量。 cursorIDs 要关闭的游标id的“数组”。如果有多个，则依次将它们写入套接字。 如果游标读取,直到耗尽(读,直到OP_QUERY或OP_GET_MORE返回0光标id),不需要杀死光标。 OP_MSG 新版本MongoDB: 3.6 OP_MSG是一种可扩展的消息格式，旨在包含其他操作码的功能。此操作码的格式如下: OP_MSG { MsgHeader header; // standard message header uint32 flagBits; // message flags Sections[] sections; // data sections optional checksum; // optional CRC-32C checksum } 字段 Description header 标准消息头，如标准消息头中所述。 flagBits 一个包含消息标志的整数位掩码，如Flag Bits中所述。 sections 消息主体部分，如部分所述。 checksum 一个可选的CRC-32C校验和，如checksum中所述。 标志位 整数flagBits是位掩码编码标志，用于修改 OP_MSG 的格式和行为。 前16位(0-15)是必须的，如果设置了未知位，解析器一定会出错。 最后16位(16-31)是可选的，解析器一定会忽略任何未知的设置位。代理和其他消息转代必须在转发消息之前清除任何未知的可选位。 位 Name 请求 Response Description 0 checksumPresent ✓ ✓ 消息以包含CRC-32C校验和的4个字节结束。详细信息请参见Checksum。 1 moreToCome ✓ ✓ 另一条消息将跟随此消息而不需要接收者采取进一步的操作。接收方在接收到moreToCome设置为0的消息之前，不能再发送另一条消息，因为发送可能会阻塞，导致死锁。带有moreToCome位集的请求将不会收到回复。对于设置了“exhaustAllowed”位的请求，应答将只有此设置。 16 exhaustAllowed ✓ 客户端已经准备好使用moreToCome位来多次响应此请求。除非请求设置了这个位，否则服务器将永远不会产生设置了moreToCome位的响应。这确保了只有当请求者的网络层为它们准备好时，多个响应才会被发送。重要:MongoDB 3.6会忽略这个标志，并以一条消息响应。 部分 一个OP_MSG消息包含一个或多个部分。每个节以表示其类型的kind字节开始。kind字节之后的所有内容构成了节的有效负载。 下面是可用的部分类型。 Kind 0: 身体 主体部分被编码为一个单个 BSON对象。BSON对象中的大小也用作部分的大小。本节类是标准命令请求和应答体。 所有顶级字段必须有一个唯一的名称。 Kind 1: 文档顺序 Type Description int32 节的大小，以字节为单位。 C String 文档序列标识符。在当前的所有命令中，这个字段是它从主体部分替换的(可能是嵌套的)字段.这个字段不能也存在于body部分中. Zero or more BSON objects 不使用分隔符对对象进行反向排序。每个对象被限制为服务器的maxBSONObjectSize。所有对象的组合并不局限于maxBSONObjSize。文档序列在消耗完size字节后结束。在转换为语言级对象时，解析器可以选择将这些对象作为数组合并到主体中，并将其作为序列标识符指定的路径。 Checksum 每个消息可能以CRC-32CChecksum结束，它涵盖了消息中除了Checksum本身之外的所有字节。 从MongoDB 4.2开始: 如果不使用TLS/SSL连接，mongod实例、mongos实例和mongo shell实例将使用Checksum交换消息。 如果使用TLS/SSL连接，mongod 实例、 mongos实例和 mongo shell实例将跳过Checksum。 如果显示带有Checksum的消息，驱动程序和较老的二进制文件将忽略Checksum。 Checksum的存在是由checksumPresent标志位来表示的。 数据库响应消息 OP_REPLY OP_REPLY消息由数据库发送，以响应一个OP_QUERY或OP_GET_MORE消息。OP_REPLY消息的格式为: struct { MsgHeader header; // standard message header int32 responseFlags; // bit vector - see details below int64 cursorID; // cursor id if client needs to do get more's int32 startingFrom; // where in the cursor this reply is starting int32 numberReturned; // number of documents in the reply document* documents; // documents } Field Description header 消息头，正如在标准消息头中描述的那样。 responseFlags 指定标志的位向量。位值对应如下:0对应于CursorNotFound。在调用 getMore 时设置，但游标id在服务器上无效。返回的结果为零。1对应于QueryFailure。查询失败时设置。结果包含一个文档，其中包含描述失败的“$err”字段。2对应于ShardConfigStale。驱动程序应该忽略这一点。只有mongos会看到这个设置，在这种情况下，它需要从服务器更新配置。3对应于awaitable。当服务器支持AwaitData查询选项时设置。如果没有，客户端应该在可定制游标的getMore之间稍作休息。Mongod 1.6版本支持AwaitData，因此总是设置AwaitCapable。4--31保留。忽视。 cursorID OP_REPLY所属的 cursorID 。如果查询的结果集能放入一个OP_REPLY消息中，' cursorID '将为0。这种cursorID必须使用在任何OP_GET_MORE消息用于获取更多的数据,也不再需要时,必须关闭客户端通过一个OP_KILL_CURSORS消息。 startingFrom 光标的起始位置。 numberReturned 回复文件的数量。 documents 返回的文档。 参见 原文 - MongoDB Wire Protocol Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/13-log-messages.html":{"url":"16-reference/13-log-messages.html","title":"日志消息","keywords":"","body":" 日志消息 在本页面 概述 结构化日志 日志消息字段类型 详细程度 解析结构化日志消息 日志消息示例 概述 作为正常操作的一部分，MongoDB维护事件的运行日志，包括传入的连接、运行的命令和遇到的问题等条目。通常，日志消息对于诊断问题、监视部署和调优性能非常有用。 结构化日志 在MongoDB 4.4开始,mongod /mongos实例中所有日志消息输出结构化的JSON格式。日志条目以一系列键值对的形式写入，其中每个键表示一个日志消息字段类型，比如“severity”，而每个对应的值记录该字段类型的相关日志信息，比如“information”。以前，日志条目是以明文输出的。 例子 以下是一个示例日志消息在JSON格式，因为它将出现在MongoDB日志文件: {\"t\":{\"$date\":\"2020-05-01T15:16:17.180+00:00\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":12345, \"ctx\":\"listener\", \"msg\":\"Listening on\",\"attr\":{\"address\":\"127.0.0.1\"}} JSON日志条目可以完美打印以提高可读性。下面是相同的日志条目，打印得很整洁: { \"t\": { \"$date\": \"2020-05-01T15:16:17.180+00:00\" }, \"s\": \"I\", \"c\": \"NETWORK\", \"id\": 12345, \"ctx\": \"listener\", \"msg\": \"Listening on\", \"attr\": { \"address\": \"127.0.0.1\" } } 例如，在这个日志条目中，代表严重性的键s具有相应的值I，表示severity，而表示component的键c具有相应的值NETWORK，表示“网络”组件负责该特定消息。日志消息字段类型部分详细介绍了各种字段类型。 具有键值对的结构化日志记录允许通过自动化工具或日志摄入量服务进行高效解析，并使日志消息的编程搜索和分析更容易执行。分析结构化日志消息的示例可以在解析结构化日志消息小节中找到。 JSON日志输出格式 在MongoDB 4.4中，所有日志输出现在都是JSON格式。这包括日志输出文件发送到 syslog 和 stdout (标准输出)log destinations,以及getLog的输出命令。 每个日志条目作为一个自包含的JSON对象输出，遵循放宽扩展JSON v2.0规范，并有以下布局和字段顺序: { \"t\": , // timestamp \"s\": , // severity \"c\": , // component \"ctx\": , // context \"id\": , // unique identifier \"msg\": , // message body \"attr\": // additional attributes (optional) \"tags\": // tags (optional) \"truncated\": // truncation info (if truncated) \"size\": // original size of entry (if truncated) } 时间戳 - 日志消息的时间戳，ISO-8601格式。参见时间戳。 严重程度 - 表示日志消息的不足严重性代码的字符串。参见严重性。 组件 - 表示日志消息的完整组件字符串的字符串。参见组件。 上下文 - 表示发出日志语句的线程的名称的字符串。 id - 表示日志语句的唯一标识符的字符串。参见根据已知日志ID进行过滤以获得一个示例。 消息 - 表示从服务器或驱动程序传递的原始日志输出消息的字符串。该消息根据JSON规范根据需要进行转义。 属性 -(可选)对象，其中包含一个或多个键值对，用于提供任何附加属性。如果日志消息不包含任何附加属性，则省略此对象。属性值可以在消息正文中通过其键名引用，具体取决于消息。与message类似，属性根据JSON规范根据需要进行转义。 标签 - (可选)字符串数组，表示适用于日志语句的任何标记，例如:[startupWarnings]。 截断 - （如果被截断）对象，包含有关日志消息截断的信息（如果适用）。仅当日志条目包含至少一个被截断的属性时，此对象才会存在。 大小 - (如果被截断)整数，表示已被 截断的日志条目的原始大小。只有当日志条目包含至少一个被截断的属性时，该字段才会出现。 转译 根据放宽扩展JSON v2.0规范，message和属性字段将根据需要转译控制字符: 字符表示 转义序列 引号(\") \\\" 反斜杠 (\\) \\\\ 回退 (0x08) \\b 跳页 (0x0C) \\f 换行符 (0x0A) \\n 回车 (0x0D) \\r 水平选项卡 (0x09) \\t 上面没有列出的控制字符用 \\uXXXX 转义，其中 XXXX 是十六进制的unicode码点。UTF-8编码无效的字节被替换为 \\ufffd 表示的unicode替换字符。 examples提供了一个消息转译的示例。 截断 任何超过maxLogSizeKB定义的最大大小的属性(默认为10kb)被截断。被截断的属性省略了超出配置限制的日志数据，但是保留了条目的JSON格式，以确保条目仍然可解析。 下面是一个带有截断属性的日志条目示例: {\"t\":{\"$date\":\"2020-05-19T18:12:05.702+00:00\"},\"s\":\"I\", \"c\":\"SHARDING\", \"id\":22104, \"ctx\":\"conn33\", \"msg\":\"Received splitChunk request\",\"attr\":{\"request\":{\"splitChunk\":\"config.system.sessions\", \"from\":\"production-shard1\",\"keyPattern\":{\"_id\":1},\"epoch\":{\"$oid\":\"5ec42172996456771753a59e\"}, \"shardVersion\":[{\"$timestamp\":{\"t\":1,\"i\":0}},{\"$oid\":\"5ec42172996456771753a59e\"}],\"min\":{\"_id\":{\"$minKey\":1}}, \"max\":{\"_id\":{\"$maxKey\":1}},\"splitKeys\":[{\"_id\":{\"id\":{\"$uuid\":\"00400000-0000-0000-0000-000000000000\"}}}, {\"_id\":{\"id\":{\"$uuid\":\"00800000-0000-0000-0000-000000000000\"}}}, ... {\"_id\":{\"id\":{\"$uuid\":\"26c00000-0000-0000-0000-000000000000\"}}},{\"_id\":{}}]}}, \"truncated\":{\"request\":{\"splitKeys\":{\"155\":{\"_id\":{\"id\":{\"type\":\"binData\",\"size\":21}}}}}}, \"size\":{\"request\":46328}} In this case, the request attribute has been truncated and the specific instance of its subfield _id that triggered truncation (i.e. caused the attribute to overrun maxLogSizeKB) is printed without data as {\"_id\":{}}. The remainder of the request attribute is then omitted. 在本例中，request属性被截断，其子字段_id的特定实例触发了截断(即导致属性溢出maxLogSizeKB)被打印为{\"_id\":{}}，没有数据。然后省略request属性的其余部分。 包含一个或多个截断属性的日志实体包括一个truncated对象，该对象为日志条目中的每个截断属性提供以下信息: 被截断的属性 触发截断的属性的特定子对象(如果适用) 截断字段的数据类型 截断字段的大小 Log entries with truncated attributes may also include an additional size field at the end of the entry which indicates the original size of the attribute before truncation, in this case 46328 or about 46KB. This final size field is only shown if it is different from the size field in the truncated object, i.e. if the total object size of the attribute is different from the size of the truncated subobject, as is the case in the example above. 属性被截断的日志条目还可能在条目的末尾包含一个额外的size字段，该字段表示截断之前属性的原始大小，在本例中为46328或大约46KB。最后的size字段只在与truncated对象中的size字段不同的情况下显示，也就是说，如果属性的对象总大小与被截断的子对象的大小不同，就像上面的例子一样。 填充 当输出到file或syslog log目的地时，在severity、context和id字段之后添加填充，以增加固定宽度字体时的可读性。 下面的MongoDB日志文件摘录演示了这种填充: {\"t\":{\"$date\":\"2020-05-18T20:18:12.724+00:00\"},\"s\":\"I\", \"c\":\"CONTROL\", \"id\":23285, \"ctx\":\"main\",\"msg\":\"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'\"} {\"t\":{\"$date\":\"2020-05-18T20:18:12.734+00:00\"},\"s\":\"W\", \"c\":\"ASIO\", \"id\":22601, \"ctx\":\"main\",\"msg\":\"No TransportLayer configured during NetworkInterface startup\"} {\"t\":{\"$date\":\"2020-05-18T20:18:12.734+00:00\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":4648601, \"ctx\":\"main\",\"msg\":\"Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set tcpFastOpenServer, tcpFastOpenClient, and tcpFastOpenQueueSize.\"} {\"t\":{\"$date\":\"2020-05-18T20:18:12.814+00:00\"},\"s\":\"I\", \"c\":\"STORAGE\", \"id\":4615611, \"ctx\":\"initandlisten\",\"msg\":\"MongoDB starting\",\"attr\":{\"pid\":10111,\"port\":27001,\"dbPath\":\"/var/lib/mongo\",\"architecture\":\"64-bit\",\"host\":\"centos8\"}} {\"t\":{\"$date\":\"2020-05-18T20:18:12.814+00:00\"},\"s\":\"I\", \"c\":\"CONTROL\", \"id\":23403, \"ctx\":\"initandlisten\",\"msg\":\"Build Info\",\"attr\":{\"buildInfo\":{\"version\":\"4.4.0\",\"gitVersion\":\"328c35e4b883540675fb4b626c53a08f74e43cf0\",\"openSSLVersion\":\"OpenSSL 1.1.1c FIPS 28 May 2019\",\"modules\":[],\"allocator\":\"tcmalloc\",\"environment\":{\"distmod\":\"rhel80\",\"distarch\":\"x86_64\",\"target_arch\":\"x86_64\"}}}} {\"t\":{\"$date\":\"2020-05-18T20:18:12.814+00:00\"},\"s\":\"I\", \"c\":\"CONTROL\", \"id\":51765, \"ctx\":\"initandlisten\",\"msg\":\"Operating System\",\"attr\":{\"os\":{\"name\":\"CentOS Linux release 8.0.1905 (Core) \",\"version\":\"Kernel 4.18.0-80.11.2.el8_0.x86_64\"}}} 完美的印刷 当使用MongoDB结构化日志时，jq命令行实用程序是一个非常有用的工具，它允许轻松地打印日志条目，以及强大的基于密钥的匹配和过滤。 jq是一个开源的JSON解析器，可用于Linux、Windows和macOS。 您可以使用jq来编辑打印日志内容，如下所示: 完整打印日志文件: cat mongod.log | jq 完美地打印最近的日志条目: cat mongod.log | tail -1 | jq 更多使用MongoDB结构化日志的例子可以在解析结构化日志消息小节中找到。 配置日志消息目的地 MongoDB日志消息可以输出到file、syslog或stdout(标准输出)。 要配置日志输出目的地，使用以下设置之一，要么在配置文件或在命令行: 配置文件: file或syslog*的systemLog.destination选项 命令行: 文件的mongod 的--logpath选项 对于syslog, mongod 的--syslog选项 文件mongos的--logpath 选项 对于syslog, mongos的--syslog选项 不指定file或syslog将把所有日志输出发送到stdout。 有关日志设置和选项的完整列表，请参阅: 配置文件: systemLog选项列表 命令行: 为 mongod的日志选项列表 为mongos的日志选项列表 注意 Error messages sent to stderr (standard error), such as fatal errors during startup when not using the file or syslog log destinations, or messages having to do with misconfigured logging settings, are not affected by the log output destination setting, and are printed to stderr in plaintext format. 发送到stderr的错误消息(标准错误)，比如在启动时没有使用file或syslog日志目的地时发生的致命错误，或者与日志设置配置错误有关的消息，不受日志输出目的地设置的影响，并以明文格式打印到stderr。 日志消息字段类型 时间戳 timestamp字段类型表示所记录事件发生的确切日期和时间。 { \"t\": { \"$date\": \"2020-05-01T15:16:17.180+00:00\" }, \"s\": \"I\", \"c\": \"NETWORK\", \"id\": 12345, \"ctx\": \"listener\", \"msg\": \"Listening on\", \"attr\": { \"address\": \"127.0.0.1\" } } 当登录到file或syslog时，时间戳的默认格式是iso8601-local。修改时间戳格式,使用--timeStampFormat运行时选项或systemLog.timeStampFormat设置。 请参见按日期范围过滤，了解在时间戳字段上过滤的日志解析示例。 注意 从MongoDB 4.4开始，不再支持“ctime”时间戳格式。 严重程度 严重性字段类型指示与日志事件关联的严重性级别。 { \"t\": { \"$date\": \"2020-05-01T15:16:17.180+00:00\" }, \"s\": \"I\", \"c\": \"NETWORK\", \"id\": 12345, \"ctx\": \"listener\", \"msg\": \"Listening on\", \"attr\": { \"address\": \"127.0.0.1\" } } 严重级别从“致命”(最严重)到“调试”(最不严重): 标准 Description F Fatal E Error W Warning I 信息性，用于详细程度级别0 D1 - D5 从4.2版本开始，MongoDB指出了特定的调试详细级别。例如，如果冗余级别为2,MongoDB表示“D2”。在以前的版本中，MongoDB日志消息为所有调试冗长级别指定 D。 您可以指定各个组件的冗余级别，以确定MongoDB输出的信息和调试消息的数量。这些级别以上的严重性类别总是显示出来。设置详细级别，请参见配置日志详细级别。 组件 组件字段类型指示日志事件所属的类别，如NETWORK或COMMAND。 { \"t\": { \"$date\": \"2020-05-01T15:16:17.180+00:00\" }, \"s\": \"I\", \"c\": \"NETWORK\", \"id\": 12345, \"ctx\": \"listener\", \"msg\": \"Listening on\", \"attr\": { \"address\": \"127.0.0.1\" } } 每个组件都可以通过其自己的verbosity过滤器进行单独配置。可提供的组件如下: 访问 与访问控制相关的消息，如身份验证。要指定ACCESS组件的日志级别，使用systemLog.component.accessControl.verbosity设置。 命令 与数据库命令相关的消息，例如count。要指定COMMAND组件的日志级别，使用systemLog.component.command.verbosity设置。 控制 与控制活动(如初始化)相关的消息。要指定CONTROL组件的日志级别，使用systemLog.component.control.verbosity设置。 选举 与复制集选举相关的消息。若要指定选举组件的日志级别，请设置systemLog.component.replication.election.verbosity参数。 REPL是选举的父组件。如果systemLog.component.replication.election.verbosity未被设置，MongoDB对选举组件使用REPL 详细级别。 FTDC 新版本3.2。与诊断数据收集机制相关的消息，如服务器统计信息和状态消息。要指定FTDC组件的日志级别，使用systemLog.component.ftdc.verbosity设置。 GEO 与地理空间形状解析相关的消息，例如验证GeoJSON形状。要指定GEO组件的日志级别，请设置systemLog.component.geo.verbosity参数。 指数 与索引操作(如创建索引)相关的消息。要指定INDEX组件的日志级别，请设置systemLog.component.index.verbosity参数。 INITSYNC 与初始同步操作相关的消息。指定的日志级别INITSYNC组件,设置systemLog.component.replication.initialSync.verbosity参数. REPL是INITSYNC的父组件。如果systemLog.component.replication.initialSync.verbosity未被设置,MongoDB使用REPL REPL冗长水平INITSYNC组件。 日志 与存储日志记录活动相关的消息。要指定JOURNAL组件的日志级别，使用systemLog.component.storage.journal.verbosity设置。 STORAGE是JOURNAL的父组件。如果systemLog.component.storage.journal.verbosity未被设置,MongoDB使用存储冗长水平JOURNAL组件。 网络 与网络活动相关的消息，例如接受连接。要指定NETWORK组件的日志级别，请设置systemLog.component.network.verbosity参数。 查询 与查询相关的消息，包括查询规划器活动。要指定QUERY组件的日志级别，请设置systemLog.component.query.verbosity参数。 恢复 与存储恢复活动相关的消息。要指定RECOVERY组件的日志级别，使用systemLog.component.storage.recovery.verbosity设置。 STORAGE是RECOVERY的父组件。如果systemLog.component.storage.recovery.verbosity未被设置,MongoDB使用存储冗长水平恢复组件。 REPL 与复制集相关的消息，如初始同步、心跳、稳定状态复制和回滚。为REPL组件指定日志级别，设置systemLog.component.replication.verbosity参数。 REPL 的父组件选举, INITSYNC,REPL_HB和ROLLBACK组件。 REPL_HB 与复制集心跳相关的消息。指定的日志级别REPL_HB组件,设置systemLog.component.replication.heartbeats.verbosity参数。 REPL是REPL_HB的父组件。如果systemLog.component.replication.heartbeats.verbosity未被设置,MongoDB使用REPL REPL冗长水平REPL_HB组件。 回滚 与回滚操作相关的消息。指定的日志级别回滚组件,设置systemLog.component.replication.rollback.verbosity参数。 REPL是ROLLBACK的父组件。如果systemLog.component.replication.rollback.verbosity未被设置,MongoDB使用REPL 冗长水平回滚组件。 分片 与分片活动相关的消息，例如mongos的启动。要指定SHARDING组件的日志级别，使用systemLog.component.sharding.verbosity设置。 存储 与存储活动相关的消息，例如fsync命令所涉及的进程。要指定STORAGE组件的日志级别，使用systemLog.component.storage.verbosity设置。 STORAGE是JOURNAL和 RECOVERY的父组件。 TXN 新版本4.0.2. 与多文档事务相关的消息。要指定TXN组件的日志级别，使用systemLog.component.transaction.verbosity设置。 写 与写操作相关的消息，例如update命令。要指定WRITE组件的日志级别，使用systemLog.component.write.verbosity设置。 - 与命名组件不关联的消息。未命名组件在systemLog.verbosity设置中指定了默认的日志级别。systemLog.verbosity设置是已命名和未命名组件的默认设置。 客户端数据 MongoDB驱动程序和客户端应用程序(包括mongo shell)有能力在连接到服务器的时候发送识别信息。连接建立后，客户端不会再次发送标识信息，除非连接被删除并重新建立。 该标识信息包含在日志条目的attributes字段中。所包括的确切信息因客户端而异。 下面是一个示例日志消息，包含从一个mongo shell连接传输的客户端数据文档。客户端数据包含在 doc 对象的属性字段中: {\"t\":{\"$date\":\"2020-05-20T16:21:31.561+00:00\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":51800, \"ctx\":\"conn202\",\"msg\":\"client metadata\",\"attr\":{\"remote\":\"127.0.0.1:37106\",\"client\":\"conn202\",\"doc\":{\"application\":{\"name\":\"MongoDB Shell\"},\"driver\":{\"name\":\"MongoDB Internal Client\",\"version\":\"4.4.0\"},\"os\":{\"type\":\"Linux\",\"name\":\"CentOS Linux release 8.0.1905 (Core) \",\"architecture\":\"x86_64\",\"version\":\"Kernel 4.18.0-80.11.2.el8_0.x86_64\"}}}} 当replica set的次要成员初始化到主节点的连接时，它们发送类似的数据。包含此启动连接的日志消息示例如下所示。客户端数据包含在 doc 对象的属性字段中: {\"t\":{\"$date\":\"2020-05-20T16:33:40.595+00:00\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":51800, \"ctx\":\"conn214\",\"msg\":\"client metadata\",\"attr\":{\"remote\":\"127.0.0.1:37176\",\"client\":\"conn214\",\"doc\":{\"driver\":{\"name\":\"NetworkInterfaceTL\",\"version\":\"4.4.0\"},\"os\":{\"type\":\"Linux\",\"name\":\"CentOS Linux release 8.0.1905 (Core) \",\"architecture\":\"x86_64\",\"version\":\"Kernel 4.18.0-80.11.2.el8_0.x86_64\"}}}} 参见示例部分以获得一个显示客户端数据的格式打印示例。 有关客户端信息和必需字段的完整描述，请参见MongoDB握手规范。 详细程度 您可以指定日志记录冗余级别，以增加或减少MongoDB输出的日志消息数量。可以针对所有组件一起调整详细级别，也可以针对特定的已命名组件单独调整详细级别。 详细程度只影响severity类别information和Debug中的日志名称。这些级别以上的严重性类别总是显示出来。 您可以将冗余级别设置为高值，以显示用于调试或开发的详细日志记录，或设置为低值，以尽量减少对经过审查的生产部署上的日志的写操作。 查看当前日志的详细程度 要查看当前的详细级别，使用db.getLogComponents()方法: db.getLogComponents() 您的输出可能类似如下: { \"verbosity\" : 0, \"accessControl\" : { \"verbosity\" : -1 }, \"command\" : { \"verbosity\" : -1 }, ... \"storage\" : { \"verbosity\" : -1, \"recovery\" : { \"verbosity\" : -1 }, \"journal\" : { \"verbosity\" : -1 } }, ... 最初的冗长为所有组件条目父冗长水平,而个人命名组件,如accessControl,指示组件的特定详细级别,覆盖全球冗长的水平如果设置特定的组件。 值-1表示，如果组件有父组件的冗余级别(与上面的recovery一样，从storage继承)，则组件继承父组件的冗余级别，如果没有，则继承全局冗余级别(与command一样)。详细级别的继承关系在components部分中指明。 配置日志冗余级别 您可以配置使用冗长水平:systemLog.verbosity和 systemLog.component..verbosity 设置,logComponentVerbosity的参数,或db.setLogLevel()方法。 systemLog冗长的设置 要为所有组件配置默认的日志级别，使用systemLog.verbosity设置。要配置特定组件的级别，请使用 systemLog.component..verbosity 设置。 例如,下面的配置设置 systemLog.verbosity 冗长1,在systemLog.component.query.verbosity冗长2, systemLog.component.storage.verbosity冗长 2,和systemLog.component.storage.journal.verbosity到1: systemLog: verbosity: 1 component: query: verbosity: 2 storage: verbosity: 2 journal: verbosity: 1 你会设置这些值配置文件或在命令行上为你的mongod或mongos实例。 所有组件未指定明确的配置有一个冗长的1,表明他们继承冗长的父级,如果他们有一个,或全球冗长级别(systemLog.verbosity)如果他们不这样做。 logComponentVerbosity参数 要设置logComponentVerbosity参数，需要传递一个文档，其中包含要更改的冗长设置。 For example, the following sets the default verbosity level to 1, the query to 2, the storage to 2, and the storage.journal to 1. 例如,下面的设置默认的详细级别 冗长1,在‘查询’冗长2,storage冗长2 ,和storage.journal到1。 db.adminCommand( { setParameter: 1, logComponentVerbosity: { verbosity: 1, query: { verbosity: 2 }, storage: { verbosity: 2, journal: { verbosity: 1 } } } } ) 您可以从mongoshell中设置这些值。 db.setLogLevel() 使用db.setLogLevel()方法更新单个组件日志级别。对于组件，可以指定0到5的冗余级别，也可以指定-1来继承父组件的冗余。例如，下面将systemLog.component.query.verbosity设置为其父级的冗长(即默认冗长): db.setLogLevel(-1, \"query\") 您可以从mongoshell中设置该值。 日志记录操作缓慢 客户操作(例如查询)出现在日志如果他们的持续时间超过缓慢操作阈值或者日志详细级别是1或更高。这些日志条目包括与操作关联的完整命令对象。 从MongoDB 4.2开始，用于读/写操作的profiler条目和诊断日志消息(即mongod/mongos日志消息)包括: queryHash帮助识别具有相同查询形状的慢速查询。 planCacheKey为慢速查询提供了更多关于查询计划缓存的信息。 下面的示例输出包含一个缓慢的聚合操作的信息: {\"t\":{\"$date\":\"2020-05-20T20:10:08.731+00:00\"},\"s\":\"I\", \"c\":\"COMMAND\", \"id\":51803, \"ctx\":\"conn281\",\"msg\":\"Slow query\",\"attr\":{\"type\":\"command\",\"ns\":\"stocks.trades\",\"appName\":\"MongoDB Shell\",\"command\":{\"aggregate\":\"trades\",\"pipeline\":[{\"$project\":{\"ticker\":1.0,\"price\":1.0,\"priceGTE110\":{\"$gte\":[\"$price\",110.0]},\"_id\":0.0}},{\"$sort\":{\"price\":-1.0}}],\"allowDiskUse\":true,\"cursor\":{},\"lsid\":{\"id\":{\"$uuid\":\"fa658f9e-9cd6-42d4-b1c8-c9160fabf2a2\"}},\"$clusterTime\":{\"clusterTime\":{\"$timestamp\":{\"t\":1590005405,\"i\":1}},\"signature\":{\"hash\":{\"$binary\":{\"base64\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\",\"subType\":\"0\"}},\"keyId\":0}},\"$db\":\"test\"},\"planSummary\":\"COLLSCAN\",\"cursorid\":1912190691485054730,\"keysExamined\":0,\"docsExamined\":1000001,\"hasSortStage\":true,\"usedDisk\":true,\"numYields\":1002,\"nreturned\":101,\"reslen\":17738,\"locks\":{\"ReplicationStateTransition\":{\"acquireCount\":{\"w\":1119}},\"Global\":{\"acquireCount\":{\"r\":1119}},\"Database\":{\"acquireCount\":{\"r\":1119}},\"Collection\":{\"acquireCount\":{\"r\":1119}},\"Mutex\":{\"acquireCount\":{\"r\":117}}},\"storage\":{\"data\":{\"bytesRead\":232899899,\"timeReadingMicros\":186017},\"timeWaitingMicros\":{\"cache\":849}},\"protocol\":\"op_msg\",\"durationMillis\":22427}} 参见examples部分，以获得该日志条目的pretty- printing版本。 解析结构化日志消息 日志解析是通过编程方式搜索和分析日志文件的行为，通常采用自动化的方式。随着MongoDB 4.4中结构化日志的引入，日志解析变得更加简单和强大。例如: 日志消息字段以键值对的形式显示。日志解析器可以根据感兴趣的特定键进行查询，从而有效地筛选结果。 日志消息总是包含相同的消息结构。日志解析器可以可靠地从任何日志消息中提取信息，而不需要为信息丢失或格式不同的情况编写代码。 下面的示例演示使用MongoDB JSON日志输出时常见的日志解析工作流。 日志解析的例子 当使用MongoDB结构化日志时，jq命令行实用程序是一个非常有用的工具，它允许轻松地打印日志条目，以及强大的基于密钥的匹配和过滤。 jq是一个开源的JSON解析器，可用于Linux、Windows和macOS。 这些示例使用jq来简化日志解析。 计数独特的消息 下面的示例显示了给定日志文件中按频率排序的前10个唯一消息值: jq -r \".msg\" /var/log/mongodb/mongod.log | sort | uniq -c | sort -rn | head -10 监视连接 远程客户端连接显示在属性对象的“Remote”键下的日志中。下面将计算整个日志文件过程中的所有唯一连接，并按出现次数降序显示它们: jq -r '.attr.remote' /var/log/mongodb/mongod.log | grep -v 'null' | sort | uniq -c | sort -r 请注意，来自相同IP地址但通过不同端口连接的连接将被此命令视为不同的连接。您可以限制输出仅考虑IP地址，如下更改: jq -r '.attr.remote' /var/log/mongodb/mongod.log | grep -v 'null' | awk -F':' '{print $1}' | sort | uniq -c | sort -r 分析客户类型 下面的例子分析报告客户端数据 log-messages-client-data远程MongoDB驱动连接的客户机应用程序,包括 mongo shell,并打印每个独特的操作系统类型,总联系,按频率: jq -r '.attr.doc.os.type' /var/log/mongodb/mongod.log | grep -v null | sort | uniq -c | sort -rn 这个日志字段中报告的字符串“Darwin”表示macOS客户机。 慢速查询分析 启用了慢操作日志，下面只返回耗时超过2000毫秒的慢操作:，供进一步分析: jq '. | select(.attr.durationMillis>=2000)' /var/log/mongodb/mongod.log 查阅jq文档以获得更多关于本例中显示的jq过滤器的信息。 过滤已知的日志ID 日志id (JSON日志输出格式中的第5个字段)映射到特定的日志事件，可以依赖它在后续的MongoDB版本中保持稳定。 例如，您可能对以下两个日志事件感兴趣，它们显示了客户机连接后断开连接: {\"t\":{\"$date\":\"2020-06-01T13:06:59.027-0500\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":22943,\"ctx\":\"listener\",\"msg\":\"connection accepted from {session_remote} {session_id} ({connectionCount}{word} now open)\",\"attr\":{\"session_remote\":\"127.0.0.1:61298\",\"session_id\":164,\"connectionCount\":11,\"word\":\" connections\"}} {\"t\":{\"$date\":\"2020-06-01T13:07:03.490-0500\"},\"s\":\"I\", \"c\":\"NETWORK\", \"id\":22944,\"ctx\":\"conn157\",\"msg\":\"end connection {remote} ({connectionCount}{word} now open)\",\"attr\":{\"remote\":\"127.0.0.1:61298\",\"connectionCount\":10,\"word\":\" connections\"}} 这两个实体的日志id分别是22943和22944。然后，您可以过滤日志输出，只显示这些日志id，有效地只显示客户端连接活动，使用以下jq语法: jq '. | select( .id as $id | [22943, 22944] | index($id) )' /var/log/mongodb/mongod.log 查阅jq文档以获得更多关于本例中显示的jq过滤器的信息。 日期范围过滤 通过过滤timestamp字段，限制返回到特定日期范围的日志记录，可以进一步细化日志输出。例如，下面返回发生在2020年4月15日的所有日志条目: jq '. | select(.t[\"$date\"] >= \"2020-04-15T00:00:00.000\" and .t[\"$date\"] 注意，该语法包含完整的时间戳，包括毫秒，但不包括时区偏移量。 按日期范围进行筛选可以与上面的任何示例结合使用，例如创建周报告或年度摘要。下面的语法扩展了“监视连接”示例，将结果限制在2020年5月: jq '. | select(.t[\"$date\"] >= \"2020-05-01T00:00:00.000\" and .t[\"$date\"] 查阅jq文档以获得更多关于本例中显示的jq过滤器的信息。 日志摄入服务 日志摄取服务是接收和聚合日志文件(通常来自分布式系统集群)的第三方产品，并在中心位置提供对该数据的持续分析。 JSON日志格式，在MongoDB 4.4中引入，在处理日志接收和分析服务时允许更大的灵活性。纯文本日志通常需要某种转换方式才能与这些产品一起使用，而JSON文件通常可以开箱即用，这取决于服务。此外，在对这些服务执行过滤时，json格式的日志提供了更多的控制，因为键-值结构提供了仅具体导入感兴趣的字段，而忽略其他字段的能力。 有关更多信息，请参阅您所选择的第三方日志摄取服务的文档。 日志消息事例 下面的示例展示了JSON输出格式的日志消息。 为了方便起见，这些日志消息以完美打印格式的形式呈现。 启动预警 这个例子显示了一个启动警告: { \"t\": { \"$date\": \"2020-05-20T19:17:06.188+00:00\" }, \"s\": \"W\", \"c\": \"CONTROL\", \"id\": 22120, \"ctx\": \"initandlisten\", \"msg\": \"Access control is not enabled for the database. Read and write access to data and configuration is unrestricted\", \"tags\": [ \"startupWarnings\" ] } 客户端连接 这个例子显示了一个客户端连接，它包含了客户端数据: { \"t\": { \"$date\": \"2020-05-20T19:18:40.604+00:00\" }, \"s\": \"I\", \"c\": \"NETWORK\", \"id\": 51800, \"ctx\": \"conn281\", \"msg\": \"client metadata\", \"attr\": { \"remote\": \"192.168.14.15:37666\", \"client\": \"conn281\", \"doc\": { \"application\": { \"name\": \"MongoDB Shell\" }, \"driver\": { \"name\": \"MongoDB Internal Client\", \"version\": \"4.4.0\" }, \"os\": { \"type\": \"Linux\", \"name\": \"CentOS Linux release 8.0.1905 (Core) \", \"architecture\": \"x86_64\", \"version\": \"Kernel 4.18.0-80.11.2.el8_0.x86_64\" } } } } 缓慢操作 这个例子显示了一个慢速操作消息: { \"t\": { \"$date\": \"2020-05-20T20:10:08.731+00:00\" }, \"s\": \"I\", \"c\": \"COMMAND\", \"id\": 51803, \"ctx\": \"conn281\", \"msg\": \"Slow query\", \"attr\": { \"type\": \"command\", \"ns\": \"stocks.trades\", \"appName\": \"MongoDB Shell\", \"command\": { \"aggregate\": \"trades\", \"pipeline\": [ { \"$project\": { \"ticker\": 1, \"price\": 1, \"priceGTE110\": { \"$gte\": [ \"$price\", 110 ] }, \"_id\": 0 } }, { \"$sort\": { \"price\": -1 } } ], \"allowDiskUse\": true, \"cursor\": {}, \"lsid\": { \"id\": { \"$uuid\": \"fa658f9e-9cd6-42d4-b1c8-c9160fabf2a2\" } }, \"$clusterTime\": { \"clusterTime\": { \"$timestamp\": { \"t\": 1590005405, \"i\": 1 } }, \"signature\": { \"hash\": { \"$binary\": { \"base64\": \"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\", \"subType\": \"0\" } }, \"keyId\": 0 } }, \"$db\": \"test\" }, \"planSummary\": \"COLLSCAN\", \"cursorid\": 1912190691485054700, \"keysExamined\": 0, \"docsExamined\": 1000001, \"hasSortStage\": true, \"usedDisk\": true, \"numYields\": 1002, \"nreturned\": 101, \"reslen\": 17738, \"locks\": { \"ReplicationStateTransition\": { \"acquireCount\": { \"w\": 1119 } }, \"Global\": { \"acquireCount\": { \"r\": 1119 } }, \"Database\": { \"acquireCount\": { \"r\": 1119 } }, \"Collection\": { \"acquireCount\": { \"r\": 1119 } }, \"Mutex\": { \"acquireCount\": { \"r\": 117 } } }, \"storage\": { \"data\": { \"bytesRead\": 232899899, \"timeReadingMicros\": 186017 }, \"timeWaitingMicros\": { \"cache\": 849 } }, \"protocol\": \"op_msg\", \"durationMillis\": 22427 } } 转义 这个例子演示了字符转义，如属性对象的 setName 字段所示: { \"t\": { \"$date\": \"2020-05-20T19:11:09.268+00:00\" }, \"s\": \"I\", \"c\": \"REPL\", \"id\": 21752, \"ctx\": \"ReplCoord-0\", \"msg\": \"Scheduling remote command request\", \"attr\": { \"context\": \"vote request\", \"request\": \"RemoteCommand 229 -- target:localhost:27003 db:admin cmd:{ replSetRequestVotes: 1, setName: \\\"my-replica-name\\\", dryRun: true, term: 3, candidateIndex: 0, configVersion: 2, configTerm: 3, lastAppliedOpTime: { ts: Timestamp(1589915409, 1), t: 3 } }\" } } 参见 原文 - Log Messages Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/14-exit-codes.html":{"url":"16-reference/14-exit-codes.html","title":"Exit Codes and Statuses","keywords":"","body":" 退出代码和状态 退出时，MongoDB将返回以下代码和状态之一。使用本指南解释日志和故障排除与mongod和mongos实例的问题。 编码 Cause 0 成功退出时由MongoDB应用程序返回。 2 指定的选项出现错误或与其他选项不兼容。 3 Returned by mongod if there is a mismatch between hostnames specified on the command line and in the local.sources collection, in master/slave mode.返回的mongod如果在命令行上指定的主机名和在local.sources中指定的主机名不匹配。源的收集，在主/从模式。mongod如果local.sources在主/从模式下，命令行和集合中指定的主机名之间不匹配，则 返回 4 数据库的版本不同于mongod(或mongod.exe)实例所支持的版本。实例干净地退出。 5 如果在初始化过程中遇到问题，返回mongos。 12 当收到一个Control-C，关闭，中断或关闭事件，在Windows上返回mongod.exe进程。 14 由MongoDB应用程序返回，遇到一个不可恢复的错误，一个未捕获的异常或未捕获的信号。系统退出时不执行完全关闭。 20 消息：错误:wsastartup failed在wsastartup函数出现错误后，由Windows上的MongoDB应用程序返回，用于初始化网络子系统。消息：NT Service ERROR由于安装、启动或删除应用程序的NT服务失败而返回。 48 由于一个错误,一个新启动的mongod或mongos不能开始监听传入连接。 62 返回mongod如果datafiles --dbpath的版本不兼容mongod当前正在运行。 100 当进程抛出一个未捕获的异常时，返回mongod。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/15-glossary.html":{"url":"16-reference/15-glossary.html","title":"词汇表","keywords":"","body":" 词汇表 $cmd 一个特殊的虚拟集合，它公开MongoDB的数据库命令。要使用数据库命令，请参见Issue commands。 _id 每个MongoDB文档中都需要的字段。_id字段必须有一个唯一的值。您可以将 _id 字段看作文档的主键。如果您创建一个没有_id字段的新文档，MongoDB将自动创建该字段并分配一个唯一的BSON ObjectId。 accumulator 聚合框架中的一种表达式，用于维护聚合管道中文档之间的状态 。有关accumulator操作的列表，请参见 。$group action 用户可以对资源执行的操作。Actions和资源组合创建特权。看行动。 admin database 一个数据库特权。用户必须能够访问 admin 数据库才能运行某些管理命令。有关管理命令的列表，请参见管理命令。 aggregation 减少和汇总大量数据的各种操作中的任何一种。MongoDB aggregate()和 mapReduce()方法是聚合操作的两个示例。有关更多信息，请参见 聚合。 aggregation framework 一组MongoDB操作符，让您不必使用map-reduce就可以计算聚合值。有关操作符的列表，请参见Aggregation Reference。 arbiter 一个复制集的成员，该成员仅存在于elections中投票。仲裁器不复制数据。查看Replica Set仲裁者。 Atlas MongoDB Atlas是云托管的数据库即服务。 authentication 验证用户身份。请看authentication。 authorization 提供对数据库和操作的访问。参见基于角色的访问控制。 B-tree 数据库管理系统通常用于存储索引的数据结构。MongoDB使用B-trees为其索引。 balancer 一个内部的MongoDB进程，运行在一个分片集群的上下文中，并管理chunk的迁移。管理员必须为分片集群上的所有维护操作禁用平衡器。参见Sharded Cluster Balancer。 BSON 一种用于在MongoDB中存储文档和进行远程过程调用的序列化格式。“BSON”是“二进制”和“JSON”的合成词。可以将BSON视为JSON（JavaScript对象表示法）文档的二进制表示形式。请参阅 BSON类型和 MongoDB扩展JSON(v2)。 BSON types BSON序列化格式支持的类型集。有关BSON类型的列表，请参见BSON types。 CAP Theorem 给定计算系统的三个属性，一致性，可用性和分区容限，分布式计算系统可以提供这些功能中的任何两个，但不能提供全部三个。 capped collection 一个固定大小的集合，当其达到最大大小时会自动覆盖其最早的条目。在复制中使用的MongoDB oplog是一个有上限的集合。。请参阅限制集合。 cardinality 对一组值中元素数量的度量。例如，集合 A ={2,4,6} 包含3个元素，基数为3。参见分片键基数。 checksum 用于确保数据完整性的计算值。有时使用md5算法作为checksum。 chunk 一个连续范围的分片键的特定内的值分片。块范围包括下边界，不包括上边界。当MongoDB超出配置的块大小（默认为64兆字节）时，MongoDB将对其进行拆分。当一个分片相对于其他分片包含一个集合的太多分块时，MongoDB会迁移这些分块。请参见 使用块和分片群集平衡器进行数据分区。 client 使用数据库进行数据持久性和存储的应用层。Drivers提供了应用程序层和数据库服务器之间的接口级别。客户端也可以引用单个线程或进程。 cluster 请看 sharded cluster. collection MongoDB 文档的分组。集合等效于RDBMS表。集合存在于单个数据库中。集合不强制执行架构。集合中的文档可以具有不同的字段。通常，集合中的所有文档都具有相似或相关的目的。请参阅命名空间。 collection scan 集合扫描是一种查询执行策略，MongoDB必须检查集合中的每个文档，以确定它是否符合查询条件。这些查询效率非常低，并且不使用索引。有关查询执行策略的详细信息，请参阅查询优化。 compound index 由两个或多个键组成的索引。请看复合索引。 concurrency control 并发控制可确保数据库操作可以并发执行而不会影响正确性。悲观并发控制，例如在带锁的系统中使用的，将阻止任何可能发生冲突的操作，即使它们可能最终并未真正冲突。乐观并发控制，即WiredTiger使用的方法将延迟检查，直到可能发生冲突之后，终止并重试任何出现 写冲突的操作。 config database 一个内部数据库，保存与分片集群相关联的元数据。应用程序和管理员不应该在正常操作过程中修改config数据库。请看配置数据库。 config server 一个mongod实例，存储与分片集群相关联的所有元数据。看到配置服务器。 container 打包在一起的一组软件及其从属库可以简化在计算环境之间的传输。容器在您的操作系统上作为分隔的进程运行，并且可以赋予它们自己的资源限制。常见的容器技术是Docker和Kubernetes。 CRUD 数据库基本操作的缩写:创建、读取、更新和删除。查看MongoDB CRUD操作。 CSV 一种基于文本的数据格式，由逗号分隔的值组成。由于该格式非常适合表格数据，因此通常用于在关系数据库之间交换数据。您可以使用导入CSV文件mongoimport。 cursor 一个指向查询结果集的指针。客户端可以遍历游标来检索结果。默认情况下，游标在不活动10分钟后超时。参见在mongo Shell中迭代游标。 daemon 后台、非交互进程的传统名称。 data directory mongod存储数据文件的文件系统位置。dbPath选项指定数据目录。 data partition 将数据划分为范围的分布式系统体系结构。 分片使用分区。请参见 使用块进行数据分区。 data-center awareness 一种属性，允许客户端根据其位置来寻址系统中的成员。复制集 使用标签实现数据中心感知。请参阅 数据中心意识。 database 集合的物理容器。每个数据库在文件系统上有自己的一组文件。一个MongoDB服务器通常有多个数据库。 database command MongoDB操作，而不是插入、更新、删除或查询。有关数据库命令的列表，请参见数据库命令。要使用数据库命令，请参见Issue commands。 database profiler 一种工具，当它被启用时，它在数据库的“系统”中保存所有长时间运行的操作的记录。概要文件的集合。分析器最常用来诊断慢速查询。请看数据库分析。 dbpath MongoDB的数据文件存储位置。请看dbPath。 delayed member 一个replica set成员，该成员不能成为主成员并在指定的延迟下应用操作。延迟对于保护数据不受人为错误(即无意中删除的数据库)或对生产数据库有不可预见影响的更新的影响非常有用。参见Delayed Replica Set Members。 document MongoDB集合中的一条记录和MongoDB中的基本数据单元。文档类似于JSON对象，但是以一种更丰富类型的格式存在于数据库中，称为BSON。请看document。 dot notation MongoDB使用点表示法来访问数组的元素和访问嵌入文档的字段。看到Dot Notation。 draining 从一个分片到另一个分片的移除或“shedding”chunks的过程。管理员必须在将分片从集群中删除之前将其排干。参见从现有分片集群中删除分片。 driver 用特定语言与MongoDB交互的客户端库。见 /drivers. durable 当一个或多个服务器进程关闭(或崩溃)和重新启动时，写操作是持久的。对于单个' mongod '服务器，当写入服务器的journal文件时，写操作被认为是持久的。对于复制集，一旦写入操作在大多数投票节点上是持久的，那么写入操作就被认为是持久的;即写给大多数投票节点的日志。 election 在启动和失败时，replica set的成员选择一个primary的进程。查看Replica Set Elections。 eventual consistency 分布式系统的一种属性，允许对系统的更改逐渐传播。在数据库系统中，这意味着可读成员不需要随时反映最新的写操作。 expression 在聚合框架的上下文中，表达式是对通过管道的数据进行操作的无状态转换。请看聚合管道。 failover 在发生故障时允许副本集的辅助成员成为主要成员 的过程。请参阅自动故障转移。 field A name-value pair in a document. A document has zero or more fields. Fields are analogous to columns in relational databases. See Document Structure. 文档中的名称-值对。一个文档有零个或多个字段。字段类似于关系数据库中的列。请看文档结构。 field path 文档中某个字段的路径。要指定字段路径，请使用一个字符串在字段名前加上美元符号(' $ ')。 firewall 一种基于IP地址限制访问的系统级网络过滤器。防火墙是有效网络安全策略的一部分。请看防火墙. fsync 将内存中所有脏页面刷新到磁盘的系统调用。MongoDB至少每60秒对其数据库文件调用 fsync() 。请看fsync。 geohash geohash值是坐标网格中位置的二进制表示。参见计算2d索引的Geohash值。 GeoJSON 基于JavaScript对象符号的数据交换格式(JSON)。GeoJSON用于地理空间查询。有关受支持的GeoJSON对象，请参见地理空间数据。有关GeoJSON格式规范，请参见https://tools.ietf.org/html/rfc7946section-3.1。 geospatial 与地理位置有关的。看到地理空间查询。 GridFS 在MongoDB数据库中存储大文件的约定。所有官方的MongoDB驱动程序都支持这个约定，就像mongofiles程序一样。参见GridFS。 hashed shard key 一种特殊类型的分片键,使用一个hash值的分片键字段成员之间分发文件的分片集群。请看Hashed索引。 haystack index 一个geospatial索引，该索引通过创建根据第二个标准分组的对象的“buckets”来增强搜索。看到geoHaystack索引。 hidden member 一个replica set成员，不能成为primary并且对客户端应用程序不可见。参见Hidden Replica Set Members。 high availability 高可用性指的是为持久性、冗余和自动故障转移而设计的系统，这样系统所支持的应用程序就可以连续运行，而不会在很长一段时间内停机。MongoDB复制集复制支持高可用性部署时根据我们的记录最佳实践 。有关复制集部署架构的指导，请参阅副本集部署架构。 idempotent 在相同的输入下产生相同结果的操作的质量，无论运行一次还是多次。 index 优化查询的数据结构。请看索引。 init script Linux平台的init系统使用的一个简单的shell脚本，用于启动、重启或停止一个daemon进程。如果您通过包管理器安装了MongoDB，那么作为安装的一部分，会为您的系统提供一个init脚本。请参阅相应的安装指南来了解您的操作系统。 init system init系统是内核启动后在Linux平台上启动的第一个进程，它管理系统上的所有其他进程。init系统使用一个init脚本开始,重新启动,或停止一个守护进程过程,如mongod或mongos。Linux的最新版本倾向于使用systemd init系统，它使用systemctl命令，而旧版本倾向于使用system V init系统，它使用service命令。请参阅相应的安装指南来了解您的操作系统。 initial sync 复制集操作，该操作将数据从现有的复制集成员复制到新的复制集成员。请看初始同步。 intent lock lock资源,表明锁的持有人将读(intent shared)或写(intent exclusive)资源使用并发控制 比资源更细粒度的概念与意图锁。意图锁允许并发读取和写入资源。查看MongoDB使用什么类型的锁?。 interrupt point 操作生命周期中可以安全中止的点。MongoDB只在指定的中断点终止操作。参见终止运行操作。 IPv6 对IP(Internet协议)标准的修订，提供更大的地址空间，以更有效地支持当代Internet上的主机数量。 ISODate mongo使用的国际日期格式来显示日期。格式是:YYYY-MM-DD HH:MM.SS.millis。 JavaScript 一种最初为web浏览器设计的流行脚本语言。MongoDB shell和某些服务器端函数使用JavaScript解释器。更多信息请参见服务器端JavaScript。 journal 一种顺序的二进制事务日志，用于在发生硬关闭时使数据库进入有效状态。日志记录首先将数据写入日志，然后写入核心数据文件。MongoDB 2.0及更新版本的64位版本默认允许日志记录。日志文件是预先分配的，并作为文件存在于data目录中。请看日志。 JSON JavaScript对象表示法。一种人类可读的纯文本格式，用于表示结构化数据，支持多种编程语言。更多信息，请参见http://www.json.org。某些MongoDB工具以JSON格式呈现MongoDB BSON文档的近似值。参见MongoDB Extended JSON (v2)。 JSON document 一个JSON文档是结构化格式的字段和值的集合。对于示例JSON文档，请参见http://json.org/example.html。 JSONP JSON填充。引用一种将JSON注入应用程序的方法。表示潜在的安全问题。 least privilege 一种授权策略，只向用户提供对该用户的工作至关重要的访问权限，而不提供其他权限。 legacy coordinate pairs 该格式用于MongoDB 2.4版本之前的geospatial数据。这种格式将地理空间数据存储为平面坐标系统上的点(例如。[x, y])。参见地理空间查询。 LineString LineString是由两个或多个位置组成的数组定义的。具有四个或更多位置的封闭LineString称为线性环，如GeoJSON LineString规范所述:https://tools.ietf.org/html/rfc7946section-3.1.4。要在MongoDB中使用LineString，请参见[GeoJSON Objects](https://docs.mongodb.com/master/reference/geojson/geospatial-indexes-store-geojson)。 lock MongoDB使用锁来确保并发不会影响正确性。MongoDB使用read locks、write locks和intent locks。更多信息，请参见MongoDB使用什么类型的锁定?。 LVM 逻辑卷管理器。LVM是一个从物理设备提取磁盘映像的程序，它提供了许多对系统管理有用的原始磁盘操作和快照功能。有关LVM和MongoDB的信息，请参见在Linux上使用LVM进行备份和恢复。 map-reduce 数据处理和聚合范例由选择数据的“映射”阶段和转换数据的“减少”阶段组成。在MongoDB中，您可以使用map-reduce在数据上运行任意的聚合。对于map-reduce实现，请参见map-reduce。对于所有的聚合方法，请参见aggregation。 mapping type 一种将键与值相关联的编程语言结构，其中键可以嵌套其他键和值对(例如字典、hash表、映射和关联数组)。这些结构的属性取决于语言规范和实现。通常，映射类型中的键的顺序是任意的，不能保证。 md5 一种hashing算法，用于有效地提供可重现的惟一字符串来识别和校验和数据。MongoDB使用md5为GridFS识别数据块。参见filemd5。 MIB 管理信息基础。MongoDB在MongoDB企业版中使用MIB文件定义SNMP跟踪的数据类型。 MIME 多用途因特网邮件扩展。一组标准的类型和编码定义，用于在多个数据存储、传输和电子邮件上下文中声明数据的编码和类型。mongofiles工具提供了一个选项来指定MIME类型来描述插入到GridFS存储中的文件。 mongo MongoDB shell。mongo流程启动MongoDB shell守护进程连接到一个mongod或mongos实例。shell有一个JavaScript接口。参见mongo和mongo Shell方法。 mongod MongoDB数据库服务器。mongod进程启动MongoDB服务器作为一个守护进程。MongoDB服务器管理数据请求和格式，并管理后台操作。参见mongod。 mongos MongoDB分片集群查询路由器。mongos进程启动MongoDB路由器作为一个daemon。MongoDB路由器充当应用程序和MongoDB sharded集群之间的接口，并在集群中处理所有路由和负载平衡。参见mongos。 namespace MongoDB中集合或索引的规范名称。命名空间是数据库名称和集合或索引名称的组合，如[database-name].[collection-or-index]。所有文档都属于一个名称空间。参见名称空间。 natural order 数据库引用磁盘上文档的顺序。这是默认的排序顺序。查看$natural和以自然顺序返回。 network partition 一种网络故障，它将分布式系统分割为多个分区，使得一个分区中的节点无法与另一个分区中的节点通信。有时，分区是部分的或不对称的。部分分区的一个例子将是一个网络的节点分成三组,第一组内的成员不能与第二组的成员,反之亦然,但所有节点可以与第三组的成员交流。在一个不对称的分区,沟通可能只有当它源自某些节点。例如，分区一端的节点只有在它们启动通信通道时才能与另一端通信。 ObjectId 一个特殊的12字节BSON类型，它保证了集合中的唯一性。ObjectId是基于时间戳、机器ID、进程ID和进程本地增量计数器生成的。MongoDB使用ObjectId值作为_id字段的默认值。 operator 以$开头的关键字，用于表示更新、复杂查询或数据转换。例如，$gt是查询语言的\" greater than \"操作符。有关可用的操作符，请参见operators。 oplog 一个capped collection，它将逻辑写入的有序历史存储到MongoDB数据库中。oplog是在MongoDB中启用复制的基本机制。参见Replica Set Oplog。 optime 以下描述了MongoDB 3.2：中引入的protocolVersion: 1使用的optime格式。对复制oplog中位置的引用。optime值是一个文档，其中包含:ts、操作的时间戳。t， term，该操作最初在主服务器上生成。 ordered query plan 一个查询计划，它以与sort()顺序一致的顺序返回结果。查询计划。 orphaned document 在分片集群中，孤立文档是指某个分片上的文档，由于迁移失败或由于异常关机而导致迁移清理不完整，这些文档也存在于其他分片上的块中。从MongoDB 4.4开始，在块迁移完成后，孤立的文档会被自动清理。删除孤立文档不再需要运行cleanuporphaned。 passive member 一个replica set的成员不能成为主元素，因为它的members[n].priority是0。参见Priority 0 Replica Set Members。 PID 一个进程标识符。类unix系统为每个正在运行的进程分配一个唯一的整数PID。可以使用PID检查正在运行的进程并向其发送信号。参见/proc文件系统。 pipe 类unix系统中的一种通信通道，允许独立进程发送和接收数据。在UNIX shell中，管道操作允许用户将一个命令的输出定向到另一个命令的输入。 pipeline 一个聚合流程中的一系列操作。看到聚合管道。 Point GeoJSON点规范中描述的单个坐标对:https://tools.ietf.org/html/rfc7946section-3.1.2。要在MongoDB中使用一个点，请参见[GeoJSON Objects](https://docs.mongodb.com/master/reference/geojson/geospatial-indexes-store-geojson)。 Polygon 一个LinearRing坐标数组，正如在GeoJSON多边形规范中描述的:https://tools.ietf.org/html/rfc7946section-3.1.6。对于有多个环的多边形，第一个必须是外环，其他必须是内环或孔。MongoDB不允许外环自交。内环必须完全包含在外环内，不能相互交叉或重叠。参见[GeoJSON对象](https://docs.mongodb.com/master/reference/geojson/ geospatial-indexes-store-geojson)。 powerOf2Sizes 每个集合设置改变和规范MongoDB为每个文档分配空间的方式，以最大化存储重用和减少碎片。这是TTL集合的默认值。查看collMod和usepowerof2size。 pre-splitting 在插入数据之前执行的一种操作，它将可能的切分键值范围划分为块，以方便插入和高写吞吐量。在某些情况下预加速文件的初始分布分片集群通过手动划分集而不是等待MongoDB均衡器。参见在分片集群中创建块。 prefix compression 通过在每一页内存中只存储一次相同的索引键前缀，减少内存和磁盘消耗。参见:压缩了解更多关于WiredTiger的压缩行为。 primary 在复制集中，主元素是接收所有写操作的成员。参见Primary。 primary key 记录的唯一不可变标识符。在RDBMS中，主键通常是存储在每行' id '字段中的整数。在MongoDB中，_id字段持有文档的主键，通常是BSON ObjectId。 primary shard shard，它包含所有未分片的集合。参见Primary Shard。 priority 一个可配置的值，帮助确定replica set中的哪些成员最有可能成为primary。参见 members[n].priority. privilege 资源上允许的指定的资源和actions的组合。参见privilege。 projection 一个给查询的文档，它指定MongoDB在结果集中返回哪些字段。有关投影操作符的列表，请参见投影操作符。 query 读请求。MongoDB使用JSON类似的查询语言，包括各种各样的查询操作符，名称以“$”字符开头。mongoshell,你可以发出查询使用db.collection.find()和db.collection.findOne()方法。参见查询文件。 query optimizer 生成查询计划的流程。对于每个查询，优化器都会生成一个计划，将查询与尽可能高效地返回结果的索引相匹配。优化器在每次运行查询时重用查询计划。如果一个集合发生重大变化，优化器将创建一个新的查询计划。参见查询计划。 query shape 查询谓词、排序和投影的组合。对于查询谓词，只有谓词的结构(包括字段名)是重要的;查询谓词中的值不重要。因此，查询谓词{type: 'food'}等价于查询形状的查询谓词{type: 'utensil'}。来帮助识别相同的慢速查询查询形状,开始在MongoDB 4.2中,每个查询形状是与queryHash。queryHash是一个十六进制字符串，表示查询形状的散列，并且只依赖于查询形状。对于任何散列函数，两个不同的查询形状可能会导致相同的散列值。但是，不同查询形状之间不太可能出现哈希冲突。 RDBMS 关系数据库管理系统。基于关系模型的数据库管理系统，通常使用SQL作为查询语言。 read concern 指定读操作的隔离级别。例如，您可以使用read concern来只读已经传播到replica set中的大多数节点的数据。参见读问题。 read lock 资源上的一个共享锁，该资源(比如集合或数据库)在持有时允许并发读取但不允许写入。查看MongoDB使用什么类型的锁?。 read preference 决定客户端如何直接读取操作的设置。读取首选项影响所有副本集，包括分片副本集。默认情况下，MongoDB将读取定向到初选。但是，您也可以为最终一致读取直接将读取指向二级。参见阅读偏好。 recovering replica set成员状态，表示成员还没有准备好开始辅助或主成员的正常活动。正在恢复的成员不可用于读取。 replica pairs MongoDB的前身replica set.自1.6版本以来已被弃用. replica set 实现复制和自动故障转移的MongoDB服务器集群。MongoDB推荐的复制策略。参见复制。 replication 允许多个数据库服务器共享相同数据的特性，从而确保冗余和促进负载平衡。参见复制。 replication lag 最后一个操作之间的时间长度primary’s oplog和最后一个操作应用于一个特定的二级。通常，您希望将复制延迟保持得尽可能小。参见复制延迟。 resident memory 当前存储在物理RAM中的应用程序内存的子集。常驻内存是虚拟内存的一个子集，其中包括映射到物理RAM和磁盘的内存。 resource 数据库、集合、集合集或集群。一个特权允许在指定的资源上执行动作。参见资源。 role 在指定的资源上允许操作的一组特权。分配给用户的角色决定了用户对资源和操作的访问。参见安全。 rollback 恢复写操作以确保所有复制集成员的一致性的进程。参见复制集故障转移期间回滚。 secondary 复制主数据库内容的replica set成员。辅助成员可以处理读请求，但是只有主成员可以处理写操作。参见Secondaries。 secondary index 一个数据库索引，通过最小化查询引擎执行查询时必须执行的工作来提高查询性能。参见索引。 set name 任意的名字给一个复制集。复制集的所有成员必须具有相同的名称指定的replSetName设置或——replSet选项。 shard 一个mongod实例或复制集存储的分片集群的一部分数据集。在生产中,所有分片都应该复制集。参见分片。 shard key MongoDB用于在分片集群的成员之间分发文档的字段。参见分片键。 sharded cluster 包含sharded MongoDB部署的节点集。分片集群由配置服务器、分片和一个或多个mongos路由进程组成。参见分片集群组件。 sharding 按键范围划分数据并将数据分布在两个或多个数据库实例之间的数据库体系结构。切分允许水平伸缩。参见分片。 shell helper mongoshell中的一个方法，它为数据库命令提供了更简洁的语法。Shell helper改善了一般的交互体验。参见mongo Shell方法。 single-master replication 一个replication topology ，其中只有一个数据库实例接受写操作。单主复制确保了一致性，是MongoDB使用的复制topology 。参见Replica Set Primary。 snappy 一个压缩/解压缩库，设计来平衡有效的计算需求与合理的压缩率。Snappy是MongoDB使用WiredTiger的默认压缩库。更多信息，请参见Snappy和WiredTiger压缩文档。 split 分片集群中的chunks的划分。参见使用块进行数据分区。 SQL 结构化查询语言(Structured Query Language, SQL)是一种通用的特殊用途编程语言，用于与关系数据库进行交互，包括访问控制、插入、更新、查询和删除。不同数据库供应商支持的基本SQL语法中有一些类似的元素，但是大多数实现都有自己的方言、数据类型和对提议的SQL标准的解释。复杂的SQL通常不能在主要的RDBMS产品之间直接移植。“SQL”经常被用作关系数据库的转喻。 SSD 固态磁盘。一种高性能的磁盘驱动器，使用固态电子器件来保持性能，与传统机械硬盘驱动器所使用的旋转磁盘和可移动读写磁头不同。 standalone 一个mongod的实例，它作为一个单独的服务器运行，而不是作为replica set的一部分。要将独立转换为复制集，请参见将独立转换为复制集。 storage engine 数据库中负责管理如何在内存和磁盘中存储和访问数据的部分。对于特定的工作负载，不同的存储引擎执行得更好。请参阅Storage Engines了解MongoDB中内置存储引擎的具体细节。 storage order 参见natural order. strict consistency 分布式系统的一种属性，要求所有成员始终反映系统的最新更改。在数据库系统中，这意味着任何能够提供数据的系统都必须始终反映最新的写操作。 sync replica set操作，其中成员从primary复制数据。同步首先发生在MongoDB创建或恢复一个成员时，该成员被称为initial Sync。然后持续进行同步，以通过复制集数据的更改更新成员。查看Replica Set Data Synchronization。 syslog 在类unix系统上，为服务器和进程提供提交日志信息的统一标准的日志过程。MongoDB提供了一个将输出发送到主机的syslog系统的选项。参见' syslogFacility '。 tag 应用于复制集成员的标签，由客户端用于发出感知数据中心的操作。使用标签复制集的更多信息,参见本手册的以下部分:阅读偏好标记集。 3.4版本中改变:在MongoDB 3.4中,分片集群zones term-zone取代tags。 tag set 包含零个或多个标签的文档。 tailable cursor 对于一个capped集合，一个可tailable游标是一个在客户端在初始游标中查看完结果后保持打开的游标。当客户端向有上限的集合插入新文档时，可定制游标将继续检索文档。 term 对于一个复制集的成员，一种单调递增的数目，对应于一次选举尝试。 topology 部署的MongoDB实例的状态,包括部署的类型(即独立、复制集,或分片集群),以及服务器的可用性,和每个服务器的角色(例如主要,二级,配置服务器,或mongos)。 TSV 一种基于文本的数据格式，由制表符分隔的值组成。这种格式通常用于在关系数据库之间交换数据，因为这种格式非常适合表格数据。您可以使用mongoimport导入TSV文件。 TTL 表示“生存时间”，表示给定信息在缓存或其他临时存储中保留的过期时间或期间，然后系统将其删除或老化。MongoDB有一个TTL集合特性。查看通过设置TTL从集合过期数据。 unique index 一种索引，强制跨单个集合的特定字段具有唯一性。参见独特的索引。 unix epoch 1970年1月1日00时。通常用于表示时间，其中从这个点开始计算的秒数或毫秒数。 unordered query plan 返回的查询计划的顺序与sort()顺序不一致。参见查询计划。 upsert 更新操作的选项;例如db.collection.update (), db.collection.findAndModify ()。如果设置为true，更新操作将更新指定查询匹配的文档，如果没有文档匹配，则插入一个新文档。新文档将在操作中指示字段。参见如果不存在匹配，插入新文档(Upsert)。 virtual memory 应用程序的工作内存，通常驻留在磁盘和物理RAM中。 WGS84 默认的参考系统和大地基准，MongoDB使用它来计算类似地球的球体上的几何图形，用于在GeoJSON对象上的地理空间查询。请参阅“EPSG:4326: WGS 84”规范:http://spatialreference.org/ref/epsg/4326/。 working set MongoDB最常用的数据。 write concern 指定写操作是否成功。Write concern允许您的应用程序检测插入错误或不可用mongod实例。对于replica sets，您可以配置write concern来确认复制到指定数量的成员。请看写问题。 write conflict 在这种情况下，两个并发操作(其中至少一个是写操作)试图以违反使用乐观并发控制的存储引擎施加的约束的方式使用资源。MongoDB将透明地中止并重试其中一个冲突的操作。 write lock 资源(比如集合或数据库)上的独占锁。当一个进程写入一个资源时，它采用独占写锁来防止其他进程写入或读取该资源。有关锁的更多信息，请参见FAQ: Concurrency。 writeBacks 切分系统内的进程确保向shard发出的不负责相关块的写被应用到适当的切分。有关信息，请参见writebacklisten在日志中的意思是什么?和writeBacksQueued。 zlib 与MongoDB使用的snappy相比，这个数据压缩库提供了更高的压缩率，但占用了更多的CPU。您可以配置WiredTiger来使用zlib作为其压缩库。更多信息请参见http://www.zlib.net和WiredTiger压缩文档。 zone 3.4版本中的新特性:给定分片集合的基于范围分片键值的文档分组。分片集群中的每个碎片可以与一个或多个区域关联。在一个平衡的集群中，MongoDB只将一个区域覆盖的读和写定向到该区域内的那些碎片。有关更多信息，请参阅zone手册页。 在MongoDB 3.2中，区域取代了标签所描述的功能。 zstd 4.2版中的新功能。 与zlib相比，该数据压缩库提供更高的压缩率和更低的CPU使用率。 参见 原文 - Glossary Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/16-default-mongodb-port.html":{"url":"16-reference/16-default-mongodb-port.html","title":"默认的MongoDB端口","keywords":"","body":" 默认的MongoDB端口 下表列出了MongoDB使用的默认TCP端口: Default Port Description 27017 mongod和mongos实例的默认端口。您可以使用port或——port来更改该端口。 27018 默认端口为mongod运行——shardsvr命令行选项或 shardsvr 值clusterRole设置在配置文件中。 27019 默认端口为mongod运行——configsvr命令行选项或 configsvr 值clusterRole设置在配置文件中。 参见 原文 - Default MongoDB Port Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/17-mongodb-defaults.html":{"url":"16-reference/17-mongodb-defaults.html","title":"Default MongoDB Read Concerns/Write Concerns","keywords":"","body":" 默认的MongoDB读/写关注 在本页面 阅读关注 写关注 因果一致性保证 阅读关注 默认读取问题 默认的 read concern如下: 操作 默认读取问题 针对主要的读取 \"local\"注意，这个读取的关注点可以返回可能被回滚的数据。此读取关注点不保证因果一致性。 如果读操作与因果一致的会话相关联，则读取二级会话。 \"local\"注意这个读关注可以返回可能回滚的数据。此读取关注点不保证因果一致性。 如果读操作与因果一致的会话没有关联，则对辅助会话进行读取。 \"available\"注意这个读关注可以返回可能回滚的数据这种已读关注点不能保证因果关系的一致性。对于分片集合，这个读关注也可以返回孤立的文档。 指定读取关注:MongoDB驱动程序 外部事务操作 注意 以下内容适用于在事务外部发出的操作。 要阅读与事务内部发出的操作相关的关注信息，请单击事务中的操作选项卡。 使用MongoDB 驱动，您可以覆盖默认的read concern，并设置以下级别的操作的read concern: 水平 描述 客户级别 应用于操作，除非在数据库/集合/操作级别设置了更细致的读取关注。否则将应用于操作。 数据库级别 应用于数据库集合上的操作(即覆盖客户端读关注)，除非已在集合级别或操作级别设置了读关注。注意：不适用于事务内部的操作。 集合级别 应用对集合的读操作(即覆盖数据库/客户端读关注)，除非已在操作级别设置了读关注。注意：不适用于事务内部的操作。 操作级别 应用特定的读操作(例如，覆盖数据库/客户端/集合读关注)。在操作中设置read concern的能力取决于驱动程序。请参考您的驱动程序文档。注意：不适用于事务内部的操作。 事务中的操作 注意 以下内容适用于在事务内部发出的操作。 要阅读与发出外部事务的操作相关的关注信息，请单击“外部事务的操作”选项卡。 使用MongoDB 驱动，您可以覆盖默认的read concern，并设置以下级别的操作的read concern: 水平 描述 客户级别 应用于事务，除非在会话/事务级别设置了更细致的读取关注。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。 会话级别 应用于在会话中启动的事务(即覆盖客户端读取关注)，除非在特定事务级别上设置了更细致的读取关注级别。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。有关更多信息，请参阅事务的阅和读关注。 事务级别 应用于特定的事务。事务写关注应用于提交操作和事务内部的操作。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。 额外的信息 有关可用的读取关注点的更多信息，请参见read Concern。 写关注 默认写问题 默认的 write concern是 w: 1 。 请注意 使用默认的写关注，数据可以回滚。 此写关注点不保证因果一致性。 指定写关注:MongoDB驱动程序 外部事务操作 注意 以下内容适用于在transactions外部发出的操作。 要阅读与事务内部发布的操作相关的关注信息，请单击“事务中的操作”选项卡。 使用MongoDB drivers，您可以覆盖默认的write concern，并在以下级别设置操作的write concern: Level Description 客户级别 除非在操作/数据库/集合中为操作设置了更细的写关注点，否则将应用于操作。 数据库级别 应用于数据库集合上的写操作(即覆盖客户端写关注点)，除非在集合级别或操作级别上设置了写关注点注意不适用于事务内部的操作。 集合级别 应用于集合上的写操作(即覆盖数据库和客户端写关注点)，除非在操作级别上设置了写关注点。注意不适用于事务内部的操作。 操作级别 应用于特定的写操作。在操作中设置写关注点的能力取决于驱动程序。请参考您的驱动程序文档。注意不适用于事务内部的操作。 事务中的操作 注意 以下内容适用于在事务内部发出的操作。 要阅读与发出外部事务的操作相关的关注信息，请单击“外部事务的操作”选项卡。 水平 描述 客户级别 应用于事务，除非在会话/事务级别设置了更细致的读取关注。事务写关注点适用于提交操作和事务内部的操作。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。 会话级别 应用于在会话中启动的事务(即覆盖客户端读取关注)，除非在特定事务级别上设置了更细致的读取关注级别。事务写关注点适用于提交操作和事务内部的操作。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。有关更多信息，请参阅事务的阅和读关注。 事务级别 应用于特定的事务。事务写关注应用于提交操作和事务内部的操作。注意事务中的所有操作都使用事务读关注;即,在事务内部忽略在操作/集合/数据库级别设置的任何读关注。 使用MongoDB驱动程序，你可以覆盖默认的写关注和设置写关注为以下级别的事务: 额外的信息 有关可用的写关注点的更多信息，请参见写关注点。 因果一致性的保证 使用因果一致的客户端会话，客户端会话仅在以下情况下保证因果一致: 相关的读取操作使用 \"majority\" 读取concern， 相关的写操作使用 \"majority\" 写关注。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"16-reference/18-server-sessions.html":{"url":"16-reference/18-server-sessions.html","title":"服务器会话","keywords":"","body":" 服务器会话 在本页面 概述 命令选项 会话命令 会话和访问控制 新增3.6版 概述 MongoDB的服务器会话或逻辑会话是客户端会话用来支持因果一致性和可重试写入的基础框架。 重要 应用程序使用客户端会话与服务器会话进行接口。 服务器会话仅可用于复制集和分片集群。 命令选项 从3.6开始，MongoDB驱动程序将所有操作与一个服务器会话关联起来，除了未确认的写操作。以下选项可用于所有命令，以支持与服务器会话的关联: 重要 mongo shell和驱动程序在会话中将这些选项分配给命令。 选项 类型 描述 lsid 文档 指定与命令关联的会话的唯一id的文档。如果指定了 txnNumber ，则需要 lsid 。 txnNumber 64位整数 一个严格递增的非负数，用于在命令的会话中唯一标识该命令。如果指定了该命令，则该命令还必须包含 lsid 选项。 删除,插入,和更新命令,采取一系列的语句,也可用以下选择: 对于delete，insert和update 命令,采取一系列的语句，以下选项也可： 重要 不要手动设置 stmtIds 。MongoDB将 stmtIds 设置为严格的非负数递增。 选项 Type Description stmtIds 32位整数的数组 在写命令中唯一标识其各自写操作的数字数组。 会话命令 The following commands can be used to list, manage, and kill server sessions throughout MongoDB clusters: 命令 描述 endSessions 指定的服务器会话过期。 killAllSessions 终止所有服务器会话。 killAllSessionsByPattern 终止与指定模式匹配的所有服务器会话。 killSessions 终止指定的服务器会话。 refreshSessions 刷新空闲服务器会话。 startSession 启动一个新的服务器会话。 会话和访问控制 如果部署强制执行身份验证/授权，则必须对用户进行身份验证才能启动会话，并且只有该用户才能使用该会话 在版本3.6.3中更改:使用 $external 身份验证用户(例如，Kerberos、LDAP、x.509个用户)，用户名不能大于10k字节。 如果部署不强制执行身份验证/授权，则创建的会话没有所有者，并且可以由任何用户在任何连接上使用。如果用户对不执行身份验证/授权的部署进行身份验证并创建会话，则该用户将拥有该会话。但是，任何连接上的任何用户都可以使用该会话。 如果部署在没有任何停机的情况下转换到身份验证，则不能使用任何没有所有者的会话。 另请参阅： maxSessions 参见 原文 - Server Sessions Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes.html":{"url":"17-release-notes.html","title":"更新说明","keywords":"","body":" Release Notes ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4.html":{"url":"17-release-notes/01-4.4.html","title":"Release Notes for MongoDB 4.4","keywords":"","body":" Release Notes for MongoDB 4.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 4.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/01-4.4-compatibility.html":{"url":"17-release-notes/01-4.4/01-4.4-compatibility.html","title":"Compatibility Changes in MongoDB 4.4","keywords":"","body":" Compatibility Changes in MongoDB 4.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 4.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/02-4.4-upgrade-standalone.html":{"url":"17-release-notes/01-4.4/02-4.4-upgrade-standalone.html","title":"Upgrade a Standalone to 4.4","keywords":"","body":" Upgrade a Standalone to 4.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Standalone to 4.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/03-4.4-upgrade-replica-set.html":{"url":"17-release-notes/01-4.4/03-4.4-upgrade-replica-set.html","title":"Upgrade a Replica Set to 4.4","keywords":"","body":" Upgrade a Replica Set to 4.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Replica Set to 4.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/04-4.4-upgrade-sharded-cluster.html":{"url":"17-release-notes/01-4.4/04-4.4-upgrade-sharded-cluster.html","title":"Upgrade a Sharded Cluster to 4.4","keywords":"","body":" Upgrade a Sharded Cluster to 4.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Sharded Cluster to 4.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/05-4.4-downgrade.html":{"url":"17-release-notes/01-4.4/05-4.4-downgrade.html","title":"Downgrade 4.4 to 4.2","keywords":"","body":" Downgrade 4.4 to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.4 to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/05-4.4-downgrade/01-4.4-downgrade-standalone.html":{"url":"17-release-notes/01-4.4/05-4.4-downgrade/01-4.4-downgrade-standalone.html","title":"Downgrade 4.4 Standalone to 4.2","keywords":"","body":" Downgrade 4.4 Standalone to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.4 Standalone to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/05-4.4-downgrade/02-4.4-downgrade-replica-set.html":{"url":"17-release-notes/01-4.4/05-4.4-downgrade/02-4.4-downgrade-replica-set.html","title":"Downgrade 4.4 Replica Set to 4.2","keywords":"","body":" Downgrade 4.4 Replica Set to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.4 Replica Set to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/05-4.4-downgrade/03-4.4-downgrade-sharded-cluster.html":{"url":"17-release-notes/01-4.4/05-4.4-downgrade/03-4.4-downgrade-sharded-cluster.html","title":"Downgrade 4.4 Sharded Cluster to 4.2","keywords":"","body":" Downgrade 4.4 Sharded Cluster to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.4 Sharded Cluster to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/01-4.4/06-4.4-changelog.html":{"url":"17-release-notes/01-4.4/06-4.4-changelog.html","title":"4.4 Changelog","keywords":"","body":" 4.4 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 4.4 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2.html":{"url":"17-release-notes/02-4.2.html","title":"Release Notes for MongoDB 4.2","keywords":"","body":" Release Notes for MongoDB 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/01-4.2-compatibility.html":{"url":"17-release-notes/02-4.2/01-4.2-compatibility.html","title":"Compatibility Changes in MongoDB 4.2","keywords":"","body":" Compatibility Changes in MongoDB 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/02-4.2-upgrade-standalone.html":{"url":"17-release-notes/02-4.2/02-4.2-upgrade-standalone.html","title":"Upgrade a Standalone to 4.2","keywords":"","body":" Upgrade a Standalone to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Standalone to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/03-4.2-upgrade-replica-set.html":{"url":"17-release-notes/02-4.2/03-4.2-upgrade-replica-set.html","title":"Upgrade a Replica Set to 4.2","keywords":"","body":" Upgrade a Replica Set to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Replica Set to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/04-4.2-upgrade-sharded-cluster.html":{"url":"17-release-notes/02-4.2/04-4.2-upgrade-sharded-cluster.html","title":"Upgrade a Sharded Cluster to 4.2","keywords":"","body":" Upgrade a Sharded Cluster to 4.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Sharded Cluster to 4.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/05-4.2-downgrade.html":{"url":"17-release-notes/02-4.2/05-4.2-downgrade.html","title":"Downgrade 4.2 to 4.0","keywords":"","body":" Downgrade 4.2 to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.2 to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/05-4.2-downgrade/01-4.2-downgrade-standalone.html":{"url":"17-release-notes/02-4.2/05-4.2-downgrade/01-4.2-downgrade-standalone.html","title":"Downgrade 4.2 Standalone to 4.0","keywords":"","body":" Downgrade 4.2 Standalone to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.2 Standalone to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/05-4.2-downgrade/02-4.2-downgrade-replica-set.html":{"url":"17-release-notes/02-4.2/05-4.2-downgrade/02-4.2-downgrade-replica-set.html","title":"Downgrade 4.2 Replica Set to 4.0","keywords":"","body":" Downgrade 4.2 Replica Set to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.2 Replica Set to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/05-4.2-downgrade/03-4.2-downgrade-sharded-cluster.html":{"url":"17-release-notes/02-4.2/05-4.2-downgrade/03-4.2-downgrade-sharded-cluster.html","title":"Downgrade 4.2 Sharded Cluster to 4.0","keywords":"","body":" Downgrade 4.2 Sharded Cluster to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.2 Sharded Cluster to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/02-4.2/06-4.2-changelog.html":{"url":"17-release-notes/02-4.2/06-4.2-changelog.html","title":"4.2 Changelog","keywords":"","body":" 4.2 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 4.2 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0.html":{"url":"17-release-notes/03-4.0.html","title":"Release Notes for MongoDB 4.0","keywords":"","body":" Release Notes for MongoDB 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/01-4.0-compatibility.html":{"url":"17-release-notes/03-4.0/01-4.0-compatibility.html","title":"Compatibility Changes in MongoDB 4.0","keywords":"","body":" Compatibility Changes in MongoDB 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/02-4.0-upgrade-standalone.html":{"url":"17-release-notes/03-4.0/02-4.0-upgrade-standalone.html","title":"Upgrade a Standalone to 4.0","keywords":"","body":" Upgrade a Standalone to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Standalone to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/03-4.0-upgrade-replica-set.html":{"url":"17-release-notes/03-4.0/03-4.0-upgrade-replica-set.html","title":"Upgrade a Replica Set to 4.0","keywords":"","body":" Upgrade a Replica Set to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Replica Set to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/04-4.0-upgrade-sharded-cluster.html":{"url":"17-release-notes/03-4.0/04-4.0-upgrade-sharded-cluster.html","title":"Upgrade a Sharded Cluster to 4.0","keywords":"","body":" Upgrade a Sharded Cluster to 4.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Sharded Cluster to 4.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/05-4.0-downgrade-standalone.html":{"url":"17-release-notes/03-4.0/05-4.0-downgrade-standalone.html","title":"Downgrade 4.0 Standalone to 3.6","keywords":"","body":" Downgrade 4.0 Standalone to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.0 Standalone to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/06-4.0-downgrade-replica-set.html":{"url":"17-release-notes/03-4.0/06-4.0-downgrade-replica-set.html","title":"Downgrade 4.0 Replica Set to 3.6","keywords":"","body":" Downgrade 4.0 Replica Set to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.0 Replica Set to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/07-4.0-downgrade-sharded-cluster.html":{"url":"17-release-notes/03-4.0/07-4.0-downgrade-sharded-cluster.html","title":"Downgrade 4.0 Sharded Cluster to 3.6","keywords":"","body":" Downgrade 4.0 Sharded Cluster to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 4.0 Sharded Cluster to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/03-4.0/08-4.0-changelog.html":{"url":"17-release-notes/03-4.0/08-4.0-changelog.html","title":"4.0 Changelog","keywords":"","body":" 4.0 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 4.0 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6.html":{"url":"17-release-notes/04-3.6.html","title":"Release Notes for MongoDB 3.6","keywords":"","body":" Release Notes for MongoDB 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/01-3.6-changelog.html":{"url":"17-release-notes/04-3.6/01-3.6-changelog.html","title":"3.6 Changelog","keywords":"","body":" 3.6 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 3.6 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/02-3.6-compatibility.html":{"url":"17-release-notes/04-3.6/02-3.6-compatibility.html","title":"Compatibility Changes in MongoDB 3.6","keywords":"","body":" Compatibility Changes in MongoDB 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/03-3.6-upgrade-standalone.html":{"url":"17-release-notes/04-3.6/03-3.6-upgrade-standalone.html","title":"Upgrade a Standalone to 3.6","keywords":"","body":" Upgrade a Standalone to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Standalone to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/04-3.6-upgrade-replica-set.html":{"url":"17-release-notes/04-3.6/04-3.6-upgrade-replica-set.html","title":"Upgrade a Replica Set to 3.6","keywords":"","body":" Upgrade a Replica Set to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Replica Set to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/05-3.6-upgrade-sharded-cluster.html":{"url":"17-release-notes/04-3.6/05-3.6-upgrade-sharded-cluster.html","title":"Upgrade a Sharded Cluster to 3.6","keywords":"","body":" Upgrade a Sharded Cluster to 3.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Sharded Cluster to 3.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/06-3.6-downgrade-standalone.html":{"url":"17-release-notes/04-3.6/06-3.6-downgrade-standalone.html","title":"Downgrade 3.6 Standalone to 3.4","keywords":"","body":" Downgrade 3.6 Standalone to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.6 Standalone to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/07-3.6-downgrade-replica-set.html":{"url":"17-release-notes/04-3.6/07-3.6-downgrade-replica-set.html","title":"Downgrade 3.6 Replica Set to 3.4","keywords":"","body":" Downgrade 3.6 Replica Set to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.6 Replica Set to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/04-3.6/08-3.6-downgrade-sharded-cluster.html":{"url":"17-release-notes/04-3.6/08-3.6-downgrade-sharded-cluster.html","title":"Downgrade 3.6 Sharded Cluster to 3.4","keywords":"","body":" Downgrade 3.6 Sharded Cluster to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.6 Sharded Cluster to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4.html":{"url":"17-release-notes/05-3.4.html","title":"Release Notes for MongoDB 3.4","keywords":"","body":" Release Notes for MongoDB 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/01-3.4-changelog.html":{"url":"17-release-notes/05-3.4/01-3.4-changelog.html","title":"3.4 Changelog","keywords":"","body":" 3.4 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 3.4 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/02-3.4-compatibility.html":{"url":"17-release-notes/05-3.4/02-3.4-compatibility.html","title":"Compatibility Changes in MongoDB 3.4","keywords":"","body":" Compatibility Changes in MongoDB 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/03-3.4-upgrade-standalone.html":{"url":"17-release-notes/05-3.4/03-3.4-upgrade-standalone.html","title":"Upgrade a Standalone to 3.4","keywords":"","body":" Upgrade a Standalone to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Standalone to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/04-3.4-upgrade-replica-set.html":{"url":"17-release-notes/05-3.4/04-3.4-upgrade-replica-set.html","title":"Upgrade a Replica Set to 3.4","keywords":"","body":" Upgrade a Replica Set to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Replica Set to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/05-3.4-upgrade-sharded-cluster.html":{"url":"17-release-notes/05-3.4/05-3.4-upgrade-sharded-cluster.html","title":"Upgrade a Sharded Cluster to 3.4","keywords":"","body":" Upgrade a Sharded Cluster to 3.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade a Sharded Cluster to 3.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/06-3.4-downgrade.html":{"url":"17-release-notes/05-3.4/06-3.4-downgrade.html","title":"Downgrade MongoDB 3.4 to 3.2","keywords":"","body":" Downgrade MongoDB 3.4 to 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade MongoDB 3.4 to 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/06-3.4-downgrade/01-3.4-downgrade-standalone.html":{"url":"17-release-notes/05-3.4/06-3.4-downgrade/01-3.4-downgrade-standalone.html","title":"Downgrade 3.4 Standalone to 3.2","keywords":"","body":" Downgrade 3.4 Standalone to 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.4 Standalone to 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/06-3.4-downgrade/02-3.4-downgrade-replica-set.html":{"url":"17-release-notes/05-3.4/06-3.4-downgrade/02-3.4-downgrade-replica-set.html","title":"Downgrade 3.4 Replica Set to 3.2","keywords":"","body":" Downgrade 3.4 Replica Set to 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.4 Replica Set to 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/05-3.4/06-3.4-downgrade/03-3.4-downgrade-sharded-cluster.html":{"url":"17-release-notes/05-3.4/06-3.4-downgrade/03-3.4-downgrade-sharded-cluster.html","title":"Downgrade 3.4 Sharded Cluster to 3.2","keywords":"","body":" Downgrade 3.4 Sharded Cluster to 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade 3.4 Sharded Cluster to 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2.html":{"url":"17-release-notes/06-3.2.html","title":"Release Notes for MongoDB 3.2","keywords":"","body":" Release Notes for MongoDB 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2/01-3.2-changelog.html":{"url":"17-release-notes/06-3.2/01-3.2-changelog.html","title":"3.2 Changelog","keywords":"","body":" 3.2 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 3.2 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2/02-3.2-compatibility.html":{"url":"17-release-notes/06-3.2/02-3.2-compatibility.html","title":"Compatibility Changes in MongoDB 3.2","keywords":"","body":" Compatibility Changes in MongoDB 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2/02-3.2-compatibility/01-3.2-javascript.html":{"url":"17-release-notes/06-3.2/02-3.2-compatibility/01-3.2-javascript.html","title":"JavaScript Changes in MongoDB 3.2","keywords":"","body":" JavaScript Changes in MongoDB 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - JavaScript Changes in MongoDB 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2/03-3.2-upgrade.html":{"url":"17-release-notes/06-3.2/03-3.2-upgrade.html","title":"Upgrade MongoDB to 3.2","keywords":"","body":" Upgrade MongoDB to 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade MongoDB to 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/06-3.2/04-3.2-downgrade.html":{"url":"17-release-notes/06-3.2/04-3.2-downgrade.html","title":"Downgrade MongoDB from 3.2","keywords":"","body":" Downgrade MongoDB from 3.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade MongoDB from 3.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0.html":{"url":"17-release-notes/07-3.0.html","title":"Release Notes for MongoDB 3.0","keywords":"","body":" Release Notes for MongoDB 3.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 3.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0/01-3.0-changelog.html":{"url":"17-release-notes/07-3.0/01-3.0-changelog.html","title":"3.0 Changelog","keywords":"","body":" 3.0 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 3.0 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0/02-3.0-compatibility.html":{"url":"17-release-notes/07-3.0/02-3.0-compatibility.html","title":"Compatibility Changes in MongoDB 3.0","keywords":"","body":" Compatibility Changes in MongoDB 3.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 3.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0/03-3.0-upgrade.html":{"url":"17-release-notes/07-3.0/03-3.0-upgrade.html","title":"Upgrade MongoDB to 3.0","keywords":"","body":" Upgrade MongoDB to 3.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade MongoDB to 3.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0/04-3.0-scram.html":{"url":"17-release-notes/07-3.0/04-3.0-scram.html","title":"Upgrade to SCRAM","keywords":"","body":" Upgrade to SCRAM ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade to SCRAM Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/07-3.0/05-3.0-downgrade.html":{"url":"17-release-notes/07-3.0/05-3.0-downgrade.html","title":"Downgrade MongoDB from 3.0","keywords":"","body":" Downgrade MongoDB from 3.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade MongoDB from 3.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6.html":{"url":"17-release-notes/08-2.6.html","title":"Release Notes for MongoDB 2.6","keywords":"","body":" Release Notes for MongoDB 2.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 2.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6/01-2.6-changelog.html":{"url":"17-release-notes/08-2.6/01-2.6-changelog.html","title":"2.6 Changelog","keywords":"","body":" 2.6 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 2.6 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6/02-2.6-compatibility.html":{"url":"17-release-notes/08-2.6/02-2.6-compatibility.html","title":"Compatibility Changes in MongoDB 2.6","keywords":"","body":" Compatibility Changes in MongoDB 2.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility Changes in MongoDB 2.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6/03-2.6-upgrade.html":{"url":"17-release-notes/08-2.6/03-2.6-upgrade.html","title":"Upgrade MongoDB to 2.6","keywords":"","body":" Upgrade MongoDB to 2.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade MongoDB to 2.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6/04-2.6-upgrade-authorization.html":{"url":"17-release-notes/08-2.6/04-2.6-upgrade-authorization.html","title":"Upgrade User Authorization Data to 2.6 Format","keywords":"","body":" Upgrade User Authorization Data to 2.6 Format ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade User Authorization Data to 2.6 Format Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/08-2.6/05-2.6-downgrade.html":{"url":"17-release-notes/08-2.6/05-2.6-downgrade.html","title":"Downgrade MongoDB from 2.6","keywords":"","body":" Downgrade MongoDB from 2.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Downgrade MongoDB from 2.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/09-2.4.html":{"url":"17-release-notes/09-2.4.html","title":"Release Notes for MongoDB 2.4","keywords":"","body":" Release Notes for MongoDB 2.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 2.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/09-2.4/01-2.4-changelog.html":{"url":"17-release-notes/09-2.4/01-2.4-changelog.html","title":"2.4 Changelog","keywords":"","body":" 2.4 Changelog ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - 2.4 Changelog Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/09-2.4/02-2.4-javascript.html":{"url":"17-release-notes/09-2.4/02-2.4-javascript.html","title":"JavaScript Changes in MongoDB 2.4","keywords":"","body":" JavaScript Changes in MongoDB 2.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - JavaScript Changes in MongoDB 2.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/09-2.4/03-2.4-upgrade.html":{"url":"17-release-notes/09-2.4/03-2.4-upgrade.html","title":"Upgrade MongoDB to 2.4","keywords":"","body":" Upgrade MongoDB to 2.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Upgrade MongoDB to 2.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/09-2.4/04-2.4-index-types.html":{"url":"17-release-notes/09-2.4/04-2.4-index-types.html","title":"Compatibility and Index Type Changes in MongoDB 2.4","keywords":"","body":" Compatibility and Index Type Changes in MongoDB 2.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Compatibility and Index Type Changes in MongoDB 2.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/10-2.2.html":{"url":"17-release-notes/10-2.2.html","title":"Release Notes for MongoDB 2.2","keywords":"","body":" Release Notes for MongoDB 2.2 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 2.2 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/11-2.0.html":{"url":"17-release-notes/11-2.0.html","title":"Release Notes for MongoDB 2.0","keywords":"","body":" Release Notes for MongoDB 2.0 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 2.0 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/12-1.8.html":{"url":"17-release-notes/12-1.8.html","title":"Release Notes for MongoDB 1.8","keywords":"","body":" Release Notes for MongoDB 1.8 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 1.8 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/13-1.6.html":{"url":"17-release-notes/13-1.6.html","title":"Release Notes for MongoDB 1.6","keywords":"","body":" Release Notes for MongoDB 1.6 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 1.6 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/14-1.4.html":{"url":"17-release-notes/14-1.4.html","title":"Release Notes for MongoDB 1.4","keywords":"","body":" Release Notes for MongoDB 1.4 ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 1.4 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/15-1.2.html":{"url":"17-release-notes/15-1.2.html","title":"Release Notes for MongoDB 1.2.x","keywords":"","body":" Release Notes for MongoDB 1.2.x ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Release Notes for MongoDB 1.2.x Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"17-release-notes/16-versioning.html":{"url":"17-release-notes/16-versioning.html","title":"MongoDB Versioning","keywords":"","body":" MongoDB Versioning ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - MongoDB Versioning Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"18-support.html":{"url":"18-support.html","title":"技术支持","keywords":"","body":" Technical Support ！本页翻译征集中！ 请点击页面上方 EDIT THIS PAGE 参与翻译。 详见： 贡献指南、 原文链接。 参见 原文 - Technical Support Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"20-mongodb-drivers/01-MongoDB-Scala-Driver.html":{"url":"20-mongodb-drivers/01-MongoDB-Scala-Driver.html","title":"MongoDB的Scala驱动","keywords":"","body":" MongoDB的Scala驱动 在本页面 概述 安装 连接到MongoDB Atlas 兼容性 概述 这是官方支持的MongoDB的Scala驱动程序。 它是一个具有异步和非阻塞IO的现代惯用Scala驱动程序。 参考文档 教程 API 文档 What's New 源代码 安装 在项目中开始使用驱动程序的推荐方法是使用依赖项管理系统，比如sbt或maven。有关更多信息，请参阅安装指南 。 连接到MongoDB Atlas 要连接到MongoDB Atlas 集群，请使用集群的Atlas连接字符串 : import org.mongodb.scala._ // ... val uri: String = \"mongodb+srv://:@/test?retryWrites=true&w=majority\" System.setProperty(\"org.mongodb.async.type\", \"netty\") val client: MongoClient = MongoClient(uri) val db: MongoDatabase = client.getDatabase(\"test\") 请参阅我们的连接指南，了解更多的连接方式。 兼容性 MongoDB的兼容性 Scala 驱动 MongoDB 4.4 MongoDB 4.2 MongoDB 4.0 MongoDB 3.6 MongoDB 3.4 MongoDB 3.2 MongoDB 3.0 MongoDB 2.6 4.1 ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2.9 ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2.8 ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2.7 ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2.6 ✓ ✓ ✓ ✓ ✓ ✓ 2.5 ✓ ✓ ✓ ✓ ✓ ✓ 2.4 ✓ ✓ ✓ ✓ ✓ ✓ 2.3 ✓ ✓ ✓ ✓ ✓ 2.2 ✓ ✓ ✓ ✓ ✓ 2.1 ✓ ✓ ✓ ✓ 2.0 ✓ ✓ ✓ ✓ 1.2 ✓ ✓ ✓ ✓ 1.1 ✓ ✓ ✓ 1.0 ✓ ✓ 驱动程序不支持旧版本的MongoDB。 语言的兼容性 Scala 驱动 Scala 2.13 Scala 2.12 Scala 2.11 2.9 ✓ ✓ ✓ 2.8 ✓ ✓ ✓ 2.7 ✓ ✓ ✓ 2.6 ✓ ✓ 2.5 ✓ ✓ 2.4 ✓ ✓ 2.3 ✓ ✓ 2.2 ✓ ✓ 2.1 ✓ ✓ 2.0 ✓ ✓ 1.1 ✓ ✓ 1.1 ✓ 1.0 ✓ 有关如何阅读兼容性表的更多信息，请参阅我们的MongoDB兼容性表指南。 如何获得帮助 在我们的MongoDB社区论坛上提问。 访问我们的支持渠道。 查看我们的SCALA JIRA项目来提出问题或请求特性。 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"contact.html":{"url":"contact.html","title":"联系我们","keywords":"","body":"上海锦木信息文档专栏上海锦木信息官网申请加入MongoDB 汉化小组 请点击 Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "},"more.html":{"url":"more.html","title":"更多资料","keywords":"","body":"doing [Mongo问题讨论区] [Mongo 驱动使用手册] Copyright © 上海锦木信息技术有限公司 all right reserved，powered by Gitbook文件修订时间： 2020-12-18 11:34:57 "}}